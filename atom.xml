<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>北极海的博客空间</title>
  
  <subtitle>You do things when the opportunities come along.</subtitle>
  <link href="https://lhhxs.github.io/atom.xml" rel="self"/>
  
  <link href="https://lhhxs.github.io/"/>
  <updated>2023-09-22T01:40:26.244Z</updated>
  <id>https://lhhxs.github.io/</id>
  
  <author>
    <name>Arcticsea</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>z-notes-模板</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/z-notes-%E6%A8%A1%E6%9D%BF/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/z-notes-%E6%A8%A1%E6%9D%BF/</id>
    <published>2023-09-22T01:38:09.765Z</published>
    <updated>2023-09-22T01:40:26.244Z</updated>
    
    <content type="html"><![CDATA[<h1 id="z-notes-模板"><a href="#z-notes-模板" class="headerlink" title="z-notes-模板"></a>z-notes-模板</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p><strong>欢迎来到云原生技术栈实战系列之基于 KubeSphere 玩转 K8s</strong></p></blockquote><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><blockquote><p><strong>导图</strong></p></blockquote><blockquote><p><strong>知识量</strong></p></blockquote><ul><li>阅读时长：xx 分</li><li>行：xx</li><li>单词：xx+</li><li>字符：xx+</li><li>图片：0 张</li></ul><blockquote><p><strong>知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>xxxx</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">storage-node-0</td><td align="center">192.168.9.95</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200+200</td><td align="center">ElasticSearch&#x2F;GlusterFS</td></tr><tr><td align="center">storage-node-0</td><td align="center">192.168.9.96</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200+200</td><td align="center">ElasticSearch&#x2F;GlusterFS</td></tr><tr><td align="center">storage-node-0</td><td align="center">192.168.9.97</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200+200</td><td align="center">ElasticSearch&#x2F;GlusterFS</td></tr><tr><td align="center">harbor</td><td align="center">192.168.9.89</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Harbor</td></tr><tr><td align="center">合计</td><td align="center">8</td><td align="center">22</td><td align="center">84</td><td align="center">320</td><td align="center">2800</td><td align="center"></td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>Ansible：<strong>2.8.20</strong></li><li>KubeSphere：<strong>3.3.0</strong></li><li>Kubernetes：<strong>v1.24.1</strong></li><li>Rook：<strong>v1.9.7</strong></li><li>Ceph： <strong>v16.2.9</strong></li><li>GlusterFS：<strong>9.5.1</strong></li><li>ElasticSearch：<strong>7.17.5</strong></li><li>Harbor：<strong>2.5.1</strong></li></ul><h2 id="2-理论正文"><a href="#2-理论正文" class="headerlink" title="2. 理论正文"></a>2. 理论正文</h2><h2 id="3-实战正文"><a href="#3-实战正文" class="headerlink" title="3. 实战正文"></a>3. 实战正文</h2><h2 id="4-常见问题"><a href="#4-常见问题" class="headerlink" title="4. 常见问题"></a>4. 常见问题</h2><h2 id="5-结束语"><a href="#5-结束语" class="headerlink" title="5. 结束语"></a>5. 结束语</h2><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p></blockquote><ul><li><strong>KubeSphere</strong></li><li><strong>Kubernetes</strong></li><li><strong>Ansible</strong></li><li><strong>自动化运维</strong></li><li><strong>CNCF 技术栈</strong></li></ul><p><strong>如果你喜欢本文，请分享给你的小伙伴！</strong></p><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li><li>知乎 <a href="https://www.zhihu.com/people/zdevops/">https://www.zhihu.com/people/zdevops/</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>Get 视频 B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D; <strong>运维</strong></li><li>微信：zdevops(公号输入框回复”w”即可)</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、DevOps、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;z-notes-模板&quot;&gt;&lt;a href=&quot;#z-notes-模板&quot; class=&quot;headerlink&quot; title=&quot;z-notes-模板&quot;&gt;&lt;/a&gt;z-notes-模板&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;大家好，我是老 Z！&lt;/strong&gt;&lt;/p&gt;
&lt;block</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>DevOps 系统</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/SpingCloud%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9D%97%E7%9A%84DevOps%E5%AE%9E%E6%88%98/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/SpingCloud%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9D%97%E7%9A%84DevOps%E5%AE%9E%E6%88%98/</id>
    <published>2023-09-22T01:38:09.680Z</published>
    <updated>2023-09-22T01:46:16.235Z</updated>
    
    <content type="html"><![CDATA[<h1 id="KubeSphere-DevOps-系统"><a href="#KubeSphere-DevOps-系统" class="headerlink" title="KubeSphere DevOps 系统"></a>KubeSphere DevOps 系统</h1><p>大家好，我是老Z。</p><p>本文接着上篇 <strong>&lt;&lt;基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署&gt;&gt;</strong> 继续打造我们Kubernetes生产环境。</p><h2 id="前提说明"><a href="#前提说明" class="headerlink" title="前提说明"></a>前提说明</h2><ol><li><p>基于 Jenkins 的 KubeSphere DevOps 系统是专为 Kubernetes 中的 CI&#x2F;CD 工作流设计的，它提供了一站式的解决方案，帮助开发和运维团队用非常简单的方式构建、测试和发布应用到 Kubernetes。它还具有插件管理、Binary-to-Image (B2I)、Source-to-Image (S2I)、代码依赖缓存、代码质量分析、流水线日志等功能。</p></li><li><p>KubeSphere DevOps 系统为用户提供了一个自动化的环境，应用可以自动发布到同一个平台。它还兼容第三方私有镜像仓库（如 Harbor）和代码库（如 GitLab&#x2F;GitHub&#x2F;SVN&#x2F;BitBucket）。它为用户提供了全面的、可视化的 CI&#x2F;CD 流水线，打造了极佳的用户体验，而且这种兼容性强的流水线能力在离线环境中非常有用，本文就是在离线环境实现了CI&#x2F;CD 流水线。</p></li><li><p>需要提前安装配置Harbor和GitLab(本文略过)。</p></li><li><p>DevOps流程架构图</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-flow.png"></p></li></ol><h2 id="KubeSphere开启DevOps系统"><a href="#KubeSphere开启DevOps系统" class="headerlink" title="KubeSphere开启DevOps系统"></a>KubeSphere开启DevOps系统</h2><h3 id="在部署Kubernetes之前"><a href="#在部署Kubernetes之前" class="headerlink" title="在部署Kubernetes之前"></a>在部署Kubernetes之前</h3><ol><li>编辑集群部署配置文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vim config-sample.yaml</span><br></pre></td></tr></table></figure><ol start="2"><li>在该文件中，搜索 <code>devops</code>，并将 <code>enabled</code> 的 <code>false </code>改为 <code>true</code>，完成后保存文件</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">devops:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span>     <span class="comment"># 将“false”更改为“true”</span></span><br><span class="line">  <span class="attr">jenkinsMemoryLim:</span> <span class="string">2Gi</span></span><br><span class="line">  <span class="attr">jenkinsMemoryReq:</span> <span class="string">1500Mi</span></span><br><span class="line">  <span class="attr">jenkinsVolumeSize:</span> <span class="string">8Gi</span></span><br><span class="line">  <span class="attr">jenkinsJavaOpts_Xms:</span> <span class="string">512m</span></span><br><span class="line">  <span class="attr">jenkinsJavaOpts_Xmx:</span> <span class="string">512m</span></span><br><span class="line">  <span class="attr">jenkinsJavaOpts_MaxRAM:</span> <span class="string">2g</span></span><br></pre></td></tr></table></figure><ol start="3"><li>使用集群部署配置文件创建集群</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# ./kk create cluster -f config-sample.yaml</span><br></pre></td></tr></table></figure><h3 id="在部署Kubernetes之后"><a href="#在部署Kubernetes之后" class="headerlink" title="在部署Kubernetes之后"></a>在部署Kubernetes之后</h3><ol><li><p>以 <code>admin</code> 用户KubeSphere登录控制台，点击左上角的<strong>平台管理</strong>，选择<strong>集群管理</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-28.jpg"></p></li><li><p>点击 <strong>自定义资源CRD</strong>，在搜索栏中输入 <code>clusterconfiguration</code>，点击搜索结果查看其详细页面</p><ul><li>自定义资源（CRD）允许用户在不新增 API 服务器的情况下创建一种新的资源类型，用户可以像使用其他 Kubernetes 原生对象一样使用这些定制资源。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-28.jpg"></p></li><li><p>在<strong>自定义资源</strong>中，点击 <code>ks-installer</code> ，选择<strong>编辑 YAML</strong>。<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-29.jpg"> </p><ul><li>在该 YAML 文件中，搜索 <code>devops</code>，将 <code>enabled</code> 的 <code>false</code> 改为 <code>true</code>。完成后，点击右下角的<strong>更新</strong>，保存配置，保存之后KubeSphere 会<strong>自动安装</strong>devops插件。</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">devops:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="comment"># 将“false”更改为“true”</span></span><br></pre></td></tr></table></figure><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-30.jpg"></p></li></ol><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><ul><li>在 kubectl 中执行以下命令检查安装过程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure><ul><li>检查Kubernetes集群devops命名空间的pod运行状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl get pod -n kubesphere-devops-system</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">ks-jenkins-677cdbc9d8-wxzxp   1/1     Running   0          19m</span><br><span class="line">s2ioperator-0                 1/1     Running   0          19m</span><br></pre></td></tr></table></figure><h2 id="使用DevOps系统"><a href="#使用DevOps系统" class="headerlink" title="使用DevOps系统"></a>使用DevOps系统</h2><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ol><li>创建企业空间</li></ol><ul><li><p>使用admin账户登录KubeSphere平台，点击工作台，进入企业空间<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-1.jpg"></p></li><li><p>创建名称为test的企业空间<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-0.jpg"></p></li><li><p>进入新建的test企业空间，点击企业空间设置，可以对企业空间进行一系列配置</p><ul><li><p>基本信息：修改企业空间的基本信息和删除企业空间</p></li><li><p>配额管理：对此企业空间进行资源配额</p></li><li><p>企业角色：新增自定义权限的企业角色</p></li><li><p>企业成员：新增和删除成员，修改成员权限</p></li><li><p>企业组织：对成员进行组织分类<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-2.jpg"></p></li></ul></li></ul><ol start="2"><li>为企业空间创建项目</li></ol><ul><li><p>点击项目管理，创建新项目（KubeSphere 中的项目对应的是 Kubernetes 的 namespace）<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-3.jpg"></p></li><li><p>查看创建好的项目，点击右方三个点可以对项目进行基本信息的修改和项目资源的配额等<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-4.jpg"></p></li><li><p>点击项目可以查看和配置此项目的一系列资源<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-5.jpg"></p></li></ul><ol start="3"><li>创建DevOps 工程与凭证</li></ol><ul><li><p>点击DevOps 工程进行新建名为test的DevOps 工程<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-6.jpg"></p></li><li><p>进入test DevOps 工程，点击凭证，创建以下凭证</p><table><thead><tr><th align="left">凭证 ID</th><th align="left">类型</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">dockerhub-id</td><td align="left">帐户凭证</td><td align="left">镜像仓库的拉取凭证</td></tr><tr><td align="left">github-id</td><td align="left">帐户凭证</td><td align="left">Git仓库的拉取凭证</td></tr><tr><td align="left">demo-kubeconfig</td><td align="left">kubeconfig</td><td align="left">Kubernetes的操作凭证</td></tr></tbody></table><ul><li><p>dockerhub-id<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-8.jpg"></p></li><li><p>github-id<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-9.jpg"></p></li><li><p>demo-kubeconfig</p><p>创建此凭证时，类型选择kubeconfig，Content会自动生成<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-10.jpg"></p></li></ul></li></ul><h3 id="配置DevOps流水线"><a href="#配置DevOps流水线" class="headerlink" title="配置DevOps流水线"></a>配置DevOps流水线</h3><h4 id="使用Jenkinsfile创建流水线"><a href="#使用Jenkinsfile创建流水线" class="headerlink" title="使用Jenkinsfile创建流水线"></a>使用Jenkinsfile创建流水线</h4><ul><li><p>点击流水线，新建名为devops的流水线<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-11.jpg"></p></li><li><p>点击下一步，进行流水线的基础配置，完成创建<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-12.jpg"></p></li></ul><ol start="2"><li>配置Jenkinsfile</li></ol><ul><li><p>点击流水线，点击编辑Jenkinsfile<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-13.jpg"></p></li><li><p>因前后端编译方式的差异，这里将分别举例前后端Jenkinsfile配置</p><ul><li>前端</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent &#123;</span><br><span class="line">    node &#123;</span><br><span class="line">      label &#x27;nodejs&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  parameters &#123;</span><br><span class="line">    // 这里定义的参数关键字、默认值、注释都会在运行流水线时显示出来</span><br><span class="line">    string(name:&#x27;APP_BRANCH&#x27;, defaultValue: &#x27;test&#x27;, description: &#x27;构建应用的代码分支或tag名称&#x27;)</span><br><span class="line">    string(name:&#x27;IMAGE_TAG&#x27;, defaultValue: &#x27;0.1.1&#x27;, description: &#x27;构建应用的镜像tag名称&#x27;)</span><br><span class="line">    string(name:&#x27;REPLICA&#x27;, defaultValue:  &#x27;1&#x27;, description: &#x27;构建应用的副本数量&#x27;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  environment &#123;</span><br><span class="line">    // Harbor 仓库的地址</span><br><span class="line">    DOCKERHUB_REGISTRY = &#x27;mydockerhub.com&#x27;</span><br><span class="line"></span><br><span class="line">    // K8s上创建的Harbor仓库凭证ID</span><br><span class="line">    DOCKERHUB_CREDENTIAL_ID = &#x27;dockerhub-id&#x27;</span><br><span class="line"></span><br><span class="line">    // Harbor 项目仓库命名空间</span><br><span class="line">    DOCKERHUB_NAMESPACE = &#x27;test&#x27;</span><br><span class="line">    DOCKERHUB_REPOSITORY = &quot;$DOCKERHUB_REGISTRY/$DOCKERHUB_NAMESPACE&quot;</span><br><span class="line"></span><br><span class="line">    // GitLab 仓库的地址</span><br><span class="line">    GITLAB = &#x27;mygitlab.com&#x27;</span><br><span class="line"></span><br><span class="line">    // K8s上创建的GitLab仓库凭证ID</span><br><span class="line">    GITLAB_CREDENTIAL_ID = &#x27;github-id&#x27;</span><br><span class="line"></span><br><span class="line">    // GitLab 项目仓库命名空间</span><br><span class="line">    GITLAB_NAMESPACE = &#x27;test&#x27;</span><br><span class="line"></span><br><span class="line">    // 构建应用的项目名称</span><br><span class="line">    APP_NAME = &#x27;test-web&#x27;</span><br><span class="line"></span><br><span class="line">    // 构建应用的devops项目名称</span><br><span class="line">    APP_DEVOPS_NAME = &quot;$APP_NAME-devops&quot;</span><br><span class="line"></span><br><span class="line">    // 构建的临时目录</span><br><span class="line">    BUILD_TMP = &#x27;/tmp&#x27;</span><br><span class="line"></span><br><span class="line">    // K8s上创建的kubeconfig凭证ID</span><br><span class="line">    KUBECONFIG_CREDENTIAL_ID = &#x27;demo-kubeconfig&#x27;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stages &#123;</span><br><span class="line">  // 拉取GitLab 代码</span><br><span class="line">   stage(&#x27;checkout scm&#x27;) &#123;</span><br><span class="line">      steps&#123;</span><br><span class="line">        container (&#x27;nodejs&#x27;) &#123;</span><br><span class="line">          withCredentials([usernamePassword(credentialsId : &quot;$GITLAB_CREDENTIAL_ID&quot; ,passwordVariable : &#x27;GITLAB_PASSWORD&#x27; ,usernameVariable : &#x27;GITLAB_USERNAME&#x27; ,)]) &#123;</span><br><span class="line">            sh &#x27;cd $BUILD_TMP &amp;&amp; git clone -b $APP_BRANCH https://$GITLAB_USERNAME:$GITLAB_PASSWORD@$GITLAB/$GITLAB_NAMESPACE/$APP_NAME.git&#x27;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   // npm 编译</span><br><span class="line">    stage(&#x27;node build&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        container (&#x27;nodejs&#x27;) &#123;</span><br><span class="line">          sh &#x27;cd $BUILD_TMP/$APP_NAME &amp;&amp; npm install &amp;&amp; npm run build&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 登录镜像仓库 根据GitLab中的Dockerfile将代码打成镜像 并推送到镜像仓库</span><br><span class="line">    stage(&#x27;docker build &amp;&amp; push&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        container (&#x27;nodejs&#x27;) &#123;</span><br><span class="line">          withCredentials([usernamePassword(credentialsId : &quot;$DOCKERHUB_CREDENTIAL_ID&quot; ,passwordVariable : &#x27;DOCKERHUB_PASSWORD&#x27; ,usernameVariable : &#x27;DOCKERHUB_USERNAME&#x27; ,)]) &#123;</span><br><span class="line">            sh &#x27;echo &quot;$DOCKERHUB_PASSWORD&quot; | docker login $DOCKERHUB_REGISTRY -u &quot;$DOCKERHUB_USERNAME&quot; --password-stdin&#x27;</span><br><span class="line">            sh &#x27;cd $BUILD_TMP/$APP_NAME &amp;&amp; docker build --no-cache -t $DOCKERHUB_REGISTRY/$DOCKERHUB_NAMESPACE/$APP_NAME:$IMAGE_TAG .&#x27;</span><br><span class="line">            sh &#x27;docker push $DOCKERHUB_REGISTRY/$DOCKERHUB_NAMESPACE/$APP_NAME:$IMAGE_TAG&#x27;</span><br><span class="line">         &#125; </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 拉取部署模块的yaml模板文件的GitLab代码</span><br><span class="line">    stage(&#x27;checkout deploy scm&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        withCredentials([usernamePassword(credentialsId : &quot;$GITLAB_CREDENTIAL_ID&quot; ,passwordVariable : &#x27;GITLAB_PASSWORD&#x27; ,usernameVariable : &#x27;GITLAB_USERNAME&#x27; ,)]) &#123;</span><br><span class="line">          sh &#x27;git clone https://$GITLAB_USERNAME:$GITLAB_PASSWORD@$GITLAB/$GITLAB_NAMESPACE/$APP_DEVOPS_NAME.git&#x27;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 修改yaml模块文件的默认配置(镜像tag、副本数量)</span><br><span class="line">    stage(&#x27;deploy to k8s&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        sh &#x27;sed -i &quot;s/0.0.1/$IMAGE_TAG/g&quot; $APP_DEVOPS_NAME/deploy/*.yaml&#x27;</span><br><span class="line">        sh &#x27;sed -i &quot;s/REPLICA/$REPLICA/g&quot; $APP_DEVOPS_NAME/deploy/*.yaml&#x27;</span><br><span class="line">        kubernetesDeploy(configs: &quot;$APP_DEVOPS_NAME/deploy/test-web.yaml&quot;, enableConfigSubstitution: true, kubeconfigId: &quot;$KUBECONFIG_CREDENTIAL_ID&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>后端</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent &#123;</span><br><span class="line">    node &#123;</span><br><span class="line">      label &#x27;maven&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  parameters &#123;</span><br><span class="line">    // 这里定义的参数关键字、默认值、注释都会在运行流水线时显示出来</span><br><span class="line">    string(name:&#x27;APP_BRANCH&#x27;, defaultValue: &#x27;test&#x27;, description: &#x27;构建应用的代码分支或tag名称&#x27;)</span><br><span class="line">    string(name:&#x27;IMAGE_TAG&#x27;, defaultValue: &#x27;0.1.1&#x27;, description: &#x27;构建应用的镜像tag名称&#x27;)</span><br><span class="line">    string(name:&#x27;REPLICA&#x27;, defaultValue:  &#x27;1&#x27;, description: &#x27;构建应用的副本数量&#x27;)</span><br><span class="line">    string(name:&#x27;ENVIRONMENT&#x27;, defaultValue: &#x27;test&#x27;, description: &#x27;读取nacos的分组&#x27;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  environment &#123;</span><br><span class="line">    // Harbor 仓库的地址</span><br><span class="line">    DOCKERHUB_REGISTRY = &#x27;mydockerhub.com&#x27;</span><br><span class="line"></span><br><span class="line">    // K8s上创建的Harbor仓库凭证ID</span><br><span class="line">    DOCKERHUB_CREDENTIAL_ID = &#x27;dockerhub-id&#x27;</span><br><span class="line"></span><br><span class="line">    // Harbor 项目仓库命名空间</span><br><span class="line">    DOCKERHUB_NAMESPACE = &#x27;test&#x27;</span><br><span class="line">    DOCKERHUB_REPOSITORY = &quot;$DOCKERHUB_REGISTRY/$DOCKERHUB_NAMESPACE&quot;</span><br><span class="line"></span><br><span class="line">    // GitLab 仓库的地址</span><br><span class="line">    GITLAB = &#x27;mygitlab.com&#x27;</span><br><span class="line"></span><br><span class="line">    // K8s上创建的GitLab仓库凭证ID</span><br><span class="line">    GITLAB_CREDENTIAL_ID = &#x27;github-id&#x27;</span><br><span class="line"></span><br><span class="line">    // GitLab 项目仓库命名空间</span><br><span class="line">    GITLAB_NAMESPACE = &#x27;test&#x27;</span><br><span class="line"></span><br><span class="line">    // 构建应用的项目名称</span><br><span class="line">    APP_NAME = &#x27;test-service&#x27;</span><br><span class="line"></span><br><span class="line">    // 构建应用的devops项目名称</span><br><span class="line">    APP_DEVOPS_NAME = &quot;$APP_NAME-devops&quot;</span><br><span class="line"></span><br><span class="line">    // 构建的临时目录</span><br><span class="line">    BUILD_TMP = &#x27;/tmp&#x27;</span><br><span class="line"></span><br><span class="line">    // K8s上创建的kubeconfig凭证ID</span><br><span class="line">    KUBECONFIG_CREDENTIAL_ID = &#x27;demo-kubeconfig&#x27;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stages &#123;</span><br><span class="line">    // 拉取GitLab 代码</span><br><span class="line">    stage(&#x27;checkout scm&#x27;) &#123;</span><br><span class="line">      steps&#123;</span><br><span class="line">        container (&#x27;maven&#x27;) &#123;</span><br><span class="line">          withCredentials([usernamePassword(credentialsId : &quot;$GITLAB_CREDENTIAL_ID&quot; ,passwordVariable : &#x27;GITLAB_PASSWORD&#x27; ,usernameVariable : &#x27;GITLAB_USERNAME&#x27; ,)]) &#123;</span><br><span class="line">            sh &#x27;cd $BUILD_TMP &amp;&amp; git clone -b $APP_BRANCH https://$GITLAB_USERNAME:$GITLAB_PASSWORD@$GITLAB/$GITLAB_NAMESPACE/$APP_NAME.git&#x27;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // maven 编译</span><br><span class="line">    stage(&#x27;maven build&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        container (&#x27;maven&#x27;) &#123;</span><br><span class="line">          sh &#x27;cd $BUILD_TMP/$APP_NAME &amp;&amp; mvn clean package -Dmaven.test.skip=true&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 登录镜像仓库 根据GitLab中的Dockerfile将代码打成镜像 并推送到镜像仓库</span><br><span class="line">    stage(&#x27;docker build &amp;&amp; push&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        container (&#x27;maven&#x27;) &#123;</span><br><span class="line">          withCredentials([usernamePassword(credentialsId : &quot;$DOCKERHUB_CREDENTIAL_ID&quot; ,passwordVariable : &#x27;DOCKERHUB_PASSWORD&#x27; ,usernameVariable : &#x27;DOCKERHUB_USERNAME&#x27; ,)]) &#123;</span><br><span class="line">           sh &#x27;cd $BUILD_TMP/$APP_NAME &amp;&amp; mvn -f test-service dockerfile:build dockerfile:push -Ddocker.repository=$DOCKERHUB_REPOSITORY -Ddockerfile.username=$DOCKERHUB_USERNAME -Ddockerfile.password=$DOCKERHUB_PASSWORD&#x27;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 拉取部署模块的yaml模板文件的GitLab代码</span><br><span class="line">    stage(&#x27;checkout deploy scm&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        withCredentials([usernamePassword(credentialsId : &quot;$GITLAB_CREDENTIAL_ID&quot; ,passwordVariable : &#x27;GITLAB_PASSWORD&#x27; ,usernameVariable : &#x27;GITLAB_USERNAME&#x27; ,)]) &#123;</span><br><span class="line">          sh &#x27;git clone -b test https://$GITLAB_USERNAME:$GITLAB_PASSWORD@$GITLAB/$GITLAB_NAMESPACE/$APP_DEVOPS_NAME.git&#x27;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // 修改yaml模块文件的默认配置(镜像tag、副本数量、nacos命名空间)</span><br><span class="line">    stage(&#x27;deploy to dev&#x27;) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">        sh &#x27;sed -i &quot;s/0.0.1/$IMAGE_TAG/g&quot; $APP_DEVOPS_NAME/deploy/*.yaml&#x27;</span><br><span class="line">        sh &#x27;sed -i &quot;s/REPLICA/$REPLICA/g&quot; $APP_DEVOPS_NAME/deploy/*.yaml&#x27;</span><br><span class="line">        sh &#x27;sed -i &quot;s/DEFAULT_GROUP/$ENVIRONMENT/g&quot; $APP_DEVOPS_NAME/deploy/*.yaml&#x27;</span><br><span class="line">        kubernetesDeploy(configs: &quot;$APP_DEVOPS_NAME/deploy/test-service&quot;, enableConfigSubstitution: true, kubeconfigId: &quot;$KUBECONFIG_CREDENTIAL_ID&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li>验证</li></ol><ul><li>创建完毕后，点击运行即可看到我们在Jenkinsfile中定义的参数<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-14.jpg"></li></ul><h4 id="创建镜像仓库拉取凭证"><a href="#创建镜像仓库拉取凭证" class="headerlink" title="创建镜像仓库拉取凭证"></a>创建镜像仓库拉取凭证</h4><p><strong>在KubeSphere平台创建镜像仓库的拉取凭证harbor-secret，用于创建模块时自动拉取镜像</strong></p><ul><li><p>创建名为harbor-secret的secret凭证，进入平台管理，点击配置中心，选择密钥，创建凭证<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-18.jpg"></p></li><li><p>类型选择kubernetes.io&#x2F;dockerconfigjson (镜像仓库密钥)，并配置密钥信息，点击验证进行测试，验证通过即可保存<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-19.jpg"></p></li></ul><h4 id="配置部署模块的yaml文件"><a href="#配置部署模块的yaml文件" class="headerlink" title="配置部署模块的yaml文件"></a>配置部署模块的yaml文件</h4><p><strong>在Git仓库中创建存储部署模块的yaml模板文件</strong></p><ul><li><p>前端</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-web</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="string">REPLICA</span>                                    <span class="comment">#定义副本数量，在devops部署时会根据填写的变量进行替换</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">test-web</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">test-web</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-web</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;mydockerhub.com/test/test-web:0.0.1&#x27;</span>        <span class="comment">#定义镜像名称，镜像版本号会根据devops部署时填写的变量进行替换</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http-80</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span>                    <span class="comment">#定义前端程序内部nginx启动的端口</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">resources:</span>                            <span class="comment">#资源配额</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4Gi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">50m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-conf</span>                    <span class="comment">#挂载nginx转发配置文件</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/nginx/conf.d/</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-conf</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">nginx-conf</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">default.conf</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">default.conf</span></span><br><span class="line">            <span class="attr">defaultMode:</span> <span class="number">420</span></span><br><span class="line">      <span class="attr">imagePullSecrets:</span>                            <span class="comment">#镜像拉取凭证</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">harbor-secret</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-web-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-web-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http-service</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-web</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br></pre></td></tr></table></figure></li><li><p>后端</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="string">REPLICA</span>                                        <span class="comment">#定义副本数量，在devops部署时会根据填写的变量进行替换</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">test-service</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">test-service</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-log</span>                                <span class="comment">#定义程序的日志持久化pvc</span></span><br><span class="line">          <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">            <span class="attr">claimName:</span> <span class="string">test-service-log</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-service</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;mydockerhub.com/test/test-service:0.0.1&#x27;</span>        <span class="comment">#定义镜像名称，镜像版本号会根据devops部署时填写的变量进行替换</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http-server</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">9000</span>                <span class="comment">#程序端口</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">env:</span>                                            <span class="comment">##下列环境变量均为示例，实际情况按照程序的具体配置配置</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">APP_PORT</span>                            <span class="comment">#后端程序的端口</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;9000&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">APP_DEPLOY</span>                            <span class="comment">#定义连接nacos的哪个命名空间，会根据devops部署时填写的变量进行替换</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;DEFAULT_GROUP&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_SERVER_IP</span>                        <span class="comment">#定义nacos的链接地址</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;nacos-server.test.svc.cluster.local&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_SERVER_PORT</span>                    <span class="comment">#定义nacos的连接端口</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;8848&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SW_AGENT_NAMESPACE</span>                    <span class="comment">#skywalking的agent的命名空间</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">test</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SW_AGENT_NAME</span>                        <span class="comment">#skywalking的agent的名称</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">test-service</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SW_AGENT_COLLECTOR_BACKEND_SERVICES</span>                            <span class="comment">#定义skywalking的连接地址</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">test-skywalk-skywalking-oap.test.svc.cluster.local:11800</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SW_GRPC_LOG_SERVER_HOST</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">test-skywalk-skywalking-oap.test.svc.cluster.local</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SW_GRPC_LOG_SERVER_PORT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;11800&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JAVA_OPTS</span>                                                    <span class="comment">#skywalking的agent的路径</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;-javaagent:/opt/agent/skywalking-agent.jar&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">APP_LOG_PATH</span>                                                <span class="comment">#定义程序的日志路径</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">/app/logs/test-service/</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">APP_LOG_NAME</span>                                                <span class="comment">#定义日志的名称</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&#x27;test-service-$&#123;POD_IP&#125;.log&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">APP_LOG_CONFIG</span>                                                <span class="comment">#定义nacos中的log配置文件url</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">http://$&#123;spring.cloud.nacos.discovery.server-addr&#125;/nacos/v1/cs/configs?group=$&#123;spring.application.deploy&#125;&amp;tenant=$&#123;spring.cloud.nacos.discovery.namespace&#125;&amp;dataId=logback-spring.xml</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_IP</span>                                                        <span class="comment">#此环境变量用于获取pod的ip地址</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">status.podIP</span></span><br><span class="line">          <span class="attr">resources:</span>                                            <span class="comment">#资源配额</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4Gi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;50m&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">512Mi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span>                                            <span class="comment">#定义程序日志持久化pvc的挂载路径</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-log</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/app/logs/test-service</span>    </span><br><span class="line">          <span class="attr">livenessProbe:</span>                                        <span class="comment">#存活探针配置</span></span><br><span class="line">            <span class="attr">tcpSocket:</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">9000</span>                                        <span class="comment">#定义活性探针的检测端口</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">60</span>                                <span class="comment">#定义初始化等待时间</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">1</span>                                    <span class="comment">#定义检测超时时间</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">20</span>                                    <span class="comment">#定义检测周期时间</span></span><br><span class="line">            <span class="attr">successThreshold:</span> <span class="number">1</span>                                    <span class="comment">#定义成功次数</span></span><br><span class="line">            <span class="attr">failureThreshold:</span> <span class="number">3</span>                                    <span class="comment">#定义失败次数</span></span><br><span class="line">          <span class="attr">readinessProbe:</span>                                        <span class="comment">#就绪探针配置</span></span><br><span class="line">            <span class="attr">tcpSocket:</span></span><br><span class="line">              <span class="attr">port:</span> <span class="number">9000</span></span><br><span class="line">            <span class="attr">initialDelaySeconds:</span> <span class="number">60</span></span><br><span class="line">            <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">periodSeconds:</span> <span class="number">20</span></span><br><span class="line">            <span class="attr">successThreshold:</span> <span class="number">1</span></span><br><span class="line">            <span class="attr">failureThreshold:</span> <span class="number">3</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span>            <span class="comment">#镜像拉取策略</span></span><br><span class="line">      <span class="attr">imagePullSecrets:</span>                        <span class="comment">#镜像拉取凭证</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">harbor-secret</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="创建前端模块nginx转发配置文件"><a href="#创建前端模块nginx转发配置文件" class="headerlink" title="创建前端模块nginx转发配置文件"></a>创建前端模块nginx转发配置文件</h4><ol><li><p>进入平台管理，点击配置中心，选择配置，创建nginx-conf<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-20.jpg"></p></li><li><p>添加数据，键填写nginx配置文件名称default.conf，值填写配置文件内容<img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-21.jpg"></p><ul><li>配置文件示例</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/default.access.log  main;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page 404 403 500 502 503 504    /40x.html;</span><br><span class="line">    location = /40x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ^~ /test2/ &#123;                            #前端转发示例</span><br><span class="line">        proxy_pass http://test2-web-service.test.svc.cluster.local;</span><br><span class="line">        proxy_redirect off;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header REMOTE-HOST $remote_addr;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location ^~ /test/api/ &#123;                    #后端转发示例</span><br><span class="line">        proxy_pass http://test-service.test.svc.cluster.local:9000/test/api/;</span><br><span class="line">        proxy_redirect off;</span><br><span class="line">        proxy_set_header REMOTE-HOST $remote_addr;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>将前端模块的service模式修改为nodeport类型，以方便集群外部的nginx代理转发</p><ul><li>进入test项目，点击应该负载下的服务，找到相应前端模块服务，点击右侧三个点，选择编辑外网访问，配置访问方式为NodePort，将生成的端口配置到集群外部的nginx代理配置文件中即可</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-25.jpg"></p></li></ol><h4 id="运行流水线"><a href="#运行流水线" class="headerlink" title="运行流水线"></a>运行流水线</h4><ul><li><p>进入企业空间，找到已创建好的流水线，点击运行，填入相应参数，点击确定。</p><ul><li>APP_BRANCH：构建应用的代码分支或tag名称</li><li>IMAGE_TAG：构建应用的镜像tag名称</li><li>REPLICA：构建应用的副本数量</li><li>ENVIRONMENT：读取nacos配置的分组</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-22.jpg"></p></li><li><p>进入活动，点击刚才运行的流水线，可查看流水线详细流程</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-23.jpg"></p></li><li><p>点击查看日志，可查看流水线的详细日志</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-24.jpg"></p></li></ul><h4 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h4><ul><li><p>进入test企业空间，点击项目管理，进入test项目查看相应的工作负载运行情况</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/devops-26.jpg"></p></li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol><li><p><a href="https://kubesphere.io/zh/docs/devops-user-guide/understand-and-manage-devops-projects/overview/">KubeSphere DevOps</a></p></li><li><p><a href="https://github.com/kubesphere/devops-maven-sample">https://github.com/kubesphere/devops-maven-sample</a></p></li></ol><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><ol><li>基于KubeSphere的Kubernetes生产实践之路-SpingCloud业务模块的日志收集实战(暂定)</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;KubeSphere-DevOps-系统&quot;&gt;&lt;a href=&quot;#KubeSphere-DevOps-系统&quot; class=&quot;headerlink&quot; title=&quot;KubeSphere DevOps 系统&quot;&gt;&lt;/a&gt;KubeSphere DevOps 系统&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>SpingCloud架构中间件的安装部署</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/SpingCloud%E6%9E%B6%E6%9E%84%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/SpingCloud%E6%9E%B6%E6%9E%84%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</id>
    <published>2023-09-22T01:38:09.649Z</published>
    <updated>2023-09-22T01:46:01.238Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署"><a href="#基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署" class="headerlink" title="基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署"></a>基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署</h1><p>大家好，我是老Z</p><p>本文接着上篇 <strong>&lt;&lt;基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS&gt;&gt;</strong> 继续打造我们Kubernetes生产环境。</p><h2 id="前提说明"><a href="#前提说明" class="headerlink" title="前提说明"></a>前提说明</h2><ol><li><p>业务程序使用SpringCloud框架开发</p></li><li><p>如果采用离线部署的方式，所有相关镜像需要提前push到镜像仓库，本文略过</p></li><li><p>部署架构图</p><img title src="https://gitee.com/zdevops/res/raw/main/cloudnative/middleware.png"></li><li><p>整体部署架构涉及的中间件包含以下组件</p><ul><li><p>nacos</p></li><li><p>RocketMQ</p></li><li><p>Redis</p></li><li><p>xxl-job</p></li><li><p>skywalking</p></li><li><p>MySQL</p></li><li><p>Nginx</p></li></ul></li><li><p>部署架构说明</p><ul><li><p>k8s集群之外采用了nginx作为网关代理，将外部流量引入k8s集群</p></li><li><p>k8s集群对外暴露服务使用了nodeport的方式，暂时没有引入Ingress(因为不会，后期学会了再引入)</p></li><li><p>其他的中间件都是部署在k8s集群之内</p></li><li><p>本文并没有写日志配置的相关内容，后续会有专门的文档介绍</p></li><li><p>本文没有介绍业务模块的配置内容，相关内容会在<strong>业务模块自动化发布</strong>文档中专门介绍</p></li></ul></li></ol><h2 id="网关代理安装配置"><a href="#网关代理安装配置" class="headerlink" title="网关代理安装配置"></a>网关代理安装配置</h2><h3 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h3><ul><li><p>操作系统 CentOS7.9</p></li><li><p>Nginx 1.20.2的rpm包</p></li></ul><h3 id="部署步骤"><a href="#部署步骤" class="headerlink" title="部署步骤"></a>部署步骤</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载rpm离线包，这里选择官方的最新稳定版1.20.2</span></span><br><span class="line">[root@nginx-0 ~]# wget http:/nginx.org/packages/centos/7/x86_64/RPMS/nginx-1.20.2-1.el7.ngx.x86_64.rpm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装</span></span><br><span class="line">[root@nginx-0 ~]# rpm -ivh nginx-1.20.2-1.el7.ngx.x86_64.rpm</span><br><span class="line">warning: nginx-1.20.2-1.el7.ngx.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID 7bd9bf62: NOKEY</span><br><span class="line">Preparing...                          ################################# [100%]</span><br><span class="line">Updating / installing...</span><br><span class="line">   1:nginx-1:1.20.2-1.el7.ngx         ################################# [100%]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看已安装的nginx</span></span><br><span class="line">[root@nginx-0 ~]# rpm -qa | grep nginx</span><br><span class="line">nginx-1.20.2-1.el7.ngx.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据需要修改/etc/nginx/nginx.conf（主要用于自定义nginx服务器的各种配置等）</span></span><br><span class="line">[root@nginx-0 ~]# vi /etc/nginx/nginx.conf</span><br><span class="line">示例配置见配置文件参考</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据需要修改/etc/nginx/conf.d/***.conf（主要用于自定义nginx的各种转发规则等）</span></span><br><span class="line">[root@nginx-0 ~]# vi /etc/nginx/conf.d/***.conf</span><br><span class="line">示例配置见配置文件参考</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检测nginx配置文件</span></span><br><span class="line">[root@nginx-0 ~]# nginx -t</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动nginx，并配置开机自启</span></span><br><span class="line">[root@nginx-0 ~]# systemctl start nginx &amp;&amp; systemctl enable nginx</span><br></pre></td></tr></table></figure><h3 id="配置文件参考"><a href="#配置文件参考" class="headerlink" title="配置文件参考"></a>配置文件参考</h3><ol><li><p>nginx.conf (&#x2F;etc&#x2F;nginx&#x2F;nginx.conf)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">user</span> <span class="string">nginx;</span></span><br><span class="line"><span class="string">worker_processes</span> <span class="string">auto;</span></span><br><span class="line"><span class="string">error_log</span> <span class="string">/var/log/nginx/error.log;</span></span><br><span class="line"><span class="string">pid</span> <span class="string">/run/nginx.pid;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span></span><br><span class="line"><span class="string">include</span> <span class="string">/usr/share/nginx/modules/*.conf;</span></span><br><span class="line"></span><br><span class="line"><span class="string">events</span> &#123;</span><br><span class="line">    <span class="string">worker_connections</span> <span class="number">10240</span><span class="string">;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">http</span> &#123;</span><br><span class="line">    <span class="string">server_tokens</span> <span class="string">off;</span>                                                <span class="comment">#隐藏版本号</span></span><br><span class="line">    <span class="string">client_header_timeout</span> <span class="number">60</span><span class="string">;</span>                                        <span class="comment">#客户端向服务端发送一个完整的 request header 的超时时间。如果客户端在指定时间内没有发送一个完整的 request header，Nginx 返回 HTTP 408(“Request timed out”)</span></span><br><span class="line">    <span class="string">client_body_timeout</span> <span class="number">60</span><span class="string">;</span>                                            <span class="comment">#该指令设置请求正文即请求体（request body）的读超时时间。超时仅设置为两个连续读取操作之间的时间段，而不是整个请求主体的传输。如果客户端在此时间内未传输任何内容，请求将以408（请求超时）错误终止</span></span><br><span class="line">    <span class="string">limit_conn_zone</span> <span class="string">$binary_remote_addr</span> <span class="string">zone=one:10m;</span>                <span class="comment">#限制可以存储多少个并发连接数（1m 可以储存 32000 个并发会话）</span></span><br><span class="line">    <span class="string">limit_conn</span> <span class="string">one</span> <span class="number">50</span><span class="string">;</span>                                                <span class="comment">#限制每个IP只能发起50个并发连接</span></span><br><span class="line">    <span class="string">limit_rate</span> <span class="string">2000k;</span>                                                <span class="comment">#控制下载速度</span></span><br><span class="line">    <span class="string">send_timeout</span> <span class="number">10</span><span class="string">;</span>                                                <span class="comment">#服务端向客户端传输数据的超时时间，单位（s）</span></span><br><span class="line">    <span class="string">keepalive_timeout</span>   <span class="number">65</span><span class="string">;</span>                                            <span class="comment">#每个TCP连接的超时时间</span></span><br><span class="line">    <span class="string">log_format</span>  <span class="string">main</span>  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">log_format</span>  <span class="string">debug</span>  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;debug-cors&quot; $cors_origin &quot;debug-origin&quot; $http_origin &#x27;</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">access_log</span>  <span class="string">/var/log/nginx/access.log</span>  <span class="string">main;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">sendfile</span>            <span class="string">on;</span>                                            <span class="comment">#sendfile是个比 read 和 write 更高性能的系统接口， 不过需要注意的是，sendfile 是将 in_fd 的内容发送到 out_fd 。而 in_fd 不能是 socket ， 也就是只能文件句柄。 所以当 Nginx 是一个静态文件服务器的时候，开启 SENDFILE 配置项能大大提高 Nginx 的性能.</span></span><br><span class="line">    <span class="string">tcp_nopush</span>          <span class="string">on;</span>                                            <span class="comment">#可以配置一次发送数据包的大小。也就是说，数据包累积到一定大小后就发送，tcp_nopush必须和sendfile配合使用.</span></span><br><span class="line">    <span class="string">tcp_nodelay</span>         <span class="string">on;</span>                                            <span class="comment">#会增加小包的数量，但是可以提高响应速度。在及时性高的通信场景中应该会有不错的效果</span></span><br><span class="line">    <span class="string">types_hash_max_size</span> <span class="number">4096</span><span class="string">;</span>                                        <span class="comment">#nginx使用了一个散列表来保存MIME type与文件扩展名之间的映射，该参数就是指定该散列表桶的大小的</span></span><br><span class="line"></span><br><span class="line">    <span class="string">include</span>             <span class="string">/etc/nginx/mime.types;</span></span><br><span class="line">    <span class="string">default_type</span>        <span class="string">application/octet-stream;</span></span><br><span class="line">    <span class="string">error_page</span>  <span class="number">400</span> <span class="number">404</span> <span class="number">413</span> <span class="number">502</span> <span class="number">504</span>  <span class="string">/index.html;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启gzip压缩</span></span><br><span class="line">    <span class="string">gzip</span>  <span class="string">on;</span></span><br><span class="line">    <span class="comment">#不压缩临界值，大于1K的才压缩</span></span><br><span class="line">    <span class="string">gzip_min_length</span> <span class="string">1k;</span></span><br><span class="line">    <span class="comment">#buffer</span></span><br><span class="line">    <span class="string">gzip_buffers</span> <span class="number">4</span> <span class="string">16k;</span></span><br><span class="line">    <span class="comment">#用了反向代理的话，末端通信是HTTP/1.0,默认是HTTP/1.1</span></span><br><span class="line">    <span class="comment">#gzip_http_version 1.0;</span></span><br><span class="line">    <span class="comment">#压缩级别，1-10，数字越大压缩的越好，时间也越长</span></span><br><span class="line">    <span class="string">gzip_comp_level</span> <span class="number">2</span><span class="string">;</span></span><br><span class="line">    <span class="comment">#进行压缩的文件类型，缺啥补啥</span></span><br><span class="line">    <span class="string">gzip_types</span> <span class="string">text/plain</span> <span class="string">application/javascript</span> <span class="string">application/x-javascript</span> <span class="string">text/css</span> <span class="string">application/xml</span> <span class="string">text/javascriptapplication/x-httpd-php</span> <span class="string">image/jpeg</span> <span class="string">image/gif</span> <span class="string">image/png;</span></span><br><span class="line">    <span class="comment">#跟Squid等缓存服务有关，on的话会在Header里增加&quot;Vary: Accept-Encoding&quot;</span></span><br><span class="line">    <span class="string">gzip_vary</span> <span class="string">off;</span></span><br><span class="line">    <span class="comment">#IE6对Gzip不友好，不进行Gzip压缩</span></span><br><span class="line">    <span class="string">gzip_disable</span> <span class="string">&quot;MSIE [1-6]\.&quot;</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">client_max_body_size</span> <span class="string">100m;</span>                                    <span class="comment">#nginx对上传文件大小的限制</span></span><br><span class="line">    <span class="string">proxy_buffer_size</span>  <span class="string">128k;</span>                                    <span class="comment">#Nginx使用该大小申请read_buf，即大小指定了 upstream header 最大长度，如果响应头超过了这个长度，Nginx会报upstream sent too big header错误，然后client收到的是502</span></span><br><span class="line">    <span class="string">proxy_buffers</span>   <span class="number">32</span> <span class="string">32k;</span>                                        <span class="comment">#设置存储被代理服务器响应的body所占用的buffer个数和每个buffer大小</span></span><br><span class="line">    <span class="string">proxy_busy_buffers_size</span> <span class="string">128k;</span>                                <span class="comment">#proxy_busy_buffers_size不是独立的空间，他是proxy_buffers和proxy_buffer_size的一部分。nginx会在没有完全读完后端响应就开始向客户端传送数据，所以它会划出一部分busy状态的buffer来专门向客户端传送数据(建议为proxy_buffers中单个缓冲区的2倍)，然后它继续从后端取数据。proxy_busy_buffer_size参数用来设置处于busy状态的buffer有多大</span></span><br><span class="line"></span><br><span class="line">    <span class="string">fastcgi_buffers</span> <span class="number">16</span> <span class="string">256k;</span>                                    <span class="comment">#设定用来读取从FastCGI服务器端收到的响应信息的缓冲区大小和缓冲区数量</span></span><br><span class="line">    <span class="string">fastcgi_buffer_size</span> <span class="string">128k;</span>                                    <span class="comment">#Nginx FastCGI 的缓冲区大小，用来读取从FastCGI服务器端收到的第一部分响应信息的缓冲区大小</span></span><br><span class="line">    <span class="string">fastcgi_busy_buffers_size</span> <span class="string">256k;</span>                                <span class="comment">#用于设置系统很忙时可以使用的 proxy_buffers 大小</span></span><br><span class="line"></span><br><span class="line">    <span class="string">map</span> <span class="string">$http_upgrade</span> <span class="string">$connection_upgrade</span> &#123;  <span class="comment">#开启websocket升级代理功能，可选</span></span><br><span class="line">        <span class="string">default</span> <span class="string">upgrade;</span></span><br><span class="line">        <span class="string">&#x27;&#x27;</span> <span class="string">close;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="string">include</span> <span class="string">/etc/nginx/conf.d/*.conf;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">server</span> &#123;                                                    <span class="comment">#http（80）转https（443）配置                </span></span><br><span class="line">        <span class="string">listen</span>       <span class="number">80</span><span class="string">;</span></span><br><span class="line">        <span class="string">listen</span>       [<span class="string">::</span>]<span class="string">:80;</span></span><br><span class="line">        <span class="string">server_name</span>  <span class="string">www.abc.com;</span></span><br><span class="line">        <span class="string">rewrite</span> <span class="string">^(.*)$</span> <span class="string">https://$</span>&#123;<span class="string">server_name</span>&#125;<span class="string">$1</span> <span class="string">permanent;</span></span><br><span class="line">        <span class="comment">#root         /usr/share/nginx/html;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load configuration files for the default server block.</span></span><br><span class="line">        <span class="string">include</span> <span class="string">/etc/nginx/default.d/*.conf;</span></span><br><span class="line"></span><br><span class="line">        <span class="string">error_page</span> <span class="number">404</span> <span class="string">/404.html;</span></span><br><span class="line">        <span class="string">location</span> <span class="string">=</span> <span class="string">/404.html</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="string">error_page</span> <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span> <span class="string">/50x.html;</span></span><br><span class="line">        <span class="string">location</span> <span class="string">=</span> <span class="string">/50x.html</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>default.conf(&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf)</p><p>配置文件里只是一个后端模块的配置，请根据实际情况增加对应的location</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">server</span> &#123;</span><br><span class="line"><span class="string">listen</span> <span class="number">80</span><span class="string">;</span></span><br><span class="line">　　<span class="string">server_name</span> <span class="string">www.abcd.com;</span></span><br><span class="line">   <span class="string">access_log</span>  <span class="string">/var/log/nginx/abc.access.log</span>  <span class="string">main;</span>                <span class="comment">#自定义专属日志文件</span></span><br><span class="line">　　</span><br><span class="line">　　<span class="string">location</span> <span class="string">/</span> &#123;</span><br><span class="line">　　　　<span class="string">root</span> <span class="string">/usr/share/nginx/dist;</span></span><br><span class="line">　　　　<span class="string">index</span>  <span class="string">index.html</span> <span class="string">index.htm;</span></span><br><span class="line">　　&#125;</span><br><span class="line"></span><br><span class="line">    <span class="string">location</span> <span class="string">^~</span> <span class="string">/api/</span> &#123;                                            <span class="comment">#转发示例</span></span><br><span class="line">        <span class="string">proxy_pass</span> <span class="string">http://192.168.1.1:8003/;</span></span><br><span class="line">        <span class="string">proxy_redirect</span> <span class="string">off;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">Host</span> <span class="string">$host;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">REMOTE-HOST</span> <span class="string">$remote_addr;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">X-Real-IP</span> <span class="string">$remote_addr;</span></span><br><span class="line">        <span class="string">proxy_set_header</span> <span class="string">X-Forwarded-For</span> <span class="string">$proxy_add_x_forwarded_for;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="k8s部署MySQL5-7"><a href="#k8s部署MySQL5-7" class="headerlink" title="k8s部署MySQL5.7"></a>k8s部署MySQL5.7</h2><p>Nacos需要使用MySQL存储配置数据，由于使用量不大，因此没有考虑高可用部署，也可以采用已有的MySQL数据库。</p><h3 id="部署步骤-1"><a href="#部署步骤-1" class="headerlink" title="部署步骤"></a>部署步骤</h3><h4 id="创建MySQL相关部署文件"><a href="#创建MySQL相关部署文件" class="headerlink" title="创建MySQL相关部署文件"></a>创建MySQL相关部署文件</h4><ol><li>创建mysql存储pvc yaml文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi mysql-pvc.yaml</span><br></pre></td></tr></table></figure><ul><li>mysql-pvc.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-pvc</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                          <span class="comment">#注意修改命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">glusterfs</span></span><br></pre></td></tr></table></figure><ol start="2"><li>创建mysql配置configmap yaml文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi mysql-config.yaml</span><br></pre></td></tr></table></figure><ul><li>mysql-config.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-cm</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                        <span class="comment">#注意修改命名空间</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">mysqld.cnf:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    [mysqld]</span></span><br><span class="line"><span class="string">    pid-file        = /var/run/mysqld/mysqld.pid</span></span><br><span class="line"><span class="string">    socket          = /var/run/mysqld/mysqld.sock</span></span><br><span class="line"><span class="string">    datadir         = /var/lib/mysql</span></span><br><span class="line"><span class="string">    bind-address    = 0.0.0.0</span></span><br><span class="line"><span class="string">    port = 3306</span></span><br><span class="line"><span class="string">    log-bin = mysql-bin</span></span><br><span class="line"><span class="string">    server-id = 1</span></span><br></pre></td></tr></table></figure><ol start="3"><li>创建mysql服务service yaml文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi mysql-service.yaml</span><br></pre></td></tr></table></figure><ul><li>mysql-service.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                            <span class="comment">#注意修改命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30850</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br></pre></td></tr></table></figure><ol start="4"><li>创建mysql配置副本Deployment yaml文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi mysql.yaml</span><br></pre></td></tr></table></figure><ul><li>mysql.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                                    <span class="comment">#注意修改命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">mysql:5.7.32</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;root@my.123&quot;</span>                                         <span class="comment">#数据库root的密码</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">3306</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql-persistent-storage</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/mysql</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql-config</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/mysql/mysql.conf.d/mysqld.cnf</span></span><br><span class="line">          <span class="attr">subPath:</span> <span class="string">mysqld.cnf</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql-persistent-storage</span></span><br><span class="line">        <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">          <span class="attr">claimName:</span> <span class="string">mysql-pvc</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql-config</span></span><br><span class="line">        <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">mysql-cm</span></span><br></pre></td></tr></table></figure><h4 id="部署MySQL"><a href="#部署MySQL" class="headerlink" title="部署MySQL"></a>部署MySQL</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl apply -f mysql-pvc.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f mysql-config.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f mysql-service.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f mysql.yaml</span><br></pre></td></tr></table></figure><h4 id="验证MySQL"><a href="#验证MySQL" class="headerlink" title="验证MySQL"></a>验证MySQL</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl get pods -n test</span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">mysql-589dcf6597-5ps6x   1/1     Running   0          8m3s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入pod登录验证</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl exec -it mysql-589dcf6597-5ps6x /bin/bash -n test</span><br><span class="line">kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.</span><br><span class="line">root@mysql-589dcf6597-5ps6x:/# mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">ALTER USER <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;P@ssword-123&#x27;</span>;        <span class="comment">#修改root密码</span></span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><h2 id="k8s部署Nacos集群"><a href="#k8s部署Nacos集群" class="headerlink" title="k8s部署Nacos集群"></a>k8s部署Nacos集群</h2><h3 id="部署步骤-2"><a href="#部署步骤-2" class="headerlink" title="部署步骤"></a>部署步骤</h3><h4 id="拉取项目代码"><a href="#拉取项目代码" class="headerlink" title="拉取项目代码"></a>拉取项目代码</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">拉取nacos代码</span></span><br><span class="line">[root@k8s-master-0 ~]# git clone https://github.com/nacos-group/nacos-k8s.git</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">拉取nacos的初始化数据库sql文件</span></span><br><span class="line">[root@k8s-master-0 ~]# wget https://github.com/alibaba/nacos/blob/develop/distribution/conf/nacos-mysql.sql</span><br></pre></td></tr></table></figure><h4 id="创建nacos所需数据库"><a href="#创建nacos所需数据库" class="headerlink" title="创建nacos所需数据库"></a>创建nacos所需数据库</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录数据库</span></span><br><span class="line">[root@k8s-master01 mysql]# kubectl exec -it mysql-589dcf6597-5ps6x /bin/bash -n test</span><br><span class="line">kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.</span><br><span class="line">root@mysql-589dcf6597-5ps6x:/# mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建数据库</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">CREATE DATABASE  IF NOT EXISTS `nacos_dev` DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建nacos用户</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">GRANT ALL PRIVILEGES ON  nacos.* to nacos@<span class="string">&#x27;%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;nacos&#x27;</span>;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">刷新权限</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">FLUSH PRIVILEGES;</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导入nacos数据库</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">use nacos;</span></span><br><span class="line">Database changed</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看mysql的连接端口</span></span><br><span class="line">[root@k8s-master01 mysql]# kubectl get svc -n test</span><br><span class="line">NAME                                                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">mysql                                                    NodePort    10.233.20.110   &lt;none&gt;        3306:30850/TCP   47m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用mysql连接工具连接数据库并导入上方sql</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">因为mysql service的类型为nodeport,所以连接地址为任一k8s集群的节点ip地址，端口为30850</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">回到命令行查看nacos数据表</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">show tables;</span></span><br><span class="line">+----------------------+</span><br><span class="line">| Tables_in_nacos      |</span><br><span class="line">+----------------------+</span><br><span class="line">| config_info          |</span><br><span class="line">| config_info_aggr     |</span><br><span class="line">| config_info_beta     |</span><br><span class="line">| config_info_tag      |</span><br><span class="line">| config_tags_relation |</span><br><span class="line">| group_capacity       |</span><br><span class="line">| his_config_info      |</span><br><span class="line">| permissions          |</span><br><span class="line">| roles                |</span><br><span class="line">| tenant_capacity      |</span><br><span class="line">| tenant_info          |</span><br><span class="line">| users                |</span><br><span class="line">+----------------------+</span><br><span class="line">12 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><h4 id="修改nacos部署yaml文件"><a href="#修改nacos部署yaml文件" class="headerlink" title="修改nacos部署yaml文件"></a>修改nacos部署yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">进入项目目录</span></span><br><span class="line">[root@k8s-master-0 ~]# cd nacos-k8s/deploy/nacos</span><br><span class="line">[root@k8s-master-0 ~]# cp nacos-pvc-nfs.yaml nacos.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改部署文件</span></span><br><span class="line">[root@k8s-master-0 nacos]# vi nacos.yaml</span><br></pre></td></tr></table></figure><ul><li>nacos.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">---</span>                         <span class="comment">#修改8848端口为nodeport形式,以便集群外部访问</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-server</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                            <span class="comment">#增加命名空间</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">service.alpha.kubernetes.io/tolerate-unready-endpoints:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">server</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30848</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                            <span class="comment">#增加命名空间</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">service.alpha.kubernetes.io/tolerate-unready-endpoints:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">server</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8848</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">client-rpc</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9848</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9849</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">raft-rpc</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9849</span></span><br><span class="line">    <span class="comment">## 兼容1.4.x版本的选举端口</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">7848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">old-raft-rpc</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">7848</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-cm</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                            <span class="comment">#增加命名空间</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">mysql.host:</span> <span class="string">&quot;mysql.test&quot;</span>                 <span class="comment">#增加mysql连接地址</span></span><br><span class="line">  <span class="attr">mysql.db.name:</span> <span class="string">&quot;nacos_devtest&quot;</span></span><br><span class="line">  <span class="attr">mysql.port:</span> <span class="string">&quot;3306&quot;</span></span><br><span class="line">  <span class="attr">mysql.user:</span> <span class="string">&quot;nacos&quot;</span></span><br><span class="line">  <span class="attr">mysql.password:</span> <span class="string">&quot;nacos&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                            <span class="comment">#增加命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">nacos-headless</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">pod.alpha.kubernetes.io/initialized:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">                <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;app&quot;</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">nacos</span></span><br><span class="line">              <span class="attr">topologyKey:</span> <span class="string">&quot;kubernetes.io/hostname&quot;</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">peer-finder-plugin-install</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nacos/nacos-peer-finder-plugin:1.1</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/home/nacos/plugins/peer-finder</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">peer-finder</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nacos</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nacos/nacos-server:latest</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">&quot;2Gi&quot;</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">client-port</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">client-rpc</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9849</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">raft-rpc</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">7848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">old-raft-rpc</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_REPLICAS</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SERVICE_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;nacos-headless&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DOMAIN_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;cluster.local&quot;</span>     <span class="comment">#修改k8s集群地址，可通过cat /etc/kubernetes/kubelet.conf查看对应字段：contexts/- context/cluster</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_HOST</span>              <span class="comment">#增加获取mysql连接地址的环境变量</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.host</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_DB_NAME</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.db.name</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PORT</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.port</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_USER</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.user</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-cm</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.password</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_SERVER_PORT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;8848&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_APPLICATION_PORT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;8848&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PREFER_HOST_MODE</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;hostname&quot;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/home/nacos/plugins/peer-finder</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">peer-finder</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/home/nacos/data</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">data</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/home/nacos/logs</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">logs</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">test</span>                                <span class="comment">#增加命名空间</span></span><br><span class="line">        <span class="attr">annotations:</span></span><br><span class="line">          <span class="attr">volume.beta.kubernetes.io/storage-class:</span> <span class="string">&quot;managed-nfs-storage&quot;</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteMany&quot;</span> ]</span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span>                    <span class="comment">#增加storageClass选择器，以便自动创建pvc</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">20Gi</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nacos</span></span><br></pre></td></tr></table></figure><h4 id="部署集群"><a href="#部署集群" class="headerlink" title="部署集群"></a>部署集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl apply  -f  nacos.yaml</span><br></pre></td></tr></table></figure><h4 id="验证集群"><a href="#验证集群" class="headerlink" title="验证集群"></a>验证集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看nacos pod</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl get pod -n test | grep nacos</span><br><span class="line">nacos-0                                               1/1     Running   0          120d</span><br><span class="line">nacos-1                                               1/1     Running   0          120d</span><br><span class="line">nacos-2                                               1/1     Running   0          120d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看nacos svc</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get svc -n test | grep nacos</span><br><span class="line">NAME                               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE</span><br><span class="line">nacos-headless                     ClusterIP   None            &lt;none&gt;        8848/TCP,9848/TCP,9849/TCP,7848/TCP   216d</span><br><span class="line">nacos-server                       NodePort    10.233.20.35    &lt;none&gt;        8848:30848/TCP                        213d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问任意节点ip+30848（nodeport端口）进行验证 http://ip:30848/nacos</span></span><br><span class="line">默认用户名/密码 ：nacos/nacos</span><br></pre></td></tr></table></figure><h2 id="k8s部署Redis集群"><a href="#k8s部署Redis集群" class="headerlink" title="k8s部署Redis集群"></a>k8s部署Redis集群</h2><p>Redis采用三主三从集群模式部署</p><h3 id="部署步骤-3"><a href="#部署步骤-3" class="headerlink" title="部署步骤"></a>部署步骤</h3><h4 id="创建redis副本文件"><a href="#创建redis副本文件" class="headerlink" title="创建redis副本文件"></a>创建redis副本文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi redis-statefulset.yaml</span><br></pre></td></tr></table></figure><ul><li>redis-statefulset.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-cluster-cm</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">redis-conf:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    appendonly yes                                                        #开启AOF模式</span></span><br><span class="line"><span class="string">    protected-mode no                                                    #关闭protected-mode模式，此时外部网络可以直接访问</span></span><br><span class="line"><span class="string">    cluster-enabled yes                                                    #开启集群模式</span></span><br><span class="line"><span class="string">    cluster-config-file /data/nodes.conf                                #Redis集群节点的集群配置文件</span></span><br><span class="line"><span class="string">    cluster-node-timeout 5000                                            #指节点在失败状态下必须不可到达的毫秒数。大多数其他内部时间限制是节点超时的倍数</span></span><br><span class="line"><span class="string">    dir /data                                                            #数据存储目录</span></span><br><span class="line"><span class="string">    port 6379</span></span><br><span class="line"><span class="string">    requirepass redis@123.com                                            #redis密码，自定义</span></span><br><span class="line"><span class="string">    masterauth redis@123.com                                            #如果master是密码保护的，在启动复制同步进程之前，可以告诉奴隶进行身份验证，否则主人将拒绝奴隶请求。</span></span><br><span class="line"><span class="string"></span><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">redis-headless</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">6</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">100</span></span><br><span class="line">            <span class="attr">podAffinityTerm:</span></span><br><span class="line">              <span class="attr">labelSelector:</span></span><br><span class="line">                <span class="attr">matchExpressions:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                  <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                  <span class="attr">values:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">redis</span></span><br><span class="line">              <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">dockerhub.test.com:18443/library/redis:6.2.5</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;redis-server&quot;</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;/etc/redis/redis.conf&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;--protected-mode&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;no&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;--cluster-announce-ip&quot;</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;$(POD_IP)&quot;</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_IP</span></span><br><span class="line">            <span class="attr">valueFrom:</span></span><br><span class="line">              <span class="attr">fieldRef:</span></span><br><span class="line">                <span class="attr">fieldPath:</span> <span class="string">status.podIP</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">6379</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">&quot;TCP&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cluster</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">16379</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">&quot;TCP&quot;</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-conf</span></span><br><span class="line">            <span class="attr">mountPath:</span> <span class="string">/etc/redis</span>        </span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-data</span></span><br><span class="line">            <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-conf</span></span><br><span class="line">        <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">redis-cluster-cm</span></span><br><span class="line">          <span class="attr">items:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">redis-conf</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">redis.conf</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">redis-data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteOnce&quot;</span> ]</span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span>                                        <span class="comment">#注意修改为自己的storageClass</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">10Gi</span>                                                    <span class="comment">#pvc容量，自定义</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-port</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">6379</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30849</span>                                                        <span class="comment">#nodeport端口自定义</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure><h4 id="部署并配置集群"><a href="#部署并配置集群" class="headerlink" title="部署并配置集群"></a>部署并配置集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl apply -f redis-statefulset.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置集群</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">自动配置3个master,3个slave节点的集群，-a指定密码</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl exec -it redis-0 -n test -- redis-cli -a redis@123.com --cluster create --cluster-replicas 1 $(kubectl get pods -n test -l app=redis -o jsonpath=&#x27;&#123;range.items[*]&#125;&#123;.status.podIP&#125;:6379 &#123;end&#125;&#x27;)</span><br></pre></td></tr></table></figure><h4 id="验证集群-1"><a href="#验证集群-1" class="headerlink" title="验证集群"></a>验证集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对redis集群进行验证</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl exec -it redis-0 -n test -- redis-cli -a redis@123.com --cluster check $(kubectl get pods -n test -l app=redis -o jsonpath=&#x27;&#123;range.items[0]&#125;&#123;.status.podIP&#125;:6379&#123;end&#125;&#x27;)</span><br><span class="line">Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.</span><br><span class="line">10.233.67.76:6379 (b8e966ed...) -&gt; 286 keys | 5461 slots | 1 slaves.</span><br><span class="line">10.233.94.207:6379 (31d925a7...) -&gt; 263 keys | 5462 slots | 1 slaves.</span><br><span class="line">10.233.98.106:6379 (11b42330...) -&gt; 275 keys | 5461 slots | 1 slaves.</span><br><span class="line">[OK] 824 keys in 3 masters.</span><br><span class="line">0.05 keys per slot on average.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing Cluster Check (using node 10.233.67.76:6379)</span></span><br><span class="line">M: b8e966ed2e00d2c9fb24ebdd409fd7eef90cbb11 10.233.67.76:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 35d46c8a708f234b73d647d1a800e52a620f2fbd 10.233.82.103:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 31d925a76d8276ec6b1735a65b3e8d238ca5b63f</span><br><span class="line">S: 8bbb3e01a5d9087327ff5ea2ee57e87c772c5ba9 10.233.94.205:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 11b42330416a1fe3da01ff696b573e35f95be0c6</span><br><span class="line">M: 31d925a76d8276ec6b1735a65b3e8d238ca5b63f 10.233.94.207:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 11b42330416a1fe3da01ff696b573e35f95be0c6 10.233.98.106:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 121cdf362ae961cb18df31588df56e2e0cd42f10 10.233.123.249:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates b8e966ed2e00d2c9fb24ebdd409fd7eef90cbb11</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubectl get pod -n test | grep redis</span><br><span class="line">redis-0                                               1/1     Running   0          130d</span><br><span class="line">redis-1                                               1/1     Running   0          130d</span><br><span class="line">redis-2                                               1/1     Running   0          130d</span><br><span class="line">redis-3                                               1/1     Running   0          130d</span><br><span class="line">redis-4                                               1/1     Running   0          130d</span><br><span class="line">redis-5                                               1/1     Running   0          130d</span><br></pre></td></tr></table></figure><h2 id="k8s部署RocketMQ集群"><a href="#k8s部署RocketMQ集群" class="headerlink" title="k8s部署RocketMQ集群"></a>k8s部署RocketMQ集群</h2><ul><li><p>为了实现快速和简单的部署，RocketMQ的部署采用了官方提供的operator</p></li><li><p>但是官方的部署使用后期发现诸多不便之处，也可能是我没玩明白，还需要深入研究</p><ul><li><p>pod如果重建的话ui可能会连不上集群</p></li><li><p>pod重建后集群发现也出现过问题</p></li></ul></li></ul><h3 id="部署步骤-4"><a href="#部署步骤-4" class="headerlink" title="部署步骤"></a>部署步骤</h3><h4 id="部署RocketMQ相关组件的crd资源"><a href="#部署RocketMQ相关组件的crd资源" class="headerlink" title="部署RocketMQ相关组件的crd资源"></a>部署RocketMQ相关组件的crd资源</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">拉取rocketmq部署文件</span></span><br><span class="line">[root@k8s-master-0 ~]# git clone -b 0.2.1 https://github.com/apache/rocketmq-operator.git</span><br><span class="line">[root@k8s-master-0 ~]# cd rocketmq-operator</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看crd部署脚本</span></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# cat install-operator.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">this work <span class="keyword">for</span> additional information regarding copyright ownership.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">(the <span class="string">&quot;License&quot;</span>); you may not use this file except <span class="keyword">in</span> compliance with</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">limitations under the License.</span></span><br><span class="line"></span><br><span class="line">kubectl create -f deploy/crds/rocketmq_v1alpha1_broker_crd.yaml</span><br><span class="line">kubectl create -f deploy/crds/rocketmq_v1alpha1_nameservice_crd.yaml</span><br><span class="line">kubectl create -f deploy/crds/rocketmq_v1alpha1_topictransfer_crd.yaml</span><br><span class="line">kubectl create -f deploy/service_account.yaml</span><br><span class="line">kubectl create -f deploy/role.yaml</span><br><span class="line">kubectl create -f deploy/role_binding.yaml</span><br><span class="line">kubectl create -f deploy/operator.yaml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl create -f example/rocketmq_v1alpha1_rocketmq_cluster.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为部署脚本中的所有yaml文件增加命名空间</span></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/crds/rocketmq_v1alpha1_broker_crd.yaml</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: brokers.rocketmq.apache.org</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/crds/rocketmq_v1alpha1_nameservice_crd.yaml</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: nameservices.rocketmq.apache.org</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/crds/rocketmq_v1alpha1_consoles_crd.yaml</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: consoles.rocketmq.apache.org</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/crds/rocketmq_v1alpha1_topictransfer_crd.yaml</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: topictransfers.rocketmq.apache.org</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/service_account.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: rocketmq-operator</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/role.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  name: rocketmq-operator</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/role_binding.yaml</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: rocketmq-operator</span><br><span class="line">  namespace: test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# vi deploy/operator.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: rocketmq-operator</span><br><span class="line">  namespace: test</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建rocketmq Operator</span></span><br><span class="line">[root@k8s-master-0 rocketmq-operator]# sh install-operator.sh</span><br><span class="line">Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/brokers.rocketmq.apache.org created</span><br><span class="line">Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/nameservices.rocketmq.apache.org created</span><br><span class="line">Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/topictransfers.rocketmq.apache.org created</span><br><span class="line">serviceaccount/rocketmq-operator created</span><br><span class="line">role.rbac.authorization.k8s.io/rocketmq-operator created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/rocketmq-operator created</span><br><span class="line">deployment.apps/rocketmq-operator created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看rocketmq Operator</span></span><br><span class="line">[root@k8s-master01 rocketmq-operator]# kubectl get pod -n test</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">rocketmq-operator-867c4955-dhgzh   1/1     Running   0          7m40s</span><br></pre></td></tr></table></figure><h4 id="配置RocketMQ集群部署yaml文件"><a href="#配置RocketMQ集群部署yaml文件" class="headerlink" title="配置RocketMQ集群部署yaml文件"></a>配置RocketMQ集群部署yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 rocketmq-operator]# vi example/rocketmq_v1alpha1_rocketmq_cluster.yaml</span><br></pre></td></tr></table></figure><ul><li>rocketmq_v1alpha1_rocketmq_cluster.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">broker-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                            <span class="comment">#添加命名空间</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="comment"># BROKER_MEM sets the broker JVM, if set to &quot;&quot; then Xms = Xmx = max(min(1/2 ram, 1024MB), min(1/4 ram, 8GB))</span></span><br><span class="line">  <span class="attr">BROKER_MEM:</span> <span class="string">&quot; -Xms2g -Xmx2g -Xmn1g &quot;</span></span><br><span class="line">  <span class="attr">broker-common.conf:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    # brokerClusterName, brokerName, brokerId are automatically generated by the operator and do not set it manually!!!</span></span><br><span class="line"><span class="string">    deleteWhen=04</span></span><br><span class="line"><span class="string">    fileReservedTime=48</span></span><br><span class="line"><span class="string">    flushDiskType=ASYNC_FLUSH</span></span><br><span class="line"><span class="string">    # set brokerRole to ASYNC_MASTER or SYNC_MASTER. DO NOT set to SLAVE because the replica instance will automatically be set!!!</span></span><br><span class="line"><span class="string">    brokerRole=ASYNC_MASTER</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rocketmq.apache.org/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Broker</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="comment"># name of broker cluster</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">broker</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                            <span class="comment">#添加命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># size is the number of the broker cluster, each broker cluster contains a master broker and [replicaPerGroup] replica brokers.</span></span><br><span class="line">  <span class="attr">size:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># nameServers is the [ip:port] list of name service</span></span><br><span class="line">  <span class="attr">nameServers:</span> <span class="string">&quot;&quot;</span>                                            <span class="comment">#无需填写自动获取</span></span><br><span class="line">  <span class="comment"># replicaPerGroup is the number of each broker cluster</span></span><br><span class="line">  <span class="attr">replicaPerGroup:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># brokerImage is the customized docker image repo of the RocketMQ broker</span></span><br><span class="line">  <span class="attr">brokerImage:</span> <span class="string">apacherocketmq/rocketmq-broker:4.5.0-alpine-operator-0.3.0</span></span><br><span class="line">  <span class="comment"># imagePullPolicy is the image pull policy</span></span><br><span class="line">  <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">  <span class="comment"># resources describes the compute resource requirements and limits</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">&quot;2048Mi&quot;</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span></span><br><span class="line">    <span class="attr">limits:</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">&quot;12288Mi&quot;</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line">  <span class="comment"># allowRestart defines whether allow pod restart</span></span><br><span class="line">  <span class="attr">allowRestart:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># storageMode can be EmptyDir, HostPath, StorageClass</span></span><br><span class="line">  <span class="attr">storageMode:</span> <span class="string">StorageClass</span></span><br><span class="line">  <span class="comment"># hostPath is the local path to store data</span></span><br><span class="line">  <span class="attr">hostPath:</span> <span class="string">/data/rocketmq/broker</span></span><br><span class="line">  <span class="comment"># scalePodName is [Broker name]-[broker group number]-master-0</span></span><br><span class="line">  <span class="attr">scalePodName:</span> <span class="string">broker-0-master-0</span></span><br><span class="line">  <span class="comment"># env defines custom env, e.g. BROKER_MEM</span></span><br><span class="line">  <span class="attr">env:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">BROKER_MEM</span></span><br><span class="line">      <span class="attr">valueFrom:</span></span><br><span class="line">        <span class="attr">configMapKeyRef:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">broker-config</span></span><br><span class="line">          <span class="attr">key:</span> <span class="string">BROKER_MEM</span></span><br><span class="line">  <span class="comment"># volumes defines the broker.conf</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">broker-config</span></span><br><span class="line">      <span class="attr">configMap:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">broker-config</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">broker-common.conf</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">broker-common.conf</span></span><br><span class="line">  <span class="comment"># volumeClaimTemplates defines the storageClass</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">broker-storage</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span>                            <span class="comment">#修改为自己的storageClass</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">8Gi</span>                                        <span class="comment">#可自定义pvc容量</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rocketmq.apache.org/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NameService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">name-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                                <span class="comment">#添加命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># size is the the name service instance number of the name service cluster</span></span><br><span class="line">  <span class="attr">size:</span> <span class="number">1</span></span><br><span class="line">  <span class="comment"># nameServiceImage is the customized docker image repo of the RocketMQ name service</span></span><br><span class="line">  <span class="attr">nameServiceImage:</span> <span class="string">apacherocketmq/rocketmq-nameserver:4.5.0-alpine-operator-0.3.0</span></span><br><span class="line">  <span class="comment"># imagePullPolicy is the image pull policy</span></span><br><span class="line">  <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">  <span class="comment"># hostNetwork can be true or false</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">#  Set DNS policy for the pod.</span></span><br><span class="line">  <span class="comment">#  Defaults to &quot;ClusterFirst&quot;.</span></span><br><span class="line">  <span class="comment">#  Valid values are &#x27;ClusterFirstWithHostNet&#x27;, &#x27;ClusterFirst&#x27;, &#x27;Default&#x27; or &#x27;None&#x27;.</span></span><br><span class="line">  <span class="comment">#  DNS parameters given in DNSConfig will be merged with the policy selected with DNSPolicy.</span></span><br><span class="line">  <span class="comment">#  To have DNS options set along with hostNetwork, you have to specify DNS policy</span></span><br><span class="line">  <span class="comment">#  explicitly to &#x27;ClusterFirstWithHostNet&#x27;.</span></span><br><span class="line">  <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirstWithHostNet</span></span><br><span class="line">  <span class="comment"># resources describes the compute resource requirements and limits</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">&quot;512Mi&quot;</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span></span><br><span class="line">    <span class="attr">limits:</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">&quot;1024Mi&quot;</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line">  <span class="comment"># storageMode can be EmptyDir, HostPath, StorageClass</span></span><br><span class="line">  <span class="attr">storageMode:</span> <span class="string">StorageClass</span></span><br><span class="line">  <span class="comment"># hostPath is the local path to store data</span></span><br><span class="line">  <span class="attr">hostPath:</span> <span class="string">/data/rocketmq/nameserver</span></span><br><span class="line">  <span class="comment"># volumeClaimTemplates defines the storageClass</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">namesrv-storage</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">rocketmq-storage</span></span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span>                                <span class="comment">#修改为自己的storageClass</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">1Gi</span>                                            <span class="comment">#可自定义pvc容量</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rocketmq.apache.org/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Console</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">console</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span>                                                    <span class="comment">#添加命名空间</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># nameServers is the [ip:port] list of name service</span></span><br><span class="line">  <span class="attr">nameServers:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="comment"># consoleDeployment define the console deployment</span></span><br><span class="line">  <span class="attr">consoleDeployment:</span></span><br><span class="line">    <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">rocketmq-console</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">selector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">app:</span> <span class="string">rocketmq-console</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">metadata:</span></span><br><span class="line">          <span class="attr">labels:</span></span><br><span class="line">            <span class="attr">app:</span> <span class="string">rocketmq-console</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">console</span></span><br><span class="line">              <span class="attr">image:</span> <span class="string">apacherocketmq/rocketmq-console:2.0.0</span></span><br><span class="line">              <span class="attr">ports:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure><h4 id="配置RocketMQ集群service-yaml文件"><a href="#配置RocketMQ集群service-yaml文件" class="headerlink" title="配置RocketMQ集群service yaml文件"></a>配置RocketMQ集群service yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 rocketmq-operator]# vi example/rocketmq_v1alpha1_cluster_service.yaml</span><br></pre></td></tr></table></figure><ul><li>rocketmq_v1alpha1_cluster_service.yaml</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">this work <span class="keyword">for</span> additional information regarding copyright ownership.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">(the <span class="string">&quot;License&quot;</span>); you may not use this file except <span class="keyword">in</span> compliance with</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">distributed under the License is distributed on an <span class="string">&quot;AS IS&quot;</span> BASIS,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">See the License <span class="keyword">for</span> the specific language governing permissions and</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">limitations under the License.</span></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: console-service</span><br><span class="line">  namespace: test                                    #修改命名空间</span><br><span class="line">  labels:</span><br><span class="line">    app: rocketmq-console</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    app: rocketmq-console</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      targetPort: 8080</span><br><span class="line">      protocol: TCP</span><br><span class="line">      nodePort: 30849                                #注意修改nodeport端口</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">---</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">apiVersion: v1                                        <span class="comment">#如果集群外的服务需要使用rockermq可以取消此service注释</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kind: Service</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">metadata:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> name: name-server-service</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> namespace: <span class="built_in">test</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">spec:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="built_in">type</span>: NodePort</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> selector:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   name_service_cr: name-service</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> ports:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   - port: 9876</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">     targetPort: 9876</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">     <span class="comment"># use this port to access the name server cluster</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">     nodePort: 30001</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">---</span></span><br></pre></td></tr></table></figure><h4 id="部署集群-1"><a href="#部署集群-1" class="headerlink" title="部署集群"></a>部署集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装rocketmq集群</span></span><br><span class="line">[root@k8s-master01 rocketmq-operator]# kubectl apply -f example/rocketmq_v1alpha1_rocketmq_cluster.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装rocketmq集群service</span></span><br><span class="line">[root@k8s-master01 rocketmq-operator]# kubectl apply -f example/rocketmq_v1alpha1_cluster_service.yaml</span><br></pre></td></tr></table></figure><h4 id="验证集群-2"><a href="#验证集群-2" class="headerlink" title="验证集群"></a>验证集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看rocketmq集群pod</span></span><br><span class="line">[root@k8s-master01 rocketmq-operator]# kubectl get pod -n test</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">broker-0-master-0                  1/1     Running   0          13m</span><br><span class="line">broker-0-replica-1-0               1/1     Running   0          13m</span><br><span class="line">console-fd66cc958-t7twh            1/1     Running   0          13m</span><br><span class="line">name-service-0                     1/1     Running   0          13m</span><br><span class="line">rocketmq-operator-867c4955-dhgzh   1/1     Running   0          13m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看rocketmq集群svc</span></span><br><span class="line">[root@k8s-master01 rocketmq-operator]# kubectl get svc -n test</span><br><span class="line">NAME                                                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">console-service                                          NodePort    10.233.46.31    &lt;none&gt;        8080:30849/TCP   12m</span><br><span class="line">glusterfs-dynamic-0fc569c2-e2fe-4ef1-be6a-b3d56f1058d1   ClusterIP   10.233.36.32    &lt;none&gt;        1/TCP            15h</span><br><span class="line">glusterfs-dynamic-ceed9eef-7264-45c5-b727-4afc64ab34ab   ClusterIP   10.233.60.200   &lt;none&gt;        1/TCP            16h</span><br><span class="line">glusterfs-dynamic-e7c85113-e164-4423-a5ad-99f7c3f8b0f1   ClusterIP   10.233.24.21    &lt;none&gt;        1/TCP            15h</span><br><span class="line">rocketmq-operator                                        ClusterIP   10.233.61.255   &lt;none&gt;        8383/TCP         13m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看rocketmq集群pvc</span></span><br><span class="line">[root@k8s-master01 rocketmq-operator]# kubectl get pvc -n test</span><br><span class="line">NAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">broker-storage-broker-0-master-0      Bound    pvc-e7c85113-e164-4423-a5ad-99f7c3f8b0f1   8Gi        RWO            glusterfs      15h</span><br><span class="line">broker-storage-broker-0-replica-1-0   Bound    pvc-0fc569c2-e2fe-4ef1-be6a-b3d56f1058d1   8Gi        RWO            glusterfs      15h</span><br><span class="line">namesrv-storage-name-service-0        Bound    pvc-ceed9eef-7264-45c5-b727-4afc64ab34ab   10Gi       RWO            glusterfs      16h</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">浏览器访问nodeip+console-service的nodeport端口进行验证</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">http://ip:30849/</span></span><br></pre></td></tr></table></figure><h2 id="k8s部署XXL-JOB"><a href="#k8s部署XXL-JOB" class="headerlink" title="k8s部署XXL-JOB"></a>k8s部署XXL-JOB</h2><h3 id="部署步骤-5"><a href="#部署步骤-5" class="headerlink" title="部署步骤"></a>部署步骤</h3><h4 id="创建XXL-JOB所需数据库"><a href="#创建XXL-JOB所需数据库" class="headerlink" title="创建XXL-JOB所需数据库"></a>创建XXL-JOB所需数据库</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">数据库sql参考地址包含创建数据库步骤,见附录</span></span><br><span class="line">[root@k8s-master-1 ~]# wget https://github.com/xuxueli/xxl-job/blob/master/doc/db/tables_xxl_job.sql</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看mysql的连接端口</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl get svc -n test</span><br><span class="line">NAME                                                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">mysql                                                    NodePort    10.233.20.110   &lt;none&gt;        3306:30850/TCP   47m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用mysql连接工具连接数据库并导入上方sql，因为mysql service的类型为nodeport,所以连接地址为任一k8s集群的节点ip地址，端口为30850</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以下创建用户操作也可以再连接工具中操作</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录数据库</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl exec -it mysql-589dcf6597-5ps6x /bin/bash -n test</span><br><span class="line">kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.</span><br><span class="line">root@mysql-589dcf6597-5ps6x:/# mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">create user <span class="string">&#x27;xxl&#x27;</span>@<span class="string">&#x27;%&#x27;</span> identified by <span class="string">&#x27;P@ssw0rd@xxl&#x27;</span>;                <span class="comment">#创建xxl用户用于xxl-job服务连接</span></span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">GRANT ALL PRIVILEGES ON  xxl_job.* TO <span class="string">&#x27;xxl&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;P@ssw0rd@xxl&#x27;</span>;     <span class="comment">#对xxl用户授权</span></span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">FLUSH PRIVILEGES;                                    <span class="comment">#刷新权限</span></span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><h4 id="创建XXL-JOB的副本yaml文件"><a href="#创建XXL-JOB的副本yaml文件" class="headerlink" title="创建XXL-JOB的副本yaml文件"></a>创建XXL-JOB的副本yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi xxl-job.yaml</span><br></pre></td></tr></table></figure><ul><li>xxl-job.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">xxl-job</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">xxl-job</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">deployment.kubernetes.io/revision:</span> <span class="string">&#x27;6&#x27;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">xxl-job</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">xxl-job</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">cni.projectcalico.org/ipv4pools:</span> <span class="string">&#x27;[&quot;default-ipv4-ippool&quot;]&#x27;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">container-e0tn05</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;xuxueli/xxl-job-admin:2.3.0&#x27;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-8080</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PARAMS</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">                --spring.datasource.url=jdbc:mysql://mysql.test:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai</span></span><br><span class="line"><span class="string">                --spring.datasource.username=xxl</span></span><br><span class="line"><span class="string">                --spring.datasource.password=P@ssw0rd@xxl</span></span><br><span class="line"><span class="string">                --xxl.job.accessToken=RfCwgzKLuRGbrqqN9Tg9WT3t                #注意修改数据库连接地址端口及用户密码</span></span><br><span class="line"><span class="string"></span>          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;4&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">8000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">          <span class="attr">terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line">          <span class="attr">terminationMessagePolicy:</span> <span class="string">File</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">default</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">default</span></span><br><span class="line">      <span class="attr">securityContext:</span> &#123;&#125;</span><br><span class="line">      <span class="attr">affinity:</span> &#123;&#125;</span><br><span class="line">      <span class="attr">schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">maxUnavailable:</span> <span class="number">25</span><span class="string">%</span></span><br><span class="line">      <span class="attr">maxSurge:</span> <span class="number">25</span><span class="string">%</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">progressDeadlineSeconds:</span> <span class="number">600</span></span><br></pre></td></tr></table></figure><h4 id="创建XXL-JOB的service-yaml文件"><a href="#创建XXL-JOB的service-yaml文件" class="headerlink" title="创建XXL-JOB的service yaml文件"></a>创建XXL-JOB的service yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi xxl-job-service.yaml</span><br></pre></td></tr></table></figure><ul><li>xxl-job-service.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-xxl-job-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-xxl-job-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http-8080</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30850</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-xxl-job</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">externalTrafficPolicy:</span> <span class="string">Cluster</span></span><br></pre></td></tr></table></figure><h4 id="创建XXL-JOB"><a href="#创建XXL-JOB" class="headerlink" title="创建XXL-JOB"></a>创建XXL-JOB</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署xxl_job副本</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl apply -f  xxl-job.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署xxl_job服务svc</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl apply -f  xxl-job-service.yaml</span><br></pre></td></tr></table></figure><h4 id="验证XXL-JOB"><a href="#验证XXL-JOB" class="headerlink" title="验证XXL-JOB"></a>验证XXL-JOB</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看xxl-job的pod</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl get pod -n test</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看xxl-job的svc</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl get svc -n test</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">浏览器访问任一节点ip+30850（nodeport端口）进行验证</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">http://ip:30850/xxl-job-admin/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认用户名/密码 ：admin/123456</span></span><br></pre></td></tr></table></figure><h2 id="k8s部署SkyWalking"><a href="#k8s部署SkyWalking" class="headerlink" title="k8s部署SkyWalking"></a>k8s部署SkyWalking</h2><h3 id="部署步骤-6"><a href="#部署步骤-6" class="headerlink" title="部署步骤"></a>部署步骤</h3><h4 id="创建SkyWalking的配置-yaml文件"><a href="#创建SkyWalking的配置-yaml文件" class="headerlink" title="创建SkyWalking的配置 yaml文件"></a>创建SkyWalking的配置 yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi skywalking-cm.yaml</span><br></pre></td></tr></table></figure><ul><li>skywalking-cm.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">skywalking-cm</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">STORAGE:</span> <span class="string">&#x27;elasticsearch7&#x27;</span></span><br><span class="line">  <span class="attr">STORAGE_ES_CLUSTER_NODES:</span> <span class="string">&#x27;*.*.*.*:9200&#x27;</span>                <span class="comment">#es的连接地址</span></span><br><span class="line">  <span class="attr">ES_USER:</span> <span class="string">&#x27;****&#x27;</span>                                            <span class="comment">#es的用户名</span></span><br><span class="line">  <span class="attr">ES_PASSWORD:</span> <span class="string">&#x27;********&#x27;</span>                                    <span class="comment">#es的密码</span></span><br><span class="line">  <span class="attr">CORE_GRPC_PORT:</span> <span class="string">&#x27;11800&#x27;</span></span><br><span class="line">  <span class="attr">CORE_REST_PORT:</span> <span class="string">&#x27;12800&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="创建SkyWalking的副本-yaml文件"><a href="#创建SkyWalking的副本-yaml文件" class="headerlink" title="创建SkyWalking的副本 yaml文件"></a>创建SkyWalking的副本 yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi skywalking-deployment.yaml</span><br></pre></td></tr></table></figure><ul><li>skywalking-deployment.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">skywalking</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-skywalk-skywalking-oap</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">skywalking</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">skywalking</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">envFrom:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">prefix:</span> <span class="string">SW_</span></span><br><span class="line">            <span class="attr">configMapRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">skywalking-cm</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">apache/skywalking-oap-server:8.7.0-es7</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">skywalking</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">12800</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">11800</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">grpc</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">volume-localtime</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">volume-localtime</span></span><br></pre></td></tr></table></figure><h4 id="创建SkyWalking的service-yaml文件"><a href="#创建SkyWalking的service-yaml文件" class="headerlink" title="创建SkyWalking的service yaml文件"></a>创建SkyWalking的service yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi skywalking-deployment.yaml</span><br></pre></td></tr></table></figure><ul><li>skywalking-service.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-skywalk-skywalking-oap</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">skywalking</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">12800</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">12800</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">grpc</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">11800</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">11800</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">skywalking</span></span><br></pre></td></tr></table></figure><h4 id="创建SkyWalking-ui副本的service-yaml文件"><a href="#创建SkyWalking-ui副本的service-yaml文件" class="headerlink" title="创建SkyWalking-ui副本的service yaml文件"></a>创建SkyWalking-ui副本的service yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi skywalking-ui-service.yaml</span><br></pre></td></tr></table></figure><ul><li>skywalking-ui-service.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">skywalking-ui</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">skywalking-ui</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">skywalking-ui</span></span><br></pre></td></tr></table></figure><h4 id="创建SkyWalking-ui的副本yaml文件"><a href="#创建SkyWalking-ui的副本yaml文件" class="headerlink" title="创建SkyWalking-ui的副本yaml文件"></a>创建SkyWalking-ui的副本yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi skywalking-ui.yaml</span><br></pre></td></tr></table></figure><ul><li>skywalking-ui.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">skywalking-ui</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">skywalking-ui</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">skywalking-ui</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">skywalking-ui</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SW_OAP_ADDRESS</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;skywalking:12800&quot;</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">apache/skywalking-ui:8.9.1</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">skywalking-ui</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;1&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">volume-localtime</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">volume-localtime</span></span><br></pre></td></tr></table></figure><h4 id="部署安装SkyWalking"><a href="#部署安装SkyWalking" class="headerlink" title="部署安装SkyWalking"></a>部署安装SkyWalking</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master01 ~]# kubectl apply -f skywalking-cm.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f skywalking-deployment.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f skywalking-service.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f skywalking-ui-service.yaml</span><br><span class="line">[root@k8s-master01 ~]# kubectl apply -f skywalking-ui.yaml</span><br></pre></td></tr></table></figure><h4 id="验证SkyWalking"><a href="#验证SkyWalking" class="headerlink" title="验证SkyWalking"></a>验证SkyWalking</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看SkyWalking副本</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get pod -n test</span><br><span class="line">NAME                                                  READY   STATUS    RESTARTS   AGE</span><br><span class="line">skywalking-ui-7cb7f68686-4sgtq                        1/1     Running   0          22d</span><br><span class="line">test-skywalk-skywalking-oap-67f6cd45fd-dm7d4          1/1     Running   0          22d</span><br><span class="line">test-skywalk-skywalking-oap-67f6cd45fd-ggg4z          1/1     Running   0          22d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看SkyWalking service</span></span><br><span class="line">[root@k8s-master01 ~]# kubectl get svc -n test </span><br><span class="line">NAME                                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE</span><br><span class="line">skywalking-ui                           NodePort    10.233.16.121   &lt;none&gt;        8080:30849/TCP                        22d</span><br><span class="line">test-skywalk-skywalking-oap             ClusterIP   10.233.12.1     &lt;none&gt;        12800/TCP,11800/TCP                   22d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用浏览器访问任意节点ip+30849（nodeport端口）进行验证</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>参考链接</strong></p></blockquote><ol><li>[Nacos](<a href="https://github.com/nacos-group/nacos-k8s/blob/master/README-CN.md">nacos-k8s&#x2F;README-CN.md at master · nacos-group&#x2F;nacos-k8s · GitHub</a>)</li><li><a href="https://github.com/apache/rocketmq-operator">RocketMQ</a></li><li><a href="https://www.xuxueli.com/xxl-job/">XXL-JOB</a></li><li><a href="https://skywalking.apache.org/">SkyWalking</a></li></ol><blockquote><p><strong>后续</strong></p></blockquote><ol><li>基于KubeSphere的Kubernetes生产实践之路-SpingCloud业务模块的devops自动化部署</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署&quot;&gt;&lt;a href=&quot;#基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构中间件的安装部署&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>持久化存储之GlusterFS</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E4%B9%8BGlusterFS/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E4%B9%8BGlusterFS/</id>
    <published>2023-09-22T01:38:09.617Z</published>
    <updated>2023-09-22T01:45:48.871Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS"><a href="#基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS" class="headerlink" title="基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS"></a>基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS</h1><p>大家好，我是老Z</p><p>本文接着上篇 <strong>&lt;&lt;基于KubeSphere的Kubernetes生产实践之路-起步篇&gt;&gt;</strong> 继续打造我们Kubernetes生产环境。</p><h2 id="前提说明"><a href="#前提说明" class="headerlink" title="前提说明"></a>前提说明</h2><h3 id="Kubernetes使用GlusterFS存储的方式"><a href="#Kubernetes使用GlusterFS存储的方式" class="headerlink" title="Kubernetes使用GlusterFS存储的方式"></a>Kubernetes使用GlusterFS存储的方式</h3><ol><li><p>通过Heketi管理GlusterFS，Kubernetes调用Heketi的接口</p></li><li><p>GlusterFS结合NFS-Ganesha提供NFS存储，Kubernetes采用NFS的方式挂载</p></li><li><p>Kubernetes挂载GlusterFS提供的数据卷到本地的存储目录，Kubernetes采用hostpatch的方式</p></li><li><p>利用KubeSphere初始化安装集群的时候也可以直接使用GlusterFS作为持久化存储，具体操作可以参考<a href="https://kubesphere.io/zh/docs/installing-on-linux/persistent-storage-configurations/install-glusterfs/">安装 GlusterFS</a></p></li></ol><h3 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h3><ol><li><p>本次选型使用的是Heketi的对接方案，使用比较广泛，网上的参考用例比较多，但是该方案也存在一定弊端，各位需要根据自己的情况选择</p><ul><li><p>实现形式在底层创建了一堆的lvs卷(文中有效果展示)，如果卷太多又太小的话，后期运维会比较麻烦，有一定的未知风险。</p></li><li><p>Heketi官方已经停止更新了，项目处于维护状态，这就比较麻烦了，新入坑者慎入</p></li></ul></li><li><p>NFS-Ganesha的方案以前对接ceph的时候使用过，但是当时的稳定度不高，经常出现进程死掉的情况，对接GlusterFS没有测试过</p></li><li><p>作为本地卷挂载的方式，个人认为稳定度和性能上应该是最好的，但是由于是本地盘，使用场景受限，可根据使用需求酌情使用</p></li></ol><h2 id="GlusterFS分布式文件系统介绍"><a href="#GlusterFS分布式文件系统介绍" class="headerlink" title="GlusterFS分布式文件系统介绍"></a>GlusterFS分布式文件系统介绍</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>GlusterFS系统是一个可扩展的网络文件系统，相比其他分布式文件系统，GlusterFS具有高扩展性、高可用性、高性能、可横向扩展等特点，并且其没有元数据服务器的设计，让整个服务没有单点故障的隐患。</p><p>架构图</p><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/glusterfs.jpg"></p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><h4 id="1-无元数据节点性能瓶颈"><a href="#1-无元数据节点性能瓶颈" class="headerlink" title="1. 无元数据节点性能瓶颈"></a>1. 无元数据节点性能瓶颈</h4><ul><li><p>采用无中心对称式架构，没有专用的元数据服务器，也就不存在元数据服务器瓶颈。</p></li><li><p>元数据存在于文件的属性和扩展属性中。当需要访问某文件时，客户端使用DHT算法，根据文件的路径和文件名计算出文件所在brick，然后由客户端从此brick获取数据，省去了同元数据服务器通信的过程。</p></li></ul><h4 id="2-良好的可扩展性"><a href="#2-良好的可扩展性" class="headerlink" title="2. 良好的可扩展性"></a>2. 良好的可扩展性</h4><ul><li>使用弹性hash算法代替传统的有元数据节点服务，获得了接近线性的高扩展性。</li></ul><h4 id="3-高可用"><a href="#3-高可用" class="headerlink" title="3. 高可用"></a>3. 高可用</h4><ul><li><p>采用副本、EC等冗余设计，保证在冗余范围内的节点掉线时，仍然可以从其它服务节点获取数据，保证高可用性。采用弱一致性的设计，当向副本中文件写入数据时，客户端计算出文件所在brick，然后通过网络把数据传给所在brick，当其中有一个成功返回，就认为数据成功写入，不必等待其它brick返回，就会避免当某个节点网络异常或磁盘损坏时因为一个brick没有成功写入而导致写操作等待。</p></li><li><p>服务器端还会随着存储池的启动，而开启一个glustershd进程，这个进程会定期检查副本和EC卷中各个brick之间数据的一致性，并恢复。</p></li></ul><h4 id="4-存储池类型丰富"><a href="#4-存储池类型丰富" class="headerlink" title="4. 存储池类型丰富"></a>4. 存储池类型丰富</h4><p>包括粗粒度、条带、副本、条带副本和EC，可以根据用户的需求，满足不同程度的冗余。</p><ul><li><p>粗粒度卷不带任何冗余，文件不进行切片，是完整的存放在某个brick上。</p></li><li><p>条带卷不带任何冗余，文件会切片存储（默认大小为128kB）在不同的brick上。这些切片可以并发读写（并发粒度是条带块），可以明显提高读写性能。该模式一般只适合用于处理超大型文件和多节点性能要求高的情况。</p></li><li><p>副本卷冗余度高，副本数量可以灵活配置，可以保证数据的安全性。</p></li><li><p>条带副本卷是条带卷和副本卷的结合。</p></li><li><p>EC卷使用EC校验算法，提供了低于副本卷的冗余度，冗余度小于100%，满足比较低的数据安全性，例如可以使2+1（冗余度为50%）、5+3（冗余度为60%）等。这个可以满足安全性要求不高的数据。</p></li></ul><h4 id="5-高性能"><a href="#5-高性能" class="headerlink" title="5. 高性能"></a>5. 高性能</h4><ul><li><p>采用弱一致性的设计，向副本中写数据时，只要有一个brick成功返回，就认为写入成功，不必等待其它brick返回，这样的方式比强一致性要快。</p></li><li><p>还提供了I&#x2F;O并发、write-behind、read-ahead、io-cache、条带等提高读写性能的技术。并且这些都还可以根据实际需求进行开启&#x2F;关闭，i&#x2F;o并发数量，cache大小都可以调整。</p></li></ul><h2 id="Heketi介绍"><a href="#Heketi介绍" class="headerlink" title="Heketi介绍"></a>Heketi介绍</h2><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h3><p>  Heketi提供了RESTful管理接口，可用于管理GlusterFS卷的生命周期。能够在<a href="https://so.csdn.net/so/search?q=OpenStack&spm=1001.2101.3001.7020">OpenStack</a>，Kubernetes，Openshift等云平台上实现动态存储资源供应（动态在GlusterFS集群内选择bricks构建volume）；支持GlusterFS多集群管理。 Heketi的目标是提供一种在多个存储群集中创建，列出和删除GlusterFS卷的简单方法。 Heketi将智能地管理群集中整个磁盘的分配，创建和删除。 在满足任何请求之前，Heketi首先需要了解集群的拓扑（topologies ）也就是需要配置topologies.json文件 。 此json文件将数据资源组织为以下内容：群集、节点、设备的归属、以及块的归属。</p><p>  Heketi-cli命令行工具向Heketi提供要管理的GlusterFS集群的信息。它通过变量<strong>HEKETI_CLI_SERVER</strong>来找自已的服务端。</p><h2 id="总体架构展示"><a href="#总体架构展示" class="headerlink" title="总体架构展示"></a>总体架构展示</h2><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/glusterfs-heketi.png"></p><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h3 id="系统基础配置"><a href="#系统基础配置" class="headerlink" title="系统基础配置"></a>系统基础配置</h3><ol><li>检查操作系统版本并进行内核升级</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# yum update</span><br><span class="line">[root@localhost ~]# cat /etc/redhat-release</span><br><span class="line">CentOS Linux release 7.9.2009 (Core)</span><br></pre></td></tr></table></figure><ol start="2"><li>修改主机名</li></ol><ul><li>节点一</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# hostnamectl set-hostname glusterfs-node-0</span><br><span class="line">[root@localhost ~]# su</span><br><span class="line">[root@glusterfs-node-0 ~]#</span><br></pre></td></tr></table></figure><ul><li>节点二</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# hostnamectl set-hostname glusterfs-node-1</span><br><span class="line">[root@localhost ~]# su</span><br><span class="line">[root@glusterfs-node-1 ~]#</span><br></pre></td></tr></table></figure><ul><li>节点三</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# hostnamectl set-hostname glusterfs-node-2</span><br><span class="line">[root@localhost ~]# su</span><br><span class="line">[root@glusterfs-node-2 ~]#</span><br></pre></td></tr></table></figure><ol start="3"><li>关闭防火墙及selinux(所有节点执行)</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭防火墙开机自启</span></span><br><span class="line">[root@glusterfs-node-0 ~]# systemctl disable firewalld</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">临时关闭防火墙</span></span><br><span class="line">[root@glusterfs-node-0 ~]# systemctl stop firewalld</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">永久关闭selinux</span></span><br><span class="line">[root@glusterfs-node-0 ~]# sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27; /etc/selinux/config</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">临时关闭selinux</span></span><br><span class="line">[root@glusterfs-node-0 ~]# setenforce 0</span><br></pre></td></tr></table></figure><h3 id="安装配置GLusterFS"><a href="#安装配置GLusterFS" class="headerlink" title="安装配置GLusterFS"></a>安装配置GLusterFS</h3><ol><li>配置glusterfs的yum源(所有节点执行)</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# vi /etc/yum.repos.d/glusterfs.repo</span><br><span class="line"></span><br><span class="line">[glusterfs]</span><br><span class="line">name=glusterfs</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/7.9.2009/storage/x86_64/gluster-9/</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">gpgkey=https://mirrors.tuna.tsinghua.edu.cn/centos/RPM-GPG-KEY-CentOS-7</span></span><br><span class="line">gpgcheck=0</span><br><span class="line">ebabled=1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">清除yum缓存</span></span><br><span class="line">[root@glusterfs-node-0 ~]# yum clean all</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">生成yum缓存</span></span><br><span class="line">[root@glusterfs-node-0 ~]# yum makecache</span><br></pre></td></tr></table></figure><ol start="2"><li>安装glusterfs(三个节点执行)</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# yum install centos-release-gluster glusterfs-server glusterfs-client -y </span><br></pre></td></tr></table></figure><ol start="3"><li>启动glusterfs服务</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]#  systemctl start glusterd.service &amp;&amp; systemctl enable glusterd.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看glusterfs服务状态</span></span><br><span class="line">[root@glusterfs-node-0 ~]# systemctl status glusterd.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看glusterfs服务端口</span></span><br><span class="line">[root@glusterfs-node-0 ~]# ss -lntp | grep glusterd</span><br><span class="line">LISTEN     0      128          *:24007                    *:*                   users:((&quot;glusterd&quot;,pid=108776,fd=10))</span><br></pre></td></tr></table></figure><h3 id="配置glusterfs集群节点"><a href="#配置glusterfs集群节点" class="headerlink" title="配置glusterfs集群节点"></a>配置glusterfs集群节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# gluster peer probe glusterfs-node-1</span><br><span class="line">peer probe: success</span><br><span class="line">[root@glusterfs-node-0 ~]# gluster peer probe glusterfs-node-2</span><br><span class="line">peer probe: success</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群节点信息</span></span><br><span class="line">[root@glusterfs-node-0 ~]# gluster peer status</span><br><span class="line">Number of Peers: 2</span><br><span class="line"></span><br><span class="line">Hostname: glusterfs-node-1</span><br><span class="line">Uuid: 50a3da37-9f0f-49c7-aae4-e4a475beecc9</span><br><span class="line">State: Peer in Cluster (Connected)</span><br><span class="line"></span><br><span class="line">Hostname: glusterfs-node-2</span><br><span class="line">Uuid: da245e40-52a7-4651-b44b-8222c237f192</span><br><span class="line">State: Peer in Cluster (Connected)</span><br></pre></td></tr></table></figure><h3 id="安装配置Heketi（任选一节点-这里选择节点一）"><a href="#安装配置Heketi（任选一节点-这里选择节点一）" class="headerlink" title="安装配置Heketi（任选一节点,这里选择节点一）"></a>安装配置Heketi（任选一节点,这里选择节点一）</h3><ol><li>安装软件包</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# yum install heketi heketi-client -y </span><br></pre></td></tr></table></figure><ol start="2"><li>heketi服务必要配置</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成密钥并配置免密登录</span></span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh-keygen -t rsa -q -f /etc/heketi/private_key -N &quot;&quot;</span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh-copy-id -i /etc/heketi/private_key.pub glusterfs-node-0</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/etc/heketi/private_key.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;glusterfs-node-0&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh-copy-id -i /etc/heketi/private_key.pub glusterfs-node-1</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/etc/heketi/private_key.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;glusterfs-node-1&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh-copy-id -i /etc/heketi/private_key.pub glusterfs-node-2</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/etc/heketi/private_key.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;glusterfs-node-2&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">测试免密登录</span></span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh glusterfs-node-0</span><br><span class="line">Last login: Wed Mar  2 09:12:30 2022</span><br><span class="line">[root@glusterfs-node-0 ~]$ exit</span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh glusterfs-node-1</span><br><span class="line">Last login: Wed Mar  2 09:12:30 2022</span><br><span class="line">[root@glusterfs-node-1 ~]$ exit</span><br><span class="line">[root@glusterfs-node-0 ~]$ ssh glusterfs-node-2</span><br><span class="line">Last login: Wed Mar  2 09:12:30 2022</span><br><span class="line">[root@glusterfs-node-2 ~]$ exit</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改目录权限</span></span><br><span class="line">[root@glusterfs-node-0 ~]# chown heketi:heketi /etc/heketi/ -R</span><br><span class="line">[root@glusterfs-node-0 ~]# chown heketi:heketi /var/lib/heketi -R</span><br><span class="line">[root@glusterfs-node-0 ~]# chown heketi.heketi /etc/heketi/private_key</span><br></pre></td></tr></table></figure><h3 id="编写heketi配置文件"><a href="#编写heketi配置文件" class="headerlink" title="编写heketi配置文件"></a>编写heketi配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改heketi的配置文件</span></span><br><span class="line">[root@glusterfs-node-0 ~]# vi /etc/heketi/heketi.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_port_comment&quot;: &quot;Heketi Server Port Number&quot;,</span><br><span class="line">  &quot;port&quot;: &quot;48080&quot;,               #######heketi服务端口可以自定义</span><br><span class="line"></span><br><span class="line">  &quot;_use_auth&quot;: &quot;Enable JWT authorization. Please enable for deployment&quot;,</span><br><span class="line">  &quot;use_auth&quot;: true,              ########启动用户认证模式</span><br><span class="line"></span><br><span class="line">  &quot;_jwt&quot;: &quot;Private keys for access&quot;,</span><br><span class="line">  &quot;jwt&quot;: &#123;</span><br><span class="line">    &quot;_admin&quot;: &quot;Admin has access to all APIs&quot;,</span><br><span class="line">    &quot;admin&quot;: &#123;</span><br><span class="line">      &quot;key&quot;: &quot;admin@P@ssW0rd&quot;          ######heketi所有接口权限admin用户的密码</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;_user&quot;: &quot;User only has access to /volumes endpoint&quot;,</span><br><span class="line">    &quot;user&quot;: &#123;</span><br><span class="line">      &quot;key&quot;: &quot;user@P@ssW0rd&quot;           #####heketi仅仅对卷相关API有权限的user用户密码</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  &quot;_glusterfs_comment&quot;: &quot;GlusterFS Configuration&quot;,</span><br><span class="line">  &quot;glusterfs&quot;: &#123;</span><br><span class="line">    &quot;_executor_comment&quot;: [</span><br><span class="line">      &quot;Execute plugin. Possible choices: mock, ssh&quot;,</span><br><span class="line">      &quot;mock: This setting is used for testing and development.&quot;,</span><br><span class="line">      &quot;      It will not send commands to any node.&quot;,</span><br><span class="line">      &quot;ssh:  This setting will notify Heketi to ssh to the nodes.&quot;,</span><br><span class="line">      &quot;      It will need the values in sshexec to be configured.&quot;,</span><br><span class="line">      &quot;kubernetes: Communicate with GlusterFS containers over&quot;,</span><br><span class="line">      &quot;            Kubernetes exec api.&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;executor&quot;: &quot;ssh&quot;,              #########配置heketi使用ssh认证模式</span><br><span class="line"></span><br><span class="line">    &quot;_sshexec_comment&quot;: &quot;SSH username and private key file information&quot;,</span><br><span class="line">    &quot;sshexec&quot;: &#123;</span><br><span class="line">      &quot;keyfile&quot;: &quot;/etc/heketi/private_key&quot;,          #######heketi使用主机用户的认证密钥文件</span><br><span class="line">      &quot;user&quot;: &quot;root&quot;,                                  ########heketi使用主机的用户root</span><br><span class="line">      &quot;port&quot;: &quot;22&quot;,                                     ######主机的ssh服务端口</span><br><span class="line">      &quot;fstab&quot;: &quot;/etc/fstab&quot;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    &quot;_kubeexec_comment&quot;: &quot;Kubernetes configuration&quot;,</span><br><span class="line">    &quot;kubeexec&quot;: &#123;</span><br><span class="line">      &quot;host&quot; :&quot;https://kubernetes.host:8443&quot;,</span><br><span class="line">      &quot;cert&quot; : &quot;/path/to/crt.file&quot;,</span><br><span class="line">      &quot;insecure&quot;: false,</span><br><span class="line">      &quot;user&quot;: &quot;kubernetes username&quot;,</span><br><span class="line">      &quot;password&quot;: &quot;password for kubernetes user&quot;,</span><br><span class="line">      &quot;namespace&quot;: &quot;OpenShift project or Kubernetes namespace&quot;,</span><br><span class="line">      &quot;fstab&quot;: &quot;Optional: Specify fstab file on node.  Default is /etc/fstab&quot;</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    &quot;_db_comment&quot;: &quot;Database file name&quot;,</span><br><span class="line">    &quot;db&quot;: &quot;/var/lib/heketi/heketi.db&quot;,       #####heketi数据存储文件</span><br><span class="line"></span><br><span class="line">    &quot;_loglevel_comment&quot;: [</span><br><span class="line">      &quot;Set log level. Choices are:&quot;,</span><br><span class="line">      &quot;  none, critical, error, warning, info, debug&quot;,</span><br><span class="line">      &quot;Default is warning&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;loglevel&quot; : &quot;debug&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启动heketi服务</span></span><br><span class="line">[root@glusterfs-node-0 ~]# systemctl enable heketi.service &amp;&amp; systemctl start heketi.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看服务状态</span></span><br><span class="line">[root@glusterfs-node-0 ~]# systemctl status heketi</span><br><span class="line">● heketi.service - Heketi Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/heketi.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Wed 2022-03-02 12:02:59 IST; 14min ago</span><br><span class="line"> Main PID: 120229 (heketi)</span><br><span class="line">   CGroup: /system.slice/heketi.service</span><br><span class="line">           └─120229 /usr/bin/heketi --config=/etc/heketi/heketi.json</span><br><span class="line"></span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: Main PID: 234479 (glusterd)</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: Tasks: 9</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: Memory: 6.0M</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: CGroup: /system.slice/glusterd.service</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: └─234479 /usr/sbin/glusterd -p /var/run/glusterd.pid --log-level INFO</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: Mar 02 13:52:19 glusterfs-node-2 systemd[1]: Starting GlusterFS, a clustered file-system server...</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: Mar 02 13:52:19 glusterfs-node-2 systemd[1]: Started GlusterFS, a clustered file-system server.</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: ]: Stderr []</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: [heketi] INFO 2022/03/02 12:17:01 Periodic health check status: node cf3ad692cc008e697eb68f2863843391 up=true</span><br><span class="line">Mar 02 12:17:01 glusterfs-node-0 heketi[120229]: [heketi] INFO 2022/03/02 12:17:01 Cleaned 0 nodes from health cache</span><br></pre></td></tr></table></figure><h3 id="配置topology"><a href="#配置topology" class="headerlink" title="配置topology"></a>配置topology</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# vi /etc/heketi/topology.json #配置三个节点的使用信息，这里/dev/db表示后端存储所要使用的数据盘</span><br><span class="line">&#123;</span><br><span class="line">    &quot;clusters&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;nodes&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;192.168.10.1&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;192.168.10.1&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/sdb&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;192.168.10.2&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;192.168.10.2&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/sdb&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;192.168.10.3&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;192.168.10.3&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/sdb&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置环境变量，便于后续管理"><a href="#配置环境变量，便于后续管理" class="headerlink" title="配置环境变量，便于后续管理"></a>配置环境变量，便于后续管理</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# echo &quot;export HEKETI_CLI_SERVER=http://192.168.10.1:48080&quot; &gt;&gt; /etc/profile.d/heketi.sh </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">192.168.10.1为heketi地址</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">--user指定的用户为heketi配置文件中配置的admin用户--secret指定的密码为heketi配置文件中配置的admin密码</span></span><br><span class="line">[root@glusterfs-node-0 ~]# echo &quot;alias heketi-cli=&#x27;heketi-cli --server &#x27;$HEKETI_CLI_SERVER&#x27; --user admin --secret admin@P@ssW0rd&#x27;&quot; &gt;&gt; ~/.bashrc </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">加载环境变量</span></span><br><span class="line">[root@glusterfs-node-0 ~]# source /etc/profile.d/heketi.sh</span><br><span class="line">[root@glusterfs-node-0 ~]# source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="根据topology-json来创建集群"><a href="#根据topology-json来创建集群" class="headerlink" title="根据topology.json来创建集群"></a>根据topology.json来创建集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建集群</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli topology load --json=/etc/heketi/topology.json</span><br><span class="line">        Found node 192.168.10.1 on cluster b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">                Adding device /dev/sdb ... OK</span><br><span class="line">        Found node 192.168.10.2 on cluster b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">                Adding device /dev/sdb ... OK</span><br><span class="line">        Found node 192.168.10.3 on cluster b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">                Adding device /dev/sdb ... OK</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看集群列表</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli cluster list</span><br><span class="line">Clusters:</span><br><span class="line">Id:b89a07c2c6e8c533322591bf2a4aa613 [file][block]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看集群详情，此命令用到的<span class="built_in">id</span>为查看集群状态时返回的<span class="built_in">id</span></span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli cluster info b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">Cluster id: b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">Nodes:</span><br><span class="line">1218c773299856ebaef6f2461051640c</span><br><span class="line">8bffed2d55f652a412c098ee31246559</span><br><span class="line">cf3ad692cc008e697eb68f2863843391</span><br><span class="line">Volumes:</span><br><span class="line"></span><br><span class="line">Block: true</span><br><span class="line"></span><br><span class="line">File: true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看集群节点</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node list</span><br><span class="line">Id:1218c773299856ebaef6f2461051640c     Cluster:b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">Id:8bffed2d55f652a412c098ee31246559     Cluster:b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">Id:cf3ad692cc008e697eb68f2863843391     Cluster:b89a07c2c6e8c533322591bf2a4aa613</span><br></pre></td></tr></table></figure><h3 id="创建集群时报错解决办法"><a href="#创建集群时报错解决办法" class="headerlink" title="创建集群时报错解决办法"></a>创建集群时报错解决办法</h3><p>如果数据盘不是新盘曾经被使用过，创建集群时会报错，可按下面的方法处理</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli topology load --json=/etc/heketi/topology.json</span><br><span class="line">Creating cluster ... ID: b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">        Allowing file volumes on cluster.</span><br><span class="line">        Allowing block volumes on cluster.</span><br><span class="line">        Creating node 10.4.11.38 ... ID: 8bffed2d55f652a412c098ee31246559</span><br><span class="line">                Adding device /dev/sdb ... Unable to add device: Setup of device /dev/sdb failed (already initialized or contains data?):   Can&#x27;t initialize physical volume &quot;/dev/sdb&quot; of volume group &quot;vg_423c25b95cf33cb94fa192aedd325b26&quot; without -ff</span><br><span class="line">  /dev/sdb: physical volume not initialized.</span><br><span class="line">        Creating node 10.4.11.39 ... ID: 1218c773299856ebaef6f2461051640c</span><br><span class="line">                Adding device /dev/sdb ... Unable to add device: Setup of device /dev/sdb failed (already initialized or contains data?):   Can&#x27;t initialize physical volume &quot;/dev/sdb&quot; of volume group &quot;vg_564e3fb62e748f1451f387deb469541e&quot; without -ff</span><br><span class="line">  /dev/sdb: physical volume not initialized.</span><br><span class="line">        Creating node 10.4.11.40 ... ID: cf3ad692cc008e697eb68f2863843391</span><br><span class="line">                Adding device /dev/sdb ... Unable to add device: Setup of device /dev/sdb failed (already initialized or contains data?):   Can&#x27;t initialize physical volume &quot;/dev/sdb&quot; of volume group &quot;vg_5bc298db6e8cc335d545c96eed7150f0&quot; without -ff</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">所有glusterfs节点执行</span></span><br><span class="line">[root@glusterfs-node-0 ~]# mkfs.xfs -f /dev/sdb</span><br><span class="line">meta-data=/dev/sdb               isize=512    agcount=4, agsize=183105408 blks</span><br><span class="line">         =                       sectsz=4096  attr=2, projid32bit=1</span><br><span class="line">         =                       crc=1        finobt=0, sparse=0</span><br><span class="line">data     =                       bsize=4096   blocks=732421632, imaxpct=5</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br><span class="line">log      =internal log           bsize=4096   blocks=357627, version=2</span><br><span class="line">         =                       sectsz=4096  sunit=1 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br><span class="line">[root@glusterfs-node-0 ~]# pvcreate -ff --metadatasize=128M --dataalignment=256K /dev/sdb</span><br><span class="line">  Wiping xfs signature on /dev/sdb.</span><br><span class="line">  Physical volume &quot;/dev/sdb&quot; successfully created.</span><br></pre></td></tr></table></figure><h3 id="验证测试"><a href="#验证测试" class="headerlink" title="验证测试"></a>验证测试</h3><ol><li><p>创建卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli volume create --size=2 --replica=3</span><br><span class="line">Name: vol_aa8a1280b5133a36b32cf552ec9dd3f3</span><br><span class="line">Size: 2</span><br><span class="line">Volume Id: aa8a1280b5133a36b32cf552ec9dd3f3</span><br><span class="line">Cluster Id: b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">Mount: 192.168.10.2:vol_aa8a1280b5133a36b32cf552ec9dd3f3</span><br><span class="line">Mount Options: backup-volfile-servers=192.168.10.1,192.168.10.3</span><br><span class="line">Block: false</span><br><span class="line">Free Size: 0</span><br><span class="line">Reserved Size: 0</span><br><span class="line">Block Hosting Restriction: (none)</span><br><span class="line">Block Volumes: []</span><br><span class="line">Durability Type: replicate</span><br><span class="line">Distribute Count: 1</span><br><span class="line">Replica Count: 3</span><br></pre></td></tr></table></figure></li><li><p>查看卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看卷</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli volume list</span><br><span class="line">Id:aa8a1280b5133a36b32cf552ec9dd3f3    Cluster:b89a07c2c6e8c533322591bf2a4aa613    Name:vol_aa8a1280b5133a36b32cf552ec9dd3f</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">挂载测试，下列命令中的192.168.10.2:vol_aa8a1280b5133a36b32cf552ec9dd3f3为上方创建卷时Mount的返回值，可以用heketi-cli volum info 卷<span class="built_in">id</span>进行查看</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# mount -t glusterfs 192.168.10.2:vol_aa8a1280b5133a36b32cf552ec9dd3f3 /mnt</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看挂载详情</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# df -h</span><br><span class="line">Filesystem                                                                              Size  Used Avail Use% Mounted on</span><br><span class="line">.............................</span><br><span class="line">192.168.10.2:vol_aa8a1280b5133a36b32cf552ec9dd3f3                                       2.0G   54M  2.0G   3% /mnt</span><br></pre></td></tr></table></figure></li><li><p>节点详细信息查看</p><p>可以看出底层vg和lv的创建详情，了解底层的分配细节</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#节点一</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看节点创建出的pv</span></span><br><span class="line">[root@glusterfs-node-0 ~]# pvdisplay</span><br><span class="line"></span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdb</span><br><span class="line">  VG Name               vg_10a23554385cca32a01d7fc3373faf2d</span><br><span class="line">  PV Size               &lt;2.73 TiB / not usable 130.00 MiB</span><br><span class="line">  Allocatable           yes</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              715223</span><br><span class="line">  Free PE              714705</span><br><span class="line">  Allocated PE          518</span><br><span class="line">  PV UUID               mkDi5V-JHnR-xy2Y-5FcW-2JKg-K9dQ-JeXQCF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看节点创建出的vg</span></span><br><span class="line">[root@glusterfs-node-0 ~]# vgdisplay</span><br><span class="line"></span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               vg_10a23554385cca32a01d7fc3373faf2d</span><br><span class="line">  System ID</span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        1</span><br><span class="line">  Metadata Sequence No  22</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                2</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                1</span><br><span class="line">  Act PV                1</span><br><span class="line">  VG Size               &lt;2.73 TiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              715223</span><br><span class="line">  Alloc PE / Size       518 / 2.02 GiB</span><br><span class="line">  Free  PE / Size       714705 / &lt;2.73 TiB</span><br><span class="line">  VG UUID               BzMbsL-FiPz-oVZO-j6o1-Du67-N094-JIbdPB</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看节点创建出的lv</span></span><br><span class="line">[root@glusterfs-node-0 ~]# lvdisplay</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_8b932b033db44bf8d6b202ec3cd9b6f3</span><br><span class="line">  VG Name                vg_10a23554385cca32a01d7fc3373faf2d</span><br><span class="line">  LV UUID                hesO25-OdId-1eYo-OLVc-Phe8-3Y3L-z0RcsH</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-0, 2022-03-03 07:21:30 +0530</span><br><span class="line">  LV Pool metadata       tp_8b932b033db44bf8d6b202ec3cd9b6f3_tmeta</span><br><span class="line">  LV Pool data           tp_8b932b033db44bf8d6b202ec3cd9b6f3_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Allocated pool data    0.70%</span><br><span class="line">  Allocated metadata     10.32%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:6</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_10a23554385cca32a01d7fc3373faf2d/brick_8b932b033db44bf8d6b202ec3cd9b6f3</span><br><span class="line">  LV Name                brick_8b932b033db44bf8d6b202ec3cd9b6f3</span><br><span class="line">  VG Name                vg_10a23554385cca32a01d7fc3373faf2d</span><br><span class="line">  LV UUID                VpkvpB-cmQo-jYgf-g83G-XA8C-1yxG-gAXksl</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-0, 2022-03-03 07:21:30 +0530</span><br><span class="line">  LV Pool name           tp_8b932b033db44bf8d6b202ec3cd9b6f3</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Mapped size            0.70%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:8</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#节点二</span></span></span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-1 ~]# pvdisplay</span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdb</span><br><span class="line">  VG Name               vg_c74562fedbcf8ea46923918cf3ac8958</span><br><span class="line">  PV Size               &lt;2.73 TiB / not usable 130.00 MiB</span><br><span class="line">  Allocatable           yes</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              715223</span><br><span class="line">  Free PE               714705</span><br><span class="line">  Allocated PE          518</span><br><span class="line">  PV UUID               cyZ6Ur-HIiQ-tREG-Ueb9-ZKBK-4Wkx-Pgc7FE</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-1 ~]# lvdisplay</span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_0524f0ec9f3ab36e11a06320c6a1afa2</span><br><span class="line">  VG Name                vg_c74562fedbcf8ea46923918cf3ac8958</span><br><span class="line">  LV UUID                jpG0fi-SvNf-Tufz-IEn8-VSBi-ChTf-t54IEN</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-1, 2022-03-03 07:20:45 +0530</span><br><span class="line">  LV Pool metadata       tp_0524f0ec9f3ab36e11a06320c6a1afa2_tmeta</span><br><span class="line">  LV Pool data           tp_0524f0ec9f3ab36e11a06320c6a1afa2_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Allocated pool data    0.70%</span><br><span class="line">  Allocated metadata     10.32%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:6</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_c74562fedbcf8ea46923918cf3ac8958/brick_7bb72d28b432248bcf9de23346d9ea3d</span><br><span class="line">  LV Name                brick_7bb72d28b432248bcf9de23346d9ea3d</span><br><span class="line">  VG Name                vg_c74562fedbcf8ea46923918cf3ac8958</span><br><span class="line">  LV UUID                gsvc2l-JDHA-0L0e-oeNE-N0hY-p1Zd-aGAXo4</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-1, 2022-03-03 07:20:45 +0530</span><br><span class="line">  LV Pool name           tp_0524f0ec9f3ab36e11a06320c6a1afa2</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Mapped size            0.70%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:8</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-1 ~]# vgdisplay</span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               vg_c74562fedbcf8ea46923918cf3ac8958</span><br><span class="line">  System ID</span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        1</span><br><span class="line">  Metadata Sequence No  22</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                2</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                1</span><br><span class="line">  Act PV                1</span><br><span class="line">  VG Size               &lt;2.73 TiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              715223</span><br><span class="line">  Alloc PE / Size       518 / 2.02 GiB</span><br><span class="line">  Free  PE / Size       714705 / &lt;2.73 TiB</span><br><span class="line">  VG UUID               ImSA9l-xtcY-q1ol-ERmA-kDtc-xGs5-6MIgNW</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#节点三</span></span></span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-2 ~]# pvdisplay</span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdb</span><br><span class="line">  VG Name               vg_96fce8c076ca08f24c256e12e8cbbde0</span><br><span class="line">  PV Size               &lt;2.73 TiB / not usable 130.00 MiB</span><br><span class="line">  Allocatable           yes</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              715223</span><br><span class="line">  Free PE               714705</span><br><span class="line">  Allocated PE          518</span><br><span class="line">  PV UUID               cA2GW7-1EoO-w00U-8OKT-qZtF-J7xK-dRaqwd</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-2 ~]# vgdisplay</span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               vg_96fce8c076ca08f24c256e12e8cbbde0</span><br><span class="line">  System ID</span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        1</span><br><span class="line">  Metadata Sequence No  22</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                2</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                1</span><br><span class="line">  Act PV                1</span><br><span class="line">  VG Size               &lt;2.73 TiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              715223</span><br><span class="line">  Alloc PE / Size       518 / 2.02 GiB</span><br><span class="line">  Free  PE / Size       714705 / &lt;2.73 TiB</span><br><span class="line">  VG UUID               PbEPjn-8zn6-wQjF-1Uvq-qaTv-aQ1J-BJFtZu</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-2 ~]# lvdisplay</span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_be0ace1a68127b0537199b654c521b2b</span><br><span class="line">  VG Name                vg_96fce8c076ca08f24c256e12e8cbbde0</span><br><span class="line">  LV UUID                nETAXU-HVYn-JZHq-afwh-2W74-YMZ4-m26xyw</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-2, 2022-03-03 09:51:14 +0800</span><br><span class="line">  LV Pool metadata       tp_be0ace1a68127b0537199b654c521b2b_tmeta</span><br><span class="line">  LV Pool data           tp_be0ace1a68127b0537199b654c521b2b_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Allocated pool data    0.70%</span><br><span class="line">  Allocated metadata     10.32%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:6</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_96fce8c076ca08f24c256e12e8cbbde0/brick_be0ace1a68127b0537199b654c521b2b</span><br><span class="line">  LV Name                brick_be0ace1a68127b0537199b654c521b2b</span><br><span class="line">  VG Name                vg_96fce8c076ca08f24c256e12e8cbbde0</span><br><span class="line">  LV UUID                yXhTeX-4r7D-5rcE-rqKw-8NZb-z158-fchMLq</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-2, 2022-03-03 09:51:15 +0800</span><br><span class="line">  LV Pool name           tp_be0ace1a68127b0537199b654c521b2b</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Mapped size            0.70%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     256</span><br><span class="line">  Block device           253:8</span><br></pre></td></tr></table></figure></li><li><p>删除卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli volume delete 951523a39e6d926764984279dbd7e4bc</span><br></pre></td></tr></table></figure></li></ol><h2 id="k8s集群的调用（两种方式）"><a href="#k8s集群的调用（两种方式）" class="headerlink" title="k8s集群的调用（两种方式）"></a>k8s集群的调用（两种方式）</h2><h3 id="命令行手动配置-方式一"><a href="#命令行手动配置-方式一" class="headerlink" title="命令行手动配置(方式一)"></a>命令行手动配置(方式一)</h3><ol><li>所有的k8s节点均安装glusterfs客户端，以保证正常挂载</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# yum install glusterfs-fuse -y</span><br></pre></td></tr></table></figure><ol start="2"><li>创建secret，heketi的认证密码,或者在kebesphere平台添加密钥,key的值,使用base64转码生成<code>echo -n &quot;admin@P@ssW0rd&quot; | base64</code> 这里的用户名密码为heketi配置文件中创建的用户密码</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi heketi_secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: heketi-secret</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  key: YWRtaW5AUEBzc1cwcmQ=</span><br><span class="line">type: kubernetes.io/glusterfs</span><br><span class="line">[root@k8s-master-1 ~]# kubectl apply -f heketi_secret.yaml</span><br></pre></td></tr></table></figure><ol start="3"><li>创建storageclass</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi heketi-storageclass.yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: glusterfs</span><br><span class="line">  namespace: kube-system</span><br><span class="line">parameters:</span><br><span class="line">  resturl: &quot;http://192.168.10.1:48080&quot;     #heketi的地址</span><br><span class="line">  clusterid: &quot;b89a07c2c6e8c533322591bf2a4aa613&quot;  #在heketi节点使用heketi-cli cluster list命令返回的集群id</span><br><span class="line">  restauthenabled: &quot;true&quot; </span><br><span class="line">  restuser: &quot;admin&quot; #heketi配置文件中创建的用户密</span><br><span class="line">  secretName: &quot;heketi-secret&quot; #与secret资源中定义一致</span><br><span class="line">  secretNamespace: &quot;kube-system&quot; #与secret资源中定义一致</span><br><span class="line">  volumetype: &quot;replicate:3&quot; </span><br><span class="line">provisioner: kubernetes.io/glusterfs</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">[root@k8s-master-1 ~]# kubectl apply -f heketi-storageclass.yaml</span><br></pre></td></tr></table></figure><ol start="4"><li>创建pvc测试</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# vi heketi-pvc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: heketi-pvc</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/glusterfs</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: &quot;glusterfs&quot;</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">[root@k8s-master-1 ~]# kubectl apply -f heketi-pvc.yaml</span><br></pre></td></tr></table></figure><ol start="5"><li>查看sc和pvc的信息</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# kubectl get sc</span><br><span class="line">[root@k8s-master-1 ~]# kubectl get pvc</span><br></pre></td></tr></table></figure><ol start="6"><li>创建Pod挂载pvc</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">root@k8s-master-1</span> <span class="string">~</span>]<span class="comment"># vi heketi-pod.yaml</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">heketi-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">heketi-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;3600&quot;</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">heketi-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&quot;/pv-data&quot;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">heketi-volume</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">heketi-pvc</span></span><br><span class="line">[<span class="string">root@k8s-master-1</span> <span class="string">~</span>]<span class="comment"># kubectl apply -f  heketi-pod.yaml</span></span><br></pre></td></tr></table></figure><ol start="7"><li>查看POD状态,若状态为runing，则挂载成功</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-1 ~]# kubectl get pod</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">heketi-pod                         1/1     Running   0          4s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">清理测试pod</span></span><br><span class="line">[root@k8s-master-1 ~]# kubectl delete -f  heketi-pod.yaml</span><br></pre></td></tr></table></figure><h3 id="kubesphere界面配置-方式二"><a href="#kubesphere界面配置-方式二" class="headerlink" title="kubesphere界面配置(方式二)"></a>kubesphere界面配置(方式二)</h3><ol><li>创建密钥</li></ol><ul><li><p>平台管理-&gt;配置中心-&gt;密钥-&gt;创建</p></li><li><p>名称：heketi-secret</p></li><li><p>项目：kube-system</p></li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-0.jpg"></p><ul><li>类型选择默认</li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-1.jpg"></p><ul><li><p>键：key</p></li><li><p>值：YWRtaW5AUEBzc1cwcmQ&#x3D;</p></li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-2.jpg"></p><ol start="2"><li>创建存储类型</li></ol><ul><li>存储名称：glusterfs</li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-3.jpg"></p><ul><li>存储类型：glusterfs</li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-4.jpg"></p><ul><li><p>创建存储类型的详细信息</p><ul><li><p>允许    存储卷扩容：是</p></li><li><p>支持的访问模式：ReadWriteOnce、ReadOnlyMany、ReadWriteMany</p></li><li><p>存储系统：kubernetes.io&#x2F;glusterfs</p></li><li><p>resturl：192.168.10.1:48080 （heketi的访问地址）</p></li><li><p>clusterid：b89a07c2c6e8c533322591bf2a4aa613（heketi-cli cluster list命令返回的集群id ）</p></li><li><p>restauthenabled：true</p></li><li><p>restuser：admin (heketi服务的admin用户)</p></li><li><p>secretNamespace：kube-system</p></li><li><p>secretName：heketi-secret （上方创建的secert名称）</p></li><li><p>volumetype：replicate:3</p></li></ul></li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-5.jpg"></p><ul><li>查看存储类型是否创建成功</li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-6.jpg"></p><ol start="3"><li>创建存储卷进行测试</li></ol><ul><li><p>名称：test （可自定义）</p></li><li><p>项目：kube-system （可自定义）</p></li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-7.jpg"></p><ul><li>存储类型选择glusterfs</li></ul><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-8.jpg"></p><ol start="4"><li>状态为准备就绪即为成功</li></ol><p><img src="https://gitee.com/zdevops/res/raw/main/cloudnative/glusterfs/kubesphere-glusterfs-9.jpg"></p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol><li><p><a href="https://www.gluster.org/">GlusterFS</a></p></li><li><p><a href="https://github.com/heketi/heketi">https://github.com/heketi/heketi</a></p></li></ol><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><ol><li>基于KubeSphere的Kubernetes生产实践之路-SpingCloud架构依赖的中间件的安装部署</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS&quot;&gt;&lt;a href=&quot;#基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS&quot; class=&quot;headerlink&quot; title=&quot;基于</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes生产实践之路-起步篇</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/Kubernetes%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF-%E8%B5%B7%E6%AD%A5%E7%AF%87/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-prod-practices/Kubernetes%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B9%8B%E8%B7%AF-%E8%B5%B7%E6%AD%A5%E7%AF%87/</id>
    <published>2023-09-22T01:38:09.583Z</published>
    <updated>2023-09-22T01:45:28.021Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于KubeSphere的Kubernetes生产实践之路-起步篇"><a href="#基于KubeSphere的Kubernetes生产实践之路-起步篇" class="headerlink" title="基于KubeSphere的Kubernetes生产实践之路-起步篇"></a>基于KubeSphere的Kubernetes生产实践之路-起步篇</h1><h2 id="前提说明"><a href="#前提说明" class="headerlink" title="前提说明"></a>前提说明</h2><p>本系列文档适用于中小规模(&lt;&#x3D;50)的Kubernetes生产环境，大型环境没有经验，有待验证</p><p>所有节点采用云上虚拟机的方式部署</p><p>本系列文档没考虑k8s安全配置，安全要求高的环境不适用，后续会补充完善</p><p>本系列文档属于实践之路上的积累，会不断根据线上遇到的问题进行优化改进</p><p>本系列文档基于KubeSphere部署的Kubernetes，后续的很多功能实现都依托于KubeSphere</p><p>本系列文档涉及的Ansible代码可以在<a href>https://gitee.com/zdevops/cloudnative</a>获取</p><h2 id="KubeSphere简介"><a href="#KubeSphere简介" class="headerlink" title="KubeSphere简介"></a><a href="https://kubesphere.io/zh/">KubeSphere简介</a></h2><h3 id="全栈的-Kubernetes-容器云-PaaS-解决方案"><a href="#全栈的-Kubernetes-容器云-PaaS-解决方案" class="headerlink" title="全栈的 Kubernetes 容器云 PaaS 解决方案"></a>全栈的 Kubernetes 容器云 PaaS 解决方案</h3><p>KubeSphere 是在 Kubernetes 之上构建的以应用为中心的多租户容器平台，提供全栈的 IT 自动化运维的能力，简化企业的<br>DevOps 工作流。KubeSphere 提供了运维友好的向导式操作界面，帮助企业快速构建一个强大和功能丰富的容器云平台。</p><ol><li><p>完全开源</p><p>通过 CNCF 一致性认证的 Kubernetes 平台，100% 开源，由社区驱动与开发</p></li><li><p>简易安装</p><p>支持部署在任何基础设施环境，提供在线与离线安装，支持一键升级与扩容集群</p></li><li><p>功能丰富</p><p>在一个平台统一纳管 DevOps、云原生可观测性、服务网格、应用生命周期、多租户、多集群、存储与网络</p></li><li><p>模块化 &amp; 可插拔</p></li><li><p>平台中的所有功能都是可插拔与松耦合，您可以根据业务场景可选安装所需功能组件</p></li></ol><h3 id="选型理由-从运维的角度考虑"><a href="#选型理由-从运维的角度考虑" class="headerlink" title="选型理由(从运维的角度考虑)"></a>选型理由(从运维的角度考虑)</h3><ul><li><p><strong>安装简单，使用简单</strong></p></li><li><p>具备构建一站式企业级的 DevOps 架构与可视化运维能力(省去自己用开源工具手工搭积木)</p></li><li><p>提供从平台到应用维度的日志、监控、事件、审计、告警与通知，实现集中式与多租户隔离的可观测性</p></li><li><p>简化应用的持续集成、测试、审核、发布、升级与弹性扩缩容</p></li><li><p>为云原生应用提供基于微服务的灰度发布、流量管理、网络拓扑与追踪</p></li><li><p>提供易用的界面命令终端与图形化操作面板，满足不同使用习惯的运维人员</p></li><li><p>可轻松解耦，避免厂商绑定</p></li></ul><h2 id="部署架构图"><a href="#部署架构图" class="headerlink" title="部署架构图"></a>部署架构图</h2><img title src="https://gitee.com/zdevops/res/raw/main/cloudnative/k8s-on-kubesphere.png" alt width="701"><h2 id="节点规划"><a href="#节点规划" class="headerlink" title="节点规划"></a>节点规划</h2><h3 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h3><ul><li><p>操作系统版本：centos7.9</p></li><li><p>kubesphere: v3.1.1</p></li><li><p>KubeKey版本：v1.1.1</p></li><li><p>Kubernetes版本：v1.20.4</p></li><li><p>docker版本：v19.03.15</p></li></ul><h3 id="规划说明"><a href="#规划说明" class="headerlink" title="规划说明"></a>规划说明</h3><ul><li><p>k8s集群规划</p><ul><li><p>负载均衡</p><ul><li>2节点，HAProxy，使用keepalived实现高可用</li></ul></li><li><p>Master节点：3节点，部署KubeSphere和Kubernetes的管理组件，etcd等服务</p><ul><li><strong>本方案并没有把etcd单独部署，有条件或是规模较大的场景可以单独部署etcd</strong></li></ul></li><li><p>Worker节点：6节点，部署应用，根据实际需求决定数量</p></li></ul></li><li><p>存储集群</p><ul><li><p>3节点，GlusterFS</p></li><li><p>每个节点1T数据盘</p></li></ul></li><li><p>中间件集群</p><ul><li>在k8s集群之外，独立部署的常见中间件</li><li>nginx代理节点，使用keepalived实现高可用，不采用Ingress</li><li>MySQL数据库，主从架构，中小规模使用，大规模需要专业运维人员或是使用云上成熟的产品，最好使用云服务商的产品</li><li>Ansible，单独的自动化运维管理节点，执行日常批量运维管理操作</li><li>Gitlab，运维代码管理，实现Gitops</li><li>Harbor，镜像仓库</li><li>Elasticsearch，3节点，存储日志</li><li>Prometheus，单独部署，用于k8s集群和pod的监控</li><li>Redis集群，3节点哨兵模式，该集群暂时还是部署在k8s上，后期考虑单独部署，因此预先规划预留机器，建议考虑云服务商的产品</li><li>RocketMQ集群，3节点，该集群暂时还是部署在k8s上，后期考虑单独部署，因此预先规划预留机器，建议考虑云服务上的产品</li></ul></li><li><p>网络规划：我们网络要求比较多。因此，不同功能模块，规划了不同的网段，各位可根据需求合理规划</p><ul><li><table><thead><tr><th align="center">功能域</th><th align="center">网段</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">k8s集群</td><td align="center">192.168.9.0&#x2F;24</td><td align="center">k8s集群内部节点使用</td></tr><tr><td align="center">存储集群</td><td align="center">192.168.10.0&#x2F;24</td><td align="center">存储集群内部节点使用</td></tr><tr><td align="center">中间件集群</td><td align="center">192.168.11.0&#x2F;24</td><td align="center">独立在k8s集群外的，各种中间件节点使用</td></tr></tbody></table></li></ul></li></ul><h4 id="存储选型说明："><a href="#存储选型说明：" class="headerlink" title="存储选型说明："></a>存储选型说明：</h4><ol><li><p>候选者</p><table><thead><tr><th align="center">存储方案</th><th align="center">优点</th><th align="center">缺点</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">Ceph</td><td align="center">资源多</td><td align="center">没有ceph集群故障处理能力，最好不要碰</td><td align="center">曾经，经历过3副本全部损坏数据丢失的惨痛经历，因此没有能力处理各种故障之前不会再轻易选择</td></tr><tr><td align="center">GlusterFS</td><td align="center">部署、维护简单；多副本高可用</td><td align="center">资料少</td><td align="center">部署和维护简单，出了问题找回数据的可能性大一些</td></tr><tr><td align="center">NFS</td><td align="center">使用广泛</td><td align="center">单点、网络抖动</td><td align="center">据说生产环境用的很多，但是单点和网络抖动风险，隐患不小，暂不考虑</td></tr><tr><td align="center">MinIO</td><td align="center"></td><td align="center"></td><td align="center">官宣全球领先的对象存储先锋，还未实践</td></tr><tr><td align="center">Longhorn</td><td align="center"></td><td align="center"></td><td align="center">官宣企业级云原生容器存储解决方案，还未实践</td></tr></tbody></table></li><li><p>入选者(第一季)</p><p><strong>GlusterFS</strong></p></li><li><p>说明</p><ul><li><p>以上方案为初期初选，属于摸着石头过河，选一个先用着，后期根据运行情况再重新调整，</p></li><li><p>大家请根据自己的存储需求和团队运维能力选择适合的方案。</p></li><li><p>因为我们的业务场景对于持久化存储的需求也就是存放一些log日志，能承受一定的数据损失，因此综合选择了GlusterFS</p></li><li><p>存储规划中假设1T数据满足需求，没考虑扩容，后续会做补充。</p></li></ul></li></ol><h3 id="Kubernetes集群节点规划"><a href="#Kubernetes集群节点规划" class="headerlink" title="Kubernetes集群节点规划"></a>Kubernetes集群节点规划</h3><table><thead><tr><th>节点角色</th><th align="center">主机名</th><th align="center">CPU(核)</th><th align="center">内存(GB)</th><th align="center">系统盘(GB)</th><th align="center">数据盘(GB)</th><th align="center">IP</th><th align="center">备注</th></tr></thead><tbody><tr><td>负载均衡</td><td align="center">k8s-slb-0</td><td align="center">2</td><td align="center">4</td><td align="center">50</td><td align="center"></td><td align="center">192.168.9.2&#x2F;192.168.9.1</td><td align="center"></td></tr><tr><td>负载均衡</td><td align="center">k8s-slb-1</td><td align="center">2</td><td align="center">4</td><td align="center">50</td><td align="center"></td><td align="center">192.168.9.3&#x2F;192.168.9.1</td><td align="center"></td></tr><tr><td>Master</td><td align="center">k8s-master-0</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.4</td><td align="center"></td></tr><tr><td>Master</td><td align="center">k8s-master-1</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.5</td><td align="center"></td></tr><tr><td>Master</td><td align="center">k8s-master-2</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.6</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-0</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.7</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-1</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.8</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-2</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.9</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-3</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.10</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-4</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.11</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-5</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.9.12</td><td align="center"></td></tr><tr><td>Worker</td><td align="center">k8s-node-n</td><td align="center">8</td><td align="center">32</td><td align="center">50</td><td align="center">500</td><td align="center">…</td><td align="center">根据自己的业务需求增加节点</td></tr></tbody></table><h3 id="存储集群节点规划"><a href="#存储集群节点规划" class="headerlink" title="存储集群节点规划"></a>存储集群节点规划</h3><table><thead><tr><th align="center">节点角色</th><th align="center">主机名</th><th align="center">CPU(核)</th><th align="center">内存(GB)</th><th align="center">系统盘(GB)</th><th align="center">数据盘(GB)</th><th align="center">IP</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">存储节点</td><td align="center">glusterfs-node-0</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">1000</td><td align="center">192.168.10.1</td><td align="center"></td></tr><tr><td align="center">存储节点</td><td align="center">glusterfs-node-1</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">1000</td><td align="center">192.168.10.2</td><td align="center"></td></tr><tr><td align="center">存储节点</td><td align="center">glusterfs-node-2</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">1000</td><td align="center">192.168.10.3</td><td align="center"></td></tr></tbody></table><h3 id="中间件节点规划"><a href="#中间件节点规划" class="headerlink" title="中间件节点规划"></a>中间件节点规划</h3><table><thead><tr><th align="center">节点角色</th><th align="center">主机名</th><th align="center">CPU(核)</th><th align="center">内存(GB)</th><th align="center">系统盘(GB)</th><th align="center">数据盘(GB)</th><th align="center">IP</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center">nginx代理</td><td align="center">nginx-0</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center"></td><td align="center">192.168.11.2&#x2F;192.168.11.1</td><td align="center">自建域名网关，不采用Ingress</td></tr><tr><td align="center">nginx代理</td><td align="center">nginx-1</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center"></td><td align="center">192.168.11.3&#x2F;192.168.11.1</td><td align="center">自建域名网关，不采用Ingress</td></tr><tr><td align="center">MySQL-主</td><td align="center">db-master</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.11.4</td><td align="center"></td></tr><tr><td align="center">MySQL-从</td><td align="center">db-slave</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.11.5</td><td align="center"></td></tr><tr><td align="center">Elasticsearch</td><td align="center">elastic-0</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">1000</td><td align="center">192.168.11.6</td><td align="center"></td></tr><tr><td align="center">Elasticsearch</td><td align="center">elastic-1</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">1000</td><td align="center">192.168.11.7</td><td align="center"></td></tr><tr><td align="center">Elasticsearch</td><td align="center">elastic-2</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">1000</td><td align="center">192.168.11.8</td><td align="center"></td></tr><tr><td align="center">自动化运维</td><td align="center">ansible</td><td align="center">2</td><td align="center">4</td><td align="center">50</td><td align="center"></td><td align="center">192.168.11.9</td><td align="center">安装ansible，用于自动化运维</td></tr><tr><td align="center">配置管理</td><td align="center">harbor</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.11.10</td><td align="center">安装gitlab和harbor</td></tr><tr><td align="center">Prometheus</td><td align="center">monitor</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">500</td><td align="center">192.168.11.11</td><td align="center"></td></tr><tr><td align="center">Redis</td><td align="center">redis-0</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">200</td><td align="center">192.168.11.12</td><td align="center">预留</td></tr><tr><td align="center">Redis</td><td align="center">redis-1</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">200</td><td align="center">192.168.11.13</td><td align="center">预留</td></tr><tr><td align="center">Redis</td><td align="center">redis-2</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">200</td><td align="center">192.168.11.14</td><td align="center">预留</td></tr><tr><td align="center">RocketMQ</td><td align="center">rocketmq-0</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">200</td><td align="center">192.168.11.15</td><td align="center">预留</td></tr><tr><td align="center">RocketMQ</td><td align="center">rocketmq-1</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">200</td><td align="center">192.168.11.16</td><td align="center">预留</td></tr><tr><td align="center">RocketMQ</td><td align="center">rocketmq-2</td><td align="center">4</td><td align="center">16</td><td align="center">50</td><td align="center">200</td><td align="center">192.168.11.17</td><td align="center">预留</td></tr></tbody></table><h2 id="k8s集群服务器基础配置"><a href="#k8s集群服务器基础配置" class="headerlink" title="k8s集群服务器基础配置"></a>k8s集群服务器基础配置</h2><h3 id="操作系统基础配置"><a href="#操作系统基础配置" class="headerlink" title="操作系统基础配置"></a>操作系统基础配置</h3><ul><li><p>以下操作在k8s集群的Master和Worker节点均执行</p></li><li><p>以下操作为了文档需要采用的手工命令的方式，实践中都采用的ansible进行的自动化配置</p></li></ul><ol><li><p>关闭防火墙和SELinux</p><p>本环境没有考虑更多的安全配置，因此关闭了防火墙和SELinux，有更高安全要求的环境不需要关闭，而是需要进行更多的安全配置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span><br><span class="line">[root@k8s-master-0 ~]# sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure></li><li><p>配置主机名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# hostnamectl set-hostname 规划的主机名</span><br></pre></td></tr></table></figure></li><li><p>配置主机名解析（可选）</p></li><li><p>挂载数据盘</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看数据盘盘符</span></span><br><span class="line">[root@k8s-master-0 ~]# lsblk  </span><br><span class="line">NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT</span><br><span class="line">vda 253:0 0 40G 0 disk</span><br><span class="line">├─vda1 253:1 0 4G 0 part</span><br><span class="line">└─vda2 253:2 0 36G 0 part /</span><br><span class="line">vdb 253:16 0 500G 0 disk</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分区</span></span><br><span class="line">[root@k8s-master-0 ~]# fdisk /dev/vdb</span><br><span class="line">n</span><br><span class="line">p</span><br><span class="line">一路回车</span><br><span class="line">....</span><br><span class="line">w </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">格式化文件系统(可选ext4或是xfs)</span></span><br><span class="line">[root@k8s-master-0 ~]# mkfs.ext4 /dev/vdb1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建挂载目录</span></span><br><span class="line">[root@k8s-master-0 ~]# mkdir /data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">挂载磁盘</span></span><br><span class="line">[root@k8s-master-0 ~]# mount /dev/vdb1 /data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开机自动挂载</span></span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;/dev/vdb1       /data   ext4    defaults        0 0&#x27; &gt;&gt; /etc/fstab</span><br></pre></td></tr></table></figure></li><li><p>更新操作系统并重启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# yum update</span><br><span class="line">[root@k8s-master-0 ~]# reboot</span><br></pre></td></tr></table></figure></li><li><p>安装依赖软件包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# yum install socat conntrack ebtables ipset</span><br></pre></td></tr></table></figure></li></ol><h3 id="基本的安全配置"><a href="#基本的安全配置" class="headerlink" title="基本的安全配置"></a>基本的安全配置</h3><ol><li><p>基线加固配置</p><ul><li><p>每个企业的基线扫描标准和工具不尽相同，因此本节内容请自行根据漏扫报告的整改要求进行配置</p></li><li><p>如有有需要，后期可以分享我们使用的基线加固的自动化配置脚本</p></li></ul></li></ol><h3 id="Docker安装配置"><a href="#Docker安装配置" class="headerlink" title="Docker安装配置"></a>Docker安装配置</h3><p>容器运行时，我们生产环境保守的选择了19.03版本的docke，安装时选择最新版的即可</p><ol><li><p>配置docker yum源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi /etc/yum.repods.d/docker.repo</span><br><span class="line"></span><br><span class="line">[docker-ce-stable]</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/$releasever/$basearch/stable</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/gpg</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# yum clean all</span><br><span class="line">[root@k8s-master-0 ~]# yum makecache</span><br></pre></td></tr></table></figure></li><li><p>创建docker的配置文件目录和配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# mkdir -p /etc/docker/</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# vi /etc/docker/daemon.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;data-root&quot;: &quot;/data/docker&quot;,</span><br><span class="line">  &quot;registry-mirrors&quot;:[&quot;https://docker.mirrors.ustc.edu.cn&quot;],</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;5m&quot;,</span><br><span class="line">    &quot;max-file&quot;:&quot;3&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>安装Docker</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# yum install  docker-ce-19.03.15-3.el7  docker-ce-cli-19.03.15-3.el7 -y</span><br></pre></td></tr></table></figure></li><li><p>启动服务并设置开机自启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# systemctl restart docker.service &amp;&amp; systemctl enable docker.service</span><br></pre></td></tr></table></figure></li><li><p>验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# docker version</span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           19.03.15</span><br><span class="line"> API version:       1.40</span><br><span class="line"> Go version:        go1.13.15</span><br><span class="line"> Git commit:        99e3ed8919</span><br><span class="line"> Built:             Sat Jan 30 03:17:57 2021</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          19.03.15</span><br><span class="line">  API version:      1.40 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.13.15</span><br><span class="line">  Git commit:       99e3ed8919</span><br><span class="line">  Built:            Sat Jan 30 03:16:33 2021</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     false</span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.4.12</span><br><span class="line">  GitCommit:        7b11cfaabd73bb80907dd23182b9347b4245eb5d</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.0.2</span><br><span class="line">  GitCommit:        v1.0.2-0-g52b36a2</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.18.0</span><br><span class="line">  GitCommit:        fec3683</span><br></pre></td></tr></table></figure></li></ol><h2 id="安装配置负载均衡"><a href="#安装配置负载均衡" class="headerlink" title="安装配置负载均衡"></a>安装配置负载均衡</h2><h3 id="三种解决方案"><a href="#三种解决方案" class="headerlink" title="三种解决方案"></a>三种解决方案</h3><ol><li><p>采用公有云或是私有云平台上自带的弹性负载均衡服务</p><ul><li><p>配置监听器监听的端口</p></li><li><table><thead><tr><th align="center">服务</th><th align="center">协议</th><th align="center">端口</th></tr></thead><tbody><tr><td align="center">apiserver</td><td align="center">TCP</td><td align="center">6443</td></tr><tr><td align="center">ks-console</td><td align="center">TCP</td><td align="center">30880</td></tr><tr><td align="center">http</td><td align="center">TCP</td><td align="center">80</td></tr><tr><td align="center">https</td><td align="center">TCP</td><td align="center">443</td></tr></tbody></table></li></ul></li><li><p>采用HAProxy或是Nginx自建负载均衡（<strong>此次选择</strong>）</p></li><li><p>使用KubeSphere自带的解决方案部署HAProxy</p><ul><li><p>kubekye v1.2.1开始支持</p></li><li><p>参考<a href="https://kubesphere.io/zh/docs/installing-on-linux/high-availability-configurations/internal-ha-configuration/">使用 KubeKey 内置 HAproxy 创建高可用集群</a></p></li></ul></li></ol><h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><ol><li><p>安装软件包(所有负载均衡节点)</p><p><code>[root@k8s-master-0 ~]# yum install haproxy keepalived</code></p></li><li><p>配置HAproxy(所有负载均衡节点，配置相同)</p><ul><li><p>编辑配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]<span class="comment"># vi /etc/haproxy/haproxy.cfg</span></span><br></pre></td></tr></table></figure></li><li><p>配置示例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">global</span></span><br><span class="line">    <span class="string">log</span> <span class="string">/dev/log</span>  <span class="string">local0</span> <span class="string">warning</span></span><br><span class="line">    <span class="string">chroot</span>      <span class="string">/var/lib/haproxy</span></span><br><span class="line">    <span class="string">pidfile</span>     <span class="string">/var/run/haproxy.pid</span></span><br><span class="line">    <span class="string">maxconn</span>     <span class="number">4000</span></span><br><span class="line">    <span class="string">user</span>        <span class="string">haproxy</span></span><br><span class="line">    <span class="string">group</span>       <span class="string">haproxy</span></span><br><span class="line">    <span class="string">daemon</span></span><br><span class="line"></span><br><span class="line">   <span class="string">stats</span> <span class="string">socket</span> <span class="string">/var/lib/haproxy/stats</span></span><br><span class="line"></span><br><span class="line"><span class="string">defaults</span></span><br><span class="line">  <span class="string">log</span> <span class="string">global</span></span><br><span class="line">  <span class="string">option</span>  <span class="string">httplog</span></span><br><span class="line">  <span class="string">option</span>  <span class="string">dontlognull</span></span><br><span class="line">        <span class="string">timeout</span> <span class="string">connect</span> <span class="number">5000</span></span><br><span class="line">        <span class="string">timeout</span> <span class="string">client</span> <span class="number">50000</span></span><br><span class="line">        <span class="string">timeout</span> <span class="string">server</span> <span class="number">50000</span></span><br><span class="line"></span><br><span class="line"><span class="string">frontend</span> <span class="string">kube-apiserver</span></span><br><span class="line">  <span class="string">bind</span> <span class="string">*:6443</span></span><br><span class="line">  <span class="string">mode</span> <span class="string">tcp</span></span><br><span class="line">  <span class="string">option</span> <span class="string">tcplog</span></span><br><span class="line">  <span class="string">default_backend</span> <span class="string">kube-apiserver</span></span><br><span class="line"></span><br><span class="line"><span class="string">backend</span> <span class="string">kube-apiserver</span></span><br><span class="line">    <span class="string">mode</span> <span class="string">tcp</span></span><br><span class="line">    <span class="string">option</span> <span class="string">tcplog</span></span><br><span class="line">    <span class="string">option</span> <span class="string">tcp-check</span></span><br><span class="line">    <span class="string">balance</span> <span class="string">roundrobin</span></span><br><span class="line">    <span class="string">default-server</span> <span class="string">inter</span> <span class="string">10s</span> <span class="string">downinter</span> <span class="string">5s</span> <span class="string">rise</span> <span class="number">2</span> <span class="string">fall</span> <span class="number">2</span> <span class="string">slowstart</span> <span class="string">60s</span> <span class="string">maxconn</span> <span class="number">250</span> <span class="string">maxqueue</span> <span class="number">256</span> <span class="string">weight</span> <span class="number">100</span></span><br><span class="line">    <span class="string">server</span> <span class="string">kube-apiserver-1</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.4</span><span class="string">:6443</span> <span class="string">check</span> <span class="comment"># Replace the IP address with your own.</span></span><br><span class="line">    <span class="string">server</span> <span class="string">kube-apiserver-2</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.5</span><span class="string">:6443</span> <span class="string">check</span> <span class="comment"># Replace the IP address with your own.</span></span><br><span class="line">    <span class="string">server</span> <span class="string">kube-apiserver-3</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.6</span><span class="string">:6443</span> <span class="string">check</span> <span class="comment"># Replace the IP address with your own.</span></span><br><span class="line"></span><br><span class="line"><span class="string">frontend</span> <span class="string">ks-console</span></span><br><span class="line">  <span class="string">bind</span> <span class="string">*:30880</span></span><br><span class="line">  <span class="string">mode</span> <span class="string">tcp</span></span><br><span class="line">  <span class="string">option</span> <span class="string">tcplog</span></span><br><span class="line">  <span class="string">default_backend</span> <span class="string">ks-console</span></span><br><span class="line"></span><br><span class="line"><span class="string">backend</span> <span class="string">ks-console</span></span><br><span class="line">    <span class="string">mode</span> <span class="string">tcp</span></span><br><span class="line">    <span class="string">option</span> <span class="string">tcplog</span></span><br><span class="line">    <span class="string">option</span> <span class="string">tcp-check</span></span><br><span class="line">    <span class="string">balance</span> <span class="string">roundrobin</span></span><br><span class="line">    <span class="string">default-server</span> <span class="string">inter</span> <span class="string">10s</span> <span class="string">downinter</span> <span class="string">5s</span> <span class="string">rise</span> <span class="number">2</span> <span class="string">fall</span> <span class="number">2</span> <span class="string">slowstart</span> <span class="string">60s</span> <span class="string">maxconn</span> <span class="number">250</span> <span class="string">maxqueue</span> <span class="number">256</span> <span class="string">weight</span> <span class="number">100</span></span><br><span class="line">    <span class="string">server</span> <span class="string">kube-apiserver-1</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.4</span><span class="string">:30880</span> <span class="string">check</span> <span class="comment"># Replace the IP address with your own.</span></span><br><span class="line">    <span class="string">server</span> <span class="string">kube-apiserver-2</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.5</span><span class="string">:30880</span> <span class="string">check</span> <span class="comment"># Replace the IP address with your own.</span></span><br><span class="line">    <span class="string">server</span> <span class="string">kube-apiserver-3</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.6</span><span class="string">:30880</span> <span class="string">check</span> <span class="comment"># Replace the IP address with your own.</span></span><br></pre></td></tr></table></figure></li><li><p>启动服务并设置开机自启动(所有负载均衡节点)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# systemctl restart haproxy &amp;&amp; systemctl enable haproxy</span><br></pre></td></tr></table></figure></li></ul></li><li><p>配置Keepalived</p><ul><li><p>编辑配置文件(所有负载均衡节点)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# vi /etc/keepalived/keepalived.conf</span><br></pre></td></tr></table></figure></li><li><p>LB节点1配置文件示例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">global_defs</span> &#123;</span><br><span class="line">  <span class="string">notification_email</span> &#123;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">router_id</span> <span class="string">LVS_DEVEL</span></span><br><span class="line">  <span class="string">vrrp_skip_check_adv_addr</span></span><br><span class="line">  <span class="string">vrrp_garp_interval</span> <span class="number">0</span></span><br><span class="line">  <span class="string">vrrp_gna_interval</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">vrrp_script</span> <span class="string">chk_haproxy</span> &#123;</span><br><span class="line">  <span class="string">script</span> <span class="string">&quot;killall -0 haproxy&quot;</span></span><br><span class="line">  <span class="string">interval</span> <span class="number">2</span></span><br><span class="line">  <span class="string">weight</span> <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">vrrp_instance</span> <span class="string">haproxy-vip</span> &#123;</span><br><span class="line">  <span class="string">state</span> <span class="string">MASTER</span>                   <span class="comment"># 主服务器的初始状态</span></span><br><span class="line">  <span class="string">priority</span> <span class="number">100</span>                   <span class="comment"># 优先级主服务器的要高</span></span><br><span class="line">  <span class="string">interface</span> <span class="string">eth0</span>                 <span class="comment"># 网卡名称，根据实际情况替换</span></span><br><span class="line">  <span class="string">virtual_router_id</span> <span class="number">60</span></span><br><span class="line">  <span class="string">advert_int</span> <span class="number">1</span></span><br><span class="line">  <span class="string">authentication</span> &#123;</span><br><span class="line">    <span class="string">auth_type</span> <span class="string">PASS</span></span><br><span class="line">    <span class="string">auth_pass</span> <span class="number">1111</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">unicast_src_ip</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.2</span>      <span class="comment"># 本机eth0网卡的IP地址</span></span><br><span class="line">  <span class="string">unicast_peer</span> &#123;</span><br><span class="line">    <span class="number">192.168</span><span class="number">.9</span><span class="number">.3</span>                   <span class="comment"># SLB节点2的IP地址</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="string">virtual_ipaddress</span> &#123;</span><br><span class="line">    <span class="number">192.168</span><span class="number">.9</span><span class="number">.1</span><span class="string">/24</span>               <span class="comment"># VIP地址</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="string">track_script</span> &#123;</span><br><span class="line">    <span class="string">chk_haproxy</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>LB节点2配置文件示例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">global_defs</span> &#123;</span><br><span class="line">  <span class="string">notification_email</span> &#123;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">router_id</span> <span class="string">LVS_DEVEL</span></span><br><span class="line">  <span class="string">vrrp_skip_check_adv_addr</span></span><br><span class="line">  <span class="string">vrrp_garp_interval</span> <span class="number">0</span></span><br><span class="line">  <span class="string">vrrp_gna_interval</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">vrrp_script</span> <span class="string">chk_haproxy</span> &#123;</span><br><span class="line">  <span class="string">script</span> <span class="string">&quot;killall -0 haproxy&quot;</span></span><br><span class="line">  <span class="string">interval</span> <span class="number">2</span></span><br><span class="line">  <span class="string">weight</span> <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">vrrp_instance</span> <span class="string">haproxy-vip</span> &#123;</span><br><span class="line">  <span class="string">state</span> <span class="string">BACKUP</span>                   <span class="comment"># 从服务器的初始状态</span></span><br><span class="line">  <span class="string">priority</span> <span class="number">99</span>                    <span class="comment"># 优先级,从服务器的低于主服务器的值</span></span><br><span class="line">  <span class="string">interface</span> <span class="string">eth0</span>                 <span class="comment"># 网卡名称，根据实际情况替换</span></span><br><span class="line">  <span class="string">virtual_router_id</span> <span class="number">60</span></span><br><span class="line">  <span class="string">advert_int</span> <span class="number">1</span></span><br><span class="line">  <span class="string">authentication</span> &#123;</span><br><span class="line">    <span class="string">auth_type</span> <span class="string">PASS</span></span><br><span class="line">    <span class="string">auth_pass</span> <span class="number">1111</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">unicast_src_ip</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.3</span>      <span class="comment"># 本机eth0网卡的IP地址</span></span><br><span class="line">  <span class="string">unicast_peer</span> &#123;</span><br><span class="line">    <span class="number">192.168</span><span class="number">.9</span><span class="number">.2</span>                   <span class="comment"># SLB节点1的IP地址</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="string">virtual_ipaddress</span> &#123;</span><br><span class="line">    <span class="number">192.168</span><span class="number">.9</span><span class="number">.1</span><span class="string">/24</span>                <span class="comment"># VIP地址</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="string">track_script</span> &#123;</span><br><span class="line">    <span class="string">chk_haproxy</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>启动服务并设置开机自启动(所有负载均衡节点)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# systemctl restart keepalived &amp;&amp; systemctl enable keepalived</span><br></pre></td></tr></table></figure></li></ul></li><li><p>验证</p><ul><li><p>查看vip(在负载均衡节点)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-slb-0 ~]# ip a s</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link/ether 52:54:9e:27:38:c8 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.9.2/24 brd 192.168.9.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 73334sec preferred_lft 73334sec</span><br><span class="line">    inet 192.168.9.1/24 scope global secondary eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::510e:f96:98b2:af40/64 scope link noprefixroute</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></li><li><p>验证vip的连通性（在k8s-master其他节点）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# ping -c 4 192.168.9.1</span><br><span class="line">PING 192.168.9.1 (192.168.9.1) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.9.1: icmp_seq=1 ttl=64 time=0.664 ms</span><br><span class="line">64 bytes from 192.168.9.1: icmp_seq=2 ttl=64 time=0.354 ms</span><br><span class="line">64 bytes from 192.168.9.1: icmp_seq=3 ttl=64 time=0.339 ms</span><br><span class="line">64 bytes from 192.168.9.1: icmp_seq=4 ttl=64 time=0.304 ms</span><br><span class="line"></span><br><span class="line">--- 192.168.9.1 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.304/0.415/0.664/0.145 ms</span><br></pre></td></tr></table></figure></li></ul></li></ol><h2 id="KubeSphere安装Kubernetes"><a href="#KubeSphere安装Kubernetes" class="headerlink" title="KubeSphere安装Kubernetes"></a>KubeSphere安装Kubernetes</h2><ol><li><p>下载KubeKey</p><p>KubeKey安装在了master-0节点，也可以安装在运维管理节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用国内环境</span></span><br><span class="line">[root@k8s-master-0 ~]# export KKZONE=cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行以下命令下载 KubeKey</span></span><br><span class="line">[root@k8s-master-0 ~]# curl -sfL https://get-kk.kubesphere.io | VERSION=v1.1.1 sh -</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为kk添加可执行权限(可选)</span></span><br><span class="line">[root@k8s-master-0 ~]# chmod +x kk</span><br></pre></td></tr></table></figure></li><li><p>创建包含默认配置的示例配置文件<strong>config-sample.yaml</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# ./kk create config --with-kubesphere v3.1.1 --with-kubernetes v1.20.4</span><br></pre></td></tr></table></figure><ul><li><p>–with-kubesphere 指定KubeSphere 版本v3.1.1</p></li><li><p>–with-kubernetes 指定Kubernetes 版本v1.20.4</p></li></ul></li><li><p>根据规划，编辑修改配置文件</p><ul><li><p>vi config-sample.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubekey.kubesphere.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Cluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sample</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-master-0</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.3</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.3</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">P@ssw0rd@123</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-master-1</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.4</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.4</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">P@ssw0rd@123</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-master-2</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.5</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.5</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">P@ssw0rd@123</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-node-0</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.6</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.6</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">P@ssw0rd@123</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-node-1</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.7</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.7</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">P@ssw0rd@123</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-node-2</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.8</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.8</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">P@ssw0rd@123</span>&#125;</span><br><span class="line">  <span class="attr">roleGroups:</span></span><br><span class="line">    <span class="attr">etcd:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-master-2</span></span><br><span class="line">    <span class="attr">master:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-master-2</span></span><br><span class="line">    <span class="attr">worker:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-node-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-node-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-node-2</span></span><br><span class="line">  <span class="attr">controlPlaneEndpoint:</span></span><br><span class="line">    <span class="attr">domain:</span> <span class="string">lb.kubesphere.local</span></span><br><span class="line">    <span class="attr">address:</span> <span class="string">&quot;192.168.9.1&quot;</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6443</span></span><br><span class="line">  <span class="attr">kubernetes:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1.20.4</span></span><br><span class="line">    <span class="attr">imageRepo:</span> <span class="string">kubesphere</span></span><br><span class="line">    <span class="attr">clusterName:</span> <span class="string">cluster.local</span></span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">plugin:</span> <span class="string">calico</span></span><br><span class="line">    <span class="attr">kubePodsCIDR:</span> <span class="number">10.233</span><span class="number">.64</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">    <span class="attr">kubeServiceCIDR:</span> <span class="number">10.233</span><span class="number">.0</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">registryMirrors:</span> []</span><br><span class="line">    <span class="attr">insecureRegistries:</span> []</span><br><span class="line">  <span class="attr">addons:</span> []</span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">installer.kubesphere.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"></span><br><span class="line"><span class="string">....(后面太多都是ks的配置，本文不涉及，先省略)</span></span><br></pre></td></tr></table></figure></li><li><p>重点配置项说明</p><ul><li><p>hosts 配置k8s集群节点的名字、IP、管理用户、管理用户名</p></li><li><p>roleGroups</p><ul><li><p><em>etcd:</em> etcd节点名称</p></li><li><p><em>master:</em> master节点的名称</p></li><li><p><em>worker:</em>  work节点的名称</p></li></ul></li><li><p>controlPlaneEndpoint</p><ul><li><p><em>domain：</em> 负载衡器IP对应的域名，一般形式lb.clusterName</p></li><li><p><em>address：</em> 负载衡器IP地址</p></li></ul></li><li><p>kubernetes</p><ul><li><em>clusterName：</em> kubernetes集群的集群名称</li></ul></li></ul></li></ul></li><li><p>安装KubeSphere和Kubernetes集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# ./kk create cluster -f config-sample.yaml</span><br></pre></td></tr></table></figure></li><li><p>验证安装结果</p><ul><li><p>验证安装过程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure></li><li><p>验证集群状态</p><p>安装完成后，您会看到如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##              Welcome to KubeSphere!           ###</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"></span><br><span class="line">Console: http://192.168.9.2:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you log into the console, please check the</span><br><span class="line">     monitoring status of service components in</span><br><span class="line">     the &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">     ready, please wait patiently until all components</span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line">https://kubesphere.io             20xx-xx-xx xx:xx:xx</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br></pre></td></tr></table></figure></li></ul></li></ol><blockquote><p><strong>参考文档</strong></p></blockquote><ol><li><p><a href="https://kubesphere.io/zh/docs/installing-on-linux/introduction/multioverview/">多节点安装</a></p></li><li><p><a href="https://kubesphere.io/zh/docs/installing-on-linux/high-availability-configurations/set-up-ha-cluster-using-keepalived-haproxy/">使用 Keepalived 和 HAproxy 创建高可用 Kubernetes 集群</a></p></li></ol><blockquote><p><strong>后续</strong></p></blockquote><ol><li>基于KubeSphere的Kubernetes生产实践之路-持久化存储之GlusterFS</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于KubeSphere的Kubernetes生产实践之路-起步篇&quot;&gt;&lt;a href=&quot;#基于KubeSphere的Kubernetes生产实践之路-起步篇&quot; class=&quot;headerlink&quot; title=&quot;基于KubeSphere的Kubernetes生产实</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s｜60 分钟 Rook 实战入门</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-60%E5%88%86%E9%92%9FRook%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-60%E5%88%86%E9%92%9FRook%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/</id>
    <published>2023-09-22T01:38:09.544Z</published>
    <updated>2023-09-22T01:45:08.741Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s｜60-分钟-Rook-实战入门"><a href="#基于-KubeSphere-玩转-k8s｜60-分钟-Rook-实战入门" class="headerlink" title="基于 KubeSphere 玩转 k8s｜60 分钟 Rook 实战入门"></a>基于 KubeSphere 玩转 k8s｜60 分钟 Rook 实战入门</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p><strong>欢迎来到云原生技术栈实战系列之基于 KubeSphere 玩转 K8s</strong></p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p><strong>导图</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-architecture.png" alt="rook-architecture"></p><blockquote><p><strong>知识量</strong></p></blockquote><ul><li>阅读时长：20 分</li><li>行：944</li><li>单词：4800+</li><li>字符：30900+</li><li>图片：7 张</li></ul><blockquote><p><strong>知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>Rook 概览</li><li>Rook 集群的部署</li><li>Rook Block 存储的配置</li><li>Ceph Dashboard 的配置使用</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">storage-node-0</td><td align="center">192.168.9.95</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200+200</td><td align="center">ElasticSearch&#x2F;GlusterFS</td></tr><tr><td align="center">storage-node-1</td><td align="center">192.168.9.96</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200+200</td><td align="center">ElasticSearch&#x2F;GlusterFS</td></tr><tr><td align="center">storage-node-2</td><td align="center">192.168.9.97</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200+200</td><td align="center">ElasticSearch&#x2F;GlusterFS</td></tr><tr><td align="center">harbor</td><td align="center">192.168.9.89</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Harbor</td></tr><tr><td align="center">合计</td><td align="center">8</td><td align="center">22</td><td align="center">84</td><td align="center">320</td><td align="center">2800</td><td align="center"></td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>Ansible：<strong>2.8.20</strong></li><li>KubeSphere：<strong>3.3.0</strong></li><li>Kubernetes：<strong>v1.24.1</strong></li><li>Rook：<strong>v1.9.7</strong></li><li>GlusterFS：<strong>9.5.1</strong></li><li>ElasticSearch：<strong>7.17.5</strong></li><li>Harbor：<strong>2.5.1</strong></li></ul><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><h3 id="1-1-Rook-是什么？"><a href="#1-1-Rook-是什么？" class="headerlink" title="1.1. Rook 是什么？"></a>1.1. Rook 是什么？</h3><blockquote><p><strong>官方定义</strong></p></blockquote><ul><li>Rook 是一个开源的云原生存储编排器，为各种存储解决方案提供平台、框架和支持，以便与云原生环境进行原生集成。</li><li>Rook 将存储软件转变为自管理、自扩展和自修复的存储服务。它通过自动化部署、引导、置备、配置、伸缩、升级、迁移、灾难恢复、监控和资源管理来实现这一点。</li><li>Rook 使用底层云原生容器提供的工具执行其管理、调度和编排平台的职责。</li><li>Rook 利用扩展点深度集成到云原生环境中，为调度、生命周期管理、资源管理、安全、监控和用户体验提供无缝体验。</li><li>Ceph operator 于 2018 年 12 月在 Rook <strong>v0.9</strong> 版本中宣布<strong>稳定</strong>，已经提供了多年的生产存储平台。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-1.png" alt="rook-1"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-2.png" alt="rook-2"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-3.png" alt="rook-3"></p><blockquote><p><strong>多种存储解决方案</strong></p></blockquote><ul><li>Rook 编排多个存储解决方案，每个解决方案都有一个专门的 Kubernetes Operator 来自动化管理。</li><li>为您的使用场景选择最好的存储提供商，Rook 确保它们在 Kubernetes 上都能良好运行，具有相同、一致的体验。</li><li>目前支持 <strong>Ceph</strong> 和 <strong>NFS</strong></li></ul><h3 id="1-2-Rook-Architecture"><a href="#1-2-Rook-Architecture" class="headerlink" title="1.2. Rook Architecture"></a>1.2. Rook Architecture</h3><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-kubernetes.png" alt="rook-kubernetes"></p><h2 id="2-前提条件"><a href="#2-前提条件" class="headerlink" title="2. 前提条件"></a>2. 前提条件</h2><h3 id="2-1-Kubernetes-Minimum-Version"><a href="#2-1-Kubernetes-Minimum-Version" class="headerlink" title="2.1.  Kubernetes Minimum Version"></a>2.1.  Kubernetes Minimum Version</h3><ul><li><p>Rook 可以安装在任何现有的 Kubernetes 集群上，只要它满足最低版本，并且授予 Rook 所需的特权 .</p></li><li><p>Kubernetes <strong>v1.17</strong> or higher is supported for the Ceph operator.</p></li></ul><h3 id="2-2-CPU-Architecture"><a href="#2-2-CPU-Architecture" class="headerlink" title="2.2. CPU Architecture"></a>2.2. CPU Architecture</h3><p>Architectures released are <code>amd64 / x86_64</code> and <code>arm64</code>.</p><h3 id="2-3-Ceph-Prerequisites"><a href="#2-3-Ceph-Prerequisites" class="headerlink" title="2.3. Ceph Prerequisites"></a>2.3. Ceph Prerequisites</h3><p>为了配置 Ceph 存储集群，至少需要以下任意一种本地存储选项 :</p><ul><li>Raw devices (no partitions or formatted filesystems，没有分区和格式化文件系统)</li><li>Raw partitions (no formatted filesystem，已分区但是没有格式化文件系统)</li><li>PVs available from a storage class in <code>block</code> mode</li></ul><p>可以使用以下命令确认分区或设备是否使用文件系统进行了格式化。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# lsblk -f</span><br><span class="line">NAME            FSTYPE      LABEL UUID                                   MOUNTPOINT</span><br><span class="line">sda                                                                      </span><br><span class="line">├─sda1          xfs               6a66c441-78cf-4d86-a9a5-201fcccaa0ba   /boot</span><br><span class="line">└─sda2          LVM2_member       4Qx7ir-P9HJ-eqRf-c4ZA-v3hA-YCtr-8Ufgbo </span><br><span class="line">  ├─centos-root xfs               ea556f53-4505-42d7-953e-a20aacb799d5   /</span><br><span class="line">  └─centos-swap swap              306bc365-0c12-4c12-b3d2-971ce22caa3b   </span><br><span class="line">sdb                                                                      </span><br><span class="line">└─sdb1          xfs               1e644d09-507c-45ca-8d3f-57adbae6e600   /var/lib/containerd</span><br><span class="line">sdc  </span><br></pre></td></tr></table></figure><ul><li>如果 FSTYPE 字段不为空，说明该设备已经格式化为文件系统，对应的值就是文件系统类型</li><li>如果 FSTYPE 字段为空，说明该设备还没有被格式化，可以被 Ceph 使用</li><li>本例中可以使用的设备为 <strong>sdc</strong></li></ul><h3 id="2-4-Admission-Controller"><a href="#2-4-Admission-Controller" class="headerlink" title="2.4. Admission Controller"></a>2.4. Admission Controller</h3><p>本文忽略，详情见<a href="https://rook.io/docs/rook/v1.9/Getting-Started/Prerequisites/prerequisites/#admission-controller">官方文档</a></p><h3 id="2-5-LVM-package"><a href="#2-5-LVM-package" class="headerlink" title="2.5. LVM package"></a>2.5. LVM package</h3><p>Ceph OSDs 在以下场景依赖 LVM。</p><ul><li>OSDs are created on raw devices or partitions</li><li>If encryption is enabled (<code>encryptedDevice: &quot;true&quot;</code> in the cluster CR)</li><li>A <code>metadata</code> device is specified</li></ul><p>Ceph OSDs 在以下场景不需要 LVM。</p><ul><li>Creating OSDs on PVCs using the <code>storageClassDeviceSets</code></li></ul><p>CentOS 默认已经安装 LVM，如果没有装，使用下面的命令安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y lvm2</span><br></pre></td></tr></table></figure><h3 id="2-6-Kernel"><a href="#2-6-Kernel" class="headerlink" title="2.6. Kernel"></a>2.6. Kernel</h3><ul><li>RBD</li></ul><p>Ceph 需要使用构建了 RBD 模块的 Linux 内核。许多 Linux 发行版都有这个模块，但不是所有发行版都有。例如，GKE Container-Optimised OS (COS) 就没有 RBD。</p><p>在 Kubernetes 节点使用 <code>modprober rbd</code> 命令验证，正常情况下该命名没有任何输出，如果输出提示 ‘not found’，则需要重新编译内核或是更换操作系统。</p><ul><li>CephFS</li></ul><p>如果您将从 Ceph shared file system (CephFS) 创建卷，推荐的最低内核版本是 4.17。如果内核版本小于 4.17，则不会强制执行请求的 PVC sizes。存储配额只会在更新的内核上执行。</p><h2 id="3-ROOK-资源准备"><a href="#3-ROOK-资源准备" class="headerlink" title="3.  ROOK 资源准备"></a>3.  ROOK 资源准备</h2><h3 id="3-1-下载-ROOK-部署代码"><a href="#3-1-下载-ROOK-部署代码" class="headerlink" title="3.1. 下载 ROOK 部署代码"></a>3.1. 下载 ROOK 部署代码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --single-branch --branch v1.9.7 https://github.com/rook/rook.git</span><br></pre></td></tr></table></figure><h3 id="3-2-离线镜像制作"><a href="#3-2-离线镜像制作" class="headerlink" title="3.2. 离线镜像制作"></a>3.2. 离线镜像制作</h3><p>此过程为可选项，离线内网环境可用，如果是直连互联网的场景，可以直接使用互联网的镜像。</p><p>在一台能同时访问互联网和内网 Harbor 仓库的服务器上进行下面的操作。</p><ul><li>Harbor 创建项目</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Harbor 仓库地址</span></span><br><span class="line">url=&quot;https://registry.zdevops.com.cn&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问 Harbor 仓库用户</span></span><br><span class="line">user=&quot;admin&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问 Harbor 仓库用户密码</span></span><br><span class="line">passwd=&quot;Harbor12345&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要创建的项目名列表，正常只需要创建一个**kubesphereio**即可，这里为了保留变量可扩展性多写了两个。</span></span><br><span class="line">harbor_projects=(csiaddons</span><br><span class="line">    sig-storage</span><br><span class="line">    rook</span><br><span class="line">    cephcsi</span><br><span class="line">    ceph</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for project in &quot;$&#123;harbor_projects[@]&#125;&quot;; do</span><br><span class="line">    echo &quot;creating $project&quot;</span><br><span class="line">    curl -u &quot;$&#123;user&#125;:$&#123;passwd&#125;&quot; -X POST -H &quot;Content-Type: application/json&quot; &quot;$&#123;url&#125;/api/v2.0/projects&quot; -d &quot;&#123; \&quot;project_name\&quot;: \&quot;$&#123;project&#125;\&quot;, \&quot;public\&quot;: true&#125;&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ul><li>下载镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd rook/deploy/examples</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">两条命令二选一 都可以</span></span><br><span class="line">for i in `cat images.txt`;do docker pull $i;done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> images.txt | awk -F <span class="string">&quot;/&quot;</span> <span class="string">&#x27;&#123; print &quot;docker pull &quot;$0 &#125;&#x27;</span> | bash</span></span><br></pre></td></tr></table></figure><ul><li>images.txt 文件内容</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">quay.io/ceph/ceph:v16.2.9</span><br><span class="line">quay.io/cephcsi/cephcsi:v3.6.2</span><br><span class="line">quay.io/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">quay.io/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">registry.k8s.io/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">registry.k8s.io/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">registry.k8s.io/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><ul><li>重新打 tag</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker tag quay.io/ceph/ceph:v16.2.9 registry.zdevops.com.cn/ceph/ceph:v16.2.9</span><br><span class="line">docker tag quay.io/cephcsi/cephcsi:v3.6.2 registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2</span><br><span class="line">docker tag quay.io/csiaddons/k8s-sidecar:v0.4.0 registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">docker tag quay.io/csiaddons/volumereplication-operator:v0.3.0 registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">docker tag registry.k8s.io/sig-storage/csi-attacher:v3.4.0 registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">docker tag registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1 registry.zdevops.com.cn/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">docker tag registry.k8s.io/sig-storage/csi-provisioner:v3.1.0 registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">docker tag registry.k8s.io/sig-storage/csi-resizer:v1.4.0 registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">docker tag registry.k8s.io/sig-storage/csi-snapshotter:v6.0.1 registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">docker tag registry.k8s.io/sig-storage/nfsplugin:v4.0.0 registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">docker tag rook/ceph:v1.9.7 registry.zdevops.com.cn/rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><ul><li>推送到私有镜像仓库</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker push registry.zdevops.com.cn/ceph/ceph:v16.2.9</span><br><span class="line">docker push registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2</span><br><span class="line">docker push registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">docker push registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">docker push registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">docker push registry.zdevops.com.cn/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">docker push registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">docker push registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">docker push registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">docker push registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">docker push registry.zdevops.com.cn/rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><ul><li>清理临时镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">docker rmi registry.zdevops.com.cn/ceph/ceph:v16.2.9</span><br><span class="line">docker rmi registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2</span><br><span class="line">docker rmi registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">docker rmi registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">docker rmi registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/rook/ceph:v1.9.7</span><br><span class="line">docker rmi quay.io/ceph/ceph:v16.2.9</span><br><span class="line">docker rmi quay.io/cephcsi/cephcsi:v3.6.2</span><br><span class="line">docker rmi quay.io/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">docker rmi quay.io/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">docker rmi registry.k8s.io/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">docker rmi registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">docker rmi registry.k8s.io/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">docker rmi registry.k8s.io/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">docker rmi registry.k8s.io/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">docker rmi registry.k8s.io/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">docker rmi rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><ul><li>自动化脚本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pull | tag | push</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> images.txt | awk -F <span class="string">&quot;/&quot;</span> <span class="string">&#x27;&#123;sub(&quot;^ *&quot;,&quot;&quot;);print &quot;docker pull &quot;$0&quot; &amp;&amp; docker tag &quot;$0&quot; registry.zdevops.com.cn/&quot;$(NF-1)&quot;/&quot;$NF &quot; &amp;&amp; docker push registry.zdevops.com.cn/&quot;$(NF-1)&quot;/&quot;$NF&#125;&#x27;</span></span></span><br><span class="line">cat images.txt | awk -F &quot;/&quot; &#x27;&#123;print &quot;docker pull &quot;$0&quot; &amp;&amp; docker tag &quot;$0&quot; registry.zdevops.com.cn/&quot;$(NF-1)&quot;/&quot;$NF &quot; &amp;&amp; docker push registry.zdevops.com.cn/&quot;$(NF-1)&quot;/&quot;$NF &quot; &amp;&amp; docker rmi &quot; $0&quot; &amp;&amp; docker rmi registry.zdevops.com.cn/&quot;$(NF-1)&quot;/&quot;$NF &#125;&#x27; | bash</span><br></pre></td></tr></table></figure><h3 id="3-3-服务器镜像下载"><a href="#3-3-服务器镜像下载" class="headerlink" title="3.3. 服务器镜像下载"></a>3.3. 服务器镜像下载</h3><p>此步骤本文并未执行，适用于<strong>「4.1 修改镜像地址」</strong>方案二。</p><ul><li>拉取内网镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ctr images pull registry.zdevops.com.cn/ceph/ceph:v16.2.9</span><br><span class="line">ctr images pull registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2</span><br><span class="line">ctr images pull registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">ctr images pull registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">ctr images pull registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">ctr images pull registry.zdevops.com.cn/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">ctr images pull registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">ctr images pull registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">ctr images pull registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">ctr images pull registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">ctr images pull registry.zdevops.com.cn/rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><ul><li>重新打 tag</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/ceph/ceph:v16.2.9 quay.io/ceph/ceph:v16.2.9</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2 quay.io/cephcsi/cephcsi:v3.6.2</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0 quay.io/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0 quay.io/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0 registry.k8s.io/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/sig-storage/csi-node-driver-registrar:v2.5.1 registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0 registry.k8s.io/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0 registry.k8s.io/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1 registry.k8s.io/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0 registry.k8s.io/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">ctr -n k8s.io images tag registry.zdevops.com.cn/rook/ceph:v1.9.7 rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><ul><li>清理临时镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/ceph/ceph:v16.2.9</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/csi-node-driver-registrar:v2.5.1</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0</span><br><span class="line">ctr -n k8s.io images rm registry.zdevops.com.cn/rook/ceph:v1.9.7</span><br></pre></td></tr></table></figure><h2 id="4-Rook-部署-Ceph-集群"><a href="#4-Rook-部署-Ceph-集群" class="headerlink" title="4. Rook 部署 Ceph 集群"></a>4. Rook 部署 Ceph 集群</h2><h3 id="4-1-修改镜像地址"><a href="#4-1-修改镜像地址" class="headerlink" title="4.1. 修改镜像地址"></a>4.1. 修改镜像地址</h3><p>默认的配置文件中，使用的镜像为互联网地址的镜像，使用本地镜像仓库时，需要做一些特殊处理。</p><p>有两种可选方案，</p><ul><li>方案一：编辑配置文件，替换引用的镜像仓库地址。</li><li>方案二：利用内网镜像仓库将镜像下载到服务器，然后重新打 tag，将前缀换为互联网的原始地址，具体操作参考<strong>「3.3 服务器镜像下载」</strong>。</li></ul><p><strong>本文采用方案一，具体操作如下：</strong></p><ul><li>编辑配置文件<strong>「operator.yaml」</strong>，修改镜像为本地镜像</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">ROOK_CSI_CEPH_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/cephcsi/cephcsi:v3.6.2&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSI_REGISTRAR_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/sig-storage/csi-node-driver-registrar:v2.5.1&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSI_RESIZER_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/sig-storage/csi-resizer:v1.4.0&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSI_PROVISIONER_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/sig-storage/csi-provisioner:v3.1.0&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSI_SNAPSHOTTER_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/sig-storage/csi-snapshotter:v6.0.1&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSI_ATTACHER_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/sig-storage/csi-attacher:v3.4.0&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSI_NFS_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/sig-storage/nfsplugin:v4.0.0&quot;</span></span><br><span class="line"><span class="attr">CSI_VOLUME_REPLICATION_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/csiaddons/volumereplication-operator:v0.3.0&quot;</span></span><br><span class="line"><span class="attr">ROOK_CSIADDONS_IMAGE:</span> <span class="string">&quot;registry.zdevops.com.cn/csiaddons/k8s-sidecar:v0.4.0&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">image:</span> <span class="string">registry.zdevops.com.cn/rook/ceph:v1.9.7</span></span><br></pre></td></tr></table></figure><ul><li>编辑配置文件<strong>「cluster.yaml」</strong>，修改镜像为本地镜像</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="string">registry.zdevops.com.cn/ceph/ceph:v16.2.9</span></span><br></pre></td></tr></table></figure><ul><li>自动化操作脚本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">取消镜像注释</span></span><br><span class="line">sed -i &#x27;91,97s/^.*#/ /g&#x27; operator.yaml</span><br><span class="line">sed -i &#x27;434,434s/^.*#/ /g&#x27; operator.yaml</span><br><span class="line">sed -i &#x27;437,437s/^.*#/ /g&#x27; operator.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">替换镜像地址前缀</span></span><br><span class="line">sed -i -e &#x27;s/registry.k8s.io/registry.zdevops.com.cn/g&#x27; -e &#x27;s/quay.io/registry.zdevops.com.cn/g&#x27; operator.yaml</span><br><span class="line">sed -i &#x27;s|rook/ceph:v1.9.7|registry.zdevops.com.cn/rook/ceph:v1.9.7|g&#x27; operator.yaml</span><br><span class="line">sed -i &#x27;24,24s/quay.io/registry.zdevops.com.cn/g&#x27; cluster.yaml</span><br></pre></td></tr></table></figure><h3 id="4-2-Deploy-the-Rook-Operator"><a href="#4-2-Deploy-the-Rook-Operator" class="headerlink" title="4.2. Deploy the Rook Operator"></a>4.2. Deploy the Rook Operator</h3><ul><li>根据资源配置清单创建资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd deploy/examples</span><br><span class="line">kubectl create -f crds.yaml -f common.yaml -f operator.yaml</span><br></pre></td></tr></table></figure><ul><li>验证 **rook-ceph-operator ** Pod 的状态是否为 <code>Running</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl -n rook-ceph get pod</span><br><span class="line">NAME                                                        READY   STATUS      RESTARTS   AGE</span><br><span class="line">rook-ceph-operator-85dcb9d489-98mx8                         1/1     Running     0          50s</span><br></pre></td></tr></table></figure><h3 id="4-3-Create-a-Ceph-Cluster"><a href="#4-3-Create-a-Ceph-Cluster" class="headerlink" title="4.3. Create a Ceph Cluster"></a>4.3. Create a Ceph Cluster</h3><ul><li>修改集群配置文件<strong>「cluster.yaml」</strong>，增加磁盘配置</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">storage:</span> <span class="comment"># cluster level storage configuration and selection</span></span><br><span class="line">  <span class="attr">useAllNodes:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">useAllDevices:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">deviceFilter:</span></span><br><span class="line">  <span class="attr">config:</span></span><br><span class="line">    <span class="attr">storeType:</span> <span class="string">bluestore</span></span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">      <span class="attr">devices:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;sdc&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">      <span class="attr">devices:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;sdc&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">      <span class="attr">devices:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;sdc&quot;</span></span><br></pre></td></tr></table></figure><ul><li>创建集群</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f cluster.yaml</span><br></pre></td></tr></table></figure><ul><li>查看资源状态，确保所有相关 Pod 均为 <code>Running</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl -n rook-ceph get pod</span><br><span class="line">NAME                                                        READY   STATUS      RESTARTS   AGE</span><br><span class="line">csi-cephfsplugin-njmdn                                      3/3     Running     0          3m24s</span><br><span class="line">csi-cephfsplugin-provisioner-84bc77ff84-j9vgz               6/6     Running     0          3m24s</span><br><span class="line">csi-cephfsplugin-provisioner-84bc77ff84-t52pm               6/6     Running     0          3m24s</span><br><span class="line">csi-cephfsplugin-rwmjm                                      3/3     Running     0          3m24s</span><br><span class="line">csi-cephfsplugin-xhc67                                      3/3     Running     0          3m24s</span><br><span class="line">csi-rbdplugin-2xpvs                                         3/3     Running     0          3m24s</span><br><span class="line">csi-rbdplugin-4m898                                         3/3     Running     0          3m24s</span><br><span class="line">csi-rbdplugin-provisioner-845945c9cb-2sclk                  6/6     Running     0          3m24s</span><br><span class="line">csi-rbdplugin-provisioner-845945c9cb-dl4vx                  6/6     Running     0          3m24s</span><br><span class="line">csi-rbdplugin-xhkpv                                         3/3     Running     0          3m24s</span><br><span class="line">rook-ceph-crashcollector-ks-k8s-master-0-75fc5f778c-9pq6b   1/1     Running     0          90s</span><br><span class="line">rook-ceph-crashcollector-ks-k8s-master-1-7bc7cc898d-75rr4   1/1     Running     0          57s</span><br><span class="line">rook-ceph-crashcollector-ks-k8s-master-2-74f7fc9b5-k55w4    1/1     Running     0          57s</span><br><span class="line">rook-ceph-mgr-a-6cc97dc547-lrtzq                            2/2     Running     0          99s</span><br><span class="line">rook-ceph-mgr-b-556f474b5f-jshp8                            2/2     Running     0          98s</span><br><span class="line">rook-ceph-mon-a-6cc594c678-8lms5                            1/1     Running     0          3m14s</span><br><span class="line">rook-ceph-mon-b-c54846f8c-2lffx                             1/1     Running     0          2m15s</span><br><span class="line">rook-ceph-mon-c-5fcf8f98b8-hs6w6                            1/1     Running     0          2m</span><br><span class="line">rook-ceph-operator-85dcb9d489-98mx8                         1/1     Running     0          3h34m</span><br><span class="line">rook-ceph-osd-0-57687f7bf9-qc6f5                            1/1     Running     0          59s</span><br><span class="line">rook-ceph-osd-1-6bdf65b96b-lw2sv                            1/1     Running     0          57s</span><br><span class="line">rook-ceph-osd-2-78676b7bf-c9tct                             1/1     Running     0          57s</span><br><span class="line">rook-ceph-osd-prepare-ks-k8s-master-0-vq24c                 0/1     Completed   0          75s</span><br><span class="line">rook-ceph-osd-prepare-ks-k8s-master-1-w9vjg                 0/1     Completed   0          75s</span><br><span class="line">rook-ceph-osd-prepare-ks-k8s-master-2-zj89n                 0/1     Completed   0          75s</span><br></pre></td></tr></table></figure><h3 id="4-4-创建-Rook-toolbox"><a href="#4-4-创建-Rook-toolbox" class="headerlink" title="4.4. 创建 Rook toolbox"></a>4.4. 创建 Rook toolbox</h3><p>通过 Rook 提供的 toolbox，我们可以实现对 Ceph 集群的管理。</p><ul><li>创建 toolbox</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f toolbox.yaml</span><br></pre></td></tr></table></figure><ul><li>查看 toolbox 状态，确认状态为 <strong>Running</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph rollout status deploy/rook-ceph-tools</span><br></pre></td></tr></table></figure><ul><li>登录 Toolbox</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash</span><br></pre></td></tr></table></figure><ul><li>验证 Ceph 集群状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[rook@rook-ceph-tools-6c6974f44c-pq49w /]$ ceph -s </span><br><span class="line">  cluster:</span><br><span class="line">    id:     b670b67a-83a4-42e7-905d-ed3f97759bb6</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum a,b,c (age 20h)</span><br><span class="line">    mgr: b(active, since 3m), standbys: a</span><br><span class="line">    osd: 3 osds: 3 up (since 20h), 3 in (since 20h)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 0 objects, 0 B</span><br><span class="line">    usage:   15 MiB used, 600 GiB / 600 GiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure><blockquote><p>观察 Ceph 集群状态，需要满足下面的条件才会认为集群状态是健康的。</p><ul><li>health 的值为 HEALTH_OK</li><li>Mons 的数量和状态</li><li>Mgr 有一个是 active 状态</li><li>OSD 状态都是 up</li></ul></blockquote><ul><li>其他常用的 Ceph 命令</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 OSD 状态</span></span><br><span class="line">ceph osd status</span><br><span class="line">ceph osd df</span><br><span class="line">ceph osd utilization</span><br><span class="line">ceph osd pool stats</span><br><span class="line">ceph osd tree</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 Ceph 容量</span></span><br><span class="line">ceph df</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 Rados 状态</span></span><br><span class="line">rados df</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 PG 状态</span></span><br><span class="line">ceph pg stat</span><br></pre></td></tr></table></figure><ul><li>删除 toolbox(可选)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph delete deploy/rook-ceph-tools</span><br></pre></td></tr></table></figure><h3 id="4-5-Storage-介绍"><a href="#4-5-Storage-介绍" class="headerlink" title="4.5. Storage 介绍"></a>4.5. Storage 介绍</h3><p>Rock 提供了三种存储类型，请参考官方指南了解详情：</p><ul><li><strong><a href="https://rook.io/docs/rook/v1.9/Storage-Configuration/Block-Storage-RBD/block-storage/">Block</a></strong>: Create block storage to be consumed by a pod (RWO)</li><li><strong><a href="https://rook.io/docs/rook/v1.9/Storage-Configuration/Shared-Filesystem-CephFS/filesystem-storage/">Shared Filesystem</a></strong>: Create a filesystem to be shared across multiple pods (RWX)</li><li><strong><a href="https://rook.io/docs/rook/v1.9/Storage-Configuration/Object-Storage-RGW/object-storage/">Object</a></strong>: Create an object store that is accessible inside or outside the Kubernetes cluster</li></ul><h2 id="5-Block-Storage"><a href="#5-Block-Storage" class="headerlink" title="5. Block Storage"></a>5. Block Storage</h2><h3 id="5-1-Block-存储"><a href="#5-1-Block-存储" class="headerlink" title="5.1. Block 存储"></a>5.1. Block 存储</h3><p>Rook 允许通过自定义资源定义 (crd) 创建和自定义 Block 存储池。支持 Replicated 和 Erasure Coded 类型。本文演示 Replicated 的创建过程。</p><ul><li>创建 Ceph 块存储，编辑 <code>CephBlockPool</code> CR 资源清单 , ceph-replicapool.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephBlockPool</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">replicapool</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">failureDomain:</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">replicated:</span></span><br><span class="line">    <span class="attr">size:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure><p>上面的操作会创建一个 3 副本的块存储池子</p><ul><li>创建 CephBlockPool 资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl create -f ceph-replicapool.yaml</span><br></pre></td></tr></table></figure><ul><li>查看资源创建情况</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl get cephBlockPool -n rook-ceph -o wide</span><br><span class="line">NAME          PHASE</span><br><span class="line">replicapool   Ready</span><br></pre></td></tr></table></figure><ul><li>在 ceph toolbox 中查看 Ceph 集群状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录</span></span><br><span class="line">kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群</span></span><br><span class="line">[rook@rook-ceph-tools-6c6974f44c-pq49w /]$ ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     b670b67a-83a4-42e7-905d-ed3f97759bb6</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum a,b,c (age 27h)</span><br><span class="line">    mgr: b(active, since 7h), standbys: a</span><br><span class="line">    osd: 3 osds: 3 up (since 27h), 3 in (since 27h)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   2 pools, 33 pgs</span><br><span class="line">    objects: 1 objects, 19 B</span><br><span class="line">    usage:   16 MiB used, 600 GiB / 600 GiB avail</span><br><span class="line">    pgs:     33 active+clean</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群存储池</span> </span><br><span class="line">[rook@rook-ceph-tools-6c6974f44c-pq49w /]$ceph osd pool ls</span><br><span class="line">device_health_metrics</span><br><span class="line">replicapool</span><br><span class="line"></span><br><span class="line">[rook@rook-ceph-tools-6c6974f44c-pq49w /]$ rados df</span><br><span class="line">POOL_NAME                USED  OBJECTS  CLONES  COPIES  MISSING_ON_PRIMARY  UNFOUND  DEGRADED  RD_OPS   RD  WR_OPS     WR  USED COMPR  UNDER COMPR</span><br><span class="line">device_health_metrics     0 B        0       0       0                   0        0         0       0  0 B       0    0 B         0 B          0 B</span><br><span class="line">replicapool            12 KiB        1       0       3                   0        0         0       0  0 B       2  2 KiB         0 B          0 B</span><br><span class="line"></span><br><span class="line">total_objects    1</span><br><span class="line">total_used       16 MiB</span><br><span class="line">total_avail      600 GiB</span><br><span class="line">total_space      600 GiB</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看存储池的 pg number</span></span><br><span class="line">[rook@rook-ceph-tools-6c6974f44c-pq49w /]$ ceph osd pool get replicapool pg_num</span><br><span class="line">pg_num: 32</span><br></pre></td></tr></table></figure><ul><li>编辑 StorageClass 资源清单 ,storageclass-rook-ceph-block.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">rook-ceph-block</span></span><br><span class="line"><span class="comment"># Change &quot;rook-ceph&quot; provisioner prefix to match the operator namespace if needed</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.rbd.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">    <span class="comment"># clusterID is the namespace where the rook cluster is running</span></span><br><span class="line">    <span class="attr">clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="comment"># Ceph pool into which the RBD image shall be created</span></span><br><span class="line">    <span class="attr">pool:</span> <span class="string">replicapool</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># RBD image format. Defaults to &quot;2&quot;.</span></span><br><span class="line">    <span class="attr">imageFormat:</span> <span class="string">&quot;2&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># RBD image features. Available for imageFormat: &quot;2&quot;. CSI RBD currently supports only `layering` feature.</span></span><br><span class="line">    <span class="attr">imageFeatures:</span> <span class="string">layering</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># The secrets contain Ceph admin credentials.</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-csi-rbd-provisioner</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/controller-expand-secret-name:</span> <span class="string">rook-csi-rbd-provisioner</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/controller-expand-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-csi-rbd-node</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Specify the filesystem type of the volume. If not specified, csi-provisioner</span></span><br><span class="line">    <span class="comment"># will set default as `ext4`. Note that `xfs` is not recommended due to potential deadlock</span></span><br><span class="line">    <span class="comment"># in hyperconverged settings where the volume is mounted on the same node as the osds.</span></span><br><span class="line">    <span class="attr">csi.storage.k8s.io/fstype:</span> <span class="string">ext4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete the rbd volume when a PVC is deleted</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional, if you want to add dynamic resize for PVC.</span></span><br><span class="line"><span class="comment"># For now only ext3, ext4, xfs resize support provided, like in Kubernetes itself.</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>创建 StorageClass 资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl create -f storageclass-rook-ceph-block.yaml</span><br></pre></td></tr></table></figure><p><strong>examples&#x2F;csi&#x2F;rbd</strong> 目录中有更多的参考用例。</p><ul><li>验证资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl get sc</span><br><span class="line">NAME              PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">local (default)   openebs.io/local             Delete          WaitForFirstConsumer   false                  10d</span><br><span class="line">rook-ceph-block   rook-ceph.rbd.csi.ceph.com   Delete          Immediate              true                   3m36s</span><br></pre></td></tr></table></figure><h3 id="5-2-创建测试应用"><a href="#5-2-创建测试应用" class="headerlink" title="5.2. 创建测试应用"></a>5.2. 创建测试应用</h3><p>我们使用经典的 wordpress 和 mysql 应用程序创建一个使用 Rook 提供块存储的示例应用程序，这两个应用程序都使用由 Rook 提供的块存储卷。</p><ul><li>创建 mysql 和 wordpress</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f mysql.yaml</span><br><span class="line">kubectl create -f wordpress.yaml</span><br></pre></td></tr></table></figure><ul><li>查看 PVC 资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl get pvc</span><br><span class="line">NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE</span><br><span class="line">mysql-pv-claim   Bound    pvc-33a2c666-a001-447c-81d4-9a93b80cd782   20Gi       RWO            rook-ceph-block   53s</span><br><span class="line">wp-pv-claim      Bound    pvc-d9d1e10c-dd94-402d-bf0d-ca9bc9d2b6af   20Gi       RWO            rook-ceph-block   51s</span><br></pre></td></tr></table></figure><ul><li>查看 SVC 资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl get svc</span><br><span class="line">NAME              TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">kubernetes        ClusterIP      10.233.0.1     &lt;none&gt;        443/TCP        10d</span><br><span class="line">wordpress         LoadBalancer   10.233.6.210   &lt;pending&gt;     80:30463/TCP   16s</span><br><span class="line">wordpress-mysql   ClusterIP      None           &lt;none&gt;        3306/TCP       18s</span><br></pre></td></tr></table></figure><ul><li>查看 Pod 资源</li></ul> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl get pod -o wide</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE     IP              NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">wordpress-7964897bd9-7gjdp         1/1     Running   0          2m21s   10.233.116.75   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">wordpress-mysql-776b4f56c4-sphrk   1/1     Running   0          2m24s   10.233.87.162   ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p><strong>上面的细节文档中不做过多展示，更多细节会在直播中演示讲解</strong>。</p><h2 id="6-Ceph-Dashboard"><a href="#6-Ceph-Dashboard" class="headerlink" title="6. Ceph Dashboard"></a>6. Ceph Dashboard</h2><p>Ceph 提供了一个 Dashboard 工具，我们可以在上面查看集群的状态，包括集群整体运行状态、Mgr、Mon、OSD 和其他 Ceph 进程的状态，查看存储池和 PG 状态，以及显示守护进程的日志等。</p><p>具体使用流程如下：</p><h3 id="6-1-Enable-the-Ceph-Dashboard"><a href="#6-1-Enable-the-Ceph-Dashboard" class="headerlink" title="6.1. Enable the Ceph Dashboard"></a>6.1. Enable the Ceph Dashboard</h3><p>可以通过 cluster.yaml 中 Ceph Cluster CRD 中的设置启用 Dashboard 功能，默认的清单文件中已经启用该功能，配置示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">...</span>]</span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">dashboard:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Dashboard 启用后，Rook operator 将启用 ceph-mgr 的 dashboard 模块。</p><h3 id="6-2-获取-Dashboard-的-service-地址"><a href="#6-2-获取-Dashboard-的-service-地址" class="headerlink" title="6.2. 获取 Dashboard 的 service 地址"></a>6.2. 获取 Dashboard 的 service 地址</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl -n rook-ceph get service</span><br><span class="line">NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">rook-ceph-mgr              ClusterIP   10.233.31.147   &lt;none&gt;        9283/TCP            21h</span><br><span class="line">rook-ceph-mgr-dashboard    ClusterIP   10.233.18.59    &lt;none&gt;        8443/TCP            21h</span><br></pre></td></tr></table></figure><h3 id="6-3-配置在集群外部访问-Dashboard"><a href="#6-3-配置在集群外部访问-Dashboard" class="headerlink" title="6.3. 配置在集群外部访问 Dashboard"></a>6.3. 配置在集群外部访问 Dashboard</h3><p>通常我们需要在 K8s 集群外部访问 Ceph Dashboard，可以通过 NodePort 或是 Ingress 的方式 .</p><p>本文采用 NodePort 的方式，并且按集群规划使用固定的端口号 <code>31443</code>。</p><ul><li>创建资源清单文件 <code>ceph-dashboard-external-https.yaml</code></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-ceph-mgr-dashboard-external-https</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">rook-ceph-mgr</span></span><br><span class="line">    <span class="attr">rook_cluster:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dashboard</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8443</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8443</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">31443</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">rook-ceph-mgr</span></span><br><span class="line">    <span class="attr">rook_cluster:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br></pre></td></tr></table></figure><p><strong>官方 example 也提供了参考样例 <code>dashboard-external-https.yaml</code>，可以直接使用</strong></p><ul><li>创建资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl create -f ceph-dashboard-external-https.yaml</span><br></pre></td></tr></table></figure><ul><li>验证创建的资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl -n rook-ceph get service rook-ceph-mgr-dashboard-external-https</span><br><span class="line">NAME                                     TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">rook-ceph-mgr-dashboard-external-https   NodePort   10.233.28.87   &lt;none&gt;        8443:31443/TCP   55s</span><br></pre></td></tr></table></figure><h3 id="6-4-获取-Login-Credentials"><a href="#6-4-获取-Login-Credentials" class="headerlink" title="6.4. 获取 Login Credentials"></a>6.4. 获取 Login Credentials</h3><p>登陆 Dashboard 时需要身份验证，Rook 创建了一个默认用户，用户名 admin。创建了一个名为 rook-ceph-dashboard-password 的 secret 存储密码，使用下面的命令获取随机生成的密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 examples]# kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=&quot;&#123;[&#x27;data&#x27;][&#x27;password&#x27;]&#125;&quot; | base64 --decode &amp;&amp; echo</span><br><span class="line">/Vl^679ck440/nf6~G&quot;l</span><br></pre></td></tr></table></figure><h3 id="6-5-通过浏览器打开-Dashboard"><a href="#6-5-通过浏览器打开-Dashboard" class="headerlink" title="6.5. 通过浏览器打开 Dashboard"></a>6.5. 通过浏览器打开 Dashboard</h3><p>访问 K8s 集群中任意节点的 IP，<code>https://192.168.9.91:31443</code>，默认用户名 <code>admin</code>，密码通过上面的命令获取。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-dashboard-1.png" alt="rook-dashboard-1"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/rook-dashboard-2.png" alt="rook-dashboard-2"></p><h2 id="7-生产环境思考"><a href="#7-生产环境思考" class="headerlink" title="7. 生产环境思考"></a>7. 生产环境思考</h2><ul><li>磁盘 SSD 和 SAS&#x2F;SATA</li><li>存储类型选择</li><li>Block 存储池类型选择</li><li>存储节点规划</li><li>…</li></ul><h2 id="8-常见问题"><a href="#8-常见问题" class="headerlink" title="8. 常见问题"></a>8. 常见问题</h2><h3 id="8-1-OSD-pod-创建失败"><a href="#8-1-OSD-pod-创建失败" class="headerlink" title="8.1. OSD pod 创建失败"></a>8.1. OSD pod 创建失败</h3><ul><li>invalid main GPT header</li></ul><p>这个盘是新添加的，并没有创建 GPT 分区信息，手动给各个盘创建 GPT header</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">问题细节</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl -n rook-ceph <span class="built_in">log</span> rook-ceph-osd-prepare-ke-dev1-worker1-bbm9t provision</span></span><br><span class="line">...</span><br><span class="line">2018-11-29 03:28:36.533532 I | exec: Running command: lsblk /dev/vde --bytes --nodeps --pairs --output SIZE,ROTA,RO,TYPE,PKNAME</span><br><span class="line">2018-11-29 03:28:36.537270 I | exec: Running command: sgdisk --print /dev/vde</span><br><span class="line">2018-11-29 03:28:36.547839 W | inventory: skipping device vde with an unknown uuid. Failed to complete &#x27;get disk vde uuid&#x27;: exit status 2. ^GCaution: invalid main GPT header, but valid backup; regenerating main header</span><br><span class="line">from backup!</span><br><span class="line"></span><br><span class="line">Invalid partition data!</span><br></pre></td></tr></table></figure><h3 id="8-2-部署失败后清理重新部署"><a href="#8-2-部署失败后清理重新部署" class="headerlink" title="8.2. 部署失败后清理重新部署"></a>8.2. 部署失败后清理重新部署</h3><ul><li>执行下面的命令清理环境，再重新部署</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /var/lib/rook/</span><br><span class="line">dd if=/dev/zero of=/dev/sdc bs=512k count=1</span><br><span class="line">wipefs -af /dev/sdc</span><br></pre></td></tr></table></figure><h3 id="8-3-Dashboard-打不开"><a href="#8-3-Dashboard-打不开" class="headerlink" title="8.3. Dashboard 打不开"></a>8.3. Dashboard 打不开</h3><p>当你配置完在集群外部访问 Dashboard，用浏览器打开页面，出现以下问题</p><ul><li>页面一致处于加载状态，浏览器的左下角会显示一个 10开头的K8s 内部网络IP</li><li>用浏览器的开发者工具观察网络请求，也会有访问 10开头的K8s 内部网络IP 的请求</li><li>过一段时间就会超时并跳转到 Mgr 的 POD IP</li></ul><p>使用如下的资源清单重新创建服务能暂时解决问题，深层次的原因还需要再分析</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rook-ceph-mgr-dashboard-external-https</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">rook-ceph-mgr</span></span><br><span class="line">    <span class="attr">rook_cluster:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">dashboard</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8443</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8443</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">31443</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">rook-ceph-mgr</span></span><br><span class="line">    <span class="attr">rook_cluster:</span> <span class="string">rook-ceph</span></span><br><span class="line">    <span class="attr">mgr:</span> <span class="string">a</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br></pre></td></tr></table></figure><blockquote><p>主要是加了一个<code>mgr: a</code>的selector，因为mgr是主备模式的，默认a处于活动状态，因此要选择a才能打开</p></blockquote><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p></blockquote><ul><li><strong>KubeSphere</strong></li><li><strong>Kubernetes</strong></li><li><strong>Ansible</strong></li><li><strong>自动化运维</strong></li><li><strong>CNCF 技术栈</strong></li></ul><p><strong>如果你喜欢本文，请分享给你的小伙伴！</strong></p><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li><li>知乎 <a href="https://www.zhihu.com/people/zdevops/">https://www.zhihu.com/people/zdevops/</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>Get 视频 B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s｜60-分钟-Rook-实战入门&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s｜60-分钟-Rook-实战入门&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-KubeSphere3.3 离线安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-KubeSphere3.3%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-KubeSphere3.3%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.512Z</published>
    <updated>2023-09-22T01:44:47.397Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-KubeSphere3-3-离线安装手记"><a href="#基于-KubeSphere-玩转-k8s-KubeSphere3-3-离线安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-KubeSphere3.3 离线安装手记"></a>基于 KubeSphere 玩转 k8s-KubeSphere3.3 离线安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><p><strong>本文内容概览</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220701085657576.png" alt="内容概览"></p><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>KubeKey 是一个用于部署 Kubernetes 集群的开源轻量级工具。</p><p>它提供了一种灵活、快速、便捷的方式来仅安装 Kubernetes&#x2F;K3s，或同时安装 Kubernetes&#x2F;K3s 和 KubeSphere，以及其他云原生插件。除此之外，它也是扩展和升级集群的有效工具。</p><p>KubeKey v2.1.0 版本新增了清单 (manifest) 和制品 (artifact) 的概念，为用户离线部署 Kubernetes 集群提供了一种解决方案。</p><p>manifest 是一个描述当前 Kubernetes 集群信息和定义 artifact 制品中需要包含哪些内容的文本文件。</p><p>在过去，用户需要准备部署工具，镜像 tar 包和其他相关的二进制文件，每位用户需要部署的 Kubernetes 版本和需要部署的镜像都是不同的。现在使用 KubeKey，用户只需使用清单 manifest 文件来定义将要离线部署的集群环境需要的内容，再通过该 manifest 来导出制品 artifact 文件即可完成准备工作。离线部署时只需要 KubeKey 和 artifact 就可快速、简单的在环境中部署镜像仓库和 Kubernetes 集群。</p><p>KubeKey 生成 manifest 文件有两种方式。</p><ul><li>利用现有运行中的集群作为源生成 manifest 文件，也是官方推荐的一种方式，具体参考 KubeSphere <a href="https://kubesphere.com.cn/docs/v3.3/installing-on-linux/introduction/air-gapped-installation/">官网的离线部署文档</a>。</li><li>根据 <a href="https://github.com/kubesphere/kubekey/blob/master/docs/manifest-example.md">模板文件</a> 手动编写 manifest 文件。</li></ul><p>第一种方式的好处是可以构建 1:1 的运行环境，但是需要提前部署一个集群，不够灵活度，并不是所有人都具备这种条件的。</p><p>因此，本文参考官方的离线文档，采用手写 manifest 文件的方式，实现离线环境的安装部署。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：10 分</li><li>行：666</li><li>单词：3100+</li><li>字符：23200+</li><li>图片：2 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>了解清单 (manifest) 和制品 (artifact) 的概念</li><li>掌握 manifest 清单的编写方法</li><li>根据 manifest 清单制作 artifact</li><li>离线部署 KubeSphere 和 Kubernetes</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">es-node-0</td><td align="center">192.168.9.95</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">ElasticSearch</td></tr><tr><td align="center">es-node-1</td><td align="center">192.168.9.96</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">ElasticSearch</td></tr><tr><td align="center">es-node-2</td><td align="center">192.168.9.97</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">ElasticSearch</td></tr><tr><td align="center">harbor</td><td align="center">192.168.9.89</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Harbor</td></tr><tr><td align="center">合计</td><td align="center">8</td><td align="center">22</td><td align="center">84</td><td align="center">320</td><td align="center">2200</td><td align="center"></td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li><p>操作系统：<strong>CentOS-7.9-x86_64</strong></p></li><li><p>KubeSphere：<strong>3.3.0</strong></p></li><li><p>Kubernetes：<strong>1.24.1</strong></p></li><li><p>Kubekey：<strong>v2.2.1</strong></p></li><li><p>Ansible：<strong>2.8.20</strong></p></li><li><p>Harbor：<strong>2.5.1</strong></p></li></ul><h2 id="2-离线部署资源制作"><a href="#2-离线部署资源制作" class="headerlink" title="2. 离线部署资源制作"></a>2. 离线部署资源制作</h2><h3 id="2-1-下载-KubeKey"><a href="#2-1-下载-KubeKey" class="headerlink" title="2.1. 下载 KubeKey"></a>2.1. 下载 KubeKey</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在zdevops-master 运维开发服务器执行</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">选择中文区下载(访问github受限时使用)</span></span><br><span class="line">[root@zdevops-master dev]# export KKZONE=cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载KubeKey</span></span><br><span class="line">[root@zdevops-master dev]# mkdir /data/kubekey</span><br><span class="line">[root@zdevops-master dev]# cd /data/kubekey/</span><br><span class="line">[root@zdevops-master kubekey]# curl -sfL https://get-kk.kubesphere.io | VERSION=v2.2.1 sh -</span><br></pre></td></tr></table></figure><h3 id="2-2-获取-manifest-模板"><a href="#2-2-获取-manifest-模板" class="headerlink" title="2.2. 获取 manifest 模板"></a>2.2. 获取 manifest 模板</h3><p>参考 <strong><a href="https://github.com/kubesphere/kubekey/blob/master/docs/manifest-example.md">https://github.com/kubesphere/kubekey/blob/master/docs/manifest-example.md</a></strong></p><p>有两个参考用例，一个简单版，一个完整版。参考简单版就可以。</p><h3 id="2-3-获取-ks-installer-images-list"><a href="#2-3-获取-ks-installer-images-list" class="headerlink" title="2.3. 获取 ks-installer images-list"></a>2.3. 获取 ks-installer images-list</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/kubesphere/ks-installer/releases/download/v3.3.0/images-list.txt</span><br></pre></td></tr></table></figure><p>文中的 image 列表选用的 dockerhub 仓库其他组件存放的公共仓库，国内建议统一更改前缀为 <strong>registry.cn-beijing.aliyuncs.com&#x2F;kubesphereio</strong></p><p>修改后的完整的镜像列表在下面的 manifest 文件中展示。</p><p>请注意，<strong>example-images</strong> 包含的 image 中只保留了 <strong>busybox</strong>，其他的在本文中没有使用。</p><h3 id="2-4-获取操作系统依赖包"><a href="#2-4-获取操作系统依赖包" class="headerlink" title="2.4. 获取操作系统依赖包"></a>2.4. 获取操作系统依赖包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/kubesphere/kubekey/releases/download/v2.2.1/centos7-rpms-amd64.iso</span><br></pre></td></tr></table></figure><p>将该 ISO 文件放到制作离线镜像的服务器的 &#x2F;data&#x2F;kubekey 目录下</p><h3 id="2-5-生成-manifest-文件"><a href="#2-5-生成-manifest-文件" class="headerlink" title="2.5. 生成 manifest 文件"></a>2.5. 生成 manifest 文件</h3><p>根据上面的文件及相关信息，生成最终 <strong>manifest.yaml</strong>。</p><p>命名为 <strong>ks-v3.3.0-manifest.yaml</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubekey.kubesphere.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Manifest</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sample</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">arches:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">amd64</span></span><br><span class="line">  <span class="attr">operatingSystems:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">arch:</span> <span class="string">amd64</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">linux</span></span><br><span class="line">    <span class="attr">id:</span> <span class="string">centos</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">&quot;7&quot;</span></span><br><span class="line">    <span class="attr">osImage:</span> <span class="string">CentOS</span> <span class="string">Linux</span> <span class="number">7</span> <span class="string">(Core)</span></span><br><span class="line">    <span class="attr">repository:</span></span><br><span class="line">      <span class="attr">iso:</span></span><br><span class="line">        <span class="attr">localPath:</span> <span class="string">&quot;/data/kubekey/centos7-rpms-amd64.iso&quot;</span></span><br><span class="line">        <span class="attr">url:</span></span><br><span class="line">  <span class="attr">kubernetesDistributions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">kubernetes</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1.24.1</span></span><br><span class="line">  <span class="attr">components:</span></span><br><span class="line">    <span class="attr">helm:</span> </span><br><span class="line">      <span class="attr">version:</span> <span class="string">v3.6.3</span></span><br><span class="line">    <span class="attr">cni:</span> </span><br><span class="line">      <span class="attr">version:</span> <span class="string">v0.9.1</span></span><br><span class="line">    <span class="attr">etcd:</span> </span><br><span class="line">      <span class="attr">version:</span> <span class="string">v3.4.13</span></span><br><span class="line">    <span class="attr">containerRuntimes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">containerd</span></span><br><span class="line">      <span class="attr">version:</span> <span class="number">1.6</span><span class="number">.4</span></span><br><span class="line">    <span class="attr">crictl:</span> </span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1.24.0</span></span><br><span class="line">    <span class="attr">docker-registry:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">&quot;2&quot;</span></span><br><span class="line">    <span class="attr">harbor:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2.4.1</span></span><br><span class="line">    <span class="attr">docker-compose:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2.2.2</span></span><br><span class="line">  <span class="attr">images:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.23.7</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.23.7</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.23.7</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.23.7</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.24.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.24.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.24.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.24.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.22.10</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.22.10</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.22.10</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.22.10</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.21.13</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.21.13</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.21.13</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.21.13</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.7</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.6</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.5</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/coredns:1.8.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/coredns:1.8.6</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/cni:v3.20.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controllers:v3.20.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/node:v3.20.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/pod2daemon-flexvol:v3.20.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/typha:v3.20.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/flannel:v0.12.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/provisioner-localpv:2.10.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/linux-utils:2.10.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/haproxy:2.3</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/nfs-subdir-external-provisioner:v4.0.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/k8s-dns-node-cache:1.15.12</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/ks-installer:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/ks-apiserver:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/ks-console:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/ks-controller-manager:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kubectl:v1.22.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kubectl:v1.21.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kubectl:v1.20.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kubefed:v0.8.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/tower:v0.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/minio:RELEASE.2019-08-07T01-59-21Z</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/mc:RELEASE.2019-08-07T23-14-43Z</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/snapshot-controller:v4.0.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/nginx-ingress-controller:v1.1.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/defaultbackend-amd64:1.4</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/metrics-server:v0.4.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/redis:5.0.14-alpine</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/haproxy:2.0.25-alpine</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/alpine:3.14</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/openldap:1.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/netshoot:v1.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/cloudcore:v1.9.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/iptables-manager:v1.9.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/edgeservice:v0.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/gatekeeper:v3.5.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/openpitrix-jobs:v3.2.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/devops-apiserver:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/devops-controller:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/devops-tools:v3.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/ks-jenkins:v3.3.0-2.319.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/inbound-agent:4.10-2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-base:v3.2.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-nodejs:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-maven:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-maven:v3.2.1-jdk11</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-python:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.2-1.16</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.2-1.17</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.2-1.18</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-base:v3.2.2-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-nodejs:v3.2.0-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-maven:v3.2.0-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-maven:v3.2.1-jdk11-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-python:v3.2.0-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.0-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.2-1.16-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.2-1.17-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/builder-go:v3.2.2-1.18-podman</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/s2ioperator:v3.2.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/s2irun:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/s2i-binary:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/tomcat85-java11-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/tomcat85-java11-runtime:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/tomcat85-java8-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/tomcat85-java8-runtime:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/java-11-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/java-8-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/java-8-runtime:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/java-11-runtime:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/nodejs-8-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/nodejs-6-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/nodejs-4-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/python-36-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/python-35-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/python-34-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/python-27-centos7:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/argocd:v2.3.3</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/argocd-applicationset:v0.4.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/dex:v2.30.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/redis:6.2.6-alpine</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/configmap-reload:v0.5.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/prometheus:v2.34.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/prometheus-config-reloader:v0.55.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/prometheus-operator:v0.55.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-rbac-proxy:v0.11.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-state-metrics:v2.3.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/node-exporter:v1.3.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/alertmanager:v0.23.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/thanos:v0.25.2</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/grafana:8.3.3</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-rbac-proxy:v0.8.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/notification-manager-operator:v1.4.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/notification-manager:v1.4.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/notification-tenant-sidecar:v3.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/elasticsearch-curator:v5.7.6</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/elasticsearch-oss:6.8.22</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/fluentbit-operator:v0.13.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/docker:19.03</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/fluent-bit:v1.8.11</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/log-sidecar-injector:1.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/filebeat:6.7.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-events-operator:v0.4.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-events-exporter:v0.4.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-events-ruler:v0.4.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-auditing-operator:v0.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kube-auditing-webhook:v0.2.0</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/pilot:1.11.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/proxyv2:1.11.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/jaeger-operator:1.27</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/jaeger-agent:1.27</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/jaeger-collector:1.27</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/jaeger-query:1.27</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/jaeger-es-index-cleaner:1.27</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kiali-operator:v1.38.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/kiali:v1.38</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/busybox:1.31.1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">registry.cn-beijing.aliyuncs.com/kubesphereio/scope:1.13.0</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">auths:</span> &#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>manifest 修改说明</strong></p><ul><li>开启 <strong>harbor</strong> 和 <strong>docker-compose</strong> 配置项，为后面通过 KubeKey 自建 harbor 仓库推送镜像使用。</li><li>默认创建的 manifest 里面的镜像列表从 <strong>docker.io</strong> 获取，替换前缀为 <strong>registry.cn-beijing.aliyuncs.com&#x2F;kubesphereio</strong>。</li><li>若需要导出的 artifact 文件中包含操作系统依赖文件（如：conntarck、chrony 等），可在 <strong>operationSystem</strong> 元素中的 <strong>.repostiory.iso.url</strong> 中配置相应的 ISO 依赖文件下载地址为 <strong>localPath</strong> ，填写提前下载好的 ISO 包在本地的存放路径，并将 <strong>url</strong> 配置项置空。</li><li>您可以访问 <a href="https://github.com/kubesphere/kubekey/releases/tag/v2.2.1">https://github.com/kubesphere/kubekey/releases/tag/v2.2.1</a> 下载 ISO 文件。</li></ul></blockquote><h3 id="2-6-导出制品-artifact"><a href="#2-6-导出制品-artifact" class="headerlink" title="2.6. 导出制品 artifact"></a>2.6. 导出制品 artifact</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export KKZONE=cn</span><br><span class="line"></span><br><span class="line">./kk artifact export -m ks-v3.3.0-manifest.yaml -o kubesphere-v3.3.0-artifact.tar.gz</span><br></pre></td></tr></table></figure><blockquote><p><strong>制品 (artifact) 说明</strong></p><ul><li><p>制品（artifact）是一个根据指定的 manifest 文件内容导出的包含镜像 tar 包和相关二进制文件的 tgz 包。</p></li><li><p>在 KubeKey 初始化镜像仓库、创建集群、添加节点和升级集群的命令中均可指定一个 artifact，KubeKey 将自动解包该 artifact 并在执行命令时直接使用解包出来的文件。</p></li></ul></blockquote><h3 id="2-7-导出-Kubekey"><a href="#2-7-导出-Kubekey" class="headerlink" title="2.7. 导出 Kubekey"></a>2.7. 导出 Kubekey</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master kubekey]# tar zcvf kubekey-v2.2.1.tar.gz kk kubekey-v2.2.1-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="3-K8S-服务器初始化配置"><a href="#3-K8S-服务器初始化配置" class="headerlink" title="3. K8S 服务器初始化配置"></a>3. K8S 服务器初始化配置</h2><p> 本节执行离线环境 K8S 服务器初始化配置。</p><h3 id="3-1-Ansible-hosts-配置"><a href="#3-1-Ansible-hosts-配置" class="headerlink" title="3.1. Ansible hosts 配置"></a>3.1. Ansible hosts 配置</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[k8s]</span></span><br><span class="line">ks-k8s-master-0 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.91</span>  host_name=ks-k8s-master-<span class="number">0</span></span><br><span class="line">ks-k8s-master-1 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.92</span>  host_name=ks-k8s-master-<span class="number">1</span></span><br><span class="line">ks-k8s-master-2 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.93</span>  host_name=ks-k8s-master-<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="section">[es]</span></span><br><span class="line">es-node-0 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.95</span> host_name=es-node-<span class="number">0</span></span><br><span class="line">es-node-1 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.96</span> host_name=es-node-<span class="number">1</span></span><br><span class="line">es-node-2 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.97</span> host_name=es-node-<span class="number">2</span></span><br><span class="line"></span><br><span class="line">harbor <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.89</span> host_name=harbor</span><br><span class="line"></span><br><span class="line"><span class="section">[servers:children]</span></span><br><span class="line">k8s</span><br><span class="line">es</span><br><span class="line"></span><br><span class="line"><span class="section">[servers:vars]</span></span><br><span class="line"><span class="attr">ansible_connection</span>=paramiko</span><br><span class="line"><span class="attr">ansible_ssh_user</span>=root</span><br><span class="line"><span class="attr">ansible_ssh_pass</span>=F@ywwpTj4bJtYwzpwCqD</span><br></pre></td></tr></table></figure><h3 id="3-2-检测服务器连通性"><a href="#3-2-检测服务器连通性" class="headerlink" title="3.2. 检测服务器连通性"></a>3.2. 检测服务器连通性</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 检测服务器的连通性</span></span><br><span class="line"></span><br><span class="line">cd /data/ansible/ansible-zdevops/inventories/dev/</span><br><span class="line">source /opt/ansible2.8/bin/activate</span><br><span class="line">ansible -m ping all</span><br></pre></td></tr></table></figure><h3 id="3-3-初始化服务器配置"><a href="#3-3-初始化服务器配置" class="headerlink" title="3.3. 初始化服务器配置"></a>3.3. 初始化服务器配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化服务器配置</span></span><br><span class="line"></span><br><span class="line">ansible-playbook ../../playbooks/init-base.yaml -l k8s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 添加hosts 解析</span></span><br><span class="line">ansible k8s -m shell -a &#x27;echo &quot;192.168.9.89 registry.zdevops.com.cn&quot; &gt;&gt; /etc/hosts&#x27;</span><br></pre></td></tr></table></figure><h3 id="3-4-挂载数据盘"><a href="#3-4-挂载数据盘" class="headerlink" title="3.4. 挂载数据盘"></a>3.4. 挂载数据盘</h3><ul><li><strong>挂载第一块数据盘</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化主机数据盘</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意 -e data_disk_path=<span class="string">&quot;/data&quot;</span> 指定挂载目录, 用于存储 Docker 容器数据</span></span><br><span class="line"></span><br><span class="line">ansible-playbook ../../playbooks/init-disk.yaml -e data_disk_path=&quot;/data&quot; -l k8s</span><br></pre></td></tr></table></figure><ul><li><strong>挂载验证</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否格式化并挂载</span></span><br><span class="line">ansible k8s -m shell -a &#x27;df -h&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否配置自动挂载</span></span><br><span class="line">ansible k8s -m shell -a &#x27;tail -1  /etc/fstab&#x27;</span><br></pre></td></tr></table></figure><h3 id="3-5-安装-K8S-系统依赖包"><a href="#3-5-安装-K8S-系统依赖包" class="headerlink" title="3.5. 安装 K8S 系统依赖包"></a>3.5. 安装 K8S 系统依赖包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 安装 kubernetes 系统依赖包</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ansible-playbook 中设置了启用 GlusterFS 存储的开关，默认开启,不需要的可以将参数设置为 False</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/deploy-kubesphere.yaml -e k8s_storage_glusterfs=false -l k8s</span><br></pre></td></tr></table></figure><h2 id="4-离线安装集群"><a href="#4-离线安装集群" class="headerlink" title="4. 离线安装集群"></a>4. 离线安装集群</h2><h3 id="4-1-传输离线部署资源到部署节点"><a href="#4-1-传输离线部署资源到部署节点" class="headerlink" title="4.1. 传输离线部署资源到部署节点"></a>4.1. 传输离线部署资源到部署节点</h3><p>将以下离线部署资源，传到部署节点 (通常是第一个 master 节点) 的 &#x2F;data&#x2F;kubekey 目录。</p><ul><li>Kubekey：<strong>kubekey-v2.2.1.tar.gz</strong></li><li>制品 artifact：<strong>kubesphere-v3.3.0-artifact.tar.gz</strong></li></ul><p>执行以下操作，解压 kubekey。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /data/kubekey</span><br><span class="line">tar xvf kubekey-v2.2.1.tar.gz</span><br></pre></td></tr></table></figure><h3 id="4-2-创建离线集群配置文件"><a href="#4-2-创建离线集群配置文件" class="headerlink" title="4.2. 创建离线集群配置文件"></a>4.2. 创建离线集群配置文件</h3><ul><li>创建配置文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kk create config --with-kubesphere v3.3.0 --with-kubernetes v1.24.1 -f config-sample.yaml</span><br></pre></td></tr></table></figure><ul><li>修改配置文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim config-sample.yaml</span><br></pre></td></tr></table></figure><blockquote><p><strong>修改内容说明</strong></p><ul><li>按照实际离线环境配置修改节点信息。</li><li>按实际情况添加 <strong>registry</strong> 的相关信息。</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubekey.kubesphere.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Cluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sample</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">ks-k8s-master-0</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.91</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.91</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">&quot;F@ywwpTj4bJtYwzpwCqD&quot;</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">ks-k8s-master-1</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.92</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.92</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">&quot;F@ywwpTj4bJtYwzpwCqD&quot;</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">ks-k8s-master-2</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.93</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.93</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">&quot;F@ywwpTj4bJtYwzpwCqD&quot;</span>&#125;</span><br><span class="line">  <span class="attr">roleGroups:</span></span><br><span class="line">    <span class="attr">etcd:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">    <span class="attr">control-plane:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">    <span class="attr">worker:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">  <span class="attr">controlPlaneEndpoint:</span></span><br><span class="line">    <span class="comment">## Internal loadbalancer for apiservers </span></span><br><span class="line">    <span class="attr">internalLoadbalancer:</span> <span class="string">haproxy</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">domain:</span> <span class="string">lb.zdevops.com.cn</span></span><br><span class="line">    <span class="attr">address:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6443</span></span><br><span class="line">  <span class="attr">kubernetes:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1.24.1</span></span><br><span class="line">    <span class="attr">clusterName:</span> <span class="string">zdevops.com.cn</span></span><br><span class="line">    <span class="attr">autoRenewCerts:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">containerManager:</span> <span class="string">containerd</span></span><br><span class="line">  <span class="attr">etcd:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">kubekey</span></span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">plugin:</span> <span class="string">calico</span></span><br><span class="line">    <span class="attr">kubePodsCIDR:</span> <span class="number">10.233</span><span class="number">.64</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">    <span class="attr">kubeServiceCIDR:</span> <span class="number">10.233</span><span class="number">.0</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">    <span class="comment">## multus support. https://github.com/k8snetworkplumbingwg/multus-cni</span></span><br><span class="line">    <span class="attr">multusCNI:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">&quot;harbor&quot;</span></span><br><span class="line">    <span class="attr">auths:</span></span><br><span class="line">      <span class="attr">&quot;registry.zdevops.com.cn&quot;:</span></span><br><span class="line">         <span class="attr">username:</span> <span class="string">admin</span></span><br><span class="line">         <span class="attr">password:</span> <span class="string">Harbor12345</span></span><br><span class="line">    <span class="attr">privateRegistry:</span> <span class="string">&quot;registry.zdevops.com.cn&quot;</span></span><br><span class="line">    <span class="attr">namespaceOverride:</span> <span class="string">&quot;kubesphereio&quot;</span></span><br><span class="line">    <span class="attr">registryMirrors:</span> []</span><br><span class="line">    <span class="attr">insecureRegistries:</span> []</span><br><span class="line">  <span class="attr">addons:</span> []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面的内容不修改，不做展示</span></span><br></pre></td></tr></table></figure><h3 id="4-3-在-Harbor-中创建项目"><a href="#4-3-在-Harbor-中创建项目" class="headerlink" title="4.3. 在 Harbor 中创建项目"></a>4.3. 在 Harbor 中创建项目</h3><p>本文采用提前部署好的 Harbor 来存放镜像，部署过程参考我之前写的<a href="https://gitee.com/zdevops/z-notes/blob/main/k8s-on-kubesphere/10-%E5%9F%BA%E4%BA%8EKubeSphere%E7%8E%A9%E8%BD%ACk8s-Harbor%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0.md"> 基于 KubeSphere 玩转 k8s-Harbor 安装手记</a>。</p><p>你可以使用 kk 工具自动部署 Harbor，具体参考<a href="https://kubesphere.com.cn/docs/v3.3/installing-on-linux/introduction/air-gapped-installation/">官方离线部署文档</a>。</p><ul><li>下载创建项目脚本模板</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -O https://raw.githubusercontent.com/kubesphere/ks-installer/master/scripts/create_project_harbor.sh</span><br></pre></td></tr></table></figure><ul><li>根据实际情况修改项目脚本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Harbor 仓库地址</span></span><br><span class="line">url=&quot;https://registry.zdevops.com.cn&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问 Harbor 仓库用户</span></span><br><span class="line">user=&quot;admin&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问 Harbor 仓库用户密码</span></span><br><span class="line">passwd=&quot;Harbor12345&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要创建的项目名列表，正常只需要创建一个**kubesphereio**即可，这里为了保留变量可扩展性多写了两个。</span></span><br><span class="line">harbor_projects=(library</span><br><span class="line">    kubesphereio</span><br><span class="line">    kubesphere</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for project in &quot;$&#123;harbor_projects[@]&#125;&quot;; do</span><br><span class="line">    echo &quot;creating $project&quot;</span><br><span class="line">    curl -u &quot;$&#123;user&#125;:$&#123;passwd&#125;&quot; -X POST -H &quot;Content-Type: application/json&quot; &quot;$&#123;url&#125;/api/v2.0/projects&quot; -d &quot;&#123; \&quot;project_name\&quot;: \&quot;$&#123;project&#125;\&quot;, \&quot;public\&quot;: true&#125;&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><ul><li>执行脚本创建项目</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh create_project_harbor.sh</span><br></pre></td></tr></table></figure><h3 id="4-4-推送离线镜像到-Harbor-仓库"><a href="#4-4-推送离线镜像到-Harbor-仓库" class="headerlink" title="4.4. 推送离线镜像到 Harbor 仓库"></a>4.4. 推送离线镜像到 Harbor 仓库</h3><p>将提前准备好的离线镜像推送到 Harbor 仓库，这一步为可选项，因为创建集群的时候也会再次推送镜像。为了部署一次成功率，建议先推送。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kk artifact image push -f config-sample.yaml -a  kubesphere-v3.3.0-artifact.tar.gz</span><br></pre></td></tr></table></figure><h3 id="4-5-创建集群并安装-OS-依赖"><a href="#4-5-创建集群并安装-OS-依赖" class="headerlink" title="4.5 创建集群并安装 OS 依赖"></a>4.5 创建集群并安装 OS 依赖</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kk create cluster -f config-sample.yaml -a kubesphere-v3.3.0-artifact.tar.gz --with-packages</span><br></pre></td></tr></table></figure><blockquote><p><strong>参数说明</strong></p><ul><li><strong>config-sample.yaml</strong>：离线环境集群的配置文件。</li><li><strong>kubesphere-v3.3.0-artifact.tar.gz</strong>：制品包的 tar 包镜像。</li><li><strong>–with-packages</strong>：若需要安装操作系统依赖，需指定该选项。</li></ul></blockquote><h3 id="4-6-查看集群状态"><a href="#4-6-查看集群状态" class="headerlink" title="4.6. 查看集群状态"></a>4.6. 查看集群状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l &#x27;app in (ks-install, ks-installer)&#x27; -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure><p>正确安装完成后，您会看到以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Collecting</span> <span class="string">installation</span> <span class="string">results</span> <span class="string">...</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="comment">###              Welcome to KubeSphere!           ###</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Console:</span> <span class="string">http://192.168.9.91:30880</span></span><br><span class="line"><span class="attr">Account:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">Password:</span> <span class="string">P@88w0rd</span></span><br><span class="line"></span><br><span class="line"><span class="string">NOTES：</span></span><br><span class="line">  <span class="number">1</span><span class="string">.</span> <span class="string">After</span> <span class="string">you</span> <span class="string">log</span> <span class="string">into</span> <span class="string">the</span> <span class="string">console,</span> <span class="string">please</span> <span class="string">check</span> <span class="string">the</span></span><br><span class="line">     <span class="string">monitoring</span> <span class="string">status</span> <span class="string">of</span> <span class="string">service</span> <span class="string">components</span> <span class="string">in</span></span><br><span class="line">     <span class="string">&quot;Cluster Management&quot;</span><span class="string">.</span> <span class="string">If</span> <span class="string">any</span> <span class="string">service</span> <span class="string">is</span> <span class="string">not</span></span><br><span class="line">     <span class="string">ready,</span> <span class="string">please</span> <span class="string">wait</span> <span class="string">patiently</span> <span class="string">until</span> <span class="string">all</span> <span class="string">components</span> </span><br><span class="line">     <span class="string">are</span> <span class="string">up</span> <span class="string">and</span> <span class="string">running.</span></span><br><span class="line">  <span class="number">2</span><span class="string">.</span> <span class="string">Please</span> <span class="string">change</span> <span class="string">the</span> <span class="string">default</span> <span class="string">password</span> <span class="string">after</span> <span class="string">login.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="string">https://kubesphere.io</span>             <span class="number">2022-06-30 14:30:19</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br></pre></td></tr></table></figure><h3 id="4-7-登录-Web-控制台"><a href="#4-7-登录-Web-控制台" class="headerlink" title="4.7. 登录 Web 控制台"></a>4.7. 登录 Web 控制台</h3><p>通过 <code>http://&#123;IP&#125;:30880</code> 使用默认帐户和密码 <code>admin/P@88w0rd</code> 访问 KubeSphere 的 Web 控制台，进行后续的操作配置。</p><p><img src="https://kubesphere.com.cn/images/docs/v3.3/zh-cn/upgrade/air-gapped-upgrade-with-ks-installer/kubesphere-login.PNG"></p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>感谢您完整的阅读完本文，您应该 Get 到了以下技能</p><ul><li>了解了清单 (manifest) 和制品 (artifact) 的概念</li><li>了解 manifest 和 image 资源的获取地址</li><li>手写 manifest 清单</li><li>根据 manifest 清单制作 artifact</li><li>离线部署 KubeSphere 和 Kubernetes</li><li>Harbor 镜像仓库自动创建项目</li><li>Ansible 使用的小技巧</li></ul><p>目前为止，我们已经完成了最小化环境的 KubeSphere 和 Kubernetes 集群的部署。但是，这仅仅是一个开始，后续还有很多配置和使用技巧，敬请持续关注 …</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li>见正文</li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D; <strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-KubeSphere3-3-离线安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-KubeSphere3-3-离线安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSph</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-Nacos 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Nacos%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Nacos%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.463Z</published>
    <updated>2023-09-22T01:44:31.126Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-Nacos-安装手记"><a href="#基于-KubeSphere-玩转-k8s-Nacos-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-Nacos 安装手记"></a>基于 KubeSphere 玩转 k8s-Nacos 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><strong>KubeSphere</strong></li><li><strong>Kubernetes</strong></li><li><strong>Ansible</strong></li><li><strong>自动化运维</strong></li><li><strong>CNCF 技术栈</strong></li></ul></blockquote><p><strong>本文内容概览</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220702172207520.png" alt="nacos"></p><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>Nacos 集群如何在 K8S 集群上部署？Nacos 依赖的 MySQL 数据库如何在 K8S 集群上部署？GitOps 在 K8S 集群上是一种什么体验？本文将带你全面了解上述问题。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：10 分</li><li>行：835</li><li>单词：2900+</li><li>字符：22100</li><li>图片：6 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>MySQL StatefulSet 部署</li><li>Nacoc 集群部署</li><li>GitOps</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200+200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker&#x2F;Ceph</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">harbor</td><td align="center">192.168.9.89</td><td align="center">2</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Harbor</td></tr><tr><td align="center">合计</td><td align="center">8</td><td align="center">22</td><td align="center">84</td><td align="center">320</td><td align="center">2200</td><td align="center"></td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>Ansible：<strong>2.8.20</strong></li><li>Harbor：<strong>2.5.1</strong></li><li>Nacos：<strong>v2.1.0</strong></li><li>MySQL：<strong>5.7.38</strong></li></ul><h2 id="2-前提条件"><a href="#2-前提条件" class="headerlink" title="2. 前提条件"></a>2. 前提条件</h2><h3 id="2-1-准备离线镜像"><a href="#2-1-准备离线镜像" class="headerlink" title="2.1. 准备离线镜像"></a>2.1. 准备离线镜像</h3><p>此过程为可选项，离线内网环境可用，如果是直连互联网的场景，可以直接使用互联网的镜像。</p><p>在一台能同时访问互联网和内网 Harbor 仓库的服务器上进行下面的操作。</p><ul><li>下载镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull mysql:5.7.38</span><br><span class="line">docker pull nacos/nacos-peer-finder-plugin:1.1</span><br><span class="line">docker pull nacos/nacos-server:v2.1.0</span><br></pre></td></tr></table></figure><ul><li>重新打 tag</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker tag mysql:5.7.38 registry.zdevops.com.cn/library/mysql:5.7.38</span><br><span class="line">docker tag nacos/nacos-peer-finder-plugin:1.1 registry.zdevops.com.cn/nacos/nacos-peer-finder-plugin:1.1</span><br><span class="line">docker tag nacos/nacos-server:v2.1.0 registry.zdevops.com.cn/nacos/nacos-server:v2.1.0</span><br></pre></td></tr></table></figure><ul><li>推送到私有镜像仓库</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要提前在镜像仓库中创建 Harbor 项目</span></span><br><span class="line">docker push registry.zdevops.com.cn/library/mysql:5.7.38</span><br><span class="line">docker push registry.zdevops.com.cn/nacos/nacos-peer-finder-plugin:1.1</span><br><span class="line">docker push registry.zdevops.com.cn/nacos/nacos-server:v2.1.0</span><br></pre></td></tr></table></figure><ul><li>清理临时镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker rmi mysql:5.7.38</span><br><span class="line">docker rmi nacos/nacos-peer-finder-plugin:1.1</span><br><span class="line">docker rmi nacos/nacos-server:v2.1.0</span><br><span class="line">docker rmi registry.zdevops.com.cn/library/mysql:5.7.38</span><br><span class="line">docker rmi registry.zdevops.com.cn/nacos/nacos-peer-finder-plugin:1.1</span><br><span class="line">docker rmi registry.zdevops.com.cn/nacos/nacos-server:v2.1.0</span><br></pre></td></tr></table></figure><h3 id="2-2-准备-Nacos-部署资源"><a href="#2-2-准备-Nacos-部署资源" class="headerlink" title="2.2. 准备 Nacos 部署资源"></a>2.2. 准备 Nacos 部署资源</h3><ul><li>官方资源配置清单</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">拉取官方的配置清单，各位参考着进行修改，本文不涉及修改过程</span></span><br><span class="line">git clone https://github.com/nacos-group/nacos-k8s.git</span><br></pre></td></tr></table></figure><ul><li>初始化数据库文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/alibaba/nacos/develop/distribution/conf/nacos-mysql.sql</span><br></pre></td></tr></table></figure><h2 id="3-部署-MySQL"><a href="#3-部署-MySQL" class="headerlink" title="3. 部署 MySQL"></a>3. 部署 MySQL</h2><p>Nacos 需要使用 MySQL 存储配置数据，由于使用量不大，没有考虑高可用部署，直接在 K8S 上部署。也可以采用已有的 MySQL 数据库。</p><h3 id="3-1-资源配置清单"><a href="#3-1-资源配置清单" class="headerlink" title="3.1. 资源配置清单"></a>3.1. 资源配置清单</h3><ul><li>mysql-cm.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-mysql-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">custom.cnf:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    [mysqld]</span></span><br><span class="line"><span class="string">    #performance setttings</span></span><br><span class="line"><span class="string">    lock_wait_timeout = 3600</span></span><br><span class="line"><span class="string">    open_files_limit    = 65535</span></span><br><span class="line"><span class="string">    back_log = 1024</span></span><br><span class="line"><span class="string">    max_connections = 1024</span></span><br><span class="line"><span class="string">    max_connect_errors = 1000000</span></span><br><span class="line"><span class="string">    table_open_cache = 1024</span></span><br><span class="line"><span class="string">    table_definition_cache = 1024</span></span><br><span class="line"><span class="string">    thread_stack = 512K</span></span><br><span class="line"><span class="string">    sort_buffer_size = 4M</span></span><br><span class="line"><span class="string">    join_buffer_size = 4M</span></span><br><span class="line"><span class="string">    read_buffer_size = 8M</span></span><br><span class="line"><span class="string">    read_rnd_buffer_size = 4M</span></span><br><span class="line"><span class="string">    bulk_insert_buffer_size = 64M</span></span><br><span class="line"><span class="string">    thread_cache_size = 768</span></span><br><span class="line"><span class="string">    interactive_timeout = 600</span></span><br><span class="line"><span class="string">    wait_timeout = 600</span></span><br><span class="line"><span class="string">    tmp_table_size = 32M</span></span><br><span class="line"><span class="string">    max_heap_table_size = 32M</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><ul><li>mysql-secret.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-mysql-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">UEA4OHcwcmQ=</span></span><br><span class="line">  <span class="attr">MYSQL_PASSWORD:</span> <span class="string">UEA4OHcwcmQ=</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>MYSQL_ROOT_PASSWORD</strong> 和 <strong>MYSQL_PASSWORD</strong> 是 MySQL 中 root 和 nacos 用户的密码。</p><p>密码需要使用 <code>echo -n &quot;P@88w0rd&quot; | base64</code> 加密的方式。</p><ul><li>mysql-sts.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-mysql</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nacos-mysql</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nacos-mysql</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">nacos-mysql-config</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">custom.cnf</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">custom.cnf</span></span><br><span class="line">            <span class="attr">defaultMode:</span> <span class="number">420</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nacos-mysql</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;registry.zdevops.com.cn/library/mysql:5.7.38&#x27;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-3306</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">3306</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-mysql-secret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-mysql-secret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">MYSQL_PASSWORD</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_DATABASE</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;nacos&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_USER</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;nacos&quot;</span> </span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/var/lib/mysql</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/mysql/conf.d/custom.cnf</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">custom.cnf</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">glusterfs</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">mysql-headless</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-mysql-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-mysql</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-3306</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-mysql</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>MYSQL_DATABASE</strong> 和 <strong>MYSQL_USER</strong> 是 MySQL 初始化时创建的 nacos 数据库名称和 nacos 用户名称。</p><ul><li>mysql-external.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-mysql-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-mysql-external</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql-external</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31006</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos-mysql</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-2-GitOps"><a href="#3-2-GitOps" class="headerlink" title="3.2. GitOps"></a>3.2. GitOps</h3><p><strong>在运维开发服务器上操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建新分支</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git checkout -b main-nacos-062401 main</span><br><span class="line">Switched to a new branch &#x27;main-nacos-062401&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在已有代码仓库创建 nacos 目录</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# mkdir nacos</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑资源配置清单</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/mysql-cm.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/mysql-secret.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/mysql-sts.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/mysql-external.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交 Git</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git add nacos</span><br><span class="line">[root@zdevops-master k8s-yaml]# git commit -am &#x27;添加 nacos mysql部署资源配置清单&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分支合并</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git checkout main</span><br><span class="line">Switched to branch &#x27;main&#x27;</span><br><span class="line">Your branch is up to date with &#x27;origin/main&#x27;.</span><br><span class="line"></span><br><span class="line">[root@zdevops-master k8s-yaml]# git merge main-nacos-062401</span><br><span class="line">Updating e60e3e3..2d51a5a</span><br><span class="line">Fast-forward</span><br><span class="line"> nacos/mysql-cm.yaml       | 27 +++++++++++++++++++++++</span><br><span class="line"> nacos/mysql-external.yaml | 17 ++++++++++++++</span><br><span class="line"> nacos/mysql-secret.yaml   |  9 ++++++++</span><br><span class="line"> nacos/mysql-sts.yaml      | 98 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"> nodeport.md               |  2 +-</span><br><span class="line"> 5 files changed, 152 insertions(+), 1 deletion(-)</span><br><span class="line"> create mode 100644 nacos/mysql-cm.yaml</span><br><span class="line"> create mode 100644 nacos/mysql-external.yaml</span><br><span class="line"> create mode 100644 nacos/mysql-secret.yaml</span><br><span class="line"> create mode 100644 nacos/mysql-sts.yaml</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">删除临时分支</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git branch -d  main-nacos-062401</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">推送到远程仓库</span> </span><br><span class="line"> [root@zdevops-master k8s-yaml]# git push</span><br></pre></td></tr></table></figure><h3 id="3-3-部署资源"><a href="#3-3-部署资源" class="headerlink" title="3.3. 部署资源"></a>3.3. 部署资源</h3><p><strong>在运维管理服务器上操作</strong></p><ul><li>更新镜像仓库代码</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# git pull</span><br></pre></td></tr></table></figure><ul><li>部署资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/mysql-cm.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/mysql-secret.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/mysql-sts.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/mysql-external.yaml</span><br></pre></td></tr></table></figure><h3 id="3-4-验证"><a href="#3-4-验证" class="headerlink" title="3.4. 验证"></a>3.4. 验证</h3><ul><li>查看资源状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl get cm,secrets,pvc,sts,pods -n zdevops -o wide</span><br><span class="line">NAME                             DATA   AGE</span><br><span class="line">configmap/nacos-mysql-config     1      3h10m</span><br><span class="line"></span><br><span class="line">NAME                           TYPE                                  DATA   AGE</span><br><span class="line">secret/nacos-mysql-secret      Opaque                                2      3h10m</span><br><span class="line"></span><br><span class="line">NAME                                       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE     VOLUMEMODE</span><br><span class="line">persistentvolumeclaim/data-nacos-mysql-0   Bound    pvc-13bec5c5-33e2-46df-bcdc-dc216c17f88a   5Gi        RWO            glusterfs      3h10m   Filesystem</span><br><span class="line"></span><br><span class="line">NAME                           READY   AGE     CONTAINERS    IMAGES</span><br><span class="line">statefulset.apps/nacos-mysql   1/1     3h10m   nacos-mysql   registry.zdevops.com.cn/library/mysql:5.7.38</span><br><span class="line"></span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE   IP               NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">pod/nacos-mysql-0   1/1     Running   0          32m   10.233.116.189   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><ul><li>MySQL 登录验证</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入 MySQL POD</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl exec -it nacos-mysql-0 -n zdevops -- /bin/bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 MySQL POD 内部以 root 用户连接 MySQL 服务器，并列出数据库</span></span><br><span class="line">root@nacos-mysql-0:/# mysql -u root -pP@88w0rd</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 4</span><br><span class="line">Server version: 5.7.38 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2022, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">show databases;</span></span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| nacos              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line">5 rows in set (0.01 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">quit</span></span><br><span class="line">Bye</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 MySQL POD 内部以 nacos 用户连接 MySQL 服务器，并列出数据库</span></span><br><span class="line">root@nacos-mysql-0:/# mysql -u nacos -pP@88w0rd</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 5</span><br><span class="line">Server version: 5.7.38 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2022, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">show databases;</span></span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| nacos              |</span><br><span class="line">+--------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">quit</span></span><br><span class="line">Bye</span><br></pre></td></tr></table></figure><h3 id="3-5-导入-Nacos-初始化数据"><a href="#3-5-导入-Nacos-初始化数据" class="headerlink" title="3.5. 导入 Nacos 初始化数据"></a>3.5. 导入 Nacos 初始化数据</h3><p>本文采用将 SQL 文件复制到容器内部执行的方式导入数据。实际使用中，可以直接在集群外部使用 MySQL 客户端连接 MySQL 的 NodePort 管理数据库并导入数据。</p><ul><li>获取初始化数据库文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">官方</span></span><br><span class="line">wget https://raw.githubusercontent.com/alibaba/nacos/develop/distribution/conf/nacos-mysql.sql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Gitee备用</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">wget https://gitee.com/zdevops/k8s-yaml/raw/main/nacos/nacos-mysql.sql</span></span><br></pre></td></tr></table></figure><ul><li>将 SQL 文件复制到 MySQL 容器内部</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">拷贝文件</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# cd nacos</span><br><span class="line">[root@zdevops-master nacos]# kubectl cp nacos-mysql.sql -n zdevops nacos-mysql-0:home/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确认文件成功拷贝</span></span><br><span class="line">[root@zdevops-master nacos]# kubectl exec -it nacos-mysql-0 -n zdevops -- ls /home</span><br></pre></td></tr></table></figure><ul><li>登录容器内部，导入数据</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入 MySQL POD</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl exec -it nacos-mysql-0 -n zdevops -- /bin/bash</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导入数据， 需要输入 nacos 用户的密码</span></span><br><span class="line">root@nacos-mysql-0:/# mysql -u nacos -p nacos &lt; /home/nacos-mysql.sql </span><br><span class="line">Enter password: </span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4-集群模式-Nacos-部署"><a href="#4-集群模式-Nacos-部署" class="headerlink" title="4. 集群模式 Nacos 部署"></a>4. 集群模式 Nacos 部署</h2><h3 id="4-1-资源配置清单"><a href="#4-1-资源配置清单" class="headerlink" title="4.1. 资源配置清单"></a>4.1. 资源配置清单</h3><ul><li>nacos-cm.yaml</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: nacos-config</span><br><span class="line">  namespace: zdevops</span><br><span class="line">data:</span><br><span class="line">  mysql.host: &quot;nacos-mysql-external.zdevops&quot;</span><br><span class="line">  mysql.db.name: &quot;nacos&quot;</span><br><span class="line">  mysql.port: &quot;3306&quot;</span><br><span class="line">  mysql.user: &quot;nacos&quot;</span><br><span class="line">  mysql.password: &quot;P@88w0rd&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>nacos-sts.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">nacos-headless</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">pod.alpha.kubernetes.io/initialized:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">                <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;app&quot;</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">nacos</span></span><br><span class="line">              <span class="attr">topologyKey:</span> <span class="string">&quot;kubernetes.io/hostname&quot;</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">peer-finder-plugin-install</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">registry.zdevops.com.cn/nacos/nacos-peer-finder-plugin:1.1</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/home/nacos/plugins/peer-finder</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">peer-finder</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nacos</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">registry.zdevops.com.cn/nacos/nacos-server:v2.1.0</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4Gi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">&quot;1Gi&quot;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">client-port</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">client-rpc</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">9849</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">raft-rpc</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">7848</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">old-raft-rpc</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_REPLICAS</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SERVICE_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;nacos-headless&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DOMAIN_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;cluster.local&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_HOST</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-config</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.host</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_DB_NAME</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-config</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.db.name</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PORT</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-config</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.port</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_USER</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-config</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.user</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_SERVICE_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">configMapKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">nacos-config</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">mysql.password</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_SERVER_PORT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;8848&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NACOS_APPLICATION_PORT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;8848&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PREFER_HOST_MODE</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;hostname&quot;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/home/nacos/plugins/peer-finder</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">peer-finder</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/home/nacos/data</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">data</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/home/nacos/logs</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">logs</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteMany&quot;</span> ]</span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">service.alpha.kubernetes.io/tolerate-unready-endpoints:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">server</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8848</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">client-rpc</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9848</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9849</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">raft-rpc</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9849</span></span><br><span class="line">    <span class="comment">## 兼容1.4.x版本的选举端口</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">7848</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">old-raft-rpc</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">7848</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>DOMAIN_NAME</strong> 要改成实际的 K8S 的集群域名</p><ul><li>nacos-external.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nacos-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">external</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-nacos-external</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8848</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31848</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nacos</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-2-GitOps"><a href="#4-2-GitOps" class="headerlink" title="4.2. GitOps"></a>4.2. GitOps</h3><p><strong>在运维开发服务器上操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建新分支</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git checkout -b main-nacos-062402 main</span><br><span class="line">Switched to a new branch &#x27;main-nacos-062402&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑资源配置清单</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/nacos-cm.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/nacos-sts.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi nacos/nacos-external.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交 Git</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git add nacos</span><br><span class="line">[root@zdevops-master k8s-yaml]# git commit -am &#x27;添加nacos部署资源配置清单&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分支合并</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git checkout main</span><br><span class="line">[root@zdevops-master k8s-yaml]# git merge main-nacos-062402</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除临时分支</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git branch -d  main-nacos-062402</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">推送到远程仓库</span> </span><br><span class="line"> [root@zdevops-master k8s-yaml]# git push</span><br></pre></td></tr></table></figure><h3 id="4-3-部署资源"><a href="#4-3-部署资源" class="headerlink" title="4.3. 部署资源"></a>4.3. 部署资源</h3><p><strong>在运维管理服务器上操作</strong></p><ul><li>更新镜像仓库代码</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# git pull</span><br></pre></td></tr></table></figure><ul><li>部署资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/nacos-cm.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/nacos-sts.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f nacos/nacos-external.yaml</span><br></pre></td></tr></table></figure><h3 id="4-4-验证"><a href="#4-4-验证" class="headerlink" title="4.4. 验证"></a>4.4. 验证</h3><ul><li>资源验证</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sts</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl get sts -n zdevops -o wide</span><br><span class="line">NAME          READY   AGE     CONTAINERS    IMAGES</span><br><span class="line">nacos         3/3     3h13m   nacos         registry.zdevops.com.cn/nacos/nacos-server:v2.1.0</span><br><span class="line">nacos-mysql   1/1     26h     nacos-mysql   registry.zdevops.com.cn/library/mysql:5.7.38</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pods</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl get pods -n zdevops -o wide</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE     IP               NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">nacos-0         1/1     Running   0          3h12m   10.233.116.220   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nacos-1         1/1     Running   0          3h12m   10.233.117.101   ks-k8s-master-0   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nacos-2         1/1     Running   0          3h12m   10.233.87.14     ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nacos-mysql-0   1/1     Running   0          23h     10.233.116.189   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">svc</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl get svc -n zdevops -o wide</span><br><span class="line">NAME                                                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                               AGE     SELECTOR</span><br><span class="line">glusterfs-dynamic-13bec5c5-33e2-46df-bcdc-dc216c17f88a   ClusterIP   10.233.48.177   &lt;none&gt;        1/TCP                                 26h     &lt;none&gt;</span><br><span class="line">glusterfs-dynamic-39795af9-8307-408c-ba2a-d0648f658f1b   ClusterIP   10.233.31.22    &lt;none&gt;        1/TCP                                 3h12m   &lt;none&gt;</span><br><span class="line">glusterfs-dynamic-cc4be907-9ef3-4a69-92d7-1875f7051e36   ClusterIP   10.233.34.82    &lt;none&gt;        1/TCP                                 3h12m   &lt;none&gt;</span><br><span class="line">glusterfs-dynamic-e73324a8-3f97-4697-a7dc-67576863f21a   ClusterIP   10.233.27.2     &lt;none&gt;        1/TCP                                 3h12m   &lt;none&gt;</span><br><span class="line">nacos-external                                           NodePort    10.233.63.221   &lt;none&gt;        8848:30848/TCP                        3h12m   app=nacos</span><br><span class="line">nacos-headless                                           ClusterIP   None            &lt;none&gt;        8848/TCP,9848/TCP,9849/TCP,7848/TCP   3h12m   app=nacos</span><br><span class="line">nacos-mysql-external                                     NodePort    10.233.12.228   &lt;none&gt;        3306:31006/TCP                        23h     app=nacos-mysql</span><br><span class="line">nacos-mysql-headless                                     ClusterIP   None            &lt;none&gt;        3306/TCP                              26h     app=nacos-mysql</span><br></pre></td></tr></table></figure><ul><li>登录 Nacos 管理控制台</li></ul><p>在浏览器中输入 <strong>http:&#x2F;&#x2F; 任意节点 IP:30848</strong>，输入默认的用户名和密码，<strong>nacos</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-nacos-0.png" alt="kubesphere-nacos-0"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-nacos-1.png" alt="kubesphere-nacos-1"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-nacos-2.png" alt="kubesphere-nacos-2"></p><h3 id="4-5-初始化配置"><a href="#4-5-初始化配置" class="headerlink" title="4.5. 初始化配置"></a>4.5. 初始化配置</h3><ul><li>修改默认密码</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-nacos-3.png" alt="kubesphere-nacos-3"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-nacos-4.png" alt="kubesphere-nacos-4"></p><ul><li>后续配置</li></ul><p>后面我也不知道需要干啥了，找研发给配置导入就行了。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>本文详细介绍了 Nacos 集群模式在基于 KubeSphere 部署的 K8S 集群上的安装部署方法。同时，介绍了 MySQL 在 K8S 上的安装部署方法。</p><p>本文的配置方案可直接用于开发测试环境，对于生产环境也有一定的借鉴意义。</p><blockquote><p><strong>参考文档</strong></p></blockquote><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-Nacos-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-Nacos-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s-Nacos 安装手</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-Redis 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Redis%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Redis%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.429Z</published>
    <updated>2023-09-22T01:44:15.926Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-Redis-安装手记"><a href="#基于-KubeSphere-玩转-k8s-Redis-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-Redis 安装手记"></a>基于 KubeSphere 玩转 k8s-Redis 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>Redis 单节点如何在 K8S 集群上部署？Redis 集群模式如何在 K8S 集群上部署？是否有能在 K8S 集群上部署的 Web 图形化的 Redis 管理工具？GitOps 在 K8S 集群上是咋玩的？本文将带你解决上面的问题。</p><blockquote><p>本文知识量</p></blockquote><ul><li>阅读时长：10 分</li><li>行：810</li><li>单词：3200+</li><li>字符：21700+</li><li>图片：9 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>Redis 单节点安装部署</li><li>Redis 集群安装部署</li><li>RedisInsight 安装部署</li><li>GitOps 运维思想</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">ceph-node-0</td><td align="center">192.168.9.85</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Ceph</td></tr><tr><td align="center">ceph-node-1</td><td align="center">192.168.9.86</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Ceph</td></tr><tr><td align="center">ceph-node-2</td><td align="center">192.168.9.87</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Ceph</td></tr><tr><td align="center">harbor</td><td align="center">192.168.9.89</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Harbor</td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>Redis： <strong>6.2.7</strong></li><li>RedisInsight：<strong>1.12.0</strong></li></ul><h2 id="2-单节点-Redis-部署"><a href="#2-单节点-Redis-部署" class="headerlink" title="2. 单节点 Redis 部署"></a>2. 单节点 Redis 部署</h2><h3 id="2-1-思路梳理"><a href="#2-1-思路梳理" class="headerlink" title="2.1. 思路梳理"></a>2.1. 思路梳理</h3><ul><li>StatefulSet</li><li>Headless Service</li><li>ConfigMap：redis.conf</li></ul><h3 id="2-2-准备离线镜像"><a href="#2-2-准备离线镜像" class="headerlink" title="2.2. 准备离线镜像"></a>2.2. 准备离线镜像</h3><p>此过程为可选项，离线内网环境可用。</p><p>在一台能同时访问互联网和内网 Harbor 仓库的服务器上进行下面的操作。</p><ul><li>下载镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull redis:6.2.7</span><br></pre></td></tr></table></figure><ul><li>重新打 tag</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag redis:6.2.7 registry.zdevops.com.cn/library/redis:6.2.7</span><br></pre></td></tr></table></figure><ul><li>推送到私有镜像仓库</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push registry.zdevops.com.cn/library/redis:6.2.7</span><br></pre></td></tr></table></figure><h3 id="2-3-资源配置清单"><a href="#2-3-资源配置清单" class="headerlink" title="2.3. 资源配置清单"></a>2.3. 资源配置清单</h3><ul><li><strong>redis-cm.yaml</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">redis-config:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    appendonly yes</span></span><br><span class="line"><span class="string">    protected-mode no</span></span><br><span class="line"><span class="string">    dir /data</span></span><br><span class="line"><span class="string">    port 6379</span></span><br><span class="line"><span class="string">    requirepass redis@abc.com</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><ul><li><strong>redis-sts.yaml</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">redis-headless</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;registry.zdevops.com.cn/library/redis:6.2.7&#x27;</span></span><br><span class="line">          <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;redis-server&quot;</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;/etc/redis/redis.conf&quot;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-6379</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">6379</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/redis</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">redis-config</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">redis-config</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">redis.conf</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteOnce&quot;</span> ]</span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-6379</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">6379</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-4-GitOps"><a href="#2-4-GitOps" class="headerlink" title="2.4. GitOps"></a>2.4. GitOps</h3><p><strong>在运维开发服务器上操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在已有代码仓库创建 redis/single 目录</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# mkdir -p redis/single</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑资源配置清单</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# vi redis/single/redis-cm.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi redis/single/redis-sts.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交 Git</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git add redis</span><br><span class="line">[root@zdevops-master k8s-yaml]# git commit -am &#x27;添加redis 单节点资源配置清单&#x27;</span><br><span class="line">[root@zdevops-master k8s-yaml]# git push</span><br></pre></td></tr></table></figure><h3 id="2-5-部署资源"><a href="#2-5-部署资源" class="headerlink" title="2.5. 部署资源"></a>2.5. 部署资源</h3><p><strong>在运维管理服务器上操作</strong></p><ul><li>更新镜像仓库代码</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# git pull</span><br></pre></td></tr></table></figure><ul><li>部署资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f redis/single/</span><br></pre></td></tr></table></figure><h3 id="2-6-验证"><a href="#2-6-验证" class="headerlink" title="2.6. 验证"></a>2.6. 验证</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl get sts -o wide -n zdevops</span><br><span class="line"></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl get pods -o wide -n zdevops</span><br></pre></td></tr></table></figure><h2 id="3-集群模式-Redis-部署"><a href="#3-集群模式-Redis-部署" class="headerlink" title="3. 集群模式 Redis 部署"></a>3. 集群模式 Redis 部署</h2><h3 id="3-1-思路梳理"><a href="#3-1-思路梳理" class="headerlink" title="3.1. 思路梳理"></a>3.1. 思路梳理</h3><ul><li>StatefulSet</li><li>Headless Service</li><li>ConfigMap：redis.conf</li><li>最少 6 个节点</li></ul><h3 id="3-2-准备离线镜像"><a href="#3-2-准备离线镜像" class="headerlink" title="3.2. 准备离线镜像"></a>3.2. 准备离线镜像</h3><p>过程略，参考 2.2</p><h3 id="3-3-资源配置清单"><a href="#3-3-资源配置清单" class="headerlink" title="3.3. 资源配置清单"></a>3.3. 资源配置清单</h3><ul><li><strong>redis-cm.yaml</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-cluster-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">redis-config:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    appendonly yes</span></span><br><span class="line"><span class="string">    protected-mode no</span></span><br><span class="line"><span class="string">    dir /data</span></span><br><span class="line"><span class="string">    port 6379</span></span><br><span class="line"><span class="string">    cluster-enabled yes</span></span><br><span class="line"><span class="string">    cluster-config-file /data/nodes.conf</span></span><br><span class="line"><span class="string">    cluster-node-timeout 5000</span></span><br><span class="line"><span class="string">    masterauth redis@abc.com</span></span><br><span class="line"><span class="string">    requirepass redis@abc.com</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><ul><li><strong>redis-sts.yaml</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">redis-headless</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">6</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">100</span></span><br><span class="line">            <span class="attr">podAffinityTerm:</span></span><br><span class="line">              <span class="attr">labelSelector:</span></span><br><span class="line">                <span class="attr">matchExpressions:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                  <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                  <span class="attr">values:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">redis</span></span><br><span class="line">              <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;registry.zdevops.com.cn/library/redis:6.2.7&#x27;</span></span><br><span class="line">          <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;redis-server&quot;</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;/etc/redis/redis.conf&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;--protected-mode&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;no&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;--cluster-announce-ip&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;$(POD_IP)&quot;</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_IP</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">status.podIP</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-6379</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">6379</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/redis</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">redis-cluster-config</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">redis-config</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">redis.conf</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteOnce&quot;</span> ]</span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">&quot;glusterfs&quot;</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-6379</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">6379</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redis</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注意 <strong>POD_IP</strong> 的相关配置，如果不配置会导致线上的 POD 重启换 IP 后，集群状态无法自动同步。</p><h3 id="3-4-GitOps"><a href="#3-4-GitOps" class="headerlink" title="3.4. GitOps"></a>3.4. GitOps</h3><p><strong>在运维开发服务器上操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在已有代码仓库创建 redis/cluster 目录</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# mkdir -p redis/cluster</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑资源配置清单</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# vi redis/cluster/redis-cluster-cm.yaml</span><br><span class="line">[root@zdevops-master k8s-yaml]# vi redis/cluster/redis-cluster-sts.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交 Git</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git add redis/cluster</span><br><span class="line">[root@zdevops-master k8s-yaml]# git commit -am &#x27;添加 redis 集群模式部署资源配置清单&#x27;</span><br><span class="line">[root@zdevops-master k8s-yaml]# git push</span><br></pre></td></tr></table></figure><h3 id="3-5-部署资源"><a href="#3-5-部署资源" class="headerlink" title="3.5. 部署资源"></a>3.5. 部署资源</h3><p><strong>在运维管理服务器上操作</strong></p><ul><li>&#96;更新镜像仓库代码</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# git pull</span><br></pre></td></tr></table></figure><ul><li>部署资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f redis/cluster/</span><br></pre></td></tr></table></figure><h3 id="3-6-确认资源状态"><a href="#3-6-确认资源状态" class="headerlink" title="3.6. 确认资源状态"></a>3.6. 确认资源状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl get sts -o wide -n zdevops</span><br><span class="line">NAME    READY   AGE    CONTAINERS   IMAGES</span><br><span class="line">redis   6/6     150m   redis        registry.zdevops.com.cn/library/redis:6.2.7</span><br><span class="line"></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl get pods -o wide -n zdevops</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE    IP              NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">redis-0   1/1     Running   0          150m   10.233.116.48   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-1   1/1     Running   0          150m   10.233.117.85   ks-k8s-master-0   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-2   1/1     Running   0          147m   10.233.87.244   ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-3   1/1     Running   0          147m   10.233.116.13   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-4   1/1     Running   0          146m   10.233.117.93   ks-k8s-master-0   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-5   1/1     Running   0          146m   10.233.87.249   ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><h3 id="3-7-自动创建-Redis-集群"><a href="#3-7-自动创建-Redis-集群" class="headerlink" title="3.7. 自动创建 Redis 集群"></a>3.7. 自动创建 Redis 集群</h3><p>POD 创建完成后默认不会自动创建 Redis 集群，需要手工执行集群初始化的命令，有自动创建和手工创建两种方式，二选一，建议选择<strong>自动</strong>。</p><p>自动配置 3 个 master 3 个 slave 的集群，执行下面的命令，中间需要输入一次 yes。</p><ul><li>执行命令</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster create --cluster-replicas 1 $(kubectl get pods -n zdevops -l app=redis -o jsonpath=&#x27;&#123;range.items[*]&#125;&#123;.status.podIP&#125;:6379 &#123;end&#125;&#x27;)</span><br></pre></td></tr></table></figure><ul><li>正常结果</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster create --cluster-replicas 1 $(kubectl get pods -n zdevops -l app=redis -o jsonpath=&#x27;&#123;range.items[*]&#125;&#123;.status.podIP&#125;:6379 &#123;end&#125;&#x27;)</span><br><span class="line">Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 10.233.117.93:6379 to 10.233.116.48:6379</span><br><span class="line">Adding replica 10.233.87.249:6379 to 10.233.117.85:6379</span><br><span class="line">Adding replica 10.233.116.13:6379 to 10.233.87.244:6379</span><br><span class="line">M: 457fed7883cd08cfac98db4bdf6be0d7028b741e 10.233.116.48:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">M: 63021f3f78fc133215d244dd99d42519f3116aad 10.233.117.85:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">M: ba6d84c6cfda009061df0955201e175ab4c95845 10.233.87.244:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: ebeef4043ef84179a939d5c033ad0599d77307a4 10.233.116.13:6379</span><br><span class="line">   replicates ba6d84c6cfda009061df0955201e175ab4c95845</span><br><span class="line">S: 9133d29edbae393431eebe8b5ef3a34b7abe6163 10.233.117.93:6379</span><br><span class="line">   replicates 457fed7883cd08cfac98db4bdf6be0d7028b741e</span><br><span class="line">S: adbbdfe0e862270771d77e500939a799df698d71 10.233.87.249:6379</span><br><span class="line">   replicates 63021f3f78fc133215d244dd99d42519f3116aad</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Sending CLUSTER MEET messages to <span class="built_in">join</span> the cluster</span></span><br><span class="line">Waiting for the cluster to join</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing Cluster Check (using node 10.233.116.48:6379)</span></span><br><span class="line">M: 457fed7883cd08cfac98db4bdf6be0d7028b741e 10.233.116.48:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: ba6d84c6cfda009061df0955201e175ab4c95845 10.233.87.244:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 63021f3f78fc133215d244dd99d42519f3116aad 10.233.117.85:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: adbbdfe0e862270771d77e500939a799df698d71 10.233.87.249:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 63021f3f78fc133215d244dd99d42519f3116aad</span><br><span class="line">S: ebeef4043ef84179a939d5c033ad0599d77307a4 10.233.116.13:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates ba6d84c6cfda009061df0955201e175ab4c95845</span><br><span class="line">S: 9133d29edbae393431eebe8b5ef3a34b7abe6163 10.233.117.93:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 457fed7883cd08cfac98db4bdf6be0d7028b741e</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><h3 id="3-8-手动创建-Redis-集群"><a href="#3-8-手动创建-Redis-集群" class="headerlink" title="3.8. 手动创建 Redis 集群"></a>3.8. 手动创建 Redis 集群</h3><p>手动配置 3 个 master 3 个 slave 的集群，此步骤只为了记录手动操作的过程，实际环境建议用自动创建的方式。</p><p>一共创建了 6 个 Redis pod，集群主-&gt; 从配置的规则为 0-&gt;3，1-&gt;4，2-&gt;5。</p><p>没有采用自动获取 IP 的方式，太长了占地方，手工查询 pod IP 并进行相关配置。</p><ul><li>查询 Redis pod 分配的 IP</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl get pods -n zdevops -o wide | grep redis</span><br><span class="line">redis-0                         1/1     Running   0          6m49s   10.233.116.254   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-1                         1/1     Running   0          6m38s   10.233.117.96    ks-k8s-master-0   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-2                         1/1     Running   0          6m26s   10.233.87.230    ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-3                         1/1     Running   0          6m15s   10.233.116.9     ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-4                         1/1     Running   0          6m4s    10.233.117.97    ks-k8s-master-0   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">redis-5                         1/1     Running   0          5m52s   10.233.87.255    ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><ul><li>创建集群 master 节点</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">三个IP地址为 redis-0 redis-1 redis-2 对应的IP, 中间需要输入一次<span class="built_in">yes</span></span></span><br><span class="line">[root@zdevops-master k8s-yaml]# kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster create 10.233.116.254:6379 10.233.117.96:6379 10.233.87.230:6379</span><br><span class="line">Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 3 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">M: 3f9728539f5eed406cbc0542f4c8fc1bd247916c 10.233.116.254:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">M: eead96f0bd0e778787b524505fc83dcf20683912 10.233.117.96:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">M: fef1d03b6a613cbe306a334bf584d7cf9846d07b 10.233.87.230:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Sending CLUSTER MEET messages to <span class="built_in">join</span> the cluster</span></span><br><span class="line">Waiting for the cluster to join</span><br><span class="line">..</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing Cluster Check (using node 10.233.116.254:6379)</span></span><br><span class="line">M: 3f9728539f5eed406cbc0542f4c8fc1bd247916c 10.233.116.254:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">M: eead96f0bd0e778787b524505fc83dcf20683912 10.233.117.96:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">M: fef1d03b6a613cbe306a334bf584d7cf9846d07b 10.233.87.230:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><ul><li>为每个 master 添加 slave 节点</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">10.233.116.254:6379 的位置为任意一个 master 节点的 ip 地址,一般用 redis-0 的 IP 地址</span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">10.233.123.142:6379 的位置为 slave 的 IP 地址</span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">--cluster-master-id 参数为 slave 对应的 master 的 ID，如果不指定则随机分配到任意一个主节点</span></span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第一组 redis0 -&gt; redis3</span></span><br><span class="line">kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster add-node 10.233.116.9:6379 10.233.116.254:6379 --cluster-slave --cluster-master-id 3f9728539f5eed406cbc0542f4c8fc1bd247916c</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第二组 redis1 -&gt; redis4</span></span><br><span class="line">kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster add-node 10.233.117.97:6379 10.233.116.254:6379 --cluster-slave --cluster-master-id eead96f0bd0e778787b524505fc83dcf20683912</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第三组 redis2 -&gt; redis5</span></span><br><span class="line">kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster add-node 10.233.87.255:6379 10.233.116.254:6379 --cluster-slave --cluster-master-id fef1d03b6a613cbe306a334bf584d7cf9846d07b</span><br></pre></td></tr></table></figure><h3 id="3-9-验证集群状态"><a href="#3-9-验证集群状态" class="headerlink" title="3.9. 验证集群状态"></a>3.9. 验证集群状态</h3><ul><li>执行命令</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster check $(kubectl get pods -n zdevops -l app=redis -o jsonpath=&#x27;&#123;range.items[0]&#125;&#123;.status.podIP&#125;:6379&#123;end&#125;&#x27;)</span><br></pre></td></tr></table></figure><ul><li>正常状态结果</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master data]# kubectl exec -it redis-0 -n zdevops -- redis-cli -a redis@abc.com --cluster check $(kubectl get pods -n zdevops -l app=redis -o jsonpath=&#x27;&#123;range.items[0]&#125;&#123;.status.podIP&#125;:6379&#123;end&#125;&#x27;)</span><br><span class="line">Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.</span><br><span class="line">10.233.116.254:6379 (3f972853...) -&gt; 0 keys | 5461 slots | 1 slaves.</span><br><span class="line">10.233.87.230:6379 (fef1d03b...) -&gt; 0 keys | 5461 slots | 1 slaves.</span><br><span class="line">10.233.117.96:6379 (eead96f0...) -&gt; 0 keys | 5462 slots | 1 slaves.</span><br><span class="line">[OK] 0 keys in 3 masters.</span><br><span class="line">0.00 keys per slot on average.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Performing Cluster Check (using node 10.233.116.254:6379)</span></span><br><span class="line">M: 3f9728539f5eed406cbc0542f4c8fc1bd247916c 10.233.116.254:6379</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: cf077e77b35c1b8cd7f19a2dd79320f8960b31f5 10.233.87.255:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates fef1d03b6a613cbe306a334bf584d7cf9846d07b</span><br><span class="line">S: 03e3d21e028e506c246e702abb8fc0ce5676ac22 10.233.117.97:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates eead96f0bd0e778787b524505fc83dcf20683912</span><br><span class="line">S: 49b3f1ad6200b4171e02bc23b0ac55fa7b3ef0cf 10.233.116.9:6379</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 3f9728539f5eed406cbc0542f4c8fc1bd247916c</span><br><span class="line">M: fef1d03b6a613cbe306a334bf584d7cf9846d07b 10.233.87.230:6379</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: eead96f0bd0e778787b524505fc83dcf20683912 10.233.117.96:6379</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><h2 id="4-安装管理客户端"><a href="#4-安装管理客户端" class="headerlink" title="4. 安装管理客户端"></a>4. 安装管理客户端</h2><p>大部分开发、运维人员还是喜欢图形化的 Redis 管理工具，所以安排一个 Redis 官方提供的图形化工具 RedisInsight。</p><p>由于 RedisInsight 默认并不提供登录验证功能，因此，在系统安全要求比较高的环境会有安全风险，请慎用！</p><p>个人建议生产环境使用命令行工具。</p><h3 id="4-1-准备离线镜像"><a href="#4-1-准备离线镜像" class="headerlink" title="4.1. 准备离线镜像"></a>4.1. 准备离线镜像</h3><ul><li>下载镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull redislabs/redisinsight:1.12.0</span><br></pre></td></tr></table></figure><ul><li>重新打 tag</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag redislabs/redisinsight:1.12.0 registry.zdevops.com.cn/library/redisinsight:1.12.0</span><br></pre></td></tr></table></figure><ul><li>推送到私有镜像仓库</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push registry.zdevops.com.cn/library/redisinsight:1.12.0</span><br></pre></td></tr></table></figure><h3 id="4-2-资源配置清单"><a href="#4-2-资源配置清单" class="headerlink" title="4.2. 资源配置清单"></a>4.2. 资源配置清单</h3><ul><li><strong>redisinsight-deploy.yaml</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redisinsight</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redisinsight</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">redisinsight</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">redisinsight</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redisinsight</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">registry.zdevops.com.cn/library/redisinsight:1.12.0</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-8001</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">8001</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redisinsight-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">zdevops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redisinsight-external</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-8001</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">8001</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8001</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">31000</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">redisinsight</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-3-GitOps"><a href="#4-3-GitOps" class="headerlink" title="4.3. GitOps"></a>4.3. GitOps</h3><p><strong>在运维开发服务器上操作</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在已有代码仓库创建 redis/redisinsight 目录</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# mkdir -p redis/redisinsight</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑资源配置清单</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# vi redis/redisinsight/redisinsight-deploy.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交 Git</span></span><br><span class="line">[root@zdevops-master k8s-yaml]# git add redis/redisinsight</span><br><span class="line">[root@zdevops-master k8s-yaml]# git commit -am &#x27;添加 redisinsight 资源配置清单&#x27;</span><br><span class="line">[root@zdevops-master k8s-yaml]# git push</span><br></pre></td></tr></table></figure><h3 id="4-4-部署资源"><a href="#4-4-部署资源" class="headerlink" title="4.4. 部署资源"></a>4.4. 部署资源</h3><p><strong>在运维管理服务器上操作</strong></p><ul><li>&#96;更新镜像仓库代码</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# git pull</span><br></pre></td></tr></table></figure><ul><li>部署资源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master k8s-yaml]# kubectl apply -f redis/redisinsight/redisinsight-deploy.yaml</span><br></pre></td></tr></table></figure><h3 id="4-5-界面初始化"><a href="#4-5-界面初始化" class="headerlink" title="4.5. 界面初始化"></a>4.5. 界面初始化</h3><ul><li>打开 RedisInsight 控制台，<a href="http://192.168.9.91:31000/">http://192.168.9.91:31000</a></li><li>进入默认配置页面，只勾选<strong>第一个</strong>按钮，点击 <strong>CONFIRM</strong></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-0.png" alt="kubesphere-redis-0"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-1.png" alt="kubesphere-redis-1"></p><ul><li>连接 Redis 数据库</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-2.png" alt="kubesphere-redis-2"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-3.png" alt="kubesphere-redis-3"></p><ul><li>点击 <strong>Connect to Redis Database</strong>，按提示填写信息，点击 <strong>ADD REDIS DATABASE</strong><ul><li>Host 填写 Redis headless 服务的域名简写</li><li>Name 随便写，就是一个标识</li><li>Password 填写连接 Redis 的密码</li></ul></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-4.png" alt="kubesphere-redis-4"></p><ul><li>选择一个 master 数据库，点击 <strong>ADD CLUSTER DATABASE</strong></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-5.png" alt="kubesphere-redis-5"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-6.png" alt="kubesphere-redis-6"></p><ul><li>点击新创建的数据库连接，进入管理界面</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-7.png" alt="kubesphere-redis-7"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-redis-8.png" alt="kubesphere-redis-8"></p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>本文详细介绍了 Redis 单节点和集群模式在基于 KubeSphere 部署的 K8S 集群上的安装部署过程。同时，介绍了 Redis 图形化管理工具 RedisInsight 的安装使用。</p><p>本文的配置方案可直接用于开发测试环境，对于生产环境也有一定的借鉴意义。</p><blockquote><p><strong>参考文档</strong></p></blockquote><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-Redis-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-Redis-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s-Redis 安装手</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-Harbor 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Harbor%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Harbor%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.403Z</published>
    <updated>2023-09-22T01:43:57.636Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-Harbor-安装手记"><a href="#基于-KubeSphere-玩转-k8s-Harbor-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-Harbor 安装手记"></a>基于 KubeSphere 玩转 k8s-Harbor 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文详细展示了采用 HTTPS 协议的 Harbor 的安装部署、安装后的初始化以及与 KubeSphere 对接的详细过程， 本文的安装部署方案适用于中小规模生产环境。 </p><blockquote><p>本文知识量</p></blockquote><ul><li>阅读时长：15分</li><li>行：775</li><li>单词：4400+</li><li>字符：22700+</li><li>图片：30 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>Harbor 安装部署</li><li>Harbor 基本配置</li><li>Harbor 启用 HTTPS 访问</li><li>KubeSphere 对接 Harbor</li><li>CoreDNS 和 NodeLocalDNS 的配置</li><li>KubeSphere 使用私有仓库创建工作负载</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">harbor</td><td align="center">192.168.9.89</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200</td><td align="center">Harbor 和 Gitlab</td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>Ansible：<strong>2.8.20</strong></li><li>Harbor：<strong>2.5.1</strong></li></ul><h2 id="2-安装-Harbor-的前提条件"><a href="#2-安装-Harbor-的前提条件" class="headerlink" title="2. 安装 Harbor 的前提条件"></a>2. 安装 Harbor 的前提条件</h2><h3 id="2-1-硬件"><a href="#2-1-硬件" class="headerlink" title="2.1. 硬件"></a>2.1. 硬件</h3><p>下表列出了安装 Harbor 的最低和推荐的硬件配置要求。</p><table><thead><tr><th align="left">Resource</th><th align="left">Minimum</th><th align="left">Recommended</th></tr></thead><tbody><tr><td align="left">CPU</td><td align="left">2 CPU</td><td align="left">4 CPU</td></tr><tr><td align="left">Mem</td><td align="left">4 GB</td><td align="left">8 GB</td></tr><tr><td align="left">Disk</td><td align="left">40 GB</td><td align="left">160 GB</td></tr></tbody></table><h3 id="2-2-软件"><a href="#2-2-软件" class="headerlink" title="2.2. 软件"></a>2.2. 软件</h3><p>下表列出了安装 Harbor 需要安装的相关软件及版本。</p><table><thead><tr><th align="left">Software</th><th align="left">Version</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">Docker engine</td><td align="left">Version 17.06.0-ce+ or higher</td><td align="left">For installation instructions, see <a href="https://docs.docker.com/engine/installation/">Docker Engine documentation</a></td></tr><tr><td align="left">Docker Compose</td><td align="left">Version 1.18.0 or higher</td><td align="left">For installation instructions, see <a href="https://docs.docker.com/compose/install/">Docker Compose documentation</a></td></tr><tr><td align="left">Openssl</td><td align="left">Latest is preferred</td><td align="left">Used to generate certificate and keys for Harbor</td></tr></tbody></table><h3 id="2-3-网络"><a href="#2-3-网络" class="headerlink" title="2.3. 网络"></a>2.3. 网络</h3><p>需要在安装 Harbor 的服务器上开放以下端口。</p><table><thead><tr><th align="left">Port</th><th align="left">Protocol</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">443</td><td align="left">HTTPS</td><td align="left">Harbor portal and core API accept HTTPS requests on this port. You can change this port in the configuration file.</td></tr><tr><td align="left">4443</td><td align="left">HTTPS</td><td align="left">Connections to the Docker Content Trust service for Harbor. Only required if Notary is enabled. You can change this port in the configuration file.</td></tr><tr><td align="left">80</td><td align="left">HTTP</td><td align="left">Harbor portal and core API accept HTTP requests on this port. You can change this port in the configuration file.</td></tr></tbody></table><h2 id="3-Harbor-服务器初始化配置"><a href="#3-Harbor-服务器初始化配置" class="headerlink" title="3. Harbor 服务器初始化配置"></a>3. Harbor 服务器初始化配置</h2><h3 id="3-1-Ansible-增加-hosts"><a href="#3-1-Ansible-增加-hosts" class="headerlink" title="3.1. Ansible 增加 hosts"></a>3.1. Ansible 增加 hosts</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主要增加 harbor 节点配置, 注意没有主机组只有一条主机记录</span></span><br><span class="line"></span><br><span class="line">harbor <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.89</span> host_name=harbor</span><br></pre></td></tr></table></figure><h3 id="3-2-检测服务器连通性"><a href="#3-2-检测服务器连通性" class="headerlink" title="3.2. 检测服务器连通性"></a>3.2. 检测服务器连通性</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 检测服务器的连通性</span></span><br><span class="line"></span><br><span class="line">cd /data/ansible/ansible-zdevops/inventories/dev/</span><br><span class="line">source /opt/ansible2.8/bin/activate</span><br><span class="line">ansible -m ping harbor</span><br></pre></td></tr></table></figure><h3 id="3-3-初始化服务器配置"><a href="#3-3-初始化服务器配置" class="headerlink" title="3.3. 初始化服务器配置"></a>3.3. 初始化服务器配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化服务器配置</span></span><br><span class="line"></span><br><span class="line">ansible-playbook ../../playbooks/init-base.yaml -l harbor</span><br></pre></td></tr></table></figure><h3 id="3-4-挂载数据盘"><a href="#3-4-挂载数据盘" class="headerlink" title="3.4. 挂载数据盘"></a>3.4. 挂载数据盘</h3><ul><li><strong>挂载数据盘</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化主机数据盘</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意 -e data_disk_path=<span class="string">&quot;/data&quot;</span> 指定挂载目录</span></span><br><span class="line"></span><br><span class="line">ansible-playbook ../../playbooks/init-disk.yaml -e data_disk_path=&quot;/data&quot; -l harbor</span><br></pre></td></tr></table></figure><ul><li><strong>挂载验证</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否格式化并挂载</span></span><br><span class="line">ansible harbor -m shell -a &#x27;df -h&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否配置自动挂载</span></span><br><span class="line"></span><br><span class="line">ansible harbor -m shell -a &#x27;tail -1  /etc/fstab&#x27;</span><br></pre></td></tr></table></figure><h2 id="4-Docker-安装配置"><a href="#4-Docker-安装配置" class="headerlink" title="4. Docker 安装配置"></a>4. Docker 安装配置</h2><ul><li>安装配置 Docker 和 Docker Compose</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 安装配置 Docker</span></span><br><span class="line">ansible-playbook ../../playbooks/deploy-docker.yaml -l harbor</span><br></pre></td></tr></table></figure><h2 id="5-Harbor-离线安装配置"><a href="#5-Harbor-离线安装配置" class="headerlink" title="5. Harbor 离线安装配置"></a>5. Harbor 离线安装配置</h2><h3 id="5-1-准备域名-https-证书"><a href="#5-1-准备域名-https-证书" class="headerlink" title="5.1. 准备域名 https 证书"></a>5.1. 准备域名 https 证书</h3><p>本文使用了已购域名加免费 SSL 证书的方式，如果是自定义域名或是 IP 的自签名证书请参考官方文档<a href="https://goharbor.io/docs/2.5.0/install-config/configure-https/">Configure HTTPS Access to Harbor</a>。</p><p>建议购买一个域名，不要自定义域名也不要用 IP。</p><blockquote><p><strong>免费 SSL 证书</strong></p></blockquote><ul><li><strong>阿里云 (一年)</strong></li><li>腾讯云 (一年)</li><li>Let’s Encrypt(90 天)</li></ul><p>我的域名 (registry.zdevops.com.cn) 是在阿里云买的，所有就选择阿里云的 SSL 免费证书，申请过程略。</p><p>申请后，下载 <strong>Nginx</strong> 或是<strong>其他</strong>类型的证书。</p><p>将下载的证书文件放到服务器指定目录。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">最小化安装的服务器需要安装 unzip</span></span><br><span class="line">yum install unzip -y</span><br><span class="line"></span><br><span class="line">unzip 7966948_registry.zdevops.com.cn_nginx.zip -d /data/harbor-certs</span><br></pre></td></tr></table></figure><h3 id="5-2-离线安装包下载"><a href="#5-2-离线安装包下载" class="headerlink" title="5.2. 离线安装包下载"></a>5.2. 离线安装包下载</h3><ul><li>下载安装包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /data</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">wget https://github.com/goharbor/harbor/releases/download/v2.5.1/harbor-offline-installer-v2.5.1.tgz</span></span><br><span class="line">curl https://github.com/goharbor/harbor/releases/download/v2.5.1/harbor-offline-installer-v2.5.1.tgz -O harbor-offline-installer-v2.5.1.tgz</span><br></pre></td></tr></table></figure><ul><li>解压安装包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xzvf harbor-offline-installer-v2.5.1.tgz</span><br></pre></td></tr></table></figure><ul><li>更改解压后的目录名 (个人习惯)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv harbor harbor-v2.5.1</span><br></pre></td></tr></table></figure><h3 id="5-3-配置-Harbor-YML-文件"><a href="#5-3-配置-Harbor-YML-文件" class="headerlink" title="5.3. 配置 Harbor YML 文件"></a>5.3. 配置 Harbor YML 文件</h3><p>本文只说明需要修改的重点参数，更完整的参数说明，请参考官方文档<a href="https://goharbor.io/docs/2.5.0/install-config/configure-yml-file/">Configure the Harbor YML File</a>。</p><p>本文的 Harbor 使用默认的 HTTPS 443 端口，提供给内网客户端直接访问，不通过防火墙转发到外部，如果需要通过转发的方式暴露给外网，需要使用 <strong>external_url</strong> 的配置项。</p><ul><li>编辑配置文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /data/harbor-v2.5.1/</span><br><span class="line">cp harbor.yml.tmpl harbor.yml</span><br><span class="line">vi harbor.yml</span><br></pre></td></tr></table></figure><ul><li>必须修改的参数</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Harbor 服务器的主机名或是 IP</span></span><br><span class="line"><span class="attr">hostname:</span> <span class="string">registry.zdevops.com.cn</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生产环境一定要使用 https</span></span><br><span class="line"><span class="attr">https:</span></span><br><span class="line">  <span class="comment"># https 端口, 默认443, 根据实际环境修改</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">  <span class="comment"># Nginx 使用的 cert 和 key 文件(绝对路径)</span></span><br><span class="line">  <span class="attr">certificate:</span> <span class="string">/data/harbor-certs/7966948_registry.zdevops.com.cn.pem</span></span><br><span class="line">  <span class="attr">private_key:</span> <span class="string">/data/harbor-certs/7966948_registry.zdevops.com.cn.key</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Harbor admin用户的初始密码，配置文件里可以不用改，但是部署完必须第一时间登录Harbor，更改密码</span></span><br><span class="line"><span class="attr">harbor_admin_password:</span> <span class="string">Harbor12345</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Harbor DB configuration</span></span><br><span class="line"><span class="attr">database:</span></span><br><span class="line">  <span class="comment"># Harbor DB root用户的密码, 必须修改.</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">root123</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Harbor数据存储路径</span></span><br><span class="line"><span class="attr">data_volume:</span> <span class="string">/data/harbor</span></span><br></pre></td></tr></table></figure><ul><li>非必需但是重要参数</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果 harbor 需要通过防火墙或是其他方式转发给外部访问，需要配置此参数为外网 IP 或是外部域名。</span></span><br><span class="line"><span class="attr">external_url:</span> <span class="string">https://reg.mydomain.com:8433</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果是离线内网环境，并且启用trivy的场景，还需要配置以下两个参数</span></span><br><span class="line"><span class="attr">trivy:</span></span><br><span class="line">  <span class="comment"># skipUpdate The flag to enable or disable Trivy DB downloads from GitHub</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># You might want to enable this flag in test or CI/CD environments to avoid GitHub rate limiting issues.</span></span><br><span class="line">  <span class="comment"># If the flag is enabled you have to download the `trivy-offline.tar.gz` archive manually, extract `trivy.db` and</span></span><br><span class="line">  <span class="comment"># `metadata.json` files and mount them in the `/home/scanner/.cache/trivy/db` path.</span></span><br><span class="line">  <span class="attr">skip_update:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">#</span></span><br><span class="line">  <span class="comment"># The offline_scan option prevents Trivy from sending API requests to identify dependencies.</span></span><br><span class="line">  <span class="comment"># Scanning JAR files and pom.xml may require Internet access for better detection, but this option tries to avoid it.</span></span><br><span class="line">  <span class="comment"># For example, the offline mode will not try to resolve transitive dependencies in pom.xml when the dependency doesn&#x27;t</span></span><br><span class="line">  <span class="comment"># exist in the local repositories. It means a number of detected vulnerabilities might be fewer in offline mode.</span></span><br><span class="line">  <span class="comment"># It would work if all the dependencies are in local.</span></span><br><span class="line">  <span class="comment"># This option doesn’t affect DB download. You need to specify &quot;skip-update&quot; as well as &quot;offline-scan&quot; in an air-gapped environment.</span></span><br><span class="line">  <span class="attr">offline_scan:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="5-4-运行安装脚本"><a href="#5-4-运行安装脚本" class="headerlink" title="5.4. 运行安装脚本"></a>5.4. 运行安装脚本</h3><p>官方默认安装命令没有启用 Notary, Trivy 和 Chart Repository Service。</p><ul><li>Notary：镜像签名认证</li><li><strong>Trivy： 容器漏洞扫描</strong></li><li><strong>Chart Repository Service： Helm chart 仓库服务</strong></li></ul><p><strong>生产环境我启用了 Trivy 和 Chart Repository Service 功能，因此执行下面的命令。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./install.sh --with-trivy --with-chartmuseum</span><br></pre></td></tr></table></figure><p>如果想启用所有插件，可以执行下面的命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./install.sh --with-notary --with-trivy --with-chartmuseum</span><br></pre></td></tr></table></figure><h3 id="5-5-安装成功效果"><a href="#5-5-安装成功效果" class="headerlink" title="5.5. 安装成功效果"></a>5.5. 安装成功效果</h3><p>能看到类似下面的输出，说明安装成功。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[Step 5]: starting Harbor ...</span><br><span class="line">[+] Running 13/13</span><br><span class="line"> ⠿ Network harbor-v251_harbor-chartmuseum  Created                                                                                    0.2s</span><br><span class="line"> ⠿ Network harbor-v251_harbor              Created                                                                                    0.1s</span><br><span class="line"> ⠿ Container harbor-log                    Started                                                                                    1.5s</span><br><span class="line"> ⠿ Container redis                         Started                                                                                    5.2s</span><br><span class="line"> ⠿ Container registryctl                   Started                                                                                    5.2s</span><br><span class="line"> ⠿ Container registry                      Started                                                                                    4.4s</span><br><span class="line"> ⠿ Container harbor-db                     Started                                                                                    3.2s</span><br><span class="line"> ⠿ Container harbor-portal                 Started                                                                                    5.3s</span><br><span class="line"> ⠿ Container chartmuseum                   Started                                                                                    4.2s</span><br><span class="line"> ⠿ Container trivy-adapter                 Started                                                                                    7.0s</span><br><span class="line"> ⠿ Container harbor-core                   Started                                                                                    7.0s</span><br><span class="line"> ⠿ Container harbor-jobservice             Started                                                                                    8.3s</span><br><span class="line"> ⠿ Container nginx                         Started                                                                                    8.7s</span><br><span class="line">✔ ----Harbor has been installed and started successfully.----</span><br></pre></td></tr></table></figure><h3 id="5-6-客户端配置"><a href="#5-6-客户端配置" class="headerlink" title="5.6. 客户端配置"></a>5.6. 客户端配置</h3><p><strong>由于是内网服务器配置的域名 registry.zdevops.com.cn，所有访问 Harbor 的服务器需要手动配置 &#x2F;etc&#x2F;hosts 文件解析。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 配置服务器的/etc/hosts</span></span><br><span class="line">ansible all -m shell -a &#x27;echo &quot;192.168.9.89   registry.zdevops.com.cn&quot; &gt;&gt; /etc/hosts&#x27;</span><br></pre></td></tr></table></figure><h2 id="6-Harbor-初始化配置"><a href="#6-Harbor-初始化配置" class="headerlink" title="6. Harbor 初始化配置"></a>6. Harbor 初始化配置</h2><h3 id="6-1-修改-admin-用户密码"><a href="#6-1-修改-admin-用户密码" class="headerlink" title="6.1. 修改 admin 用户密码"></a>6.1. 修改 admin 用户密码</h3><p>初次登陆系统，必须修改 admin 用户的默认密码。</p><ul><li>通过浏览器登录 Harbor 控制台，<a href="https://registry.zdevops.com.cn.默认用户/">https://registry.zdevops.com.cn。默认用户</a> admin，默认密码 Harbor12345。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-0.png" alt="kube-harbor-0"></p><ul><li>右上角 <strong>admin</strong>-&gt;<strong>修改密码</strong>。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-1.png" alt="kube-harbor-1"></p><ul><li>在弹出的<strong>修改密码</strong>对话框中修改。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-3.png" alt="kube-harbor-3"></p><h3 id="6-2-创建管理员用户"><a href="#6-2-创建管理员用户" class="headerlink" title="6.2. 创建管理员用户"></a>6.2. 创建管理员用户</h3><p>创建一个新的具有管理员权限的用户用于日常管理。</p><ul><li><strong>系统管理</strong>-&gt;<strong>用户管理</strong>-&gt;<strong>创建用户</strong>，在弹出的<strong>创建用户</strong>对话框中按提示输入用户信息。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-4.png" alt="kube-harbor-4"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-5.png" alt="kube-harbor-5"></p><ul><li>用户创建完成后，自动返回<strong>用户管理</strong>页面，选择新创建的用户，点击<strong>设置为管理员</strong>。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-6.png" alt="kube-harbor-6"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-7.png" alt="kube-harbor-7"></p><h3 id="6-3-创建-devops-用户"><a href="#6-3-创建-devops-用户" class="headerlink" title="6.3. 创建 devops 用户"></a>6.3. 创建 devops 用户</h3><p>为了实现 CI&#x2F;CD 工作流，需要创建一个用于 Devops 的全局系统级机器人账户 <strong>zdevops</strong>。当然，也可以创建一个额外管理员用户用于自动化操作，建议使用机器人账户，权限控制的更精细。</p><p>如果多租户使用、项目比较多，建议创建项目级机器人账户。</p><p>默认的机器人账户名称前缀为 **robot$**，默认创建的全局机器人账户的名字为 <strong>robot$zdevops</strong>，这种带 <strong>$</strong> 号的形式在有些 CI&#x2F;CD 系统里会有识别问题，因此最好修改一下。</p><ul><li>修改机器人账户名称前缀，<strong>系统管理</strong>-&gt;<strong>配置管理</strong>-&gt;<strong>系统设置</strong>，修改<strong>机器人账户名称前缀</strong>为 **robot-**。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-8.png" alt="kube-harbor-8"></p><ul><li>创建机器人账户，<strong>系统管理</strong>-&gt;<strong>机器人账户</strong>-&gt;<strong>添加机器人账户</strong>，在弹出的<strong>创建系统级机器人账户</strong>窗口，按图示填写账户信息，点击<strong>添加</strong>。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-9.png" alt="kube-harbor-9"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-10.png" alt="kube-harbor-10"></p><ul><li>账户创建成功，弹出<strong>机器人账户令牌</strong>界面，选择<strong>导出到文件中</strong>，并妥善保存。也可以选择复制令牌到自己的密码管理软件中。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-11.png" alt="kube-harbor-11"></p><ul><li>令牌导出后，自动返回<strong>机器人账户</strong>列表。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-12.png" alt="kube-harbor-12"></p><h3 id="6-4-创建项目"><a href="#6-4-创建项目" class="headerlink" title="6.4. 创建项目"></a>6.4. 创建项目</h3><p>创建一个新的项目存放自定义的镜像。</p><ul><li><strong>项目</strong>-&gt;<strong>新建项目</strong>，在弹出的<strong>新建项目</strong>对话框中填写信息，点击<strong>确定</strong>，自动返回项目列表。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-13.png" alt="kube-harbor-13"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-14.png" alt="kube-harbor-14"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-15.png" alt="kube-harbor-15"></p><ul><li>设置自动漏洞扫描，在项目列表页面选择新创建的项目，<strong>配置管理</strong>，勾选<strong>自动扫描镜像</strong>。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-16.png" alt="kube-harbor-16"></p><h2 id="7-KubeSphere-对接-Harbor"><a href="#7-KubeSphere-对接-Harbor" class="headerlink" title="7. KubeSphere 对接 Harbor"></a>7. KubeSphere 对接 Harbor</h2><h3 id="7-1-配置-Harbor-域名解析"><a href="#7-1-配置-Harbor-域名解析" class="headerlink" title="7.1 配置 Harbor 域名解析"></a>7.1 配置 Harbor 域名解析</h3><ul><li>测试域名连通性</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 busybox ping 测</span> </span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl run busybox --image=busybox --command -- ping registry.zdevops.com.cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建pod error，<span class="built_in">log</span>显示错误信息</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl logs busybox</span><br><span class="line">ping: bad address &#x27;registry.zdevops.com.cn&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除测试 pod</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl delete pod busybox</span><br></pre></td></tr></table></figure><ul><li>编辑 coredns 的 configmap</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit cm coredns -n kube-system</span><br></pre></td></tr></table></figure><ul><li>添加自定义的域名解析记录</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fallthrough 必须添加，否则会造成内部域名全部无法解析</span></span><br><span class="line"><span class="comment"># hosts是CoreDNS的一个plugin，用于自定义hosts解析，fallthrough 表示如果hosts找不到，则进入下一个plugin继续。缺少这个指令，后面的plugins配置就无意义了。</span></span><br><span class="line"></span><br><span class="line"><span class="string">hosts</span> &#123;</span><br><span class="line">   <span class="number">192.168</span><span class="number">.9</span><span class="number">.89</span> <span class="string">registry.zdevops.com.cn</span></span><br><span class="line">   <span class="string">fallthrough</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>编辑后完整的 configmap</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">Corefile:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    .:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        health &#123;</span></span><br><span class="line"><span class="string">           lameduck 5s</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        ready</span></span><br><span class="line"><span class="string">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span></span><br><span class="line"><span class="string">           pods insecure</span></span><br><span class="line"><span class="string">           fallthrough in-addr.arpa ip6.arpa</span></span><br><span class="line"><span class="string">           ttl 30</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        hosts &#123;</span></span><br><span class="line"><span class="string">           192.168.9.89 registry.zdevops.com.cn</span></span><br><span class="line"><span class="string">           fallthrough</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        prometheus :9153</span></span><br><span class="line"><span class="string">        forward . /etc/resolv.conf &#123;</span></span><br><span class="line"><span class="string">           max_concurrent 1000</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        cache 30</span></span><br><span class="line"><span class="string">        loop</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loadbalance</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2022-04-09T14:33:53Z&quot;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">coredns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;258&quot;</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">/api/v1/namespaces/kube-system/configmaps/coredns</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">f0d9774c-a330-4de7-9f77-334dc82f710b</span></span><br></pre></td></tr></table></figure><ul><li>重启 coreDNS，使配置生效</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看现有 coredns 状态</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get deployment -n kube-system</span><br><span class="line">NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">calico-kube-controllers       1/1     1            1           69d</span><br><span class="line">coredns                       2/2     2            2           69d</span><br><span class="line">openebs-localpv-provisioner   1/1     1            1           69d</span><br><span class="line">rbd-provisioner               1/1     1            1           22d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 Deployment replicas 设置为0</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl scale deployment coredns -n kube-system --replicas=0</span><br><span class="line">deployment.apps/coredns scaled</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看变更后 coredns 状态</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get deployment -n kube-system</span><br><span class="line">NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">calico-kube-controllers       1/1     1            1           69d</span><br><span class="line">coredns                       0/0     0            0           69d</span><br><span class="line">openebs-localpv-provisioner   1/1     1            1           69d</span><br><span class="line">rbd-provisioner               1/1     1            1           22d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 Deployment replicas 设置为2</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl scale deployment coredns -n kube-system --replicas=2</span><br><span class="line">deployment.apps/coredns scaled</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看变更后 coredns 状态</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get deployment -n kube-system</span><br><span class="line">NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">calico-kube-controllers       1/1     1            1           69d</span><br><span class="line">coredns                       2/2     2            2           69d</span><br><span class="line">openebs-localpv-provisioner   1/1     1            1           69d</span><br><span class="line">rbd-provisioner               1/1     1            1           22d</span><br></pre></td></tr></table></figure><ul><li>再次测试，结果依旧失败</li></ul><p>原因：K8S 集群使用 kubesphere 的 kubekey 工具部署，默认部署了 coredns 和 nodelocaldns，<code>NodeLocal DNS Cache</code> 通过在集群节点上作为 DaemonSet 运行 dns 缓存代理来提高集群 DNS 性能。集群中 <code>kube-proxy</code> 运行在 IPVS 模式，在此模式下，<code>nodelocaldns Pods</code> 只会侦听 <code>&lt;node-local-address&gt;</code> 的地址，不会侦听 <code>coreDNS</code> 服务的 IP 地址。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# kubectl get cm kube-proxy -n kube-system -o yaml | grep mode</span><br><span class="line">    mode: ipvs</span><br></pre></td></tr></table></figure><p><code>nodelocaldns</code> 通过添加 <code>iptables</code> 规则能够接收节点上所有发往 <code>169.254.20.10</code> 的 <code>dns</code> 查询请求，把针对集群内部域名查询请求路由到 <code>coredns</code>；把集群外部域名请求直接通过 <code>host</code> 网络发往集群外部 <code>dns</code> 服务器。之所以 <code>coredns</code> 的 <code>hosts</code> 插件不起作用 , 是因为集群 <code>pod</code> 使用的 <code>dns</code> 是 <code>169.254.20.10</code>, 也就是请求 <code>nodelocaldns</code>，而 <code>nodelocaldns</code> 配置的 <code>forward</code> 如下 :</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">~</span>]<span class="comment"># kubectl get cm  nodelocaldns -n kube-system -o yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">Corefile:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    cluster.local:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        cache &#123;</span></span><br><span class="line"><span class="string">            success 9984 30</span></span><br><span class="line"><span class="string">            denial 9984 5</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loop</span></span><br><span class="line"><span class="string">        bind 169.254.25.10</span></span><br><span class="line"><span class="string">        forward . 10.233.0.3 &#123;</span></span><br><span class="line"><span class="string">            force_tcp</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        prometheus :9253</span></span><br><span class="line"><span class="string">        health 169.254.25.10:9254</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    in-addr.arpa:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        cache 30</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loop</span></span><br><span class="line"><span class="string">        bind 169.254.25.10</span></span><br><span class="line"><span class="string">        forward . 10.233.0.3 &#123;</span></span><br><span class="line"><span class="string">            force_tcp</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        prometheus :9253</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    ip6.arpa:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        cache 30</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loop</span></span><br><span class="line"><span class="string">        bind 169.254.25.10</span></span><br><span class="line"><span class="string">        forward . 10.233.0.3 &#123;</span></span><br><span class="line"><span class="string">            force_tcp</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        prometheus :9253</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    .:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        cache 30</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loop</span></span><br><span class="line"><span class="string">        bind 169.254.25.10</span></span><br><span class="line"><span class="string">        forward . /etc/resolv.conf</span></span><br><span class="line"><span class="string">        prometheus :9253</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubectl.kubernetes.io/last-applied-configuration:</span> <span class="string">|</span></span><br><span class="line"><span class="string">      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:&#123;&quot;Corefile&quot;:&quot;cluster.local:53 &#123;\n    errors\n    cache &#123;\n        success 9984 30\n        denial 9984 5\n    &#125;\n    reload\n    loop\n    bind 169.254.25.10\n    forward . 10.233.0.3 &#123;\n        force_tcp\n    &#125;\n    prometheus :9253\n    health 169.254.25.10:9254\n&#125;\nin-addr.arpa:53 &#123;\n    errors\n    cache 30\n    reload\n    loop\n    bind 169.254.25.10\n    forward . 10.233.0.3 &#123;\n        force_tcp\n    &#125;\n    prometheus :9253\n&#125;\nip6.arpa:53 &#123;\n    errors\n    cache 30\n    reload\n    loop\n    bind 169.254.25.10\n    forward . 10.233.0.3 &#123;\n        force_tcp\n    &#125;\n    prometheus :9253\n&#125;\n.:53 &#123;\n    errors\n    cache 30\n    reload\n    loop\n    bind 169.254.25.10\n    forward . /etc/resolv.conf\n    prometheus :9253\n&#125;\n&quot;&#125;,&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;addonmanager.kubernetes.io/mode&quot;:&quot;EnsureExists&quot;&#125;,&quot;name&quot;:&quot;nodelocaldns&quot;,&quot;namespace&quot;:&quot;kube-system&quot;&#125;&#125;</span></span><br><span class="line"><span class="string"></span>  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2022-04-09T14:33:58Z&quot;</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">addonmanager.kubernetes.io/mode:</span> <span class="string">EnsureExists</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nodelocaldns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;291&quot;</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">/api/v1/namespaces/kube-system/configmaps/nodelocaldns</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">fe05a75c-b462-45bf-b265-8f9c393a20a1</span></span><br></pre></td></tr></table></figure><p>重点在最后一段配置 <strong>:53</strong>, <code>10.233.0.3</code> 为 <code>coredns</code> 的 <code>service</code> <code>ip</code>, 所以集群内部域名会转发给 <code>coredns</code>, 而非集群内部域名会转发给 <code>/etc/resolv.conf</code>, 根本就不会转发给 <code>coredns</code>, 所以 <code>coredns</code> 里面配置的 <code>hosts</code> 自然不会生效</p><p>解决：需要将 <code>nodelocaldns Pods</code> 中 的 <code>/etc/resolv.conf</code> 也就是 <code>__PILLAR__UPSTREAM__SERVERS__</code> 变量自动配置的值，设置为 <code>coreDNS</code> 服务的 IP 地址。</p><ul><li>修改 nodelocaldns 配置</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确认 coredns 的 IP 地址</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get svc -n kube-system | grep coredns</span><br><span class="line">coredns                       ClusterIP   10.233.0.3   &lt;none&gt;        53/UDP,53/TCP,9153/TCP         69d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑 nodelocaldns 的 configmap</span></span><br><span class="line">root@ks-k8s-master-0 ~]# kubectl edit cm nodelocaldns -n kube-system</span><br></pre></td></tr></table></figure><ul><li>修改对比</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改前</span></span><br><span class="line"><span class="string">.:53</span> &#123;</span><br><span class="line">    <span class="string">errors</span></span><br><span class="line">    <span class="string">cache</span> <span class="number">30</span></span><br><span class="line">    <span class="string">reload</span></span><br><span class="line">    <span class="string">loop</span></span><br><span class="line">    <span class="string">bind</span> <span class="number">169.254</span><span class="number">.25</span><span class="number">.10</span></span><br><span class="line">    <span class="string">forward</span> <span class="string">.</span> <span class="string">/etc/resolv.conf</span></span><br><span class="line">    <span class="string">prometheus</span> <span class="string">:9253</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后</span></span><br><span class="line"><span class="string">.:53</span> &#123;</span><br><span class="line">    <span class="string">errors</span></span><br><span class="line">    <span class="string">cache</span> <span class="number">30</span></span><br><span class="line">    <span class="string">reload</span></span><br><span class="line">    <span class="string">loop</span></span><br><span class="line">    <span class="string">bind</span> <span class="number">169.254</span><span class="number">.25</span><span class="number">.10</span></span><br><span class="line">    <span class="string">forward</span> <span class="string">.</span> <span class="number">10.233</span><span class="number">.0</span><span class="number">.3</span></span><br><span class="line">    <span class="string">prometheus</span> <span class="string">:9253</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>再次测试</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# kubectl run busybox --image=busybox --command -- ping -c 4 registry.zdevops.com.cn</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl logs busybox</span><br><span class="line">PING registry.zdevops.com.cn (192.168.9.89): 56 data bytes</span><br><span class="line">64 bytes from 192.168.9.89: seq=0 ttl=63 time=0.467 ms</span><br><span class="line">64 bytes from 192.168.9.89: seq=1 ttl=63 time=0.614 ms</span><br><span class="line">64 bytes from 192.168.9.89: seq=2 ttl=63 time=0.435 ms</span><br><span class="line">64 bytes from 192.168.9.89: seq=3 ttl=63 time=1.186 ms</span><br><span class="line"></span><br><span class="line">--- registry.zdevops.com.cn ping statistics ---</span><br><span class="line">4 packets transmitted, 4 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max = 0.435/0.675/1.186 ms</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl delete pod busybox</span><br></pre></td></tr></table></figure><h3 id="7-2-创建-Secret"><a href="#7-2-创建-Secret" class="headerlink" title="7.2. 创建 Secret"></a>7.2. 创建 Secret</h3><ul><li>用项目管理员账户登录 KubeSphere 控制台。</li><li><strong>在具体项目 zdevos 下</strong>-&gt;<strong>配置</strong>-&gt;<strong>保密字典</strong>-&gt;<strong>创建</strong>, 按图示填写相关信息。<ul><li><strong>类型：</strong> 镜像仓库信息</li><li><strong>仓库地址：</strong> 镜像仓库的地址，自建或是 Docker Hub 仓库</li><li><strong>用户名：</strong> 登录镜像仓库所需的用户名</li><li><strong>密码：</strong> 登录镜像仓库所需用户的密码</li></ul></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-17.png" alt="kube-harbor-17"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-18.png" alt="kube-harbor-18"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-19.png" alt="kube-harbor-19"></p><ul><li>输入正确的信息后，点击<strong>验证</strong>按钮，如图显示 <strong>镜像仓库验证通过</strong>，点击<strong>创建</strong>，返回保密字典列表。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-20.png" alt="kube-harbor-20"></p><h2 id="8-验证测试"><a href="#8-验证测试" class="headerlink" title="8. 验证测试"></a>8. 验证测试</h2><h3 id="8-1-准备-Nginx-测试镜像"><a href="#8-1-准备-Nginx-测试镜像" class="headerlink" title="8.1. 准备 Nginx 测试镜像"></a>8.1. 准备 Nginx 测试镜像</h3><ul><li>下载镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nginx</span><br></pre></td></tr></table></figure><ul><li>重新打 tag</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag nginx:latest registry.zdevops.com.cn/zdevops/nginx:latest</span><br></pre></td></tr></table></figure><ul><li>登录到 Harbor 仓库</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master data]# docker login registry.zdevops.com.cn</span><br><span class="line">Username: z</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><ul><li>推送到 Harbor 仓库</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master data]# docker push registry.zdevops.com.cn/zdevops/nginx:latest</span><br><span class="line">The push refers to repository [registry.zdevops.com.cn/zdevops/nginx]</span><br><span class="line">d874fd2bc83b: Pushed </span><br><span class="line">32ce5f6a5106: Pushed </span><br><span class="line">f1db227348d0: Pushed </span><br><span class="line">b8d6e692a25e: Pushed </span><br><span class="line">e379e8aedd4d: Pushed </span><br><span class="line">2edcec3590a4: Pushed </span><br><span class="line">latest: digest: sha256:ee89b00528ff4f02f2405e4ee221743ebc3f8e8dd0bfd5c4c20a2fa2aaa7ede3 size: 1570</span><br></pre></td></tr></table></figure><h3 id="8-2-部署-Nginx"><a href="#8-2-部署-Nginx" class="headerlink" title="8.2. 部署 Nginx"></a>8.2. 部署 Nginx</h3><ul><li>用项目管理员账户登录 KubeSphere 控制台</li><li><strong>在具体项目 zdevos 下</strong>-&gt;<strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>部署</strong>-&gt;<strong>创建</strong>, <strong>创建部署</strong>页面输入<strong>名称</strong>。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-21.png" alt="kube-harbor-21"></p><ul><li>点击<strong>添加容器</strong>，容器设置里选择自定义容器仓库。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-22.png" alt="kube-harbor-22"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-23.png" alt="kube-harbor-23"></p><ul><li>镜像选择：输入上传的 nginx 私有镜像的仓库地址</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-24.png" alt="kube-harbor-24"></p><ul><li>接下来按图示下一步即可。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-25.png" alt="kube-harbor-25"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-26.png" alt="kube-harbor-26"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-27.png" alt="kube-harbor-27"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-28.png" alt="kube-harbor-28"></p><ul><li>查看创建的 nginx 的 YAML 配置文件</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-29.png" alt="kube-harbor-29"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-harbor-30.png" alt="kube-harbor-30"></p><h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h2><p>本文详细演示了以下相关内容：</p><ul><li>Harbor 服务器的安装部署和安装后的初始化过程</li><li>K8S 配置自定义域名解析</li><li>KubeSphere 图形化创建镜像仓库类型的 Secret</li><li>KubeSphere 利用私有镜像仓库图形化创建工作负载</li></ul><blockquote><p><strong>参考文档</strong></p></blockquote><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-Harbor-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-Harbor-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s-Harbor </summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-Ceph 之 Ceph-deploy 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-%E5%A4%96%E9%83%A8Ceph%E9%9B%86%E7%BE%A4%E5%AF%B9%E6%8E%A5%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-%E5%A4%96%E9%83%A8Ceph%E9%9B%86%E7%BE%A4%E5%AF%B9%E6%8E%A5%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.372Z</published>
    <updated>2023-09-22T01:43:42.022Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-Ceph-之-Ceph-deploy-安装手记"><a href="#基于-KubeSphere-玩转-k8s-Ceph-之-Ceph-deploy-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-Ceph 之 Ceph-deploy 安装手记"></a>基于 KubeSphere 玩转 k8s-Ceph 之 Ceph-deploy 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文接着上一篇 &lt;&lt; 基于 KubeSphere 玩转 k8s-Ceph 安装手记 &gt;&gt;，继续实战 Kubernetes 对接外部 Ceph 集群。</p><p>本文简要介绍了 Kubernetes 对接已有 Ceph 集群的几种方案，重点演示了现在主流选用的 Ceph-CSI 方案的详细操作过程。</p><p>本文适用于学习测试环境，只是采用官方默认配置详细演示了 Kubernetes 对接已有 Ceph 集群的全部操作流程。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：5 分</li><li>行：500+</li><li>单词：1900+</li><li>字符：12600+</li><li>图片：0 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>CSI RBD</li><li>Ceph 的基础操作</li><li>Kubernetes 对接 Ceph</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ceph-node-0</td><td align="center">192.168.9.85</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">100</td><td align="center">Ceph</td></tr><tr><td align="center">ceph-node-1</td><td align="center">192.168.9.86</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">100</td><td align="center">Ceph</td></tr><tr><td align="center">ceph-node-2</td><td align="center">192.168.9.87</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">100</td><td align="center">Ceph</td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>KubeSphere：<strong>3.2.1</strong></li><li>Ceph：<strong>Octopus(15.2.16 )</strong> </li><li>Ansible：<strong>2.8.20</strong></li><li>Ceph-CSI：<strong>v3.6.1</strong></li></ul><h2 id="2-K8S-持久化存储对接-Ceph-介绍"><a href="#2-K8S-持久化存储对接-Ceph-介绍" class="headerlink" title="2. K8S 持久化存储对接 Ceph 介绍"></a>2. K8S 持久化存储对接 Ceph 介绍</h2><h3 id="2-1-支持的对接方式"><a href="#2-1-支持的对接方式" class="headerlink" title="2.1. 支持的对接方式"></a>2.1. 支持的对接方式</h3><ul><li>Ceph RBD<ul><li>Kubernetes 内置的 in-tree storage plugin</li><li>Ceph RBD only works on Kubernetes with <strong>hyperkube</strong> images, and <strong>hyperkube</strong> images were <a href="https://github.com/kubernetes/kubernetes/pull/85094">deprecated since Kubernetes 1.17</a></li></ul></li><li>rbd-provisioner<ul><li>类似于 Ceph RBD 但是属于 out-tree</li><li><code>rbd-provisioner</code> is an out-of-tree dynamic provisioner for Kubernetes 1.5+</li><li>KubeSphere 图形化界面选择了 <strong>rbd-provisioner</strong></li><li>折腾了两天没搞定，一堆报错，改造成本太高，相关插件都是三年前开发的了，彻底放弃了</li><li>愿意折腾的可以参考<a href="https://github.com/kubernetes-retired/external-storage/tree/master/ceph/rbd">rbd-provisioner 官方网站</a>自己折腾吧</li></ul></li><li><strong>Ceph-CSI</strong><ul><li>如果 Ceph 集群版本在 14.0.0 (Nautilus)+，首选，</li><li>Container Storage Interface (CSI) driver for RBD, CephFS</li><li>功能支持更好，例如 cloning、expanding 、snapshots</li><li><strong>本文的最终选择</strong></li></ul></li><li>Rook<ul><li>Rook (<a href="https://rook.io/">https://rook.io/</a>) is an orchestration tool that can run Ceph inside a Kubernetes cluster</li><li>生产环境如果需要可能会选择 Rook</li></ul></li></ul><h2 id="3-Ceph-集群配置"><a href="#3-Ceph-集群配置" class="headerlink" title="3. Ceph 集群配置"></a>3. Ceph 集群配置</h2><h3 id="3-1-创建-RBD-存储池"><a href="#3-1-创建-RBD-存储池" class="headerlink" title="3.1. 创建 RBD 存储池"></a>3.1. 创建 RBD 存储池</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ceph osd pool create kube 128 128</span><br><span class="line">rbd pool init kube</span><br><span class="line"></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph osd pool ls</span><br><span class="line">device_health_metrics</span><br><span class="line">kube</span><br></pre></td></tr></table></figure><h3 id="3-2-创建访问-Ceph-存储池的-client-用户"><a href="#3-2-创建访问-Ceph-存储池的-client-用户" class="headerlink" title="3.2. 创建访问 Ceph 存储池的 client 用户"></a>3.2. 创建访问 Ceph 存储池的 client 用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph auth get-or-create client.kube mon &#x27;profile rbd&#x27; osd &#x27;profile rbd pool=kube&#x27; mgr &#x27;profile rbd pool=kube&#x27;</span><br><span class="line">[client.kube]</span><br><span class="line">        key = AQBHlIxiuRgiARAANMrLQIEXaDCm7uDSMeuZaw==</span><br></pre></td></tr></table></figure><h3 id="3-3-获取-key"><a href="#3-3-获取-key" class="headerlink" title="3.3. 获取 key"></a>3.3. 获取 key</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph auth list | grep client.kube -A 3</span><br><span class="line">installed auth entries:</span><br><span class="line"></span><br><span class="line">client.kube</span><br><span class="line">        key: AQBHlIxiuRgiARAANMrLQIEXaDCm7uDSMeuZaw==</span><br><span class="line">        caps: [mgr] profile rbd pool=kube</span><br><span class="line">        caps: [mon] profile rbd</span><br><span class="line">   </span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph auth get-key client.kube</span><br><span class="line">AQBHlIxiuRgiARAANMrLQIEXaDCm7uDSMeuZaw==</span><br><span class="line"></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph auth get-key client.kube | base64</span><br><span class="line">QVFCSGxJeGl1UmdpQVJBQU5NckxRSUVYYURDbTd1RFNNZXVaYXc9PQ==</span><br></pre></td></tr></table></figure><h2 id="4-K8S-持久化存储对接-Ceph"><a href="#4-K8S-持久化存储对接-Ceph" class="headerlink" title="4. K8S 持久化存储对接 Ceph"></a>4. K8S 持久化存储对接 Ceph</h2><h3 id="4-1-获取配置文件参考模板"><a href="#4-1-获取配置文件参考模板" class="headerlink" title="4.1. 获取配置文件参考模板"></a>4.1. 获取配置文件参考模板</h3><p><a href="https://github.com/ceph/ceph-csi/tree/v3.6.1/deploy/rbd/kubernetes">ceph-csi-v3.6.1 deploy</a></p><p><a href="https://github.com/ceph/ceph-csi/tree/v3.6.1/examples">ceph-csi-v3.6.1-examples</a></p><p>直接将仓考模板下载到服务器 (本文写作时最新版是 v3.6.1)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/ceph/ceph-csi/archive/refs/tags/v3.6.1.tar.gz</span><br><span class="line">tar xvf v3.6.1.tar.gz</span><br></pre></td></tr></table></figure><p><strong>YAML manifests 在 <code>deploy/rbd/kubernetes</code> 目录中。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ceph-csi-3.6.1/deploy/rbd/kubernetes/</span><br></pre></td></tr></table></figure><h3 id="4-2-Deploy-RBACs-for-sidecar-containers-and-node-plugins"><a href="#4-2-Deploy-RBACs-for-sidecar-containers-and-node-plugins" class="headerlink" title="4.2. Deploy RBACs for sidecar containers and node plugins"></a>4.2. Deploy RBACs for sidecar containers and node plugins</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">csi-provisioner-rbac.yaml</span></span><br><span class="line"><span class="string">kubectl</span> <span class="string">create</span> <span class="string">-f</span> <span class="string">csi-nodeplugin-rbac.yaml</span></span><br></pre></td></tr></table></figure><h3 id="4-3-Deploy-ConfigMap-for-CSI-plugins"><a href="#4-3-Deploy-ConfigMap-for-CSI-plugins" class="headerlink" title="4.3. Deploy ConfigMap for CSI plugins"></a>4.3. Deploy ConfigMap for CSI plugins</h3><p>deploy 目录中提供的配置文件是个空的配置，因此，需要根据实际情况修改。</p><blockquote><p><strong>修改后的 csi-config-map.yaml</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&quot;ceph-csi-config&quot;</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.json:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    [</span></span><br><span class="line"><span class="string">      &#123;</span></span><br><span class="line"><span class="string">        &quot;clusterID&quot;: &quot;a614e796-6875-4134-a735-2e4db541bba8&quot;,</span></span><br><span class="line"><span class="string">        &quot;monitors&quot;: [</span></span><br><span class="line"><span class="string">        &quot;192.168.9.85:6789&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.9.86:6789&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.9.87:6789&quot;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br></pre></td></tr></table></figure><ul><li>clusterID：通过 <code>ceph -s</code> 或是 <code>ceph fsid</code> 获取</li><li>monitors：Ceph mon 节点的 IP，可以通过 <code>ceph mon dump</code> 获取</li></ul><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-config-map.yaml</span><br></pre></td></tr></table></figure><h3 id="4-4-Deploy-Ceph-configuration-ConfigMap-for-CSI-pods"><a href="#4-4-Deploy-Ceph-configuration-ConfigMap-for-CSI-pods" class="headerlink" title="4.4. Deploy Ceph configuration ConfigMap for CSI pods"></a>4.4. Deploy Ceph configuration ConfigMap for CSI pods</h3><blockquote><p><strong>创建 ceph-config.yaml</strong></p></blockquote><p>把实际的 ceph.conf 的内容粘贴上，配置文件模板参考 <strong>ceph-csi-3.6.1&#x2F;examples&#x2F;ceph-conf.yaml</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">ceph.conf:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    [global]</span></span><br><span class="line"><span class="string">    fsid = a614e796-6875-4134-a735-2e4db541bba8</span></span><br><span class="line"><span class="string">    mon_initial_members = ceph-node-0</span></span><br><span class="line"><span class="string">    mon_host = 192.168.9.85</span></span><br><span class="line"><span class="string">    auth_cluster_required = cephx</span></span><br><span class="line"><span class="string">    auth_service_required = cephx</span></span><br><span class="line"><span class="string">    auth_client_required = cephx</span></span><br><span class="line"><span class="string">    public network = 192.168.9.0/24</span></span><br><span class="line"><span class="string"></span>  <span class="comment"># keyring is a required key and its value should be empty</span></span><br><span class="line">  <span class="attr">keyring:</span> <span class="string">|</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ceph-config</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f ceph-config.yaml</span><br></pre></td></tr></table></figure><h3 id="4-5-创建-ceph-csi-encryption-kms-config"><a href="#4-5-创建-ceph-csi-encryption-kms-config" class="headerlink" title="4.5. 创建 ceph-csi-encryption-kms-config"></a>4.5. 创建 ceph-csi-encryption-kms-config</h3><p>官方文档中没有提及，下面的命令执行时报错，经排查需要创建 <strong>ceph-csi-encryption-kms-config</strong></p><p>Kms 是个复杂的话题，我们这里创建一个空的，有兴趣的自行参考<a href="https://github.com/ceph/ceph-csi/blob/devel/docs/deploy-rbd.md">官方文档</a></p><blockquote><p><strong>创建 ceph-csi-encryption-kms-config.yaml</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.json:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    &#123;&#125;</span></span><br><span class="line"><span class="string"></span><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ceph-csi-encryption-kms-config</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f ceph-csi-encryption-kms-config.yaml</span><br></pre></td></tr></table></figure><h3 id="4-6-Deploy-CSI-sidecar-containers"><a href="#4-6-Deploy-CSI-sidecar-containers" class="headerlink" title="4.6. Deploy CSI sidecar containers"></a>4.6. Deploy CSI sidecar containers</h3><blockquote><p><strong>部署 provision 的 deployment 包括</strong></p></blockquote><ul><li>external-provisioner</li><li>external-attacher</li><li>csi-snapshotter sidecar containers</li><li>CSI RBD plugin</li></ul><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-rbdplugin-provisioner.yaml</span><br></pre></td></tr></table></figure><h3 id="4-7-Deploy-RBD-CSI-driver"><a href="#4-7-Deploy-RBD-CSI-driver" class="headerlink" title="4.7. Deploy RBD CSI driver"></a>4.7. Deploy RBD CSI driver</h3><blockquote><p><strong>部署一个 daemon set 包含两个 containers</strong></p></blockquote><ul><li>CSI node-driver-registrar</li><li>CSI RBD driver</li></ul><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-rbdplugin.yaml</span><br></pre></td></tr></table></figure><h3 id="4-8-Verifying-the-deployment-in-Kubernetes"><a href="#4-8-Verifying-the-deployment-in-Kubernetes" class="headerlink" title="4.8. Verifying the deployment in Kubernetes"></a>4.8. Verifying the deployment in Kubernetes</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 rbd]# kubectl get all</span><br><span class="line">NAME                                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/csi-rbdplugin-42v8p                          3/3     Running   0          4m30s</span><br><span class="line">pod/csi-rbdplugin-gm8v7                          3/3     Running   0          4m30s</span><br><span class="line">pod/csi-rbdplugin-p9jvx                          3/3     Running   0          4m30s</span><br><span class="line">pod/csi-rbdplugin-provisioner-85c6b9d548-526zr   7/7     Running   0          7m7s</span><br><span class="line">pod/csi-rbdplugin-provisioner-85c6b9d548-sq66v   7/7     Running   0          7m7s</span><br><span class="line">pod/csi-rbdplugin-provisioner-85c6b9d548-xhfkb   7/7     Running   0          7m7s</span><br><span class="line"></span><br><span class="line">NAME                                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">service/csi-metrics-rbdplugin       ClusterIP   10.233.10.168   &lt;none&gt;        8080/TCP   4m30s</span><br><span class="line">service/csi-rbdplugin-provisioner   ClusterIP   10.233.5.181    &lt;none&gt;        8080/TCP   7m8s</span><br><span class="line">service/kubernetes                  ClusterIP   10.233.0.1      &lt;none&gt;        443/TCP    46d</span><br><span class="line"></span><br><span class="line">NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/csi-rbdplugin   3         3         3       3            3           &lt;none&gt;          4m30s</span><br><span class="line"></span><br><span class="line">NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/csi-rbdplugin-provisioner   3/3     1            3           7m8s</span><br><span class="line"></span><br><span class="line">NAME                                                   DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/csi-rbdplugin-provisioner-74fd478c9d   1         1         0       5m11s</span><br><span class="line">replicaset.apps/csi-rbdplugin-provisioner-85c6b9d548   3         3         3       7m7s</span><br></pre></td></tr></table></figure><h3 id="4-9-Deploy-Secret"><a href="#4-9-Deploy-Secret" class="headerlink" title="4.9. Deploy Secret"></a>4.9. Deploy Secret</h3><blockquote><p><strong>创建 csi-rbd-secret.yaml</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: csi-rbd-secret</span><br><span class="line">  namespace: default</span><br><span class="line">stringData:</span><br><span class="line">  userID: kube</span><br><span class="line">  userKey: AQBHlIxiuRgiARAANMrLQIEXaDCm7uDSMeuZaw==</span><br></pre></td></tr></table></figure><ul><li>userKey：通过 <code>ceph auth get-key client.kube</code> 获取，不要使用 <code>ceph auth get-key client.kube | base64</code></li></ul><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-rbd-secret.yaml</span><br></pre></td></tr></table></figure><h3 id="4-10-Deploy-StorageClass"><a href="#4-10-Deploy-StorageClass" class="headerlink" title="4.10. Deploy StorageClass"></a>4.10. Deploy StorageClass</h3><blockquote><p><strong>创建 csi-rbd-sc.yaml</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">csi-rbd-sc</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rbd.csi.ceph.com</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">   <span class="attr">clusterID:</span> <span class="string">a614e796-6875-4134-a735-2e4db541bba8</span></span><br><span class="line">   <span class="attr">pool:</span> <span class="string">kube</span></span><br><span class="line">   <span class="attr">imageFeatures:</span> <span class="string">&quot;layering&quot;</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">csi-rbd-secret</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">default</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/controller-expand-secret-name:</span> <span class="string">csi-rbd-secret</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/controller-expand-secret-namespace:</span> <span class="string">default</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">csi-rbd-secret</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">default</span></span><br><span class="line">   <span class="attr">csi.storage.k8s.io/fstype:</span> <span class="string">ext4</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">mountOptions:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="string">discard</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-rbd-sc.yaml</span><br></pre></td></tr></table></figure><h3 id="4-11-Deploy-PVC"><a href="#4-11-Deploy-PVC" class="headerlink" title="4.11. Deploy PVC"></a>4.11. Deploy PVC</h3><blockquote><p><strong>创建 csi-rbd-pvc.yaml</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">rbd-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">csi-rbd-sc</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-rbd-pvc.yaml</span><br></pre></td></tr></table></figure><h3 id="4-12-Deploy-POD"><a href="#4-12-Deploy-POD" class="headerlink" title="4.12. Deploy POD"></a>4.12. Deploy POD</h3><blockquote><p><strong>创建 csi-rbd-pod.yaml</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">csi-rbd-demo-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web-server</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mypvc</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/www/html</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mypvc</span></span><br><span class="line">      <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">        <span class="attr">claimName:</span> <span class="string">rbd-pvc</span></span><br><span class="line">        <span class="attr">readOnly:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>执行创建命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f csi-rbd-pod.yaml</span><br></pre></td></tr></table></figure><h3 id="4-13-验证"><a href="#4-13-验证" class="headerlink" title="4.13. 验证"></a>4.13. 验证</h3><blockquote><p><strong>K8S 集群验证</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 kubernetes]# kubectl get sc</span><br><span class="line">NAME              PROVISIONER               RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">csi-rbd-sc        rbd.csi.ceph.com          Delete          Immediate              true                   43m</span><br><span class="line">glusterfs         kubernetes.io/glusterfs   Delete          Immediate              false                  2d</span><br><span class="line">local (default)   openebs.io/local          Delete          WaitForFirstConsumer   false                  47d</span><br><span class="line">[root@ks-k8s-master-0 kubernetes]# kubectl get pvc</span><br><span class="line">NAME      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">rbd-pvc   Bound    pvc-5bf3b852-1297-4340-aebd-61895dd5705d   1Gi        RWO            csi-rbd-sc     27m</span><br></pre></td></tr></table></figure><blockquote><p><strong>Ceph 集群验证</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 ~]# rbd -p kube ls</span><br><span class="line">csi-vol-d0a599f0-dd5a-11ec-9ff3-768bcf86381f</span><br><span class="line"></span><br><span class="line">[root@ceph-node-0 ~]# rbd -p kube info csi-vol-d0a599f0-dd5a-11ec-9ff3-768bcf86381f</span><br><span class="line">rbd image &#x27;csi-vol-d0a599f0-dd5a-11ec-9ff3-768bcf86381f&#x27;:</span><br><span class="line">        size 1 GiB in 256 objects</span><br><span class="line">        order 22 (4 MiB objects)</span><br><span class="line">        snapshot_count: 0</span><br><span class="line">        id: 85e5fedccd17</span><br><span class="line">        block_name_prefix: rbd_data.85e5fedccd17</span><br><span class="line">        format: 2</span><br><span class="line">        features: layering</span><br><span class="line">        op_features: </span><br><span class="line">        flags: </span><br><span class="line">        create_timestamp: Fri May 27 09:18:35 2022</span><br><span class="line">        access_timestamp: Fri May 27 09:18:35 2022</span><br><span class="line">        modify_timestamp: Fri May 27 09:18:35 2022</span><br></pre></td></tr></table></figure><h2 id="5-常见问题"><a href="#5-常见问题" class="headerlink" title="5. 常见问题"></a>5. 常见问题</h2><h3 id="5-1-Ceph-userKey-使用错误"><a href="#5-1-Ceph-userKey-使用错误" class="headerlink" title="5.1. Ceph userKey 使用错误"></a>5.1. Ceph userKey 使用错误</h3><blockquote><p><strong>报错现象</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">failed to provision volume with StorageClass &quot;csi-rbd-sc&quot;: rpc error: code = Internal desc = failed to get connection: connecting failed: rados: ret=-22, Invalid argument</span><br></pre></td></tr></table></figure><blockquote><p><strong>解决方案</strong></p></blockquote><ul><li>出现这个报错，原因是 ceph 集群连接失败，检查 <strong>csi-rbd-secret</strong> 配置中的 <strong>userKey</strong>。</li><li>需要使用 <code>ceph auth get-key client.kube</code> 的原始输出值，不要进行 base64 加密。</li></ul><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>本文首先演示了 Ceph 集群创建对接 Kubernetes 必须资源的操作配置，接下来重点演示了 Kubernetes 使用 Ceph-CSI 方式对接外部 Ceph 集群的全流程操作。本文的演示仅适用于学习测试，生产环境需要考虑更多的配置。如果是新建的 Ceph 集群，建议考虑 Rook 方案。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><a href="https://github.com/ceph/ceph-csi/blob/devel/docs/deploy-rbd.md">CSI RBD 安装</a></li><li><a href="https://github.com/ceph/ceph-csi/tree/v3.6.1/examples">CSI RBD examples</a></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-Ceph-之-Ceph-deploy-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-Ceph-之-Ceph-deploy-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 K</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-Ceph 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Ceph%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Ceph%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.337Z</published>
    <updated>2023-09-22T01:43:27.428Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-Ceph-安装手记"><a href="#基于-KubeSphere-玩转-k8s-Ceph-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-Ceph 安装手记"></a>基于 KubeSphere 玩转 k8s-Ceph 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文简要介绍了几种常见的 Ceph 分布式存储安装方案，重点演示了 Ceph-deploy 方案的详细操作过程。</p><p>由于 Ceph-deploy 已经被官方所放弃，因此，本文适用于学习测试环境。</p><blockquote><p>本文知识量</p></blockquote><ul><li>阅读时长：20 分</li><li>行：1600+</li><li>单词：8000+</li><li>字符：74400+</li><li>图片：0 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>Ceph 的常用安装部署</li><li>Ceph-deploy 安装部署 Ceph 集群</li><li>Ceph-deploy 扩展 Ceph 集群</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ceph-node-0</td><td align="center">192.168.9.85</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Ceph</td></tr><tr><td align="center">ceph-node-1</td><td align="center">192.168.9.86</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Ceph</td></tr><tr><td align="center">ceph-node-2</td><td align="center">192.168.9.87</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">Ceph</td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>KubeSphere：<strong>3.2.1</strong></li><li>Ansible：<strong>2.8.20</strong></li><li>Ceph：<strong>Octopus(15.2.16 )</strong></li></ul><h2 id="2-Ansible-配置"><a href="#2-Ansible-配置" class="headerlink" title="2. Ansible 配置"></a>2. Ansible 配置</h2><h3 id="2-1-增加-hosts-配置"><a href="#2-1-增加-hosts-配置" class="headerlink" title="2.1. 增加 hosts 配置"></a>2.1. 增加 hosts 配置</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主要增加 ceph 节点配置</span></span><br><span class="line"></span><br><span class="line"><span class="section">[ceph]</span></span><br><span class="line">ceph-node-0 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.85</span> host_name=ceph-node-<span class="number">0</span></span><br><span class="line">ceph-node-1 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.86</span> host_name=ceph-node-<span class="number">1</span></span><br><span class="line">ceph-node-2 <span class="attr">ansible_ssh_host</span>=<span class="number">192.168</span>.<span class="number">9.87</span> host_name=ceph-node-<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="section">[servers:children]</span></span><br><span class="line">k8s</span><br><span class="line">glusterfs</span><br><span class="line">es</span><br><span class="line">ceph</span><br></pre></td></tr></table></figure><h2 id="3-Ceph-安装方式介绍"><a href="#3-Ceph-安装方式介绍" class="headerlink" title="3. Ceph 安装方式介绍"></a>3. Ceph 安装方式介绍</h2><h3 id="3-1-Ceph-deploy"><a href="#3-1-Ceph-deploy" class="headerlink" title="3.1. Ceph-deploy"></a>3.1. Ceph-deploy</h3><ul><li><p><a href="https://docs.ceph.com/projects/ceph-deploy/en/latest/">Ceph-deploy</a> 是一个快速部署 Ceph 集群的工具。</p></li><li><p><strong>Ceph-deploy 不再 (actively) 积极维护。</strong></p></li><li><p><strong>在高于 Nautilus 的版本上没有测试过。</strong></p></li><li><p><strong>不支持 RHEL8, CentOS 8, 或者更新的操作系统。</strong></p></li><li><p>CentOS 7.9 搭配 Ceph Nautilus 版本时首选，但是 <strong>Ceph Nautilus</strong>(2019-05-01 首发) 有点老旧了能不选还是不要选了。</p></li></ul><blockquote><p>CentOS 8 我还没有玩过，也没有计划去搞，所有学习测试环境最终选择了 CentOS7.9 搭配 <strong>Octopus</strong> 的方案。</p></blockquote><h3 id="3-2-Cephadm"><a href="#3-2-Cephadm" class="headerlink" title="3.2. Cephadm"></a>3.2. Cephadm</h3><ul><li><p><a href="https://docs.ceph.com/en/quincy/cephadm/#cephadm">Cephadm</a> 使用容器和 systemd 安装和管理 Ceph 集群，并与 CLI 和仪表板 GUI 紧密集成。</p></li><li><p>Cephadm 仅支持 Octopus  v15.2.0 和更新版本。</p></li><li><p>Cephadm 与新的 orchestrator API 完全集成，并完全支持新的 CLI 和仪表盘功能来管理集群部署。</p></li><li><p>Cephadm 需要容器支持 (podman 或 docker) 和 Python 3。</p></li><li><p>非 Kubernetes 环境首选。</p></li></ul><h3 id="3-3-Rook"><a href="#3-3-Rook" class="headerlink" title="3.3. Rook"></a>3.3. Rook</h3><ul><li><p><a href="https://rook.io/">Rook</a> 部署和管理运行在 Kubernetes 中的 Ceph 集群，同时也支持通过 Kubernetes APi 管理存储资源和 provisionin。</p></li><li><p>官方推荐使用 Rook 在 Kubernetes 中运行 Ceph，或者将现有的 Ceph 存储集群连接到 Kubernetes。</p></li><li><p>Rook 只支持 Nautilus 和 Ceph 的更新版本。</p></li><li><p>Rook 支持新的 orchestrator API，并完全支持在 CLI 和仪表盘 中的新的管理功能。</p></li><li><p>Rook 是在 Kubernetes 上运行 Ceph 的首选方法，或者是将 Kubernetes 集群连接到现有 (外部)Ceph 集群的首选方法。</p></li></ul><h3 id="3-4-手动安装"><a href="#3-4-手动安装" class="headerlink" title="3.4. 手动安装"></a>3.4. 手动安装</h3><p>你也可以不采用任何部署工具，一步步的手工安装 Ceph 集群，安装软件包、初始化集群、安装 Mon、安装配置 OSD 等。</p><p>具体可以参考<a href="https://docs.ceph.com/en/latest/install/index_manual/">官方手工安装文档</a>，除非你要自己编写自动化部署工具，可以参考官方的手工操作方式，否则不建议采用手工的方式。</p><h2 id="4-Ceph-节点初始化配置"><a href="#4-Ceph-节点初始化配置" class="headerlink" title="4. Ceph 节点初始化配置"></a>4. Ceph 节点初始化配置</h2><h3 id="4-1-检测服务器连通性"><a href="#4-1-检测服务器连通性" class="headerlink" title="4.1. 检测服务器连通性"></a>4.1. 检测服务器连通性</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 检测服务器的连通性</span></span><br><span class="line">cd /data/ansible/ansible-zdevops/inventories/dev/</span><br><span class="line">source /opt/ansible2.8/bin/activate</span><br><span class="line">ansible -m ping es </span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master ~]# cd /data/ansible/ansible-zdevops/inventories/dev/</span><br><span class="line">[root@zdevops-master dev]# source /opt/ansible2.8/bin/activate</span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible -m ping ceph</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ceph-node-2 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">ceph-node-1 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">ceph-node-0 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-2-初始化服务器配置"><a href="#4-2-初始化服务器配置" class="headerlink" title="4.2. 初始化服务器配置"></a>4.2. 初始化服务器配置</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><p><strong>重点注意：ansible-playbook 的 -l 参数，需要指定为 ceph，因为 init-base.yaml 文件默认指定的是所有服务器都执行，不加-l 就会把 hosts 文件里指定的所有服务器都初始化了。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化服务器配置</span></span><br><span class="line">ansible-playbook ../../playbooks/init-base.yaml -l ceph</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/init-base.yaml -l ceph</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [初始化服务器配置.] *************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-停止并禁用firewalld服务.] **************************************************************************************</span><br><span class="line">changed: [ceph-node-0]</span><br><span class="line">changed: [ceph-node-2]</span><br><span class="line">changed: [ceph-node-1]</span><br><span class="line"></span><br><span class="line">TASK [02-配置主机名.] *************************************************************************************************</span><br><span class="line">changed: [ceph-node-0]</span><br><span class="line">changed: [ceph-node-2]</span><br><span class="line">changed: [ceph-node-1]</span><br><span class="line"></span><br><span class="line">TASK [03-配置/etc/hosts.] ******************************************************************************************</span><br><span class="line">changed: [ceph-node-2]</span><br><span class="line">changed: [ceph-node-0]</span><br><span class="line">changed: [ceph-node-1]</span><br><span class="line"></span><br><span class="line">TASK [04-配置时区.] **************************************************************************************************</span><br><span class="line">ok: [ceph-node-1]</span><br><span class="line">ok: [ceph-node-0]</span><br><span class="line">ok: [ceph-node-2]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统.] ************************************************************************************************</span><br><span class="line">skipping: [ceph-node-0]</span><br><span class="line">skipping: [ceph-node-1]</span><br><span class="line">skipping: [ceph-node-2]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统后如果需要重启，则重启服务器.] **********************************************************************************</span><br><span class="line">skipping: [ceph-node-0]</span><br><span class="line">skipping: [ceph-node-1]</span><br><span class="line">skipping: [ceph-node-2]</span><br><span class="line"></span><br><span class="line">TASK [05-等待服务器完成重启.] *********************************************************************************************</span><br><span class="line">skipping: [ceph-node-0]</span><br><span class="line">skipping: [ceph-node-1]</span><br><span class="line">skipping: [ceph-node-2]</span><br><span class="line"></span><br><span class="line">PLAY [安装配置chrony服务器.] ********************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-安装chrony软件包.] *******************************************************************************************</span><br><span class="line">changed: [ceph-node-2] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [ceph-node-1] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [ceph-node-0] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line"></span><br><span class="line">TASK [02-配置chrony.conf.] *****************************************************************************************</span><br><span class="line">changed: [ceph-node-1]</span><br><span class="line">changed: [ceph-node-2]</span><br><span class="line">changed: [ceph-node-0]</span><br><span class="line"></span><br><span class="line">TASK [03-确认chrony服务启动并实现开机自启.] ***********************************************************************************</span><br><span class="line">changed: [ceph-node-2]</span><br><span class="line">changed: [ceph-node-1]</span><br><span class="line">changed: [ceph-node-0]</span><br><span class="line"></span><br><span class="line">TASK [04-查看chrony时间同步服务器列表(1).] **********************************************************************************</span><br><span class="line">changed: [ceph-node-2]</span><br><span class="line">changed: [ceph-node-1]</span><br><span class="line">changed: [ceph-node-0]</span><br><span class="line"></span><br><span class="line">TASK [04-查看chrony时间同步服务器列表(2).] **********************************************************************************</span><br><span class="line">ok: [ceph-node-0] =&gt; &#123;</span><br><span class="line">    &quot;chronyc_out.stdout_lines&quot;: [</span><br><span class="line">        &quot;210 Number of sources = 1&quot;, </span><br><span class="line">        &quot;MS Name/IP address         Stratum Poll Reach LastRx Last sample               &quot;, </span><br><span class="line">        &quot;===============================================================================&quot;, </span><br><span class="line">        &quot;^? 114.118.7.161                 0   6     0     -     +0ns[   +0ns] +/-    0ns&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">ok: [ceph-node-1] =&gt; &#123;</span><br><span class="line">    &quot;chronyc_out.stdout_lines&quot;: [</span><br><span class="line">        &quot;210 Number of sources = 1&quot;, </span><br><span class="line">        &quot;MS Name/IP address         Stratum Poll Reach LastRx Last sample               &quot;, </span><br><span class="line">        &quot;===============================================================================&quot;, </span><br><span class="line">        &quot;^? 114.118.7.161                 1   6     1     1   -63.8s[ -63.8s] +/- 6042us&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">ok: [ceph-node-2] =&gt; &#123;</span><br><span class="line">    &quot;chronyc_out.stdout_lines&quot;: [</span><br><span class="line">        &quot;210 Number of sources = 1&quot;, </span><br><span class="line">        &quot;MS Name/IP address         Stratum Poll Reach LastRx Last sample               &quot;, </span><br><span class="line">        &quot;===============================================================================&quot;, </span><br><span class="line">        &quot;^? 114.118.7.163                 0   6     0     -     +0ns[   +0ns] +/-    0ns&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PLAY RECAP *******************************************************************************************************</span><br><span class="line">ceph-node-0                : ok=9    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">ceph-node-1                : ok=9    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">ceph-node-2                : ok=9    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0</span><br></pre></td></tr></table></figure><h3 id="4-3-EPEL-软件源配置"><a href="#4-3-EPEL-软件源配置" class="headerlink" title="4.3. EPEL 软件源配置"></a>4.3. EPEL 软件源配置</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible ceph -m shell -a &#x27;yum install -y epel-release&#x27;</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible ceph -m shell -a &#x27;yum install -y epel-release&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">[WARNING]: Consider using the yum module rather than running &#x27;yum&#x27;.  If you need to use command because yum is</span><br><span class="line">insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27; in ansible.cfg to get</span><br><span class="line">rid of this message.</span><br><span class="line"></span><br><span class="line">ceph-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package epel-release.noarch 0:7-11 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package                Arch             Version         Repository        Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> epel-release           noarch           7-11            extras            15 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 15 k</span><br><span class="line">Installed size: 24 k</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : epel-release-7-11.noarch                                     1/1 </span><br><span class="line">  Verifying  : epel-release-7-11.noarch                                     1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  epel-release.noarch 0:7-11                                                    </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">ceph-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package epel-release.noarch 0:7-11 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package                Arch             Version         Repository        Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> epel-release           noarch           7-11            extras            15 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 15 k</span><br><span class="line">Installed size: 24 k</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : epel-release-7-11.noarch                                     1/1 </span><br><span class="line">  Verifying  : epel-release-7-11.noarch                                     1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  epel-release.noarch 0:7-11                                                    </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">ceph-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package epel-release.noarch 0:7-11 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package                Arch             Version         Repository        Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> epel-release           noarch           7-11            extras            15 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 15 k</span><br><span class="line">Installed size: 24 k</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : epel-release-7-11.noarch                                     1/1 </span><br><span class="line">  Verifying  : epel-release-7-11.noarch                                     1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  epel-release.noarch 0:7-11                                                    </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure><h3 id="4-4-Ceph-软件源配置"><a href="#4-4-Ceph-软件源配置" class="headerlink" title="4.4. Ceph 软件源配置"></a>4.4. Ceph 软件源配置</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 安装 ceph-release 包</span></span><br><span class="line">ansible ceph -m shell -a &#x27;yum install -y https://download.ceph.com/rpm-octopus/el7/noarch/ceph-release-1-1.el7.noarch.rpm&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证生成的 ceph.repo 文件</span></span><br><span class="line">ansible ceph -m shell -a &#x27;cat /etc/yum.repos.d/ceph.repo&#x27;</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 安装 ceph-release 包</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible ceph -m shell -a &#x27;yum install -y https://download.ceph.com/rpm-octopus/el7/noarch/ceph-release-1-1.el7.noarch.rpm&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">[WARNING]: Consider using the yum module rather than running &#x27;yum&#x27;.  If you need to use command because yum is</span><br><span class="line">insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27; in ansible.cfg to get</span><br><span class="line">rid of this message.</span><br><span class="line"></span><br><span class="line">ceph-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Examining /var/tmp/yum-root-UJAX7G/ceph-release-1-1.el7.noarch.rpm: ceph-release-1-1.el7.noarch</span><br><span class="line">Marking /var/tmp/yum-root-UJAX7G/ceph-release-1-1.el7.noarch.rpm to be installed</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ceph-release.noarch 0:1-1.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package          Arch       Version     Repository                        Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ceph-release     noarch     1-1.el7     /ceph-release-1-1.el7.noarch     541  </span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total size: 541  </span><br><span class="line">Installed size: 541  </span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ceph-release-1-1.el7.noarch                                  1/1 </span><br><span class="line">  Verifying  : ceph-release-1-1.el7.noarch                                  1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ceph-release.noarch 0:1-1.el7                                                 </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">ceph-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Examining /var/tmp/yum-root-JWJnoN/ceph-release-1-1.el7.noarch.rpm: ceph-release-1-1.el7.noarch</span><br><span class="line">Marking /var/tmp/yum-root-JWJnoN/ceph-release-1-1.el7.noarch.rpm to be installed</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ceph-release.noarch 0:1-1.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package          Arch       Version     Repository                        Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ceph-release     noarch     1-1.el7     /ceph-release-1-1.el7.noarch     541  </span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total size: 541  </span><br><span class="line">Installed size: 541  </span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ceph-release-1-1.el7.noarch                                  1/1 </span><br><span class="line">  Verifying  : ceph-release-1-1.el7.noarch                                  1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ceph-release.noarch 0:1-1.el7                                                 </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">ceph-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Examining /var/tmp/yum-root-z2H1Lx/ceph-release-1-1.el7.noarch.rpm: ceph-release-1-1.el7.noarch</span><br><span class="line">Marking /var/tmp/yum-root-z2H1Lx/ceph-release-1-1.el7.noarch.rpm to be installed</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ceph-release.noarch 0:1-1.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package          Arch       Version     Repository                        Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ceph-release     noarch     1-1.el7     /ceph-release-1-1.el7.noarch     541  </span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total size: 541  </span><br><span class="line">Installed size: 541  </span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ceph-release-1-1.el7.noarch                                  1/1 </span><br><span class="line">  Verifying  : ceph-release-1-1.el7.noarch                                  1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ceph-release.noarch 0:1-1.el7                                                 </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证生成的 ceph.repo 文件</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible ceph -m shell -a &#x27;cat /etc/yum.repos.d/ceph.repo&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ceph-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">[Ceph]</span><br><span class="line">name=Ceph packages for $basearch</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/$basearch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[Ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph source packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/SRPMS</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">ceph-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">[Ceph]</span><br><span class="line">name=Ceph packages for $basearch</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/$basearch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[Ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph source packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/SRPMS</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">ceph-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">[Ceph]</span><br><span class="line">name=Ceph packages for $basearch</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/$basearch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[Ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph source packages</span><br><span class="line">baseurl=http://download.ceph.com/rpm-octopus/el7/SRPMS</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br></pre></td></tr></table></figure><h2 id="5-Ceph-deploy-安装配置"><a href="#5-Ceph-deploy-安装配置" class="headerlink" title="5. Ceph-deploy 安装配置"></a>5. Ceph-deploy 安装配置</h2><p><strong>本节所有操作都在 ceph-node-0 节点执行</strong>。</p><h3 id="5-1-Ceph-deploy-节点-SSH-免密配置"><a href="#5-1-Ceph-deploy-节点-SSH-免密配置" class="headerlink" title="5.1. Ceph-deploy 节点 SSH 免密配置"></a>5.1. Ceph-deploy 节点 SSH 免密配置</h3><p>指定 <strong>ceph-node-0</strong> 节点作为 Ceph-deploy 服务器，在该节点配置免密登录所有 Ceph 节点。</p><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成密钥</span></span><br><span class="line">ssh-keygen -f $HOME/.ssh/id_rsa -t rsa -N &#x27;&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制密钥(按提示输入 <span class="built_in">yes</span> 和服务器密码)</span></span><br><span class="line">ssh-copy-id root@192.168.9.85</span><br><span class="line">ssh-copy-id root@192.168.9.86</span><br><span class="line">ssh-copy-id root@192.168.9.87</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成密钥</span></span><br><span class="line">[root@ceph-node-0 ~]# ssh-keygen -f $HOME/.ssh/id_rsa -t rsa -N &#x27;&#x27;</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:/h4qNJIck6K4nCWwBLXPvJKPPu/m/opjBVb31rFgABA root@ceph-node-0</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">| .Eo....         |</span><br><span class="line">|.  .. . o .      |</span><br><span class="line">|. .. o o o o     |</span><br><span class="line">|..+++   o o      |</span><br><span class="line">|++ +++ .S        |</span><br><span class="line">|+. o=.o.         |</span><br><span class="line">|..*..o .. .      |</span><br><span class="line">|.o+=. .  o .     |</span><br><span class="line">| o+OBo....o      |</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制密钥</span></span><br><span class="line">[root@ceph-node-0 ~]# ssh-copy-id root@192.168.9.85</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;</span><br><span class="line">The authenticity of host &#x27;192.168.9.85 (192.168.9.85)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:/0HffAhG/oTriuqo7KjAdf/YQNoFSbwYk/SAVUYH6Fs.</span><br><span class="line">ECDSA key fingerprint is MD5:34:67:af:a6:50:c0:5f:33:07:45:11:e8:b8:52:e2:ae.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@192.168.9.85&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;root@192.168.9.85&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="5-2-Ceph-deploy-安装"><a href="#5-2-Ceph-deploy-安装" class="headerlink" title="5.2 Ceph-deploy 安装"></a>5.2 Ceph-deploy 安装</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装ceph-deploy</span></span><br><span class="line">yum install ceph-deploy -y</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装依赖</span></span><br><span class="line">yum install python-setuptools -y</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 ceph-deploy</span></span><br><span class="line">[root@ceph-node-0 ~]# yum install ceph-deploy -y</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line">epel/x86_64/metalink                                                                       | 6.3 kB  00:00:00     </span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * epel: ftp.iij.ad.jp</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">epel                                                                                       | 4.7 kB  00:00:00     </span><br><span class="line">(1/3): epel/x86_64/group_gz                                                                |  96 kB  00:00:00     </span><br><span class="line">(2/3): epel/x86_64/updateinfo                                                              | 1.0 MB  00:00:03     </span><br><span class="line">(3/3): epel/x86_64/primary_db                                                              | 7.0 MB  00:00:34     </span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ceph-deploy.noarch 0:2.0.1-0 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">==================================================================================================================</span><br><span class="line"> Package                      Arch                    Version                  Repository                    Size</span><br><span class="line">==================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ceph-deploy                  noarch                  2.0.1-0                  Ceph-noarch                  286 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==================================================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 286 k</span><br><span class="line">Installed size: 1.2 M</span><br><span class="line">Downloading packages:</span><br><span class="line">warning: /var/cache/yum/x86_64/7/Ceph-noarch/packages/ceph-deploy-2.0.1-0.noarch.rpm: Header V4 RSA/SHA256 Signature, key ID 460f3994: NOKEY</span><br><span class="line">Public key for ceph-deploy-2.0.1-0.noarch.rpm is not installed</span><br><span class="line">ceph-deploy-2.0.1-0.noarch.rpm                                                             | 286 kB  00:00:01     </span><br><span class="line">Retrieving key from https://download.ceph.com/keys/release.asc</span><br><span class="line">Importing GPG key 0x460F3994:</span><br><span class="line"> Userid     : &quot;Ceph.com (release key) &lt;security@ceph.com&gt;&quot;</span><br><span class="line"> Fingerprint: 08b7 3419 ac32 b4e9 66c1 a330 e84a c2c0 460f 3994</span><br><span class="line"> From       : https://download.ceph.com/keys/release.asc</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ceph-deploy-2.0.1-0.noarch                                                                     1/1 </span><br><span class="line">  Verifying  : ceph-deploy-2.0.1-0.noarch                                                                     1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ceph-deploy.noarch 0:2.0.1-0                                                                                    </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 python-setuptools</span></span><br><span class="line">[root@localhost ~]# yum install python-setuptools -y</span><br><span class="line">Loaded plugins: fastestmirror, priorities</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * epel: ftp.iij.ad.jp</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package python-setuptools.noarch 0:0.9.8-7.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: python-backports-ssl_match_hostname <span class="keyword">for</span> package: python-setuptools-0.9.8-7.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package python-backports-ssl_match_hostname.noarch 0:3.5.0.1-1.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: python-ipaddress <span class="keyword">for</span> package: python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: python-backports <span class="keyword">for</span> package: python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package python-backports.x86_64 0:1.0-8.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package python-ipaddress.noarch 0:1.0.16-2.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">==================================================================================================================</span><br><span class="line"> Package                                        Arch              Version                   Repository       Size</span><br><span class="line">==================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> python-setuptools                              noarch            0.9.8-7.el7               base            397 k</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> python-backports                               x86_64            1.0-8.el7                 base            5.8 k</span><br><span class="line"> python-backports-ssl_match_hostname            noarch            3.5.0.1-1.el7             base             13 k</span><br><span class="line"> python-ipaddress                               noarch            1.0.16-2.el7              base             34 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==================================================================================================================</span><br><span class="line">Install  1 Package (+3 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 450 k</span><br><span class="line">Installed size: 2.2 M</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/4): python-backports-1.0-8.el7.x86_64.rpm                                               | 5.8 kB  00:00:00     </span><br><span class="line">(2/4): python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch.rpm                        |  13 kB  00:00:00     </span><br><span class="line">(3/4): python-ipaddress-1.0.16-2.el7.noarch.rpm                                            |  34 kB  00:00:00     </span><br><span class="line">(4/4): python-setuptools-0.9.8-7.el7.noarch.rpm                                            | 397 kB  00:00:00     </span><br><span class="line">------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                             1.4 MB/s | 450 kB  00:00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : python-backports-1.0-8.el7.x86_64                                                              1/4 </span><br><span class="line">  Installing : python-ipaddress-1.0.16-2.el7.noarch                                                           2/4 </span><br><span class="line">  Installing : python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch                                       3/4 </span><br><span class="line">  Installing : python-setuptools-0.9.8-7.el7.noarch                                                           4/4 </span><br><span class="line">  Verifying  : python-ipaddress-1.0.16-2.el7.noarch                                                           1/4 </span><br><span class="line">  Verifying  : python-setuptools-0.9.8-7.el7.noarch                                                           2/4 </span><br><span class="line">  Verifying  : python-backports-ssl_match_hostname-3.5.0.1-1.el7.noarch                                       3/4 </span><br><span class="line">  Verifying  : python-backports-1.0-8.el7.x86_64                                                              4/4 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  python-setuptools.noarch 0:0.9.8-7.el7                                                                          </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  python-backports.x86_64 0:1.0-8.el7           python-backports-ssl_match_hostname.noarch 0:3.5.0.1-1.el7       </span><br><span class="line">  python-ipaddress.noarch 0:1.0.16-2.el7       </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure><h2 id="6-创建-Ceph-存储集群"><a href="#6-创建-Ceph-存储集群" class="headerlink" title="6. 创建 Ceph 存储集群"></a>6. 创建 Ceph 存储集群</h2><p><strong>如无特殊说明，本节所有操作都在 ceph-node-0 节点执行</strong></p><h3 id="6-1-创建集群配置目录"><a href="#6-1-创建集群配置目录" class="headerlink" title="6.1. 创建集群配置目录"></a>6.1. 创建集群配置目录</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir k8s-cluster</span><br><span class="line">cd k8s-cluster</span><br></pre></td></tr></table></figure><h3 id="6-2-初始化-Ceph-集群"><a href="#6-2-初始化-Ceph-集群" class="headerlink" title="6.2. 初始化 Ceph 集群"></a>6.2. 初始化 Ceph 集群</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><ul><li>创建集群</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy new ceph-node-0</span><br></pre></td></tr></table></figure><ul><li>添加配置项到配置文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可选添加，如果不加，后续再添加新的mon节点会报错</span></span><br><span class="line">echo &quot;public network = 192.168.9.0/24&quot; &gt;&gt; ceph.conf</span><br></pre></td></tr></table></figure><ul><li>安装软件包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">官方的正常命令是</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ceph-deploy install ceph-node-0 ceph-node-1 ceph-node-2</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">但是这种方式最多能安装到 nautilus 版，所以需要采用手工安装的方式</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在Ansible控制服务器上批量手工安装</span></span><br><span class="line"></span><br><span class="line">ansible ceph -m shell -a &#x27;yum install -y yum-plugin-priorities&#x27;</span><br><span class="line">ansible ceph -m shell -a &#x27;yum install -y ceph&#x27;</span><br></pre></td></tr></table></figure><ul><li>部署初始 monitor 服务</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mon create-initial</span><br></pre></td></tr></table></figure><ul><li>复制配置文件和 admin key 到其他节点</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy admin ceph-node-0 ceph-node-1 ceph-node-2</span><br></pre></td></tr></table></figure><ul><li>部署 manager daemon(可选)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mgr create ceph-node-0</span><br></pre></td></tr></table></figure><ul><li>创建 OSD</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy osd create --data /dev/sdb ceph-node-0</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph-node-1</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph-node-2</span><br></pre></td></tr></table></figure><ul><li>验证集群状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br><span class="line">ceph health</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">health 有WARN信息如下</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph health</span><br><span class="line">HEALTH_WARN mon is allowing insecure global_id reclaim; Module &#x27;restful&#x27; has failed dependency: No module named &#x27;pecan&#x27;</span><br></pre></td></tr></table></figure><ul><li>解决 ceph health WARN 问题</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mon is allowing insecure global_id reclaim</span> </span><br><span class="line">ceph config set mon auth_allow_insecure_global_id_reclaim false</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Module <span class="string">&#x27;restful&#x27;</span> has failed dependency: No module named <span class="string">&#x27;pecan&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">三个 Ceph 节点都要执行(可以使用Ansible批量执行)</span></span><br><span class="line">pip3 install werkzeug pecan</span><br><span class="line">systemctl restart ceph-mon.target</span><br><span class="line">systemctl restart ceph-mgr.target</span><br></pre></td></tr></table></figure><ul><li>再次验证集群状态</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建集群</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy new ceph-node-0</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy new ceph-node-0</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function new at 0x7f93b59dede8&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f93b51585a8&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ssh_copykey                   : True</span><br><span class="line">[ceph_deploy.cli][INFO  ]  mon                           : [&#x27;ceph-node-0&#x27;]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  public_network                : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster_network               : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  fsid                          : None</span><br><span class="line">[ceph_deploy.new][DEBUG ] Creating new cluster named ceph</span><br><span class="line">[ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/sbin/ip link show</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/sbin/ip addr show</span><br><span class="line">[ceph-node-0][DEBUG ] IP addresses found: [u&#x27;192.168.9.85&#x27;]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Resolving host ceph-node-0</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor ceph-node-0 at 192.168.9.85</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor initial members are [&#x27;ceph-node-0&#x27;]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Monitor addrs are [&#x27;192.168.9.85&#x27;]</span><br><span class="line">[ceph_deploy.new][DEBUG ] Creating a random mon key...</span><br><span class="line">[ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...</span><br><span class="line">[ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署初始monitor服务</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy mon create-initial</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy mon create-initial</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : create-initial</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe0d4570e18&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x7fe0d4555410&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  keyrings                      : None</span><br><span class="line">[ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts ceph-node-0</span><br><span class="line">[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-node-0 ...</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.9.2009 Core</span><br><span class="line">[ceph-node-0][DEBUG ] determining if provided host has same hostname in remote</span><br><span class="line">[ceph-node-0][DEBUG ] get remote short hostname</span><br><span class="line">[ceph-node-0][DEBUG ] deploying mon to ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] get remote short hostname</span><br><span class="line">[ceph-node-0][DEBUG ] remote hostname: ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph-node-0][DEBUG ] create the mon path if it does not exist</span><br><span class="line">[ceph-node-0][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-node-0/done</span><br><span class="line">[ceph-node-0][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph-node-0/done</span><br><span class="line">[ceph-node-0][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph-node-0.mon.keyring</span><br><span class="line">[ceph-node-0][DEBUG ] create the monitor keyring file</span><br><span class="line">[ceph-node-0][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph-node-0 --keyring /var/lib/ceph/tmp/ceph-ceph-node-0.mon.keyring --setuser 167 --setgroup 167</span><br><span class="line">[ceph-node-0][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph-node-0.mon.keyring</span><br><span class="line">[ceph-node-0][DEBUG ] create a done file to avoid re-doing the mon deployment</span><br><span class="line">[ceph-node-0][DEBUG ] create the init path if it does not exist</span><br><span class="line">[ceph-node-0][INFO  ] Running command: systemctl enable ceph.target</span><br><span class="line">[ceph-node-0][INFO  ] Running command: systemctl enable ceph-mon@ceph-node-0</span><br><span class="line">[ceph-node-0][WARNIN] Created symlink from /etc/systemd/system/ceph-mon.target.wants/ceph-mon@ceph-node-0.service to /usr/lib/systemd/system/ceph-mon@.service.</span><br><span class="line">[ceph-node-0][INFO  ] Running command: systemctl start ceph-mon@ceph-node-0</span><br><span class="line">[ceph-node-0][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-node-0.asok mon_status</span><br><span class="line">[ceph-node-0][DEBUG ] ********************************************************************************</span><br><span class="line">[ceph-node-0][DEBUG ] status for monitor: mon.ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;election_epoch&quot;: 3, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;extra_probe_peers&quot;: [], </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;feature_map&quot;: &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;mon&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]       &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;features&quot;: &quot;0x3f01cfb8ffedffff&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;num&quot;: 1, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;</span><br><span class="line">[ceph-node-0][DEBUG ]       &#125;</span><br><span class="line">[ceph-node-0][DEBUG ]     ]</span><br><span class="line">[ceph-node-0][DEBUG ]   &#125;, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;features&quot;: &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;quorum_con&quot;: &quot;4540138292840890367&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;quorum_mon&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;kraken&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;luminous&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;mimic&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;osdmap-prune&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;nautilus&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;octopus&quot;</span><br><span class="line">[ceph-node-0][DEBUG ]     ], </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;required_con&quot;: &quot;2449958747315978244&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;required_mon&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;kraken&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;luminous&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;mimic&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;osdmap-prune&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;nautilus&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;octopus&quot;</span><br><span class="line">[ceph-node-0][DEBUG ]     ]</span><br><span class="line">[ceph-node-0][DEBUG ]   &#125;, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;monmap&quot;: &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;created&quot;: &quot;2022-05-24T03:18:55.637040Z&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;epoch&quot;: 1, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;features&quot;: &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;optional&quot;: [], </span><br><span class="line">[ceph-node-0][DEBUG ]       &quot;persistent&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;kraken&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;luminous&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;mimic&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;osdmap-prune&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;nautilus&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;octopus&quot;</span><br><span class="line">[ceph-node-0][DEBUG ]       ]</span><br><span class="line">[ceph-node-0][DEBUG ]     &#125;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;fsid&quot;: &quot;a614e796-6875-4134-a735-2e4db541bba8&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;min_mon_release&quot;: 15, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;min_mon_release_name&quot;: &quot;octopus&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;modified&quot;: &quot;2022-05-24T03:18:55.637040Z&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]     &quot;mons&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]       &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;addr&quot;: &quot;192.168.9.85:6789/0&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;name&quot;: &quot;ceph-node-0&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;priority&quot;: 0, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.9.85:6789/0&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;public_addrs&quot;: &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]           &quot;addrvec&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]             &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]               &quot;addr&quot;: &quot;192.168.9.85:3300&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]               &quot;nonce&quot;: 0, </span><br><span class="line">[ceph-node-0][DEBUG ]               &quot;type&quot;: &quot;v2&quot;</span><br><span class="line">[ceph-node-0][DEBUG ]             &#125;, </span><br><span class="line">[ceph-node-0][DEBUG ]             &#123;</span><br><span class="line">[ceph-node-0][DEBUG ]               &quot;addr&quot;: &quot;192.168.9.85:6789&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]               &quot;nonce&quot;: 0, </span><br><span class="line">[ceph-node-0][DEBUG ]               &quot;type&quot;: &quot;v1&quot;</span><br><span class="line">[ceph-node-0][DEBUG ]             &#125;</span><br><span class="line">[ceph-node-0][DEBUG ]           ]</span><br><span class="line">[ceph-node-0][DEBUG ]         &#125;, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;rank&quot;: 0, </span><br><span class="line">[ceph-node-0][DEBUG ]         &quot;weight&quot;: 0</span><br><span class="line">[ceph-node-0][DEBUG ]       &#125;</span><br><span class="line">[ceph-node-0][DEBUG ]     ]</span><br><span class="line">[ceph-node-0][DEBUG ]   &#125;, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;name&quot;: &quot;ceph-node-0&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;outside_quorum&quot;: [], </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;quorum&quot;: [</span><br><span class="line">[ceph-node-0][DEBUG ]     0</span><br><span class="line">[ceph-node-0][DEBUG ]   ], </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;quorum_age&quot;: 2, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;rank&quot;: 0, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;state&quot;: &quot;leader&quot;, </span><br><span class="line">[ceph-node-0][DEBUG ]   &quot;sync_provider&quot;: []</span><br><span class="line">[ceph-node-0][DEBUG ] &#125;</span><br><span class="line">[ceph-node-0][DEBUG ] ********************************************************************************</span><br><span class="line">[ceph-node-0][INFO  ] monitor: mon.ceph-node-0 is running</span><br><span class="line">[ceph-node-0][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-node-0.asok mon_status</span><br><span class="line">[ceph_deploy.mon][INFO  ] processing monitor mon.ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph-node-0][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-node-0.asok mon_status</span><br><span class="line">[ceph_deploy.mon][INFO  ] mon.ceph-node-0 monitor has reached quorum!</span><br><span class="line">[ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum</span><br><span class="line">[ceph_deploy.mon][INFO  ] Running gatherkeys...</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpWITFug</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-0][DEBUG ] get remote short hostname</span><br><span class="line">[ceph-node-0][DEBUG ] fetch remote file</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.ceph-node-0.asok mon_status</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-node-0/keyring auth get client.admin</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-node-0/keyring auth get client.bootstrap-mds</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-node-0/keyring auth get client.bootstrap-mgr</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-node-0/keyring auth get client.bootstrap-osd</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-ceph-node-0/keyring auth get client.bootstrap-rgw</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] keyring &#x27;ceph.mon.keyring&#x27; already exists</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring</span><br><span class="line">[ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpWITFug</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署初始monitor服务</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy admin ceph-node-0 ceph-node-1 ceph-node-2</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy admin ceph-node-0 ceph-node-1 ceph-node-2</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1f54cca440&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  client                        : [&#x27;ceph-node-0&#x27;, &#x27;ceph-node-1&#x27;, &#x27;ceph-node-2&#x27;]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function admin at 0x7f1f557e9230&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-0][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node-1</span><br><span class="line">The authenticity of host &#x27;ceph-node-1 (192.168.9.86)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:/0HffAhG/oTriuqo7KjAdf/YQNoFSbwYk/SAVUYH6Fs.</span><br><span class="line">ECDSA key fingerprint is MD5:34:67:af:a6:50:c0:5f:33:07:45:11:e8:b8:52:e2:ae.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added &#x27;ceph-node-1&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">[ceph-node-1][DEBUG ] connected to host: ceph-node-1 </span><br><span class="line">[ceph-node-1][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-1][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-1][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node-2</span><br><span class="line">The authenticity of host &#x27;ceph-node-2 (192.168.9.87)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:/0HffAhG/oTriuqo7KjAdf/YQNoFSbwYk/SAVUYH6Fs.</span><br><span class="line">ECDSA key fingerprint is MD5:34:67:af:a6:50:c0:5f:33:07:45:11:e8:b8:52:e2:ae.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added &#x27;ceph-node-2&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">[ceph-node-2][DEBUG ] connected to host: ceph-node-2 </span><br><span class="line">[ceph-node-2][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-2][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-2][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署manager daemon</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy mgr create ceph-node-0</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy mgr create ceph-node-0</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  mgr                           : [(&#x27;ceph-node-0&#x27;, &#x27;ceph-node-0&#x27;)]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : create</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f39544c3998&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function mgr at 0x7f3954d35140&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-node-0:ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph_deploy.mgr][INFO  ] Distro info: CentOS Linux 7.9.2009 Core</span><br><span class="line">[ceph_deploy.mgr][DEBUG ] remote host will use systemd</span><br><span class="line">[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph-node-0][WARNIN] mgr keyring does not exist yet, creating one</span><br><span class="line">[ceph-node-0][DEBUG ] create a keyring file</span><br><span class="line">[ceph-node-0][DEBUG ] create path recursively if it doesn&#x27;t exist</span><br><span class="line">[ceph-node-0][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.ceph-node-0 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-ceph-node-0/keyring</span><br><span class="line">[ceph-node-0][INFO  ] Running command: systemctl enable ceph-mgr@ceph-node-0</span><br><span class="line">[ceph-node-0][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@ceph-node-0.service to /usr/lib/systemd/system/ceph-mgr@.service.</span><br><span class="line">[ceph-node-0][INFO  ] Running command: systemctl start ceph-mgr@ceph-node-0</span><br><span class="line">[ceph-node-0][INFO  ] Running command: systemctl enable ceph.target</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建OSD</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy osd create --data /dev/sdb ceph-node-0</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy osd create --data /dev/sdb ceph-node-0</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  bluestore                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb25a9cbf38&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  fs_type                       : xfs</span><br><span class="line">[ceph_deploy.cli][INFO  ]  block_wal                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  journal                       : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : create</span><br><span class="line">[ceph_deploy.cli][INFO  ]  host                          : ceph-node-0</span><br><span class="line">[ceph_deploy.cli][INFO  ]  filestore                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function osd at 0x7fb25a98d8c0&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  zap_disk                      : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  data                          : /dev/sdb</span><br><span class="line">[ceph_deploy.cli][INFO  ]  block_db                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  dmcrypt                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  debug                         : False</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Creating OSD on cluster ceph with data device /dev/sdb</span><br><span class="line">[ceph-node-0][DEBUG ] connected to host: ceph-node-0 </span><br><span class="line">[ceph-node-0][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-0][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph_deploy.osd][INFO  ] Distro info: CentOS Linux 7.9.2009 Core</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Deploying osd to ceph-node-0</span><br><span class="line">[ceph-node-0][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph-node-0][WARNIN] osd keyring does not exist yet, creating one</span><br><span class="line">[ceph-node-0][DEBUG ] create a keyring file</span><br><span class="line">[ceph-node-0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /usr/sbin/ceph-volume --cluster ceph lvm create --bluestore --data /dev/sdb</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph-authtool --gen-print-key</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring -i - osd new a8238416-bd31-466f-b3ac-d10f497bd323</span><br><span class="line">[ceph-node-0][WARNIN] Running command: vgcreate --force --yes ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b /dev/sdb</span><br><span class="line">[ceph-node-0][WARNIN]  stdout: Physical volume &quot;/dev/sdb&quot; successfully created.</span><br><span class="line">[ceph-node-0][WARNIN]  stdout: Volume group &quot;ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b&quot; successfully created</span><br><span class="line">[ceph-node-0][WARNIN] Running command: lvcreate --yes -l 25599 -n osd-block-a8238416-bd31-466f-b3ac-d10f497bd323 ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b</span><br><span class="line">[ceph-node-0][WARNIN]  stdout: Logical volume &quot;osd-block-a8238416-bd31-466f-b3ac-d10f497bd323&quot; created.</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph-authtool --gen-print-key</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/mount -t tmpfs tmpfs /var/lib/ceph/osd/ceph-0</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -h ceph:ceph /dev/ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b/osd-block-a8238416-bd31-466f-b3ac-d10f497bd323</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /dev/dm-2</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ln -s /dev/ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b/osd-block-a8238416-bd31-466f-b3ac-d10f497bd323 /var/lib/ceph/osd/ceph-0/block</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /var/lib/ceph/osd/ceph-0/activate.monmap</span><br><span class="line">[ceph-node-0][WARNIN]  stderr: 2022-05-24T13:34:17.775+0800 7f1b743d4700 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.bootstrap-osd.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory</span><br><span class="line">[ceph-node-0][WARNIN] 2022-05-24T13:34:17.775+0800 7f1b743d4700 -1 AuthRegistry(0x7f1b6c0592f0) no keyring found at /etc/ceph/ceph.client.bootstrap-osd.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,, disabling cephx</span><br><span class="line">[ceph-node-0][WARNIN]  stderr: got monmap epoch 1</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph-authtool /var/lib/ceph/osd/ceph-0/keyring --create-keyring --name osd.0 --add-key AQBYboxi1LjtCRAAp+JD29cGvks4UNQftMqYCQ==</span><br><span class="line">[ceph-node-0][WARNIN]  stdout: creating /var/lib/ceph/osd/ceph-0/keyring</span><br><span class="line">[ceph-node-0][WARNIN] added entity osd.0 auth(key=AQBYboxi1LjtCRAAp+JD29cGvks4UNQftMqYCQ==)</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0/keyring</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0/</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph-osd --cluster ceph --osd-objectstore bluestore --mkfs -i 0 --monmap /var/lib/ceph/osd/ceph-0/activate.monmap --keyfile - --osd-data /var/lib/ceph/osd/ceph-0/ --osd-uuid a8238416-bd31-466f-b3ac-d10f497bd323 --setuser ceph --setgroup ceph</span><br><span class="line">[ceph-node-0][WARNIN]  stderr: 2022-05-24T13:34:19.048+0800 7f13c3f1cbc0 -1 bluestore(/var/lib/ceph/osd/ceph-0/) _read_fsid unparsable uuid</span><br><span class="line">[ceph-node-0][WARNIN]  stderr: 2022-05-24T13:34:19.108+0800 7f13c3f1cbc0 -1 freelist read_size_meta_from_db missing size meta in DB</span><br><span class="line">[ceph-node-0][WARNIN] --&gt; ceph-volume lvm prepare successful for: /dev/sdb</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ceph-bluestore-tool --cluster=ceph prime-osd-dir --dev /dev/ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b/osd-block-a8238416-bd31-466f-b3ac-d10f497bd323 --path /var/lib/ceph/osd/ceph-0 --no-mon-config</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/ln -snf /dev/ceph-9c8b5a7b-eb15-4737-9df4-48fcfd00d95b/osd-block-a8238416-bd31-466f-b3ac-d10f497bd323 /var/lib/ceph/osd/ceph-0/block</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -h ceph:ceph /var/lib/ceph/osd/ceph-0/block</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /dev/dm-2</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/systemctl enable ceph-volume@lvm-0-a8238416-bd31-466f-b3ac-d10f497bd323</span><br><span class="line">[ceph-node-0][WARNIN]  stderr: Created symlink from /etc/systemd/system/multi-user.target.wants/ceph-volume@lvm-0-a8238416-bd31-466f-b3ac-d10f497bd323.service to /usr/lib/systemd/system/ceph-volume@.service.</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/systemctl enable --runtime ceph-osd@0</span><br><span class="line">[ceph-node-0][WARNIN]  stderr: Created symlink from /run/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /usr/lib/systemd/system/ceph-osd@.service.</span><br><span class="line">[ceph-node-0][WARNIN] Running command: /usr/bin/systemctl start ceph-osd@0</span><br><span class="line">[ceph-node-0][WARNIN] --&gt; ceph-volume lvm activate successful for osd ID: 0</span><br><span class="line">[ceph-node-0][WARNIN] --&gt; ceph-volume lvm create successful for: /dev/sdb</span><br><span class="line">[ceph-node-0][INFO  ] checking OSD status...</span><br><span class="line">[ceph-node-0][DEBUG ] find the location of an executable</span><br><span class="line">[ceph-node-0][INFO  ] Running command: /bin/ceph --cluster=ceph osd stat --format=json</span><br><span class="line">[ceph_deploy.osd][DEBUG ] Host ceph-node-0 is now ready for osd use.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证集群状态</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph health</span><br><span class="line">HEALTH_WARN mon is allowing insecure global_id reclaim; Module &#x27;restful&#x27; has failed dependency: No module named &#x27;pecan&#x27;</span><br><span class="line"></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     a614e796-6875-4134-a735-2e4db541bba8</span><br><span class="line">    health: HEALTH_WARN</span><br><span class="line">            mon is allowing insecure global_id reclaim</span><br><span class="line">            Module &#x27;restful&#x27; has failed dependency: No module named &#x27;pecan&#x27;</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum ceph-node-0 (age 2h)</span><br><span class="line">    mgr: ceph-node-0(active, since 2h)</span><br><span class="line">    osd: 3 osds: 3 up (since 4m), 3 in (since 4m)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 0 objects, 0 B</span><br><span class="line">    usage:   3.0 GiB used, 297 GiB / 300 GiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">解决ceph health WARN问题</span></span><br><span class="line"> [root@ceph-node-0 k8s-cluster]# pip3 install werkzeug pecan</span><br><span class="line">WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead.</span><br><span class="line">Collecting werkzeug</span><br><span class="line">  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by &#x27;NewConnectionError(&#x27;&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6053068898&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable&#x27;,)&#x27;: /simple/werkzeug/</span><br><span class="line">  Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by &#x27;NewConnectionError(&#x27;&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6053068748&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable&#x27;,)&#x27;: /simple/werkzeug/</span><br><span class="line">  Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by &#x27;NewConnectionError(&#x27;&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f60530686a0&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable&#x27;,)&#x27;: /simple/werkzeug/</span><br><span class="line">  Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by &#x27;NewConnectionError(&#x27;&lt;pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f6053068b70&gt;: Failed to establish a new connection: [Errno 101] Network is unreachable&#x27;,)&#x27;: /simple/werkzeug/</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/f4/f3/22afbdb20cc4654b10c98043414a14057cd27fdba9d4ae61cea596000ba2/Werkzeug-2.0.3-py3-none-any.whl (289kB)</span><br><span class="line">    100% |████████████████████████████████| 296kB 116kB/s </span><br><span class="line">Collecting pecan</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/2a/cc/d7c9c62b7af117d803ed1441191a2297fd8ee0f4a6fbedaefb46c736ba52/pecan-1.4.1.tar.gz (124kB)</span><br><span class="line">    100% |████████████████████████████████| 133kB 17kB/s </span><br><span class="line">Collecting dataclasses; python_version &lt; &quot;3.7&quot; (from werkzeug)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl</span><br><span class="line">Collecting WebOb&gt;=1.8 (from pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/62/9c/e94a9982e9f31fc35cf46cdc543a6c2c26cb7174635b5fd25b0bbc6a7bc0/WebOb-1.8.7-py2.py3-none-any.whl (114kB)</span><br><span class="line">    100% |████████████████████████████████| 122kB 22kB/s </span><br><span class="line">Collecting Mako&gt;=0.4.0 (from pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/b4/4d/e03d08f16ee10e688bde9016bc80af8b78c7f36a8b37c7194da48f72207e/Mako-1.1.6-py2.py3-none-any.whl (75kB)</span><br><span class="line">    100% |████████████████████████████████| 81kB 58kB/s </span><br><span class="line">Collecting WebTest&gt;=1.3.1 (from pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/41/c7/3897bd62366cb4a50bfb411d37efca9fa33bf07a7c1c22fce8f6ad2664ff/WebTest-3.0.0-py3-none-any.whl</span><br><span class="line">Requirement already satisfied: setuptools in /usr/lib/python3.6/site-packages (from pecan)</span><br><span class="line">Requirement already satisfied: six in /usr/lib/python3.6/site-packages (from pecan)</span><br><span class="line">Collecting logutils&gt;=0.3 (from pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/49/b2/b57450889bf73da26027f8b995fd5fbfab258ec24ef967e4c1892f7cb121/logutils-0.3.5.tar.gz</span><br><span class="line">Collecting MarkupSafe&gt;=0.9.2 (from Mako&gt;=0.4.0-&gt;pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/fc/d6/57f9a97e56447a1e340f8574836d3b636e2c14de304943836bd645fa9c7e/MarkupSafe-2.0.1-cp36-cp36m-manylinux1_x86_64.whl</span><br><span class="line">Collecting beautifulsoup4 (from WebTest&gt;=1.3.1-&gt;pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/9c/d8/909c4089dbe4ade9f9705f143c9f13f065049a9d5e7d34c828aefdd0a97c/beautifulsoup4-4.11.1-py3-none-any.whl (128kB)</span><br><span class="line">    100% |████████████████████████████████| 133kB 9.7kB/s </span><br><span class="line">Collecting waitress&gt;=0.8.5 (from WebTest&gt;=1.3.1-&gt;pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)</span><br><span class="line">    100% |████████████████████████████████| 61kB 10kB/s </span><br><span class="line">Collecting soupsieve&gt;1.2 (from beautifulsoup4-&gt;WebTest&gt;=1.3.1-&gt;pecan)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/16/e3/4ad79882b92617e3a4a0df1960d6bce08edfb637737ac5c3f3ba29022e25/soupsieve-2.3.2.post1-py3-none-any.whl</span><br><span class="line">Installing collected packages: dataclasses, werkzeug, WebOb, MarkupSafe, Mako, soupsieve, beautifulsoup4, waitress, WebTest, logutils, pecan</span><br><span class="line">  Running setup.py install for logutils ... done</span><br><span class="line">  Running setup.py install for pecan ... done</span><br><span class="line">Successfully installed Mako-1.1.6 MarkupSafe-2.0.1 WebOb-1.8.7 WebTest-3.0.0 beautifulsoup4-4.11.1 dataclasses-0.8 logutils-0.3.5 pecan-1.4.1 soupsieve-2.3.2.post1 waitress-2.0.0 werkzeug-2.0.3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次验证，集群状态正常</span></span><br><span class="line">[root@ceph-node-0 k8s-cluster]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     a614e796-6875-4134-a735-2e4db541bba8</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum ceph-node-0 (age 36s)</span><br><span class="line">    mgr: ceph-node-0(active, since 25s)</span><br><span class="line">    osd: 3 osds: 3 up (since 14m), 3 in (since 14m)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 0 objects, 0 B</span><br><span class="line">    usage:   3.0 GiB used, 297 GiB / 300 GiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure><h2 id="7-扩展集群"><a href="#7-扩展集群" class="headerlink" title="7. 扩展集群"></a>7. 扩展集群</h2><h3 id="7-1-添加-MONITORS"><a href="#7-1-添加-MONITORS" class="headerlink" title="7.1. 添加 MONITORS"></a>7.1. 添加 MONITORS</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mon add ceph-node-1</span><br><span class="line">ceph-deploy mon add ceph-node-2</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy mon add ceph-node-1</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy mon add ceph-node-1</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : add</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f718b7c3e18&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  mon                           : [&#x27;ceph-node-1&#x27;]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x7f718b7a8410&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  address                       : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.mon][INFO  ] ensuring configuration of new mon host: ceph-node-1</span><br><span class="line">[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to ceph-node-1</span><br><span class="line">[ceph-node-1][DEBUG ] connected to host: ceph-node-1 </span><br><span class="line">[ceph-node-1][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-1][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-1][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph_deploy.mon][DEBUG ] Adding mon to cluster ceph, host ceph-node-1</span><br><span class="line">[ceph_deploy.mon][DEBUG ] using mon address by resolving host: 192.168.9.86</span><br><span class="line">[ceph_deploy.mon][DEBUG ] detecting platform for host ceph-node-1 ...</span><br><span class="line">[ceph-node-1][DEBUG ] connected to host: ceph-node-1 </span><br><span class="line">[ceph-node-1][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-1][DEBUG ] detect machine type</span><br><span class="line">[ceph-node-1][DEBUG ] find the location of an executable</span><br><span class="line">[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.9.2009 Core</span><br><span class="line">[ceph-node-1][DEBUG ] determining if provided host has same hostname in remote</span><br><span class="line">[ceph-node-1][DEBUG ] get remote short hostname</span><br><span class="line">[ceph-node-1][DEBUG ] adding mon to ceph-node-1</span><br><span class="line">[ceph-node-1][DEBUG ] get remote short hostname</span><br><span class="line">[ceph-node-1][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph-node-1][DEBUG ] create the mon path if it does not exist</span><br><span class="line">[ceph-node-1][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-ceph-node-1/done</span><br><span class="line">[ceph-node-1][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-ceph-node-1/done</span><br><span class="line">[ceph-node-1][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-ceph-node-1.mon.keyring</span><br><span class="line">[ceph-node-1][DEBUG ] create the monitor keyring file</span><br><span class="line">[ceph-node-1][INFO  ] Running command: ceph --cluster ceph mon getmap -o /var/lib/ceph/tmp/ceph.ceph-node-1.monmap</span><br><span class="line">[ceph-node-1][WARNIN] got monmap epoch 1</span><br><span class="line">[ceph-node-1][INFO  ] Running command: ceph-mon --cluster ceph --mkfs -i ceph-node-1 --monmap /var/lib/ceph/tmp/ceph.ceph-node-1.monmap --keyring /var/lib/ceph/tmp/ceph-ceph-node-1.mon.keyring --setuser 167 --setgroup 167</span><br><span class="line">[ceph-node-1][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-ceph-node-1.mon.keyring</span><br><span class="line">[ceph-node-1][DEBUG ] create a done file to avoid re-doing the mon deployment</span><br><span class="line">[ceph-node-1][DEBUG ] create the init path if it does not exist</span><br><span class="line">[ceph-node-1][INFO  ] Running command: systemctl enable ceph.target</span><br><span class="line">[ceph-node-1][INFO  ] Running command: systemctl enable ceph-mon@ceph-node-1</span><br><span class="line">[ceph-node-1][WARNIN] Created symlink from /etc/systemd/system/ceph-mon.target.wants/ceph-mon@ceph-node-1.service to /usr/lib/systemd/system/ceph-mon@.service.</span><br><span class="line">[ceph-node-1][INFO  ] Running command: systemctl start ceph-mon@ceph-node-1</span><br><span class="line">[ceph-node-1][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-node-1.asok mon_status</span><br><span class="line">[ceph-node-1][WARNIN] ceph-node-1 is not defined in `mon initial members`</span><br><span class="line">[ceph-node-1][WARNIN] monitor ceph-node-1 does not exist in monmap</span><br><span class="line">[ceph-node-1][INFO  ] Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph-node-1.asok mon_status</span><br><span class="line">[ceph-node-1][DEBUG ] ********************************************************************************</span><br><span class="line">[ceph-node-1][DEBUG ] status for monitor: mon.ceph-node-1</span><br><span class="line">[ceph-node-1][DEBUG ] &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;election_epoch&quot;: 0, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;extra_probe_peers&quot;: [], </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;feature_map&quot;: &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;mon&quot;: [</span><br><span class="line">[ceph-node-1][DEBUG ]       &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;features&quot;: &quot;0x3f01cfb8ffedffff&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;num&quot;: 1, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;release&quot;: &quot;luminous&quot;</span><br><span class="line">[ceph-node-1][DEBUG ]       &#125;</span><br><span class="line">[ceph-node-1][DEBUG ]     ]</span><br><span class="line">[ceph-node-1][DEBUG ]   &#125;, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;features&quot;: &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;quorum_con&quot;: &quot;0&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;quorum_mon&quot;: [], </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;required_con&quot;: &quot;2449958197560098820&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;required_mon&quot;: [</span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;kraken&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;luminous&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;mimic&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;osdmap-prune&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;nautilus&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;octopus&quot;</span><br><span class="line">[ceph-node-1][DEBUG ]     ]</span><br><span class="line">[ceph-node-1][DEBUG ]   &#125;, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;monmap&quot;: &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;created&quot;: &quot;2022-05-24T03:18:55.637040Z&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;epoch&quot;: 1, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;features&quot;: &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;optional&quot;: [], </span><br><span class="line">[ceph-node-1][DEBUG ]       &quot;persistent&quot;: [</span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;kraken&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;luminous&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;mimic&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;osdmap-prune&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;nautilus&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;octopus&quot;</span><br><span class="line">[ceph-node-1][DEBUG ]       ]</span><br><span class="line">[ceph-node-1][DEBUG ]     &#125;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;fsid&quot;: &quot;a614e796-6875-4134-a735-2e4db541bba8&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;min_mon_release&quot;: 15, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;min_mon_release_name&quot;: &quot;octopus&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;modified&quot;: &quot;2022-05-24T03:18:55.637040Z&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]     &quot;mons&quot;: [</span><br><span class="line">[ceph-node-1][DEBUG ]       &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;addr&quot;: &quot;192.168.9.85:6789/0&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;name&quot;: &quot;ceph-node-0&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;priority&quot;: 0, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;public_addr&quot;: &quot;192.168.9.85:6789/0&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;public_addrs&quot;: &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]           &quot;addrvec&quot;: [</span><br><span class="line">[ceph-node-1][DEBUG ]             &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]               &quot;addr&quot;: &quot;192.168.9.85:3300&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]               &quot;nonce&quot;: 0, </span><br><span class="line">[ceph-node-1][DEBUG ]               &quot;type&quot;: &quot;v2&quot;</span><br><span class="line">[ceph-node-1][DEBUG ]             &#125;, </span><br><span class="line">[ceph-node-1][DEBUG ]             &#123;</span><br><span class="line">[ceph-node-1][DEBUG ]               &quot;addr&quot;: &quot;192.168.9.85:6789&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]               &quot;nonce&quot;: 0, </span><br><span class="line">[ceph-node-1][DEBUG ]               &quot;type&quot;: &quot;v1&quot;</span><br><span class="line">[ceph-node-1][DEBUG ]             &#125;</span><br><span class="line">[ceph-node-1][DEBUG ]           ]</span><br><span class="line">[ceph-node-1][DEBUG ]         &#125;, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;rank&quot;: 0, </span><br><span class="line">[ceph-node-1][DEBUG ]         &quot;weight&quot;: 0</span><br><span class="line">[ceph-node-1][DEBUG ]       &#125;</span><br><span class="line">[ceph-node-1][DEBUG ]     ]</span><br><span class="line">[ceph-node-1][DEBUG ]   &#125;, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;name&quot;: &quot;ceph-node-1&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;outside_quorum&quot;: [], </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;quorum&quot;: [], </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;rank&quot;: -1, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;state&quot;: &quot;probing&quot;, </span><br><span class="line">[ceph-node-1][DEBUG ]   &quot;sync_provider&quot;: []</span><br><span class="line">[ceph-node-1][DEBUG ] &#125;</span><br><span class="line">[ceph-node-1][DEBUG ] ********************************************************************************</span><br><span class="line">[ceph-node-1][INFO  ] monitor: mon.ceph-node-1 is currently at the state of probing</span><br></pre></td></tr></table></figure><h3 id="7-2-添加-MANAGERS"><a href="#7-2-添加-MANAGERS" class="headerlink" title="7.2. 添加  MANAGERS"></a>7.2. 添加  MANAGERS</h3><blockquote><p><strong>执行任务命令</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mgr create ceph-node-1</span><br><span class="line">ceph-deploy mgr create ceph-node-2</span><br></pre></td></tr></table></figure><blockquote><p><strong>正确执行输出参考</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy mgr create ceph-node-1</span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy mgr create ceph-node-1</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  mgr                           : [(&#x27;ceph-node-1&#x27;, &#x27;ceph-node-1&#x27;)]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : create</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe995bef998&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function mgr at 0x7fe996461140&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.mgr][DEBUG ] Deploying mgr, cluster ceph hosts ceph-node-1:ceph-node-1</span><br><span class="line">[ceph-node-1][DEBUG ] connected to host: ceph-node-1 </span><br><span class="line">[ceph-node-1][DEBUG ] detect platform information from remote host</span><br><span class="line">[ceph-node-1][DEBUG ] detect machine type</span><br><span class="line">[ceph_deploy.mgr][INFO  ] Distro info: CentOS Linux 7.9.2009 Core</span><br><span class="line">[ceph_deploy.mgr][DEBUG ] remote host will use systemd</span><br><span class="line">[ceph_deploy.mgr][DEBUG ] deploying mgr bootstrap to ceph-node-1</span><br><span class="line">[ceph-node-1][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line">[ceph-node-1][WARNIN] mgr keyring does not exist yet, creating one</span><br><span class="line">[ceph-node-1][DEBUG ] create a keyring file</span><br><span class="line">[ceph-node-1][DEBUG ] create path recursively if it doesn&#x27;t exist</span><br><span class="line">[ceph-node-1][INFO  ] Running command: ceph --cluster ceph --name client.bootstrap-mgr --keyring /var/lib/ceph/bootstrap-mgr/ceph.keyring auth get-or-create mgr.ceph-node-1 mon allow profile mgr osd allow * mds allow * -o /var/lib/ceph/mgr/ceph-ceph-node-1/keyring</span><br><span class="line">[ceph-node-1][INFO  ] Running command: systemctl enable ceph-mgr@ceph-node-1</span><br><span class="line">[ceph-node-1][WARNIN] Created symlink from /etc/systemd/system/ceph-mgr.target.wants/ceph-mgr@ceph-node-1.service to /usr/lib/systemd/system/ceph-mgr@.service.</span><br><span class="line">[ceph-node-1][INFO  ] Running command: systemctl start ceph-mgr@ceph-node-1</span><br><span class="line">[ceph-node-1][INFO  ] Running command: systemctl enable ceph.target</span><br></pre></td></tr></table></figure><h3 id="7-3-集群状态查看"><a href="#7-3-集群状态查看" class="headerlink" title="7.3. 集群状态查看"></a>7.3. 集群状态查看</h3><blockquote><p><strong>执行任务命令 (含输出)</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     a614e796-6875-4134-a735-2e4db541bba8</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph-node-0,ceph-node-1,ceph-node-2 (age 3m)</span><br><span class="line">    mgr: ceph-node-0(active, since 23m), standbys: ceph-node-2, ceph-node-1</span><br><span class="line">    osd: 3 osds: 3 up (since 37m), 3 in (since 37m)</span><br><span class="line"> </span><br><span class="line">  task status:</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 0 objects, 0 B</span><br><span class="line">    usage:   3.0 GiB used, 297 GiB / 300 GiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure><h2 id="8-常见问题"><a href="#8-常见问题" class="headerlink" title="8. 常见问题"></a>8. 常见问题</h2><h3 id="8-1-报错-No-module-named-pkg-resources"><a href="#8-1-报错-No-module-named-pkg-resources" class="headerlink" title="8.1. 报错 No module named pkg_resources"></a>8.1. 报错 No module named pkg_resources</h3><blockquote><p><strong>报错信息</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy new 192.168.9.65</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/usr/bin/ceph-deploy&quot;, line 18, in &lt;module&gt;</span><br><span class="line">    from ceph_deploy.cli import main</span><br><span class="line">  File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/cli.py&quot;, line 1, in &lt;module&gt;</span><br><span class="line">    import pkg_resources</span><br><span class="line">ImportError: No module named pkg_resources</span><br></pre></td></tr></table></figure><blockquote><p><strong>解决方案</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install python-setuptools</span><br></pre></td></tr></table></figure><h3 id="8-2-报错-ceph-deploy…must-be-a-hostname-not-an-IP"><a href="#8-2-报错-ceph-deploy…must-be-a-hostname-not-an-IP" class="headerlink" title="8.2. 报错 ceph-deploy…must be a hostname not an IP"></a>8.2. 报错 ceph-deploy…must be a hostname not an IP</h3><blockquote><p><strong>报错信息</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-node-0 k8s-cluster]# ceph-deploy new 192.168.9.65</span><br><span class="line">usage: ceph-deploy new [-h] [--no-ssh-copykey] [--fsid FSID]</span><br><span class="line">                       [--cluster-network CLUSTER_NETWORK]</span><br><span class="line">                       [--public-network PUBLIC_NETWORK]</span><br><span class="line">                       MON [MON ...]</span><br><span class="line">ceph-deploy new: error: 192.168.9.65 must be a hostname not an IP</span><br></pre></td></tr></table></figure><blockquote><p><strong>解决方案</strong></p></blockquote><p>Ceph-deploy 部署时不支持节点使用 IP 的形式，必须使用主机名，因此还要注意 &#x2F;etc&#x2F;hosts 配置文件一定要做解析。</p><hr><h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h2><p>本文简单介绍了 Ceph 分布式存储集群常用的安装部署方式，重点详细讲解了通过 Ceph-deploy 部署 Ceph Octopus 的全部过程。</p><p>本文仅适用于学习测试环境，生产环境建议使用 Rook 的方式。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><a href="https://docs.ceph.com/en/octopus/install/ceph-deploy/quick-ceph-deploy/">官网 Ceph 安装过程</a></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-Ceph-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-Ceph-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s-Ceph 安装手记&quot;&gt;</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-GlusterFS 扩容手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-GlusterFS%E6%89%A9%E5%AE%B9%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-GlusterFS%E6%89%A9%E5%AE%B9%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.311Z</published>
    <updated>2023-09-22T01:43:14.132Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-GlusterFS-扩容手记"><a href="#基于-KubeSphere-玩转-k8s-GlusterFS-扩容手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-GlusterFS 扩容手记"></a>基于 KubeSphere 玩转 k8s-GlusterFS 扩容手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文来源于生产环境实际需求，生产环境部署时只挂载了一块 1T 的数据盘，随着业务量的上涨，存储空间分配完毕，需要增加磁盘，因此有了本文。</p><blockquote><p>本文知识量</p></blockquote><ul><li>阅读时长：7 分</li><li>行：800+</li><li>单词：2600+</li><li>字符：35200+</li><li>图片：0 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>Heketi 的常用操作</li><li>利用 Heketi 给 GlusterFS 增加磁盘的方法</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>KubeSphere：<strong>3.2.1</strong></li><li>Kubernetes：<strong>1.21.5</strong></li><li>GlusterFS：<strong>9.5</strong> </li><li>Ansible：<strong>2.8.20</strong></li></ul><h2 id="2-查看现有存储集群信息"><a href="#2-查看现有存储集群信息" class="headerlink" title="2. 查看现有存储集群信息"></a>2. 查看现有存储集群信息</h2><h3 id="2-1-Topology-信息"><a href="#2-1-Topology-信息" class="headerlink" title="2.1. Topology 信息"></a>2.1. Topology 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli topology info</span><br><span class="line"></span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line"></span><br><span class="line">    File:  true</span><br><span class="line">    Block: true</span><br><span class="line"></span><br><span class="line">    Volumes:</span><br><span class="line"></span><br><span class="line">        Name: vol_744e76a230868653857bd44d17ec350c</span><br><span class="line">        Size: 90</span><br><span class="line">        Id: 744e76a230868653857bd44d17ec350c</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Mount: 192.168.9.95:vol_744e76a230868653857bd44d17ec350c</span><br><span class="line">        Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">        Durability Type: replicate</span><br><span class="line">        Replica: 3</span><br><span class="line">        Snapshot: Enabled</span><br><span class="line">        Snapshot Factor: 1.00</span><br><span class="line"></span><br><span class="line">                Bricks:</span><br><span class="line">                        Id: a95e3ef850140a5561b075b9a3cb9728</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_a95e3ef850140a5561b075b9a3cb9728/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">                        Device: 4d81fdb2e784633d56a5dadf74cdb2df</span><br><span class="line"></span><br><span class="line">                        Id: aeec9456e6b171d5f8f839f4fb47dad2</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_aeec9456e6b171d5f8f839f4fb47dad2/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">                        Device: da3a8e59a6667fc54cea25d5f32bdb73</span><br><span class="line"></span><br><span class="line">                        Id: c9a9234da08003a5b23aeba06ed1c39b</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_c9a9234da08003a5b23aeba06ed1c39b/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">                        Device: ad739f5de43e2139d95677cda807a71f</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Name: vol_751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Size: 5</span><br><span class="line">        Id: 751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Mount: 192.168.9.95:vol_751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">        Durability Type: replicate</span><br><span class="line">        Replica: 3</span><br><span class="line">        Snapshot: Enabled</span><br><span class="line">        Snapshot Factor: 1.00</span><br><span class="line"></span><br><span class="line">                Bricks:</span><br><span class="line">                        Id: 2d8465c9a80faf1353b511d0da5651d2</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_2d8465c9a80faf1353b511d0da5651d2/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">                        Device: da3a8e59a6667fc54cea25d5f32bdb73</span><br><span class="line"></span><br><span class="line">                        Id: abb90d3dd295f6ce4b9f559d0592cbef</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_abb90d3dd295f6ce4b9f559d0592cbef/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">                        Device: ad739f5de43e2139d95677cda807a71f</span><br><span class="line"></span><br><span class="line">                        Id: c737738b593a82793e8695572f7cff07</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_c737738b593a82793e8695572f7cff07/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">                        Device: 4d81fdb2e784633d56a5dadf74cdb2df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Nodes:</span><br><span class="line"></span><br><span class="line">        Node Id: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.95</span><br><span class="line">        Storage Hostnames: 192.168.9.95</span><br><span class="line">        Devices:</span><br><span class="line">                Id:4d81fdb2e784633d56a5dadf74cdb2df   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:a95e3ef850140a5561b075b9a3cb9728   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_a95e3ef850140a5561b075b9a3cb9728/brick</span><br><span class="line">                                Id:c737738b593a82793e8695572f7cff07   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_c737738b593a82793e8695572f7cff07/brick</span><br><span class="line"></span><br><span class="line">        Node Id: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.97</span><br><span class="line">        Storage Hostnames: 192.168.9.97</span><br><span class="line">        Devices:</span><br><span class="line">                Id:da3a8e59a6667fc54cea25d5f32bdb73   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:2d8465c9a80faf1353b511d0da5651d2   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_2d8465c9a80faf1353b511d0da5651d2/brick</span><br><span class="line">                                Id:aeec9456e6b171d5f8f839f4fb47dad2   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_aeec9456e6b171d5f8f839f4fb47dad2/brick</span><br><span class="line"></span><br><span class="line">        Node Id: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.96</span><br><span class="line">        Storage Hostnames: 192.168.9.96</span><br><span class="line">        Devices:</span><br><span class="line">                Id:ad739f5de43e2139d95677cda807a71f   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:abb90d3dd295f6ce4b9f559d0592cbef   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_abb90d3dd295f6ce4b9f559d0592cbef/brick</span><br><span class="line">                                Id:c9a9234da08003a5b23aeba06ed1c39b   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_c9a9234da08003a5b23aeba06ed1c39b/brick</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-2-集群信息"><a href="#2-2-集群信息" class="headerlink" title="2.2. 集群信息"></a>2.2. 集群信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli cluster list</span><br><span class="line">Clusters:</span><br><span class="line">Id:94fd8a9991e4d7fd6792d0408d28033f [file][block]</span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli cluster info 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Cluster id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Nodes:</span><br><span class="line">0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">Volumes:</span><br><span class="line">751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">Block: true</span><br><span class="line"></span><br><span class="line">File: true</span><br></pre></td></tr></table></figure><h3 id="2-3-Node-信息"><a href="#2-3-Node-信息" class="headerlink" title="2.3. Node 信息"></a>2.3. Node 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli node list </span><br><span class="line">Id:0ece0d8cc9e3b69dd6d1940107cee0ef     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Id:6a2b14ba0b802a9a0cd6981639a314e2     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Id:7acfa91bd0fd96a2f13aef3ff816a75e     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli node info 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">Node Id: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.95</span><br><span class="line">Storage Hostname: 192.168.9.95</span><br><span class="line">Devices:</span><br><span class="line">Id:4d81fdb2e784633d56a5dadf74cdb2df   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2       </span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli node info 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">Node Id: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.97</span><br><span class="line">Storage Hostname: 192.168.9.97</span><br><span class="line">Devices:</span><br><span class="line">Id:da3a8e59a6667fc54cea25d5f32bdb73   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2       </span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli node info 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">Node Id: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.96</span><br><span class="line">Storage Hostname: 192.168.9.96</span><br><span class="line">Devices:</span><br><span class="line">Id:ad739f5de43e2139d95677cda807a71f   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2</span><br></pre></td></tr></table></figure><h3 id="2-4-VG-信息"><a href="#2-4-VG-信息" class="headerlink" title="2.4. VG 信息"></a>2.4. VG 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# vgs</span><br><span class="line">  VG                                  #PV #LV #SN Attr   VSize   VFree </span><br><span class="line">  centos                                1   2   0 wz--n- &lt;39.00g  4.00m</span><br><span class="line">  vg_4d81fdb2e784633d56a5dadf74cdb2df   1   4   0 wz--n-  99.87g &lt;3.94g</span><br></pre></td></tr></table></figure><h3 id="2-5-LV-信息"><a href="#2-5-LV-信息" class="headerlink" title="2.5. LV 信息"></a>2.5. LV 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# lvs</span><br><span class="line">  LV                                     VG                                  Attr       LSize  Pool                                Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  root                                   centos                              -wi-ao---- 36.99g                                                                                   </span><br><span class="line">  swap                                   centos                              -wi-ao----  2.00g                                                                                   </span><br><span class="line">  brick_a95e3ef850140a5561b075b9a3cb9728 vg_4d81fdb2e784633d56a5dadf74cdb2df Vwi-aotz-- 90.00g tp_a95e3ef850140a5561b075b9a3cb9728        0.29                                   </span><br><span class="line">  brick_c737738b593a82793e8695572f7cff07 vg_4d81fdb2e784633d56a5dadf74cdb2df Vwi-aotz--  5.00g tp_c737738b593a82793e8695572f7cff07        4.38                                   </span><br><span class="line">  tp_a95e3ef850140a5561b075b9a3cb9728    vg_4d81fdb2e784633d56a5dadf74cdb2df twi-aotz-- 90.00g                                            0.29   3.49                            </span><br><span class="line">  tp_c737738b593a82793e8695572f7cff07    vg_4d81fdb2e784633d56a5dadf74cdb2df twi-aotz--  5.00g                                            4.38   10.23  </span><br></pre></td></tr></table></figure><h2 id="3-扩容方案之调整-Topology-配置文件"><a href="#3-扩容方案之调整-Topology-配置文件" class="headerlink" title="3. 扩容方案之调整 Topology 配置文件"></a>3. 扩容方案之调整 Topology 配置文件</h2><ul><li>扩容盘符：&#x2F;dev&#x2F;sdc</li><li>扩容容量：200G</li></ul><h3 id="3-1-现有-topology-json-配置文件"><a href="#3-1-现有-topology-json-配置文件" class="headerlink" title="3.1. 现有 topology.json 配置文件"></a>3.1. 现有 topology.json 配置文件</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;clusters&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;nodes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;node&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;hostnames&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;manage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.95&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;storage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.95&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;zone&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;devices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdb&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;node&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;hostnames&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;manage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.96&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;storage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.96&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;zone&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;devices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdb&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;node&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;hostnames&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;manage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.97&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;storage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.97&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;zone&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;devices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdb&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="3-2-修改-Topology-文件"><a href="#3-2-修改-Topology-文件" class="headerlink" title="3.2. 修改 Topology 文件"></a>3.2. 修改 Topology 文件</h3><p>在每一个 node 的 devices 的配置下面增加 <strong>&#x2F;dev&#x2F;sdc</strong>，注意 <strong>&#x2F;dev&#x2F;sdb</strong> 后面的标点配置。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;clusters&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;nodes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;node&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;hostnames&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;manage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.95&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;storage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.95&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;zone&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;devices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdc&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;node&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;hostnames&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;manage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.96&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;storage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.96&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;zone&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;devices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdc&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;node&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;hostnames&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;manage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.97&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;storage&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                <span class="string">&quot;192.168.9.97&quot;</span></span><br><span class="line">                            <span class="punctuation">]</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;zone&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;devices&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="string">&quot;/dev/sdc&quot;</span></span><br><span class="line">                    <span class="punctuation">]</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="3-3-重新加载-Topology"><a href="#3-3-重新加载-Topology" class="headerlink" title="3.3 重新加载 Topology"></a>3.3 重新加载 Topology</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli topology load --json=/etc/heketi/topology.json </span><br><span class="line">        Found node 192.168.9.95 on cluster 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">                Found device /dev/sdb</span><br><span class="line">                Adding device /dev/sdc ... OK</span><br><span class="line">        Found node 192.168.9.96 on cluster 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">                Found device /dev/sdb</span><br><span class="line">                Adding device /dev/sdc ... OK</span><br><span class="line">        Found node 192.168.9.97 on cluster 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">                Found device /dev/sdb</span><br><span class="line">                Adding device /dev/sdc ... OK</span><br></pre></td></tr></table></figure><h3 id="3-4-查看更新后的-Topology-信息"><a href="#3-4-查看更新后的-Topology-信息" class="headerlink" title="3.4. 查看更新后的 Topology 信息"></a>3.4. 查看更新后的 Topology 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli topology info</span><br><span class="line"></span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line"></span><br><span class="line">    File:  true</span><br><span class="line">    Block: true</span><br><span class="line"></span><br><span class="line">    Volumes:</span><br><span class="line"></span><br><span class="line">        Name: vol_744e76a230868653857bd44d17ec350c</span><br><span class="line">        Size: 90</span><br><span class="line">        Id: 744e76a230868653857bd44d17ec350c</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Mount: 192.168.9.95:vol_744e76a230868653857bd44d17ec350c</span><br><span class="line">        Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">        Durability Type: replicate</span><br><span class="line">        Replica: 3</span><br><span class="line">        Snapshot: Enabled</span><br><span class="line">        Snapshot Factor: 1.00</span><br><span class="line"></span><br><span class="line">                Bricks:</span><br><span class="line">                        Id: a95e3ef850140a5561b075b9a3cb9728</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_a95e3ef850140a5561b075b9a3cb9728/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">                        Device: 4d81fdb2e784633d56a5dadf74cdb2df</span><br><span class="line"></span><br><span class="line">                        Id: aeec9456e6b171d5f8f839f4fb47dad2</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_aeec9456e6b171d5f8f839f4fb47dad2/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">                        Device: da3a8e59a6667fc54cea25d5f32bdb73</span><br><span class="line"></span><br><span class="line">                        Id: c9a9234da08003a5b23aeba06ed1c39b</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_c9a9234da08003a5b23aeba06ed1c39b/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">                        Device: ad739f5de43e2139d95677cda807a71f</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Name: vol_751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Size: 5</span><br><span class="line">        Id: 751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Mount: 192.168.9.95:vol_751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">        Durability Type: replicate</span><br><span class="line">        Replica: 3</span><br><span class="line">        Snapshot: Enabled</span><br><span class="line">        Snapshot Factor: 1.00</span><br><span class="line"></span><br><span class="line">                Bricks:</span><br><span class="line">                        Id: 2d8465c9a80faf1353b511d0da5651d2</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_2d8465c9a80faf1353b511d0da5651d2/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">                        Device: da3a8e59a6667fc54cea25d5f32bdb73</span><br><span class="line"></span><br><span class="line">                        Id: abb90d3dd295f6ce4b9f559d0592cbef</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_abb90d3dd295f6ce4b9f559d0592cbef/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">                        Device: ad739f5de43e2139d95677cda807a71f</span><br><span class="line"></span><br><span class="line">                        Id: c737738b593a82793e8695572f7cff07</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_c737738b593a82793e8695572f7cff07/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">                        Device: 4d81fdb2e784633d56a5dadf74cdb2df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Nodes:</span><br><span class="line"></span><br><span class="line">        Node Id: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.95</span><br><span class="line">        Storage Hostnames: 192.168.9.95</span><br><span class="line">        Devices:</span><br><span class="line">                Id:3401fa3979682be3d6d29b991a9a46bc   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     </span><br><span class="line">                        Bricks:</span><br><span class="line">                Id:4d81fdb2e784633d56a5dadf74cdb2df   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:a95e3ef850140a5561b075b9a3cb9728   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_a95e3ef850140a5561b075b9a3cb9728/brick</span><br><span class="line">                                Id:c737738b593a82793e8695572f7cff07   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_c737738b593a82793e8695572f7cff07/brick</span><br><span class="line"></span><br><span class="line">        Node Id: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.97</span><br><span class="line">        Storage Hostnames: 192.168.9.97</span><br><span class="line">        Devices:</span><br><span class="line">                Id:aa2e7f0cac4c3c4eecb6de2ce3c77165   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     </span><br><span class="line">                        Bricks:</span><br><span class="line">                Id:da3a8e59a6667fc54cea25d5f32bdb73   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:2d8465c9a80faf1353b511d0da5651d2   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_2d8465c9a80faf1353b511d0da5651d2/brick</span><br><span class="line">                                Id:aeec9456e6b171d5f8f839f4fb47dad2   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_aeec9456e6b171d5f8f839f4fb47dad2/brick</span><br><span class="line"></span><br><span class="line">        Node Id: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.96</span><br><span class="line">        Storage Hostnames: 192.168.9.96</span><br><span class="line">        Devices:</span><br><span class="line">                Id:806243bc466118e9eff0d8b08133cafc   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     </span><br><span class="line">                        Bricks:</span><br><span class="line">                Id:ad739f5de43e2139d95677cda807a71f   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:abb90d3dd295f6ce4b9f559d0592cbef   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_abb90d3dd295f6ce4b9f559d0592cbef/brick</span><br><span class="line">                                Id:c9a9234da08003a5b23aeba06ed1c39b   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_c9a9234da08003a5b23aeba06ed1c39b/brick</span><br></pre></td></tr></table></figure><h3 id="3-5-查看更新后的-Node-信息"><a href="#3-5-查看更新后的-Node-信息" class="headerlink" title="3.5. 查看更新后的 Node 信息"></a>3.5. 查看更新后的 Node 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node list</span><br><span class="line">Id:0ece0d8cc9e3b69dd6d1940107cee0ef     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Id:6a2b14ba0b802a9a0cd6981639a314e2     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Id:7acfa91bd0fd96a2f13aef3ff816a75e     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node info 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">Node Id: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.95</span><br><span class="line">Storage Hostname: 192.168.9.95</span><br><span class="line">Devices:</span><br><span class="line">Id:3401fa3979682be3d6d29b991a9a46bc   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     Bricks:0       </span><br><span class="line">Id:4d81fdb2e784633d56a5dadf74cdb2df   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2       </span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node info 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">Node Id: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.97</span><br><span class="line">Storage Hostname: 192.168.9.97</span><br><span class="line">Devices:</span><br><span class="line">Id:aa2e7f0cac4c3c4eecb6de2ce3c77165   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     Bricks:0       </span><br><span class="line">Id:da3a8e59a6667fc54cea25d5f32bdb73   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2       </span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node info 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">Node Id: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.96</span><br><span class="line">Storage Hostname: 192.168.9.96</span><br><span class="line">Devices:</span><br><span class="line">Id:806243bc466118e9eff0d8b08133cafc   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     Bricks:0       </span><br><span class="line">Id:ad739f5de43e2139d95677cda807a71f   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2  </span><br></pre></td></tr></table></figure><h3 id="3-6-查看更新后的-VG-信息"><a href="#3-6-查看更新后的-VG-信息" class="headerlink" title="3.6. 查看更新后的 VG 信息"></a>3.6. 查看更新后的 VG 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# vgs</span><br><span class="line">  VG                                  #PV #LV #SN Attr   VSize   VFree  </span><br><span class="line">  centos                                1   2   0 wz--n- &lt;39.00g   4.00m</span><br><span class="line">  vg_3401fa3979682be3d6d29b991a9a46bc   1   0   0 wz--n- 199.87g 199.87g</span><br><span class="line">  vg_4d81fdb2e784633d56a5dadf74cdb2df   1   4   0 wz--n-  99.87g  &lt;3.94g</span><br></pre></td></tr></table></figure><h2 id="4-扩容方案之-heketi-cli"><a href="#4-扩容方案之-heketi-cli" class="headerlink" title="4. 扩容方案之 heketi cli"></a>4. 扩容方案之 heketi cli</h2><h3 id="4-1-添加-Device"><a href="#4-1-添加-Device" class="headerlink" title="4.1. 添加 Device"></a>4.1. 添加 Device</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli device add --name /dev/sdc --node 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">Device added successfully</span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli device add --name /dev/sdc --node 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">Device added successfully</span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli device add --name /dev/sdc --node 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">Device added successfully</span><br></pre></td></tr></table></figure><h3 id="4-2-查看更新后的-Topology-信息"><a href="#4-2-查看更新后的-Topology-信息" class="headerlink" title="4.2. 查看更新后的 Topology 信息"></a>4.2. 查看更新后的 Topology 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli topology info</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli topology info</span><br><span class="line"></span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line"></span><br><span class="line">    File:  true</span><br><span class="line">    Block: true</span><br><span class="line"></span><br><span class="line">    Volumes:</span><br><span class="line"></span><br><span class="line">        Name: vol_744e76a230868653857bd44d17ec350c</span><br><span class="line">        Size: 90</span><br><span class="line">        Id: 744e76a230868653857bd44d17ec350c</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Mount: 192.168.9.95:vol_744e76a230868653857bd44d17ec350c</span><br><span class="line">        Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">        Durability Type: replicate</span><br><span class="line">        Replica: 3</span><br><span class="line">        Snapshot: Enabled</span><br><span class="line">        Snapshot Factor: 1.00</span><br><span class="line"></span><br><span class="line">                Bricks:</span><br><span class="line">                        Id: a95e3ef850140a5561b075b9a3cb9728</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_a95e3ef850140a5561b075b9a3cb9728/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">                        Device: 4d81fdb2e784633d56a5dadf74cdb2df</span><br><span class="line"></span><br><span class="line">                        Id: aeec9456e6b171d5f8f839f4fb47dad2</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_aeec9456e6b171d5f8f839f4fb47dad2/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">                        Device: da3a8e59a6667fc54cea25d5f32bdb73</span><br><span class="line"></span><br><span class="line">                        Id: c9a9234da08003a5b23aeba06ed1c39b</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_c9a9234da08003a5b23aeba06ed1c39b/brick</span><br><span class="line">                        Size (GiB): 90</span><br><span class="line">                        Node: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">                        Device: ad739f5de43e2139d95677cda807a71f</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Name: vol_751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Size: 5</span><br><span class="line">        Id: 751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Mount: 192.168.9.95:vol_751d2c23c1dd25265a97967aaa7c0a97</span><br><span class="line">        Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">        Durability Type: replicate</span><br><span class="line">        Replica: 3</span><br><span class="line">        Snapshot: Enabled</span><br><span class="line">        Snapshot Factor: 1.00</span><br><span class="line"></span><br><span class="line">                Bricks:</span><br><span class="line">                        Id: 2d8465c9a80faf1353b511d0da5651d2</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_2d8465c9a80faf1353b511d0da5651d2/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">                        Device: da3a8e59a6667fc54cea25d5f32bdb73</span><br><span class="line"></span><br><span class="line">                        Id: abb90d3dd295f6ce4b9f559d0592cbef</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_abb90d3dd295f6ce4b9f559d0592cbef/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">                        Device: ad739f5de43e2139d95677cda807a71f</span><br><span class="line"></span><br><span class="line">                        Id: c737738b593a82793e8695572f7cff07</span><br><span class="line">                        Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_c737738b593a82793e8695572f7cff07/brick</span><br><span class="line">                        Size (GiB): 5</span><br><span class="line">                        Node: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">                        Device: 4d81fdb2e784633d56a5dadf74cdb2df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Nodes:</span><br><span class="line"></span><br><span class="line">        Node Id: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.95</span><br><span class="line">        Storage Hostnames: 192.168.9.95</span><br><span class="line">        Devices:</span><br><span class="line">                Id:4d81fdb2e784633d56a5dadf74cdb2df   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:a95e3ef850140a5561b075b9a3cb9728   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_a95e3ef850140a5561b075b9a3cb9728/brick</span><br><span class="line">                                Id:c737738b593a82793e8695572f7cff07   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_4d81fdb2e784633d56a5dadf74cdb2df/brick_c737738b593a82793e8695572f7cff07/brick</span><br><span class="line">                Id:6f060e69953f5b26fb025c174b535505   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     </span><br><span class="line">                        Bricks:</span><br><span class="line"></span><br><span class="line">        Node Id: 6a2b14ba0b802a9a0cd6981639a314e2</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.97</span><br><span class="line">        Storage Hostnames: 192.168.9.97</span><br><span class="line">        Devices:</span><br><span class="line">                Id:0c1e296976ac6bc2b1dadf58fb36cce3   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     </span><br><span class="line">                        Bricks:</span><br><span class="line">                Id:da3a8e59a6667fc54cea25d5f32bdb73   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:2d8465c9a80faf1353b511d0da5651d2   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_2d8465c9a80faf1353b511d0da5651d2/brick</span><br><span class="line">                                Id:aeec9456e6b171d5f8f839f4fb47dad2   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_da3a8e59a6667fc54cea25d5f32bdb73/brick_aeec9456e6b171d5f8f839f4fb47dad2/brick</span><br><span class="line"></span><br><span class="line">        Node Id: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">        State: online</span><br><span class="line">        Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">        Zone: 1</span><br><span class="line">        Management Hostnames: 192.168.9.96</span><br><span class="line">        Storage Hostnames: 192.168.9.96</span><br><span class="line">        Devices:</span><br><span class="line">                Id:7b1154491d4139e3749a3a4b145fac5c   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     </span><br><span class="line">                        Bricks:</span><br><span class="line">                Id:ad739f5de43e2139d95677cda807a71f   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       </span><br><span class="line">                        Bricks:</span><br><span class="line">                                Id:abb90d3dd295f6ce4b9f559d0592cbef   Size (GiB):5       Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_abb90d3dd295f6ce4b9f559d0592cbef/brick</span><br><span class="line">                                Id:c9a9234da08003a5b23aeba06ed1c39b   Size (GiB):90      Path: /var/lib/heketi/mounts/vg_ad739f5de43e2139d95677cda807a71f/brick_c9a9234da08003a5b23aeba06ed1c39b/brick</span><br></pre></td></tr></table></figure><h3 id="4-3-查看更新后的-Node-信息"><a href="#4-3-查看更新后的-Node-信息" class="headerlink" title="4.3. 查看更新后的 Node 信息"></a>4.3. 查看更新后的 Node 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node info 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">Node Id: 0ece0d8cc9e3b69dd6d1940107cee0ef</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.95</span><br><span class="line">Storage Hostname: 192.168.9.95</span><br><span class="line">Devices:</span><br><span class="line">Id:4d81fdb2e784633d56a5dadf74cdb2df   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2       </span><br><span class="line">Id:6f060e69953f5b26fb025c174b535505   Name:/dev/sdc            State:online    Size (GiB):199     Used (GiB):0       Free (GiB):199     Bricks:0  </span><br></pre></td></tr></table></figure><h3 id="4-4-查看更新后的-VG-信息"><a href="#4-4-查看更新后的-VG-信息" class="headerlink" title="4.4. 查看更新后的 VG 信息"></a>4.4. 查看更新后的 VG 信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# vgs</span><br><span class="line">  VG                                  #PV #LV #SN Attr   VSize   VFree  </span><br><span class="line">  centos                                1   2   0 wz--n- &lt;39.00g   4.00m</span><br><span class="line">  vg_4d81fdb2e784633d56a5dadf74cdb2df   1   4   0 wz--n-  99.87g  &lt;3.94g</span><br><span class="line">  vg_6f060e69953f5b26fb025c174b535505   1   0   0 wz--n- 199.87g 199.87g</span><br></pre></td></tr></table></figure><h3 id="4-5-查看更新后的-LV-信息"><a href="#4-5-查看更新后的-LV-信息" class="headerlink" title="4.5.  查看更新后的 LV 信息"></a>4.5.  查看更新后的 LV 信息</h3><p><strong>自行在 k8s 创建存储卷后再查看</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 heketi]# lvs</span><br><span class="line">  LV                                     VG                                  Attr       LSize  Pool                                Origin Data%  Meta%  Move Log Cpy%Sync Convert</span><br><span class="line">  root                                   centos                              -wi-ao---- 36.99g                                                                                   </span><br><span class="line">  swap                                   centos                              -wi-ao----  2.00g                                                                                   </span><br><span class="line">  brick_a95e3ef850140a5561b075b9a3cb9728 vg_4d81fdb2e784633d56a5dadf74cdb2df Vwi-aotz-- 90.00g tp_a95e3ef850140a5561b075b9a3cb9728        0.29                                   </span><br><span class="line">  brick_c737738b593a82793e8695572f7cff07 vg_4d81fdb2e784633d56a5dadf74cdb2df Vwi-aotz--  5.00g tp_c737738b593a82793e8695572f7cff07        4.38                                   </span><br><span class="line">  tp_a95e3ef850140a5561b075b9a3cb9728    vg_4d81fdb2e784633d56a5dadf74cdb2df twi-aotz-- 90.00g                                            0.29   3.49                            </span><br><span class="line">  tp_c737738b593a82793e8695572f7cff07    vg_4d81fdb2e784633d56a5dadf74cdb2df twi-aotz--  5.00g                                            4.38   10.23                           </span><br><span class="line">  brick_8b2110452f07729db3ecd8064a8c74c3 vg_6f060e69953f5b26fb025c174b535505 Vwi-aotz-- 20.00g tp_8b2110452f07729db3ecd8064a8c74c3        0.68                                   </span><br><span class="line">  tp_8b2110452f07729db3ecd8064a8c74c3    vg_6f060e69953f5b26fb025c174b535505 twi-aotz-- 20.00g                                            0.68   10.07  </span><br></pre></td></tr></table></figure><hr><h2 id="5-其他常用操作"><a href="#5-其他常用操作" class="headerlink" title="5. 其他常用操作"></a>5. 其他常用操作</h2><h3 id="5-1-Device-移除"><a href="#5-1-Device-移除" class="headerlink" title="5.1. Device 移除"></a>5.1. Device 移除</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查找 Node 信息</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node list</span><br><span class="line">Id:0ece0d8cc9e3b69dd6d1940107cee0ef     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Id:6a2b14ba0b802a9a0cd6981639a314e2     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Id:7acfa91bd0fd96a2f13aef3ff816a75e     Cluster:94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 Node ID 获取 Device ID</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli node info 7acfa91bd0fd96a2f13aef3ff816a75e </span><br><span class="line">Node Id: 7acfa91bd0fd96a2f13aef3ff816a75e</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: 94fd8a9991e4d7fd6792d0408d28033f</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: 192.168.9.96</span><br><span class="line">Storage Hostname: 192.168.9.96</span><br><span class="line">Devices:</span><br><span class="line">Id:806243bc466118e9eff0d8b08133cafc   Name:/dev/sdc            State:failed    Size (GiB):199     Used (GiB):0       Free (GiB):199     Bricks:0       </span><br><span class="line">Id:ad739f5de43e2139d95677cda807a71f   Name:/dev/sdb            State:online    Size (GiB):99      Used (GiB):95      Free (GiB):4       Bricks:2       </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Disable Device</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli device disable 806243bc466118e9eff0d8b08133cafc</span><br><span class="line">Device 806243bc466118e9eff0d8b08133cafc is now offline</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Remove Device</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli device remove 806243bc466118e9eff0d8b08133cafc</span><br><span class="line">Device 806243bc466118e9eff0d8b08133cafc is now removed</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Delete Device</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli device delete  806243bc466118e9eff0d8b08133cafc</span><br><span class="line">Device 806243bc466118e9eff0d8b08133cafc deleted</span><br></pre></td></tr></table></figure><hr><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><a href="https://github.com/heketi/heketi/blob/master/docs/admin/maintenance.md">Heketi Github</a></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-GlusterFS-扩容手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-GlusterFS-扩容手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s-G</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-MySQL 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-MySQL%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-MySQL%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.274Z</published>
    <updated>2023-09-22T01:42:58.861Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-MySQL-安装手记"><a href="#基于-KubeSphere-玩转-k8s-MySQL-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-MySQL 安装手记"></a>基于 KubeSphere 玩转 k8s-MySQL 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文实现了 MySQL 数据库在基于 KubeSphere 部署的 Kubernetes 集群上的安装部署，部署方式采用了图形化和手写 YAML 文件两种形式。部署过程涉及的所有 YAML 文件都会使用 Git 进行版本管理，并存放在 Git 仓库中。因此，本文还会涉及 GitOps 的基础操作。</p><p>本文部署的 MySQL 选择了比较保守的 5.7 系列，其他版本可能会有不同。本文的操作仅适用于小规模数据量且对可靠性和性能要求不高的数据库使用场景，例如开发测试环境、例如我生产环境的 Nacos 服务。生产环境或是重要的数据库个人不建议将数据放到 K8S 上，优先采用云服务商提供的 RDS，其次自己利用虚拟机搭建 MySQL 主从或是 Galera Cluster，且一定做好备份方案。</p><p>  <strong>数据库的可靠性、可用性是运维的重中之重，不容忽视，切记！！！</strong></p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：40 分</li><li>行：2646</li><li>单词：15535</li><li>字符：110805</li><li>图片：80 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>单节点 MySQL 在 Kubernetes 上的安装配置</li><li>KubeSphere 图形化部署工作负载</li><li>GitOps 入门</li><li>Git 常用操作</li><li>配置代码如何实现在 GitHub 和 Gitee 保持同步</li><li>MySQL 性能测试基础</li><li>运维思想、思路</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">操作系统</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">CentOS-7.9-x86_64</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">CentOS-7.9-x86_64</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">CentOS-7.9-x86_64</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">CentOS-7.9-x86_64</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">CentOS-7.9-x86_64</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS&#x2F;Elasticsearch</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center"></td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS&#x2F;Elasticsearch</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">CentOS-7.9-x86_64</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS&#x2F;Elasticsearch</td></tr></tbody></table><hr><h2 id="2-MySQL-安装之旅"><a href="#2-MySQL-安装之旅" class="headerlink" title="2. MySQL 安装之旅"></a>2. MySQL 安装之旅</h2><h3 id="2-1-寻找参考文档"><a href="#2-1-寻找参考文档" class="headerlink" title="2.1. 寻找参考文档"></a>2.1. 寻找参考文档</h3><blockquote><p><strong>01-我个人查找参考文档习惯的的寻找路径</strong></p></blockquote><ul><li><strong>官方网站</strong>-精准定位<ul><li>官网有时没有相关文档、或是文档不够详细</li><li>英文文档、阅读困难</li></ul></li><li><strong>搜索关键字</strong>-大海捞针<ul><li>CSDN</li><li>博客园</li><li>某个人博客</li><li>问答网站</li><li>其他</li></ul></li></ul><blockquote><p><strong>02-打开 <a href="https://dev.mysql.com/doc/">MySQL 官方网站</a></strong></p></blockquote><p>选择 <strong>MySQL5.7</strong> 版本的 Reference Manual。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220509141222130.png" alt="image-20220509141222130"></p><p>在 <strong>Installing MySQL on Linux</strong> 章节中，搜寻一番，发现在**<a href="https://dev.mysql.com/doc/refman/5.7/en/linux-installation-docker.html">Deploying MySQL on Linux with Docker</a>**小节下两篇具有参考价值的文档，先去看看。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220509142153500.png" alt="image-20220509142153500"></p><p>浏览完以后你会发现，只是学会了利用 Docker Image 安装 MySQL 的基本方法，细节不上图了。</p><p>虽然官方没有提到如何在 K8S 上部署 MySQL，但是我已经有 Docker 和 K8S 的基础知识了，先不去进行搜索吃别人的了，自己尝试在 K8S 上部署一个单节点的 MySQL。</p><h3 id="2-2-尝试部署单节点-MySQL"><a href="#2-2-尝试部署单节点-MySQL" class="headerlink" title="2.2. 尝试部署单节点 MySQL"></a>2.2. 尝试部署单节点 MySQL</h3><blockquote><p><strong>01-先梳理一下思路，部署一个 MySQL 我们需要准备哪些资源</strong></p></blockquote><ul><li>在 DockerHub 获取 MySQL 镜像。</li><li>查看 MySQL 镜像说明，确定安装初始化参数。</li><li>MySQL 属于有状态服务，所以我们需要定义 StatefulSet 类型的资源。</li><li>编写 StatefulSet 类型的 MySQL 资源定义文件-YAML。</li></ul><blockquote><p><strong>02-查看官方镜像说明，确定初始化参数</strong></p></blockquote><p><strong>如果之前有 Docker 部署 MySQL 的经验，这一步就很简单了，直接把参数配置搬过来就行。</strong> </p><p>打开 <a href="https://hub.docker.com,搜索/">https://hub.docker.com，搜索</a> mysql。</p><p>搜索结果中会有很多的 mysql，我重点关注了两个镜像。</p><ul><li>Docker 官方维护的 <a href="https://hub.docker.com/_/mysql">mysql 仓库</a></li><li>Oracle 的 MySQL 团队维护的 <a href="https://hub.docker.com/r/mysql/mysql-server">mysql 仓库</a></li></ul><p>本次实验我使用了 Docker 官方维护的仓库，进入 MySQL 仓库页面。</p><p>大概浏览一遍，确认了几个必须要配置的地方（确定过程需要经验和技术积累）。</p><ul><li><p>镜像：<strong>mysql:5.7.38</strong></p></li><li><p>root 密码：<strong>MYSQL_ROOT_PASSWORD</strong></p></li><li><p>数据持久化存储目录：**&#x2F;var&#x2F;lib&#x2F;mysql**</p></li></ul><blockquote><p><strong>03-利用 KubeSphere 部署 MySQL(V1 版)</strong></p></blockquote><p>确定了初始化的参数，接下来就开始部署 MySQL。</p><p>按 K8S 常规套路编写资源定义 YAML 文件？NO！我现在是小白，手写配置文件太高端了，还不适合我。</p><p>我们这里投机取巧一下，利用 KubeSphere 的图形化操作一波，这样可以保证部署的一次成功率(还有一个隐藏的好处，先卖个关子)。</p><p>使用<strong>企业空间管理员</strong>权限的账户，登录 KubeSphere 控制台。</p><p><strong>这一步没有使用 admin 用户，采用多租户户形式，模拟真实的生产环境</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-lstack-login.png" alt="kubesphere-lstack-login"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-workspace-lstack.png" alt="kubesphere-workspace-lstack"></p><p>点击<strong>项目</strong>，点击 <strong>lstack</strong> 项目，进入项目的管理页面 (如无特殊说明，后面的很多界面操作都是在该页面完成)。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack.png" alt="kubesphere-projects-lstack"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-overview.png" alt="kubesphere-projects-lstack-overview"></p><p><strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>有状态副本集</strong>，点击<strong>创建</strong>。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets.png" alt="kubesphere-projects-lstack-statefulsets"></p><p>弹出<strong>创建有状态副本集</strong>页面，<strong>基本信息</strong>页，<strong>名称</strong>输入 <strong>mysql</strong>。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-0.png" alt="kubesphere-projects-lstack-statefulsets-mysql-0"></p><p><strong>容器组设置</strong>页。</p><ul><li><strong>容器组副本数量</strong>：1</li><li>点击<strong>添加容器</strong>，镜像搜索栏输入 <strong>mysql:5.7.38</strong></li><li><strong>容器名称</strong>： lstack-mysql</li><li><strong>CPU（Core）资源</strong>：预留 0.5，限制 2</li><li><strong>内存（Mi）</strong>：预留 500i，限制 4000</li><li><strong>端口设置</strong>：协议 TCP，名称 tcp-mysql，容器端口：3306，服务端口 3306</li><li><strong>环境变量</strong>：<ul><li>引用配置字典或保密字典</li><li>创建保密字典，键（MYSQL_ROOT_PASSWORD），值（P@88w0rd）</li></ul></li><li><strong>同步主机时区</strong>：勾选上</li><li>其他未说明的配置采用默认值<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-1.png" alt="kubesphere-projects-lstack-statefulsets-mysql-1"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-2.png" alt="kubesphere-projects-lstack-statefulsets-mysql-2"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-3.png" alt="kubesphere-projects-lstack-statefulsets-mysql-3"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-4.png" alt="kubesphere-projects-lstack-statefulsets-mysql-4"></li></ul><p><strong>创建保密字典</strong>：在<strong>环境变量</strong>选项中，点击<strong>创建保密字典</strong>，按后续图示操作。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-5.png" alt="kubesphere-projects-lstack-statefulsets-mysql-5"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-6.png" alt="kubesphere-projects-lstack-statefulsets-mysql-6"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-7.png" alt="kubesphere-projects-lstack-statefulsets-mysql-7"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-8.png" alt="kubesphere-projects-lstack-statefulsets-mysql-8"></p><p>点击<strong>创建</strong>，返回<strong>容器组设置</strong>页面。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-9.png" alt="kubesphere-projects-lstack-statefulsets-mysql-9"></p><p>按以上信息配置完成后，点击<strong>对号</strong>按钮。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-10.png" alt="kubesphere-projects-lstack-statefulsets-mysql-10"></p><p><strong>容器组设置</strong>完成后，点击<strong>下一步</strong>，进入<strong>存储卷设置</strong>。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-11.png" alt="kubesphere-projects-lstack-statefulsets-mysql-11"></p><p><strong>存储卷设置</strong>-&gt;<strong>存储卷模板</strong>-&gt;<strong>添加存储卷模板</strong>。</p><ul><li>存储卷名称：data<ul><li>这个地方不要多写，系统会自动添加 StatefulSet 的名称作为名称后缀，生成类似 data-mysql-0 命名形式的存储卷</li></ul></li><li>存储类型：glusterfs</li><li>访问模式：ReadWriteOnce</li><li>存储卷容量：5Gi</li><li>挂载路径：读写 &#x2F;var&#x2F;lib&#x2F;mysql<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-12.png" alt="kubesphere-projects-lstack-statefulsets-mysql-12"></li></ul><p>按以上信息配置完成后，点击<strong>对号</strong>按钮。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-13.png" alt="kubesphere-projects-lstack-statefulsets-mysql-13"></p><p><strong>存储卷设置</strong>完成后，点击<strong>下一步</strong>，进入<strong>高级设置</strong>，保持默认值，点击<strong>创建</strong>按钮。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-14.png" alt="kubesphere-projects-lstack-statefulsets-mysql-14"></p><p><strong>创建</strong>成功后，自动返回工作负载页面。第一次创建会去 DockerHub 下载镜像，所以初始显示状态为<strong>更新中</strong>。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-15.png" alt="kubesphere-projects-lstack-statefulsets-mysql-15"></p><p>镜像下载完成并且容器配置正确时，状态变成<strong>运行中</strong>。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-16.png" alt="kubesphere-projects-lstack-statefulsets-mysql-16"></p><p>点击 <strong>mysql</strong>，进入有状态副本集详细页面。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-17.png" alt="kubesphere-projects-lstack-statefulsets-mysql-17"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-18.png" alt="kubesphere-projects-lstack-statefulsets-mysql-18"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-19.png" alt="kubesphere-projects-lstack-statefulsets-mysql-19"></p><p><strong>监控</strong>，可以看到初始启动时的资源使用情况，后续可以根据监控数据调整我们的资源的配置。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-20.png" alt="kubesphere-projects-lstack-statefulsets-mysql-20"></p><p><strong>环境变量</strong>，可以看到我们新增加的 Secret 字典生效了，并且密码是隐藏显示的。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-21.png" alt="kubesphere-projects-lstack-statefulsets-mysql-21"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-22.png" alt="kubesphere-projects-lstack-statefulsets-mysql-22"></p><p>再来看看<strong>容器组</strong>的详细信息，在<strong>资源状态</strong>页面，点击容器组 <strong>mysql-0。</strong><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-23.png" alt="kubesphere-projects-lstack-statefulsets-mysql-23"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-24.png" alt="kubesphere-projects-lstack-statefulsets-mysql-24"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-25.png" alt="kubesphere-projects-lstack-statefulsets-mysql-25"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-26.png" alt="kubesphere-projects-lstack-statefulsets-mysql-26"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-27.png" alt="kubesphere-projects-lstack-statefulsets-mysql-27"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-28.png" alt="kubesphere-projects-lstack-statefulsets-mysql-28"></p><p>再来看看 StatefulSet 对应的服务(Service)，<strong>应用负载</strong>-&gt;<strong>服务</strong>。</p><p>可以看到自动创建了一个 StatefulSet MySQL 对应的有状态服务(Headless)，**mysql-2v7f(mysql)**。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-29.png" alt="kubesphere-projects-lstack-statefulsets-mysql-29"></p><p>点击 **mysql-2v7f(mysql)**，可以查看服务详情。<br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-30.png" alt="kubesphere-projects-lstack-statefulsets-mysql-30"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-31.png" alt="kubesphere-projects-lstack-statefulsets-mysql-31"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-32.png" alt="kubesphere-projects-lstack-statefulsets-mysql-32"></p><p>最后验证一下，我们的 MySQL 服务是否正常(这里只看服务本身，先不测试外部连接)。</p><p><strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>有状态副本集</strong>-&gt;<strong>mysql</strong>-&gt;<strong>容器组</strong>-&gt;<strong>mysql-0</strong>-&gt;<strong>终端。</strong><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-33.png" alt="kubesphere-projects-lstack-statefulsets-mysql-33"><br><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-34.png" alt="image-20220510112902273"></p><p>至此，MySQL 在 K8S 的基本安装就完成了，K8S 集群内的其他应用可以通过 svc 的地址访问 MySQL 服务 (svc 地址就是 <strong>mysql-2v7f.lstack</strong>)，此时名字看着还是很不友好，我们先不用它。</p><h3 id="2-3-MySQL-配置进阶"><a href="#2-3-MySQL-配置进阶" class="headerlink" title="2.3. MySQL 配置进阶"></a>2.3. MySQL 配置进阶</h3><p>上面完成了 MySQL 的基本安装配置。但是，实际使用中我们通常还有如下需求，需要我们对 MySQL 进行配置。</p><blockquote><p><strong>01 开启外部访问</strong></p></blockquote><p>开启外部访问方便管理员操作 MySQL 数据库，也可以满足 K8S 集群之外的服务访问 MySQL 数据库的需求。</p><p>在 KubeSphere 中开启服务的外部访问需要先设置项目网关。</p><p>用项目管理员用户登录控制台。</p><p><strong>工作台</strong>-&gt;<strong>项目</strong>-&gt; 点击<strong>具体的项目</strong>-&gt;<strong>项目设置</strong>-&gt;<strong>网关设置</strong>，点击<strong>开启网关</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-35.png" alt="kubesphere-projects-lstack-statefulsets-mysql-35"></p><p>目前访问模式有 NodePort 和 LoadBalancer，但是 LoadBalancer 只支持公有云提供商云上的负载均衡器，所以我们只能选择 NodePort，点击确定。</p><p><strong>NodePort 模式里会创建一个采用了 nginx-ingress 的 kubesphere-router 的容器组，细节我们会在以后的专文探讨。</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-36.png" alt="kubesphere-projects-lstack-statefulsets-mysql-36"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-37.png" alt="kubesphere-projects-lstack-statefulsets-mysql-37"></p><p>网关设置的细节不在本文深入讨论，后续会有专文探讨。现在，做到这一步就 OK 了。</p><p>接下来创建一个 MySQL 服务用于对外提供服务。</p><p><strong>应用负载</strong>-&gt;-<strong>服务</strong>&gt;<strong>创建</strong>-&gt; 选择<strong>自定义服务</strong>-&gt;<strong>指定工作负载</strong>。</p><p><strong>这里有一个外部服务的选项，那个是基于 Ingress 使用域名访问的，不是目前我们想要的方式。</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-38.png" alt="kubesphere-projects-lstack-statefulsets-mysql-38"></p><p><strong>指定工作负载创建服务-基本信息</strong>。</p><ul><li><strong>名称：</strong>mysql-external</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-39.png" alt="kubesphere-projects-lstack-statefulsets-mysql-39"></p><p><strong>指定工作负载创建服务-服务设置</strong>，点击<strong>指定工作负载</strong>，选择<strong>有状态副本集</strong>-&gt;<strong>mysql</strong>，点击<strong>确定</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-40.png" alt="kubesphere-projects-lstack-statefulsets-mysql-40"></p><p><strong>指定工作负载创建服务-服务设置</strong>，<strong>端口</strong>配置。</p><ul><li><strong>协议：</strong> TCP</li><li><strong>名称：</strong> tcp-mysql-external</li><li><strong>容器端口：</strong> 3306</li><li><strong>服务端口：</strong> 3306</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-41.png" alt="kubesphere-projects-lstack-statefulsets-mysql-41"></p><p><strong>指定工作负载创建服务-高级设置</strong>。</p><ul><li><strong>外部访问：</strong> <strong>访问模式</strong>选择 NodePort</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-42.png" alt="kubesphere-projects-lstack-statefulsets-mysql-42"></p><p>完成所有设置后，点击<strong>创建</strong>，创建成功会自动返回服务列表，在服务列表中可以看到我们新创建的服务 <strong>mysql-external</strong> 及自动分配的外部访问端口号。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-43.png" alt="kubesphere-projects-lstack-statefulsets-mysql-43"></p><p>先用 telnet 命令测试一下，MySQL 服务的连通性，能看到下面的结果就说明 MySQL 已经可以在 K8S 集群外部访问了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# telnet 192.168.9.91 32529</span><br><span class="line">Trying 192.168.9.91...</span><br><span class="line">Connected to 192.168.9.91.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line">EHost &#x27;10.233.117.0&#x27; is not allowed to connect to this MySQL serverConnection closed by foreign host.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">细节！上面的EHost地址是192.168.9.91这个节点在K8S集群内部分配的IP</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# ip add | grep 117 -B 2 -A 1</span><br><span class="line">7: tunl0@NONE: &lt;NOARP,UP,LOWER_UP&gt; mtu 1440 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">    inet 10.233.117.0/32 scope global tunl0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">[root@ks-k8s-master-0 ~]# ip add | grep 91</span><br><span class="line">    inet 192.168.9.91/24 brd 192.168.9.255 scope global noprefixroute ens160</span><br><span class="line">    link/ether c6:d3:91:95:f1:0f brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-自定义 MySQL 配置文件</strong></p></blockquote><p>默认安装的 MySQL 使用的 my.cnf 配置文件，适配的使用场景有限，所以自定义 mysql 配置文件是必然要做的一项配置。</p><p>这里我随机找了一份配置文件，仅仅是为了实现自定义配置的功能，请根据自己的使用场景使用合适的自定义配置文件。</p><p>使用自定义配置前，我们先需要了解目前 mysql 容器的配置文件结构。</p><p>使用 KubeSphere 提供的<strong>终端</strong>工具，进入 mysql 容器内部，执行下面的命令，分析执行结果(终端登录方式参考前文截图)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">bash</span></span><br><span class="line">root@mysql-0:/# ls /etc/mysql/ -l</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x 2 root root   62 Apr 28 06:20 conf.d</span><br><span class="line">lrwxrwxrwx 1 root root   24 Apr 28 06:20 my.cnf -&gt; /etc/alternatives/my.cnf</span><br><span class="line">-rw-r--r-- 1 root root  839 Aug  3  2016 my.cnf.fallback</span><br><span class="line">-rw-r--r-- 1 root root 1200 Mar 22 01:44 mysql.cnf</span><br><span class="line">drwxr-xr-x 2 root root   24 Apr 28 06:20 mysql.conf.d</span><br><span class="line"></span><br><span class="line">root@mysql-0:/# ls /etc/mysql/conf.d/ -l</span><br><span class="line">total 12</span><br><span class="line">-rw-r--r-- 1 root root 43 Apr 28 06:20 docker.cnf</span><br><span class="line">-rw-r--r-- 1 root root  8 Aug  3  2016 mysql.cnf</span><br><span class="line">-rw-r--r-- 1 root root 55 Aug  3  2016 mysqldump.cnf</span><br><span class="line"></span><br><span class="line">root@mysql-0:/# ls /etc/mysql/mysql.conf.d/ -l</span><br><span class="line">total 4</span><br><span class="line">-rw-r--r-- 1 root root 1589 Apr 28 06:20 mysqld.cnf</span><br><span class="line"></span><br><span class="line">root@mysql-0:/# ls -l /etc/alternatives/my.cnf</span><br><span class="line">lrwxrwxrwx 1 root root 20 Apr 28 06:20 /etc/alternatives/my.cnf -&gt; /etc/mysql/mysql.cnf</span><br><span class="line"></span><br><span class="line">root@mysql-0:/# cat /etc/mysql/mysql.cnf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Copyright (c) 2016, 2021, Oracle and/or its affiliates.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># This program is free software; you can redistribute it and/or modify</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">it under the terms of the GNU General Public License, version 2.0,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">as published by the Free Software Foundation.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># This program is also distributed with certain software (including</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">but not limited to OpenSSL) that is licensed under separate terms,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">as designated <span class="keyword">in</span> a particular file or component or <span class="keyword">in</span> included license</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">documentation.  The authors of MySQL hereby grant you an additional</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">permission to <span class="built_in">link</span> the program and your derivative works with the</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">separately licensed software that they have included with MySQL.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># This program is distributed in the hope that it will be useful,</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">but WITHOUT ANY WARRANTY; without even the implied warranty of</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">GNU General Public License, version 2.0, <span class="keyword">for</span> more details.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># You should have received a copy of the GNU General Public License</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">along with this program; <span class="keyword">if</span> not, write to the Free Software</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA</span></span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/conf.d/</span><br><span class="line">!includedir /etc/mysql/mysql.conf.d/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 挑两个配置文件看看</span></span></span><br><span class="line">root@mysql-0:~# cat /etc/mysql/conf.d/docker.cnf</span><br><span class="line">[mysqld]</span><br><span class="line">skip-host-cache</span><br><span class="line">skip-name-resolve</span><br><span class="line"></span><br><span class="line">root@mysql-0:~# cat /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Copyright (c) 2014, 2021, Oracle and/or its affiliates.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># This program is free software; you can redistribute it and/or modify</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">it under the terms of the GNU General Public License, version 2.0,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">as published by the Free Software Foundation.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># This program is also distributed with certain software (including</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">but not limited to OpenSSL) that is licensed under separate terms,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">as designated <span class="keyword">in</span> a particular file or component or <span class="keyword">in</span> included license</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">documentation.  The authors of MySQL hereby grant you an additional</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">permission to <span class="built_in">link</span> the program and your derivative works with the</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">separately licensed software that they have included with MySQL.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># This program is distributed in the hope that it will be useful,</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">but WITHOUT ANY WARRANTY; without even the implied warranty of</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">GNU General Public License, version 2.0, <span class="keyword">for</span> more details.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># You should have received a copy of the GNU General Public License</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">along with this program; <span class="keyword">if</span> not, write to the Free Software</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301 USA</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># The MySQL  Server configuration file.</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># For explanations see</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">http://dev.mysql.com/doc/mysql/en/server-system-variables.html</span></span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class="line">socket          = /var/run/mysqld/mysqld.sock</span><br><span class="line">datadir         = /var/lib/mysql</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">log-error      = /var/log/mysql/error.log</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">By default we only accept connections from localhost</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">bind-address   = 127.0.0.1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Disabling symbolic-links is recommended to prevent assorted security risks</span></span><br><span class="line">symbolic-links=0</span><br></pre></td></tr></table></figure><p>分析上面的输出我们得到以下结论。</p><ul><li><p>根配置文件：**&#x2F;etc&#x2F;mysql&#x2F;mysql.cnf**</p></li><li><p>自定义的配置文件可以存放在 <strong>&#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;</strong> 或 <strong>&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</strong> 目录下</p></li><li><p>通过上面的结论，发现有两种方式实现自定义配置文件。</p><ul><li><p>直接替换 <strong>&#x2F;etc&#x2F;mysql&#x2F;mysql.cnf</strong></p><blockquote><p><strong>适用于个性化配置较多较复杂的场景，比如 50+的配置项。</strong></p></blockquote></li><li><p>将自定义的配置放在 <strong>&#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;</strong> 或 <strong>&#x2F;etc&#x2F;mysql&#x2F;mysql.conf.d&#x2F;</strong> 目录下，根据官方配置使用情况，建议选择 <strong>&#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;</strong></p><blockquote><p><strong>适用于自定义配置较少的场景，比如只是为了开启个别功能，或是个别默认参数不符合使用需求</strong></p></blockquote></li></ul></li></ul><p>本文采用第二种方式，采用一个独立的 custom.cnf 文件配置以下参数。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="comment">#performance setttings</span></span><br><span class="line"><span class="attr">lock_wait_timeout</span> = <span class="number">3600</span></span><br><span class="line"><span class="attr">open_files_limit</span>    = <span class="number">65535</span></span><br><span class="line"><span class="attr">back_log</span> = <span class="number">1024</span></span><br><span class="line"><span class="attr">max_connections</span> = <span class="number">512</span></span><br><span class="line"><span class="attr">max_connect_errors</span> = <span class="number">1000000</span></span><br><span class="line"><span class="attr">table_open_cache</span> = <span class="number">1024</span></span><br><span class="line"><span class="attr">table_definition_cache</span> = <span class="number">1024</span></span><br><span class="line"><span class="attr">thread_stack</span> = <span class="number">512</span>K</span><br><span class="line"><span class="attr">sort_buffer_size</span> = <span class="number">4</span>M</span><br><span class="line"><span class="attr">join_buffer_size</span> = <span class="number">4</span>M</span><br><span class="line"><span class="attr">read_buffer_size</span> = <span class="number">8</span>M</span><br><span class="line"><span class="attr">read_rnd_buffer_size</span> = <span class="number">4</span>M</span><br><span class="line"><span class="attr">bulk_insert_buffer_size</span> = <span class="number">64</span>M</span><br><span class="line"><span class="attr">thread_cache_size</span> = <span class="number">768</span></span><br><span class="line"><span class="attr">interactive_timeout</span> = <span class="number">600</span></span><br><span class="line"><span class="attr">wait_timeout</span> = <span class="number">600</span></span><br><span class="line"><span class="attr">tmp_table_size</span> = <span class="number">32</span>M</span><br><span class="line"><span class="attr">max_heap_table_size</span> = <span class="number">32</span>M</span><br><span class="line">  </span><br></pre></td></tr></table></figure><p>实现思路。</p><ul><li><p>k8s 中我们可以通过配置 ConfigMap 的方式将文件挂载给容器</p></li><li><p>将自定义的 mysql 配置文件，定义为一个 ConfigMap</p></li><li><p>将 ConfigMap 挂载给 mysql 的容器</p></li></ul><p>创建 ConfigMap 配置文件，<strong>配置</strong>-&gt;<strong>配置字典</strong>，点击<strong>创建</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-44.png" alt="kubesphere-projects-lstack-statefulsets-mysql-44"></p><p><strong>创建配置字典-基本信息</strong>。</p><ul><li>名称：mysql-cnf</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-45.png" alt="kubesphere-projects-lstack-statefulsets-mysql-45"></p><p><strong>创建配置字典-数据设置</strong>。</p><ul><li>点击<strong>添加数据</strong></li><li><strong>键：</strong> custom.cnf</li><li><strong>值：</strong> 粘贴上面的配置参数</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-46.png" alt="kubesphere-projects-lstack-statefulsets-mysql-46"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-47.png" alt="kubesphere-projects-lstack-statefulsets-mysql-47"></p><p>填写完键值信息后，点击<strong>对号</strong>确定，最后点击<strong>创建</strong>，创建完成后会返回<strong>配置字典</strong>页面。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-48.png" alt="kubesphere-projects-lstack-statefulsets-mysql-48"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-49.png" alt="kubesphere-projects-lstack-statefulsets-mysql-49"></p><p>接下来将自定义配置文件，挂载到 mysql 容器。</p><p><strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>有状态副本集</strong>-&gt; 点击 <strong>mysql</strong>-&gt; 进入详细配置页面-&gt;<strong>更多操作</strong>-点击<strong>编辑设置</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-50.png" alt="kubesphere-projects-lstack-statefulsets-mysql-50"></p><p><strong>编辑设置</strong>-&gt;<strong>存储卷</strong>-&gt;<strong>挂载配置字典或保密字典</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-51.png" alt="kubesphere-projects-lstack-statefulsets-mysql-51"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-52.png" alt="kubesphere-projects-lstack-statefulsets-mysql-52"></p><p><strong>存储卷</strong>。</p><ul><li><strong>选择配置字典：</strong>mysql-cnf</li><li><strong>只读</strong></li><li><strong>挂载路径：</strong>&#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;custom.cnf</li><li>指定子路径：custom.cnf<ul><li><strong>此处必须这么写，否则会覆盖掉指定目录下的所有已存在文件</strong></li><li><strong>底层就是 subPath</strong></li><li><strong>具体操作看下图图示，注意细节</strong></li></ul></li><li><strong>选择特定键：</strong> <ul><li>键：custom.cnf</li><li>路径：custom.cnf</li></ul></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-53.png" alt="kubesphere-projects-lstack-statefulsets-mysql-53"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-54.png" alt="kubesphere-projects-lstack-statefulsets-mysql-54"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-55.png" alt="kubesphere-projects-lstack-statefulsets-mysql-55"></p><p>输入完成后，点击<strong>对号</strong>。 </p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-56.png" alt="kubesphere-projects-lstack-statefulsets-mysql-56"></p><p>再次点击<strong>对号</strong>，点击<strong>确定</strong>，mysql 容器会自动开始重建。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-57.png" alt="kubesphere-projects-lstack-statefulsets-mysql-57"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-58.png" alt="kubesphere-projects-lstack-statefulsets-mysql-58"></p><p>重建成功后我们验证一下配置文件是否成功挂载。</p><p>先看一下容器组的配置，发现新增了一个存储卷 <strong>volume-xxxx</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-59.png" alt="kubesphere-projects-lstack-statefulsets-mysql-59"></p><p><strong>终端</strong>-&gt; 进入容器内部查看。</p><p>查看配置文件挂载和文件内容。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">bash</span></span><br><span class="line">root@mysql-0:/# ls /etc/mysql/conf.d/</span><br><span class="line">custom.cnf  docker.cnf  mysql.cnf  mysqldump.cnf</span><br><span class="line"></span><br><span class="line">root@mysql-0:/# ls -l /etc/mysql/conf.d/</span><br><span class="line">total 16</span><br><span class="line">-rw-r--r-- 1 root root 463 May 11 11:07 custom.cnf</span><br><span class="line">-rw-r--r-- 1 root root  43 Apr 28 06:20 docker.cnf</span><br><span class="line">-rw-r--r-- 1 root root   8 Aug  3  2016 mysql.cnf</span><br><span class="line">-rw-r--r-- 1 root root  55 Aug  3  2016 mysqldump.cnf</span><br><span class="line"></span><br><span class="line">root@mysql-0:/# cat /etc/mysql/conf.d/custom.cnf</span><br><span class="line">[mysqld]</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">performance setttings</span></span><br><span class="line">lock_wait_timeout = 3600</span><br><span class="line">open_files_limit    = 65535</span><br><span class="line">back_log = 1024</span><br><span class="line">max_connections = 512</span><br><span class="line">max_connect_errors = 1000000</span><br><span class="line">table_open_cache = 1024</span><br><span class="line">table_definition_cache = 1024</span><br><span class="line">thread_stack = 512K</span><br><span class="line">sort_buffer_size = 4M</span><br><span class="line">join_buffer_size = 4M</span><br><span class="line">read_buffer_size = 8M</span><br><span class="line">read_rnd_buffer_size = 4M</span><br><span class="line">bulk_insert_buffer_size = 64M</span><br><span class="line">thread_cache_size = 768</span><br><span class="line">interactive_timeout = 600</span><br><span class="line">wait_timeout = 600</span><br><span class="line">tmp_table_size = 32M</span><br><span class="line">max_heap_table_size = 32M</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>查看配置参数是否生效。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@mysql-0:/# mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.7.38 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2022, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">SHOW GLOBAL VARIABLES LIKE <span class="string">&#x27;max_connect%&#x27;</span>;</span></span><br><span class="line">+--------------------+---------+</span><br><span class="line">| Variable_name      | Value   |</span><br><span class="line">+--------------------+---------+</span><br><span class="line">| max_connect_errors | 1000000 |</span><br><span class="line">| max_connections    | 512     |</span><br><span class="line">+--------------------+---------+</span><br><span class="line">2 rows in set (0.02 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt;</span></span><br></pre></td></tr></table></figure><p>执行结果跟我们的配置一致，说明配置成功。</p><blockquote><p><strong>03-导入数据库数据</strong></p></blockquote><p>将数据库文件（SQL），挂载到容器的指定目录下 <strong>&#x2F;docker-entrypoint-initdb.d</strong>，容器创建时会自动导入（<strong>非必要不推荐</strong>）。</p><p>用数据库管理工具远程管理数据库（<strong>推荐</strong>）。</p><hr><h2 id="3-原生-K8S-部署-MySQL-实现-GitOps"><a href="#3-原生-K8S-部署-MySQL-实现-GitOps" class="headerlink" title="3. 原生 K8S 部署 MySQL 实现 GitOps"></a>3. 原生 K8S 部署 MySQL 实现 GitOps</h2><p>上面我们完成了通过 KubeSphere 部署单实例 MySQL，那么原生的 K8S 又该如何操作？GitOps 又是什么、又该如何实现？</p><h3 id="3-1-什么是-GitOps-网文摘抄"><a href="#3-1-什么是-GitOps-网文摘抄" class="headerlink" title="3.1. 什么是 GitOps(网文摘抄)"></a>3.1. 什么是 GitOps(网文摘抄)</h3><ul><li>GitOps 是一套使用 Git 来管理基础架构和应用配置的实践，而 Git 指的是一个开源版控制系统。</li><li>GitOps 在运行过程中以 Git 为声明性基础架构和应用的单一事实来源。</li><li>GitOps 使用 Git 拉取请求来自动管理基础架构的置备和部署。</li><li>Git 存储库包含系统的全部状态，因此系统状态的修改痕迹既可查看也可审计。</li><li>GitOps 经常被用作 Kubernetes 和云原生应用开发的运维模式，并且可以实现对 Kubernetes 的持续部署。</li><li>GitOps 是一种持续交付的方式。它的核心思想是将应用系统的声明性基础架构和应用程序存放在 Git 版本库中。</li></ul><h3 id="3-2-准备-K8S-上的-MySQL-资源配置清单-思路梳理"><a href="#3-2-准备-K8S-上的-MySQL-资源配置清单-思路梳理" class="headerlink" title="3.2. 准备 K8S 上的 MySQL 资源配置清单-思路梳理"></a>3.2. 准备 K8S 上的 MySQL 资源配置清单-思路梳理</h3><p>我们知道玩 K8S 的必备技能就是要手写资源配置清单，一般使用 YAML 格式的文件来创建我们预期的资源配置。</p><p>此时我们也要手写 MySQL 的资源配置清单？我很慌，参数我记不全啊。</p><p>NO！NO！NO！投机取巧的时刻到了，前面卖的关子在这揭开了。</p><p>前面我们已经通过 KubeSphere 的图形界面创建了 MySQL 的资源配置，而且 KubeSphere 一个很棒的功能就是可以直接在线编辑资源的 YAML 文件。</p><p>我们可以在创建资源的时候，直接编辑 YAML 文件创建资源。也可以通过编辑 YAML 的方式修改已有的资源。</p><p>当然啊，你不用图形界面，直接在 K8S 底层用命令行的方式去获取 YAML 格式的输出，再编辑，也是可以的。</p><p>梳理一下 MySQL 涉及的资源配置清单包含的资源。</p><ul><li><strong>StatefulSet(有状态副本集)</strong></li><li><strong>Service(服务)</strong><ul><li>集群内部（Headless）</li><li>集群外部（自定义服务）</li></ul></li><li><strong>ConfigMap</strong></li><li><strong>Secret</strong></li></ul><p>接下来我们就分别获取这些资源配置清单。</p><h3 id="3-3-准备-K8S-上的-MySQL-资源配置清单"><a href="#3-3-准备-K8S-上的-MySQL-资源配置清单" class="headerlink" title="3.3. 准备 K8S 上的 MySQL 资源配置清单"></a>3.3. 准备 K8S 上的 MySQL 资源配置清单</h3><blockquote><p><strong>01-ConfigMap</strong></p></blockquote><p><strong>配置</strong>-&gt;<strong>配置字典</strong>，找到 <strong>mysql-cnf</strong>，点击右侧的<strong>三个竖点</strong>，点击<strong>编辑 YAML</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-60.png" alt="kubesphere-projects-lstack-statefulsets-mysql-60"></p><p>打开<strong>编辑 YAML</strong> 页面，可以直接复制所有内容，也可以点击右上角的下载图标，下载文件(也可以利用上传图标上传文件)。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-61.png" alt="kubesphere-projects-lstack-statefulsets-mysql-61"></p><p>获取的现网配置不能完全的拿来就用，需要修改，把系统自动添加的一些元数据信息清理掉。</p><p>现网的 <strong>mysql-cfm.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-cnf</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/creator:</span> <span class="string">lstack</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">custom.cnf:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    [mysqld]</span></span><br><span class="line"><span class="string">    #performance setttings</span></span><br><span class="line"><span class="string">    lock_wait_timeout = 3600</span></span><br><span class="line"><span class="string">    open_files_limit    = 65535</span></span><br><span class="line"><span class="string">    back_log = 1024</span></span><br><span class="line"><span class="string">    max_connections = 512</span></span><br><span class="line"><span class="string">    max_connect_errors = 1000000</span></span><br><span class="line"><span class="string">    table_open_cache = 1024</span></span><br><span class="line"><span class="string">    table_definition_cache = 1024</span></span><br><span class="line"><span class="string">    thread_stack = 512K</span></span><br><span class="line"><span class="string">    sort_buffer_size = 4M</span></span><br><span class="line"><span class="string">    join_buffer_size = 4M</span></span><br><span class="line"><span class="string">    read_buffer_size = 8M</span></span><br><span class="line"><span class="string">    read_rnd_buffer_size = 4M</span></span><br><span class="line"><span class="string">    bulk_insert_buffer_size = 64M</span></span><br><span class="line"><span class="string">    thread_cache_size = 768</span></span><br><span class="line"><span class="string">    interactive_timeout = 600</span></span><br><span class="line"><span class="string">    wait_timeout = 600</span></span><br><span class="line"><span class="string">    tmp_table_size = 32M</span></span><br><span class="line"><span class="string">    max_heap_table_size = 32M</span></span><br><span class="line"><span class="string"></span>    </span><br></pre></td></tr></table></figure><p>修改后的 <strong>mysql-cfm.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-cnf</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">custom.cnf:</span> <span class="string">|-</span></span><br><span class="line"><span class="string">    [mysqld]</span></span><br><span class="line"><span class="string">    #performance setttings</span></span><br><span class="line"><span class="string">    lock_wait_timeout = 3600</span></span><br><span class="line"><span class="string">    open_files_limit    = 65535</span></span><br><span class="line"><span class="string">    back_log = 1024</span></span><br><span class="line"><span class="string">    max_connections = 512</span></span><br><span class="line"><span class="string">    max_connect_errors = 1000000</span></span><br><span class="line"><span class="string">    table_open_cache = 1024</span></span><br><span class="line"><span class="string">    table_definition_cache = 1024</span></span><br><span class="line"><span class="string">    thread_stack = 512K</span></span><br><span class="line"><span class="string">    sort_buffer_size = 4M</span></span><br><span class="line"><span class="string">    join_buffer_size = 4M</span></span><br><span class="line"><span class="string">    read_buffer_size = 8M</span></span><br><span class="line"><span class="string">    read_rnd_buffer_size = 4M</span></span><br><span class="line"><span class="string">    bulk_insert_buffer_size = 64M</span></span><br><span class="line"><span class="string">    thread_cache_size = 768</span></span><br><span class="line"><span class="string">    interactive_timeout = 600</span></span><br><span class="line"><span class="string">    wait_timeout = 600</span></span><br><span class="line"><span class="string">    tmp_table_size = 32M</span></span><br><span class="line"><span class="string">    max_heap_table_size = 32M</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><blockquote><p><strong>02-Secret</strong></p></blockquote><p><strong>配置</strong>-&gt;<strong>保密字典</strong>，找到 <strong>mysql-secret</strong>，点击右侧的<strong>三个竖点</strong>，点击<strong>编辑 YAML</strong>。</p><p>现网的 <strong>mysql-secret.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/creator:</span> <span class="string">lstack</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">UEA4OHcwcmQ=</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改后的 <strong>mysql-secret.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">UEA4OHcwcmQ=</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里要说一句，Secret 里的值是用 base64 方式加密的，所以这里的 <strong>MYSQL_ROOT_PASSWORD</strong>，要用实际的密码用 base64 的方式加密。</p><ul><li><p>base64 解密。</p></li><li><p>&#96;&#96;&#96;shell<br>[root@ks-k8s-master-0 ~]# echo “UEA4OHcwcmQ&#x3D;” | base64 -d<br>P@88w0rd</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- base 加密。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# echo -n &quot;P@88w0rd&quot; | base64</span><br><span class="line">  UEA4OHcwcmQ=</span><br></pre></td></tr></table></figure></li></ul><blockquote><p><strong>03-StatefulSet</strong></p></blockquote><p><strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>有状态副本集</strong>，找到 <strong>mysql</strong>，点击右侧的<strong>三个竖点</strong>，点击<strong>编辑 YAML</strong>。</p><p>现网的 <strong>mysql-sts.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/creator:</span> <span class="string">lstack</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="attr">logging.kubesphere.io/logsidecar-config:</span> <span class="string">&#x27;&#123;&#125;&#x27;</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-rca2zx</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">mysql-cnf</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">custom.cnf</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">custom.cnf</span></span><br><span class="line">            <span class="attr">defaultMode:</span> <span class="number">420</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lstack-mysql</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;mysql:5.7.38&#x27;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">3306</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">mysql-secret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/var/lib/mysql</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-rca2zx</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/mysql/conf.d/custom.cnf</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">custom.cnf</span></span><br><span class="line">          <span class="attr">terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line">          <span class="attr">terminationMessagePolicy:</span> <span class="string">File</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">default</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">default</span></span><br><span class="line">      <span class="attr">securityContext:</span> &#123;&#125;</span><br><span class="line">      <span class="attr">schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line">      <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">        <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">glusterfs</span></span><br><span class="line">        <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">      <span class="attr">status:</span></span><br><span class="line">        <span class="attr">phase:</span> <span class="string">Pending</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">mysql-1dpr</span></span><br><span class="line">  <span class="attr">podManagementPolicy:</span> <span class="string">OrderedReady</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">    <span class="attr">rollingUpdate:</span></span><br><span class="line">      <span class="attr">partition:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">revisionHistoryLimit:</span> <span class="number">10</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改后的 <strong>mysql-sts.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="attr">type:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-cnf</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">mysql-cnf</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">custom.cnf</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">custom.cnf</span></span><br><span class="line">            <span class="attr">defaultMode:</span> <span class="number">420</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lstack-mysql</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&#x27;mysql:5.7.38&#x27;</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">3306</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">mysql-secret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">MYSQL_ROOT_PASSWORD</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">4000Mi</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">500Mi</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">host-time</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/localtime</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/var/lib/mysql</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-cnf</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/mysql/conf.d/custom.cnf</span></span><br><span class="line">              <span class="attr">subPath:</span> <span class="string">custom.cnf</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">        <span class="attr">storageClassName:</span> <span class="string">glusterfs</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">mysql-headless</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>04-Service</strong></p></blockquote><p>先创建 <strong>Headless</strong> 服务，<strong>应用负载</strong>-&gt;<strong>服务</strong>-&gt;，找到 <strong>mysql-xxxx(mysql)<strong>，点击右侧的</strong>三个竖点</strong>，点击<strong>编辑 YAML</strong>。</p><p>现网的 <strong>mysql-headless.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-1dpr</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/alias-name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">kubesphere.io/creator:</span> <span class="string">lstack</span></span><br><span class="line">    <span class="attr">kubesphere.io/serviceType:</span> <span class="string">statefulservice</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">clusterIPs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">ipFamilies:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IPv4</span></span><br><span class="line">  <span class="attr">ipFamilyPolicy:</span> <span class="string">SingleStack</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改后的 <strong>mysql-headless.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>再看看自定义的 <strong>mysql-external</strong> 服务 ,<strong>应用负载</strong>-&gt;<strong>服务</strong>-&gt;，找到 <strong>mysql-external</strong>，点击右侧的<strong>三个竖点</strong>，点击<strong>编辑 YAML</strong>。</p><p>现网的 <strong>mysql-external.yaml</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-external</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubesphere.io/creator:</span> <span class="string">lstack</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql-external</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">32529</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.233</span><span class="number">.36</span><span class="number">.71</span></span><br><span class="line">  <span class="attr">clusterIPs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">10.233</span><span class="number">.36</span><span class="number">.71</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">externalTrafficPolicy:</span> <span class="string">Cluster</span></span><br><span class="line">  <span class="attr">ipFamilies:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IPv4</span></span><br><span class="line">  <span class="attr">ipFamilyPolicy:</span> <span class="string">SingleStack</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里有一点要说明 <strong>nodePort</strong> 这个参数，如果 K8S 集群可控，建议规划一套服务端口使用规范，每个需要 <strong>nodePort</strong> 的服务都指定固定的端口，这样有利于运维的标准化。</p><p>修改后的 <strong>mysql-external.yaml</strong>(注意 <strong>nodePort</strong> 参数没有指定)。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql-external</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql-external</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-4-将-MySQL-资源配置清单提交到-Git-仓库。"><a href="#3-4-将-MySQL-资源配置清单提交到-Git-仓库。" class="headerlink" title="3.4. 将 MySQL 资源配置清单提交到 Git 仓库。"></a>3.4. 将 MySQL 资源配置清单提交到 Git 仓库。</h3><p>通过上面的操作，我们获取了 MySQL 的资源配置清单。</p><p>本人强迫症，喜欢分类存放，所以我用了 4 个文件，<strong>mysql-headless.yaml</strong> 跟 <strong>mysql-sts.yaml</strong> 合并在一个文件当然你也可以放到一个配置文件里。</p><ul><li><strong>mysql-external.yaml</strong></li><li><strong>mysql-sts.yaml</strong></li><li><strong>mysql-secret.yaml</strong></li><li><strong>mysql-cfm.yaml</strong></li></ul><blockquote><p><strong>01-将资源配置清单提交到 Git 仓库</strong></p></blockquote><p>选择 GitHub 作为主仓库，Gitee 作为同步仓库(人工)。</p><p>本系列文档所有 k8s 的资源配置清单文件使用了一个公共仓库，生产环境建议每种服务创建一个配置仓库，有利于更精细化的版本控制。</p><p>本文为了演示主备仓库的使用，所有选择了 Github 和 Gitee 两种 Git 服务，实际使用中为了更好的使用体验建议选择 Gitee。</p><p>在 GitHub 新建一个仓库，仓库名称**<a href="https://github.com/devops/k8s-yaml">k8s-yaml</a><strong>，添加一个 README 文件初始化仓库，点击</strong>Create repository**，确认创建。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-62.png" alt="kubesphere-projects-lstack-statefulsets-mysql-62"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-63.png" alt="kubesphere-projects-lstack-statefulsets-mysql-63"></p><p>将代码仓库 Clone 回本地。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">github % git clone git@github.com:devops/k8s-yaml.git</span><br><span class="line">Cloning into &#x27;k8s-yaml&#x27;...</span><br><span class="line">Enter passphrase for key &#x27;/Users/z/.ssh/id_rsa&#x27;: </span><br><span class="line">remote: Enumerating objects: 3, done.</span><br><span class="line">remote: Counting objects: 100% (3/3), done.</span><br><span class="line">remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">Receiving objects: 100% (3/3), done.</span><br><span class="line"></span><br><span class="line">github % ls k8s-yaml </span><br><span class="line">README.md</span><br></pre></td></tr></table></figure><p>新创建一个文件夹，用自己喜欢的文本编辑器 (推荐 vscode) 编辑 MySQL 的资源配置清单，并将文件放入新创建的文件夹。</p><p>为了以后的扩展性，这里创建了一个 <strong>single</strong> 命名的二级目录，存放单实例的资源配置清单文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">github % mkdir -p k8s-yaml/mysql/single</span><br><span class="line">github % ls -l k8s-yaml/mysql/single</span><br><span class="line">total 32</span><br><span class="line">-rw-r--r--  1 z  staff   646  5 11 19:23 mysql-cfm.yaml</span><br><span class="line">-rw-r--r--  1 z  staff   266  5 11 19:31 mysql-external.yaml</span><br><span class="line">-rw-r--r--  1 z  staff   134  5 11 19:23 mysql-secret.yaml</span><br><span class="line">-rw-r--r--  1 z  staff  1911  5 11 19:31 mysql-sts.yaml</span><br></pre></td></tr></table></figure><p>将编辑好的资源配置文件清单，提交到 GitHub。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">github % cd k8s-yaml</span><br><span class="line">k8s-yaml[main*] % git status</span><br><span class="line">On branch main</span><br><span class="line">Your branch is up to date with &#x27;origin/main&#x27;.</span><br><span class="line"></span><br><span class="line">Untracked files:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)</span><br><span class="line">mysql/</span><br><span class="line"></span><br><span class="line">nothing added to commit but untracked files present (use &quot;git add&quot; to track)</span><br><span class="line"></span><br><span class="line">k8s-yaml[main*] % git add .</span><br><span class="line">k8s-yaml[main*] % git commit -am &#x27;添加MySQL single资源配置清单&#x27;</span><br><span class="line">[main 1d00559] 添加MySQL single资源配置清单</span><br><span class="line"> 4 files changed, 138 insertions(+)</span><br><span class="line"> create mode 100644 mysql/single/mysql-cfm.yaml</span><br><span class="line"> create mode 100644 mysql/single/mysql-external.yaml</span><br><span class="line"> create mode 100644 mysql/single/mysql-secret.yaml</span><br><span class="line"> create mode 100644 mysql/single/mysql-sts.yaml</span><br><span class="line">k8s-yaml[main] % git status</span><br><span class="line">On branch main</span><br><span class="line">Your branch is ahead of &#x27;origin/main&#x27; by 1 commit.</span><br><span class="line">  (use &quot;git push&quot; to publish your local commits)</span><br><span class="line"></span><br><span class="line">nothing to commit, working tree clean</span><br><span class="line">k8s-yaml[main] % git push</span><br><span class="line">Enter passphrase for key &#x27;/Users/z/.ssh/id_rsa&#x27;:</span><br><span class="line">Enumerating objects: 9, done.</span><br><span class="line">Counting objects: 100% (9/9), done.</span><br><span class="line">Delta compression using up to 8 threads</span><br><span class="line">Compressing objects: 100% (7/7), done.</span><br><span class="line">Writing objects: 100% (8/8), 1.59 KiB | 1.59 MiB/s, done.</span><br><span class="line">Total 8 (delta 1), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Resolving deltas: 100% (1/1), done.</span><br><span class="line">To github.com:devops/k8s-yaml.git</span><br><span class="line">   e31f780..1d00559  main -&gt; main</span><br></pre></td></tr></table></figure><p>在 GitHub 上查看，确认代码是否提交。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-64.png" alt="kubesphere-projects-lstack-statefulsets-mysql-64"></p><p>接下来将资源配置清单同步到 Gitee 备份仓库。</p><ul><li>本文采用了手工推送同步的方式 (个人习惯)</li><li>Gitee 也支持自动同步 GitHub 的仓库 (更便捷)</li></ul><p>在 Gitee 新建一个仓库，仓库名称**<a href="https://gitee.com/zdevops/k8s-yaml">k8s-yaml</a><strong>，类型默认</strong>私有<strong>，点击</strong>创建**。</p><p><strong>创建完成后可去仓库设置中修改为开源。</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-65.png" alt="kubesphere-projects-lstack-statefulsets-mysql-65"></p><p>创建完成后，因为我们创建的时候，没选择初始化仓库的配置，所以，默认会显示一个帮助页面，告诉你该如何提交代码到仓库。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-66.png" alt="kubesphere-projects-lstack-statefulsets-mysql-66"></p><p>因为，我们已经有了代码仓库，所以我们选择<strong>已有仓库</strong>的配置方法，将已有代码提交到 Gitee。</p><p>根据帮助提示操作，要注意 <strong>origin</strong> 我们要换成 <strong>gitee</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">k8s-yaml[main] % git remote add gitee https://gitee.com/zdevops/k8s-yaml.git</span><br><span class="line"></span><br><span class="line">k8s-yaml[main] % git push -u gitee</span><br><span class="line">Enumerating objects: 11, done.</span><br><span class="line">Counting objects: 100% (11/11), done.</span><br><span class="line">Delta compression using up to 8 threads</span><br><span class="line">Compressing objects: 100% (8/8), done.</span><br><span class="line">Writing objects: 100% (11/11), 2.14 KiB | 2.14 MiB/s, done.</span><br><span class="line">Total 11 (delta 1), reused 3 (delta 0), pack-reused 0</span><br><span class="line">remote: Powered by GITEE.COM [GNK-6.3]</span><br><span class="line">remote: Create a pull request for &#x27;main&#x27; on Gitee by visiting:</span><br><span class="line">remote:     https://gitee.com/zdevops/k8s-yaml/pull/new/zdevops:main...zdevops:master</span><br><span class="line">To https://gitee.com/zdevops/k8s-yaml.git</span><br><span class="line"> * [new branch]      main -&gt; main</span><br><span class="line">Branch &#x27;main&#x27; set up to track remote branch &#x27;main&#x27; from &#x27;gitee&#x27;.</span><br></pre></td></tr></table></figure><p>在 Gitee 上查看，确认代码是否提交。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-67.png" alt="kubesphere-projects-lstack-statefulsets-mysql-67"></p><p>修改 Gitee 仓库为开源(可选)。</p><p>Gitee 仓库-&gt;<strong>管理</strong>-&gt;<strong>仓库设置</strong>-&gt;<strong>基本信息</strong>，最后面<strong>是否开源</strong>，选择<strong>开源</strong>，<strong>仓库公开须知</strong>，三个都勾选，点击<strong>保存</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-70.png" alt="kubesphere-projects-lstack-statefulsets-mysql-70"></p><p>修改后，你的代码仓库就是开源，所有人可见的了。</p><h3 id="3-5-GitOps-初体验-在-K8S-集群上部署-MySQL"><a href="#3-5-GitOps-初体验-在-K8S-集群上部署-MySQL" class="headerlink" title="3.5. GitOps 初体验-在 K8S 集群上部署 MySQL"></a>3.5. GitOps 初体验-在 K8S 集群上部署 MySQL</h3><p>MySQL 资源配置清单已经存放到了 Git 在线仓库，接下来开启我们的 GitOps 体验之旅。</p><p>登录 k8s 的 master 节点，执行后面的操作任务。</p><p><strong>生产环境建议打造独立的运维管理节点进行整个集群的管理 , 可以参考《基于 KubeSphere 玩转 k8s-运维管理节点打造手记》</strong></p><p>安装 Git。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# yum install git -y</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * centos-gluster9: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package git.x86_64 0:1.8.3.1-23.el7_8 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl-Git = 1.8.3.1-23.el7_8 <span class="keyword">for</span> package: git-1.8.3.1-23.el7_8.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: rsync <span class="keyword">for</span> package: git-1.8.3.1-23.el7_8.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Term::ReadKey) <span class="keyword">for</span> package: git-1.8.3.1-23.el7_8.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Git) <span class="keyword">for</span> package: git-1.8.3.1-23.el7_8.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Error) <span class="keyword">for</span> package: git-1.8.3.1-23.el7_8.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Error.noarch 1:0.17020-2.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Git.noarch 0:1.8.3.1-23.el7_8 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-TermReadKey.x86_64 0:2.30-20.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package rsync.x86_64 0:3.1.2-10.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">==============================================================================================================================</span><br><span class="line"> Package                            Arch                     Version                             Repository              Size</span><br><span class="line">==============================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> git                                x86_64                   1.8.3.1-23.el7_8                    base                   4.4 M</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> perl-Error                         noarch                   1:0.17020-2.el7                     base                    32 k</span><br><span class="line"> perl-Git                           noarch                   1.8.3.1-23.el7_8                    base                    56 k</span><br><span class="line"> perl-TermReadKey                   x86_64                   2.30-20.el7                         base                    31 k</span><br><span class="line"> rsync                              x86_64                   3.1.2-10.el7                        base                   404 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==============================================================================================================================</span><br><span class="line">Install  1 Package (+4 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 4.9 M</span><br><span class="line">Installed size: 23 M</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/5): perl-Error-0.17020-2.el7.noarch.rpm                                                             |  32 kB  00:00:00     </span><br><span class="line">(2/5): perl-Git-1.8.3.1-23.el7_8.noarch.rpm                                                            |  56 kB  00:00:00     </span><br><span class="line">(3/5): perl-TermReadKey-2.30-20.el7.x86_64.rpm                                                         |  31 kB  00:00:00     </span><br><span class="line">(4/5): git-1.8.3.1-23.el7_8.x86_64.rpm                                                                 | 4.4 MB  00:00:00     </span><br><span class="line">(5/5): rsync-3.1.2-10.el7.x86_64.rpm                                                                   | 404 kB  00:00:00     </span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                                          13 MB/s | 4.9 MB  00:00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : 1:perl-Error-0.17020-2.el7.noarch                                                                          1/5 </span><br><span class="line">  Installing : rsync-3.1.2-10.el7.x86_64                                                                                  2/5 </span><br><span class="line">  Installing : perl-TermReadKey-2.30-20.el7.x86_64                                                                        3/5 </span><br><span class="line">  Installing : perl-Git-1.8.3.1-23.el7_8.noarch                                                                           4/5 </span><br><span class="line">  Installing : git-1.8.3.1-23.el7_8.x86_64                                                                                5/5 </span><br><span class="line">  Verifying  : git-1.8.3.1-23.el7_8.x86_64                                                                                1/5 </span><br><span class="line">  Verifying  : 1:perl-Error-0.17020-2.el7.noarch                                                                          2/5 </span><br><span class="line">  Verifying  : perl-TermReadKey-2.30-20.el7.x86_64                                                                        3/5 </span><br><span class="line">  Verifying  : perl-Git-1.8.3.1-23.el7_8.noarch                                                                           4/5 </span><br><span class="line">  Verifying  : rsync-3.1.2-10.el7.x86_64                                                                                  5/5 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  git.x86_64 0:1.8.3.1-23.el7_8                                                                                               </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  perl-Error.noarch 1:0.17020-2.el7       perl-Git.noarch 0:1.8.3.1-23.el7_8       perl-TermReadKey.x86_64 0:2.30-20.el7      </span><br><span class="line">  rsync.x86_64 0:3.1.2-10.el7            </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure><p>创建 devops 目录，我选择 &#x2F;opt 目录作为 devops 的根目录。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# mkdir /opt/devops</span><br><span class="line">[root@ks-k8s-master-0 ~]# cd /opt/devops/</span><br><span class="line">[root@ks-k8s-master-0 devops]# </span><br></pre></td></tr></table></figure><p>从 Gitee 下载 <strong>k8s-yaml</strong> 仓库的代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 devops]# git clone https://gitee.com/zdevops/k8s-yaml.git</span><br><span class="line">Cloning into &#x27;k8s-yaml&#x27;...</span><br><span class="line">remote: Enumerating objects: 11, done.</span><br><span class="line">remote: Counting objects: 100% (11/11), done.</span><br><span class="line">remote: Compressing objects: 100% (8/8), done.</span><br><span class="line">remote: Total 11 (delta 1), reused 0 (delta 0), pack-reused 0</span><br><span class="line">Unpacking objects: 100% (11/11), done.</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 devops]# ls k8s-yaml/</span><br><span class="line">mysql  README.md</span><br></pre></td></tr></table></figure><p>由于是同一个测试环境，先清理掉现有的 MySQL 服务。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 devops]# kubectl get secrets -n lstack </span><br><span class="line">NAME                  TYPE                                  DATA   AGE</span><br><span class="line">default-token-x2gzv   kubernetes.io/service-account-token   3      31d</span><br><span class="line">mysql-secret          Opaque                                1      2d20h</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl get configmaps -n lstack </span><br><span class="line">NAME               DATA   AGE</span><br><span class="line">kube-root-ca.crt   1      31d</span><br><span class="line">mysql-cnf          1      47h</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl get service -n lstack </span><br><span class="line">NAME                                                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">glusterfs-dynamic-afe88cf4-86b1-4215-833a-534c5f779a22   ClusterIP   10.233.13.188   &lt;none&gt;        1/TCP            2d</span><br><span class="line">mysql-1dpr                                               ClusterIP   None            &lt;none&gt;        3306/TCP         2d</span><br><span class="line">mysql-external                                           NodePort    10.233.36.71    &lt;none&gt;        3306:32529/TCP   47h</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl get statefulsets -n lstack </span><br><span class="line">NAME    READY   AGE</span><br><span class="line">mysql   1/1     2d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清理</span></span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl delete statefulsets mysql -n lstack</span><br><span class="line">statefulset.apps &quot;mysql&quot; deleted</span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl delete service mysql-external -n lstack</span><br><span class="line">service &quot;mysql-external&quot; deleted</span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl delete service mysql-1dpr -n lstack</span><br><span class="line">service &quot;mysql-1dpr&quot; deleted</span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl delete secrets mysql-secret -n lstack</span><br><span class="line">secret &quot;mysql-secret&quot; deleted</span><br><span class="line">[root@ks-k8s-master-0 devops]# kubectl delete configmaps mysql-cnf -n lstack</span><br><span class="line">configmap &quot;mysql-cnf&quot; deleted</span><br></pre></td></tr></table></figure><p>利用资源配置清单一键部署 MySQL。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 devops]# cd /opt/devops/k8s-yaml/</span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# ls</span><br><span class="line">mysql  README.md</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl apply -f mysql/single/</span><br><span class="line">configmap/mysql-cnf created</span><br><span class="line">service/mysql-external created</span><br><span class="line">secret/mysql-secret created</span><br><span class="line">service/mysql-headless created</span><br></pre></td></tr></table></figure><p>验证结果，发现 <strong>StatefulSet</strong> 没有创建，分析问题。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl get statefulsets -n lstack</span><br><span class="line">No resources found in lstack namespace.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一开始我以为我遗漏了配置文件，<span class="built_in">ls</span>看一眼，发现文件都在</span></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# ls</span><br><span class="line">mysql  README.md</span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# cd mysql/</span><br><span class="line">[root@ks-k8s-master-0 mysql]# ls</span><br><span class="line">single</span><br><span class="line">[root@ks-k8s-master-0 mysql]# cd single/</span><br><span class="line">[root@ks-k8s-master-0 single]# ls</span><br><span class="line">mysql-cfm.yaml  mysql-external.yaml  mysql-secret.yaml  mysql-sts.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确认一下文件内容，发现文件也有内容</span></span><br><span class="line">[root@ks-k8s-master-0 single]# vi mysql-sts.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次执行，发现了端倪，为啥只有service/mysql-headless 的资源配置，没有statefulset</span></span><br><span class="line">[root@ks-k8s-master-0 single]# kubectl apply -f mysql-sts.yaml </span><br><span class="line">service/mysql-headless unchanged</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次确认，发现编辑文件的时候遗漏了一点，当一个配置文件有多种资源定义时，不同资源的配置直接需要用<span class="string">&quot;---&quot;</span>分隔。修改配置文件再次执行，发现执行成功。</span></span><br><span class="line">[root@ks-k8s-master-0 single]# vi mysql-sts.yaml</span><br><span class="line">[root@ks-k8s-master-0 single]# cd ..</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 mysql]# kubectl apply -f single/</span><br><span class="line">configmap/mysql-cnf unchanged</span><br><span class="line">service/mysql-external unchanged</span><br><span class="line">secret/mysql-secret unchanged</span><br><span class="line">statefulset.apps/mysql created</span><br><span class="line">service/mysql-headless unchanged</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 mysql]# kubectl get statefulsets -n lstack -o wide</span><br><span class="line">NAME    READY   AGE   CONTAINERS     IMAGES</span><br><span class="line">mysql   1/1     31s   lstack-mysql   mysql:5.7.38</span><br><span class="line">[root@ks-k8s-master-0 mysql]# kubectl get pods -n lstack -o wide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP              NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">mysql-0   1/1     Running   0          35s   10.233.116.59   ks-k8s-master-2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>回到我们的 KubeSphere 的管理控制台，发现 mysql 的工作负载也能在界面中显示，这也验证了在原生 k8s 上的操作也会直接反应到 KubeSphere 的管理控制台。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-71.png" alt="kubesphere-projects-lstack-statefulsets-mysql-71"></p><h3 id="3-6-二次体验-GitOps"><a href="#3-6-二次体验-GitOps" class="headerlink" title="3.6. 二次体验 GitOps"></a>3.6. 二次体验 GitOps</h3><p>正好借着上面出现的问题，二次体验一下 GitOps。我们直接在部署服务器上修改了 <strong>mysql-sts.yaml</strong>，且修改后的结果验证成功。</p><p><strong>为了演示 GitOps 的更多场景，直接在部署服务器上修改，然后提交到在线代码仓库。</strong></p><p><strong>实际工作中我都是在自己的办公电脑上修改，提交到在线代码仓库，然后部署服务器拉取更新代码。</strong></p><p>修改后的 <strong>mysql-sts.yaml</strong>，由于篇幅问题这里只演示关键部分，StatefulSet 的完整配置见 Gitee 仓库或是前文。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysql-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">lstack</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">tcp-mysql</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3306</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">3306</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">mysql</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br></pre></td></tr></table></figure><p>提交修改后的代码到代码仓库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改后查看git仓库的变化</span></span><br><span class="line">[root@ks-k8s-master-0 single]# git status</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">On branch main</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Changes not staged <span class="keyword">for</span> commit:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (use <span class="string">&quot;git add &lt;file&gt;...&quot;</span> to update what will be committed)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  (use <span class="string">&quot;git checkout -- &lt;file&gt;...&quot;</span> to discard changes <span class="keyword">in</span> working directory)</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment">#       modified:   mysql-sts.yaml</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash">no changes added to commit (use <span class="string">&quot;git add&quot;</span> and/or <span class="string">&quot;git commit -a&quot;</span>)</span></span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 single]# git diff </span><br><span class="line">diff --git a/mysql/single/mysql-sts.yaml b/mysql/single/mysql-sts.yaml</span><br><span class="line">index f775920..1eded9c 100644</span><br><span class="line">--- a/mysql/single/mysql-sts.yaml</span><br><span class="line">+++ b/mysql/single/mysql-sts.yaml</span><br><span class="line">@@ -1,3 +1,4 @@</span><br><span class="line">+---</span><br><span class="line"> kind: StatefulSet</span><br><span class="line"> apiVersion: apps/v1</span><br><span class="line"> metadata:</span><br><span class="line">@@ -68,6 +69,7 @@ spec:</span><br><span class="line">         storageClassName: glusterfs</span><br><span class="line">   serviceName: mysql-headless</span><br><span class="line"> </span><br><span class="line">+---</span><br><span class="line"> kind: Service</span><br><span class="line"> apiVersion: v1</span><br><span class="line"> metadata:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">本地提交代码变更</span></span><br><span class="line">[root@ks-k8s-master-0 single]# git commit -am &#x27;修复mysql statefulset配置不生效问题&#x27;</span><br><span class="line"></span><br><span class="line">*** Please tell me who you are.</span><br><span class="line"></span><br><span class="line">Run</span><br><span class="line"></span><br><span class="line">  git config --global user.email &quot;you@example.com&quot;</span><br><span class="line">  git config --global user.name &quot;Your Name&quot;</span><br><span class="line"></span><br><span class="line">to set your account&#x27;s default identity.</span><br><span class="line">Omit --global to set the identity only in this repository.</span><br><span class="line"></span><br><span class="line">fatal: unable to auto-detect email address (got &#x27;root@ks-k8s-master-0.(none)&#x27;)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">发现报错了，因为我们这是新环境，还没有配置git的user.email和user.name。按提示配置。</span> </span><br><span class="line">[root@ks-k8s-master-0 single]# git config --global user.email devops@163.com</span><br><span class="line">[root@ks-k8s-master-0 single]# git config --global user.name &quot;devops&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次提交</span></span><br><span class="line">[root@ks-k8s-master-0 single]# git commit -am &#x27;修复mysql statefulset配置不生效问题&#x27;</span><br><span class="line">[main f5ba03b] 修复mysql statefulset配置不生效问题</span><br><span class="line"> 1 file changed, 2 insertions(+)</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">push到在线代码仓库，有一个warning可以忽略，也可以按提示执行</span></span><br><span class="line">[root@ks-k8s-master-0 single]# git push</span><br><span class="line">warning: push.default is unset; its implicit value is changing in</span><br><span class="line">Git 2.0 from &#x27;matching&#x27; to &#x27;simple&#x27;. To squelch this message</span><br><span class="line">and maintain the current behavior after the default changes, use:</span><br><span class="line"></span><br><span class="line">  git config --global push.default matching</span><br><span class="line"></span><br><span class="line">To squelch this message and adopt the new behavior now, use:</span><br><span class="line"></span><br><span class="line">  git config --global push.default simple</span><br><span class="line"></span><br><span class="line">See &#x27;git help config&#x27; and search for &#x27;push.default&#x27; for further information.</span><br><span class="line">(the &#x27;simple&#x27; mode was introduced in Git 1.7.11. Use the similar mode</span><br><span class="line">&#x27;current&#x27; instead of &#x27;simple&#x27; if you sometimes use older versions of Git)</span><br><span class="line"></span><br><span class="line">Username for &#x27;https://gitee.com&#x27;: zdevops</span><br><span class="line">Password for &#x27;https://zdevops@gitee.com&#x27;: </span><br><span class="line">Counting objects: 9, done.</span><br><span class="line">Delta compression using up to 8 threads.</span><br><span class="line">Compressing objects: 100% (4/4), done.</span><br><span class="line">Writing objects: 100% (5/5), 456 bytes | 0 bytes/s, done.</span><br><span class="line">Total 5 (delta 2), reused 0 (delta 0)</span><br><span class="line">remote: Powered by GITEE.COM [GNK-6.3]</span><br><span class="line">To https://gitee.com/zdevops/k8s-yaml.git</span><br><span class="line">   1d00559..f5ba03b  main -&gt; main</span><br></pre></td></tr></table></figure><p>查看 Gitee 在线代码仓库是否有变更。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-72.png" alt="kubesphere-projects-lstack-statefulsets-mysql-72"></p><p>在个人的办公电脑上，同步更新后的代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更新代码</span></span><br><span class="line">k8s-yaml[main] % git pull</span><br><span class="line">remote: Enumerating objects: 9, done.</span><br><span class="line">remote: Counting objects: 100% (9/9), done.</span><br><span class="line">remote: Compressing objects: 100% (4/4), done.</span><br><span class="line">remote: Total 5 (delta 2), reused 0 (delta 0), pack-reused 0</span><br><span class="line">Unpacking objects: 100% (5/5), 436 bytes | 87.00 KiB/s, done.</span><br><span class="line">From https://gitee.com/zdevops/k8s-yaml</span><br><span class="line">   1d00559..f5ba03b  main       -&gt; gitee/main</span><br><span class="line">Updating 1d00559..f5ba03b</span><br><span class="line">Fast-forward</span><br><span class="line"> mysql/single/mysql-sts.yaml | 2 ++</span><br><span class="line"> 1 file changed, 2 insertions(+)</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步更新后的代码到Github</span></span><br><span class="line">k8s-yaml[main] % git push -u origin</span><br><span class="line">Enter passphrase for key &#x27;/Users/z/.ssh/id_rsa&#x27;:</span><br><span class="line">Enumerating objects: 9, done.</span><br><span class="line">Counting objects: 100% (9/9), done.</span><br><span class="line">Delta compression using up to 8 threads</span><br><span class="line">Compressing objects: 100% (4/4), done.</span><br><span class="line">Writing objects: 100% (5/5), 456 bytes | 456.00 KiB/s, done.</span><br><span class="line">Total 5 (delta 2), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Resolving deltas: 100% (2/2), completed with 2 local objects.</span><br><span class="line">To github.com:devops/k8s-yaml.git</span><br><span class="line">   1d00559..f5ba03b  main -&gt; main</span><br><span class="line">Branch &#x27;main&#x27; set up to track remote branch &#x27;main&#x27; from &#x27;origin&#x27;.</span><br></pre></td></tr></table></figure><p>查看 GitHub 在线代码仓库是否有变更。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-73.png" alt="kubesphere-projects-lstack-statefulsets-mysql-73"></p><h3 id="3-7-再次体验-GitOps"><a href="#3-7-再次体验-GitOps" class="headerlink" title="3.7.再次体验 GitOps"></a>3.7.再次体验 GitOps</h3><p><strong>模拟一个业务场景，再次体验一下 GitOps。</strong></p><ul><li><p>MySQL 上线运行后，由于业务量上涨，初始配置参数中的 <strong>max_connections</strong> 太小了，需要增大。</p></li><li><p>配置参数调整完成后，更新线上配置，并重启服务(生产环境数据库不要轻易重启，这种需求可以用临时修改解决)。</p></li><li><p>这里只是模拟一个简单的例子，带大家体验 GitOps，实际使用中所有的配置文件都建议使用 Git 进行版本控制。</p></li></ul><p>编辑本地 Git 仓库 MySQL 资源配置清单中的 <strong>mysql-cfm.yaml</strong> 文件，修改 <strong>max_connections</strong>，从 512 变成 1024。</p><p>提交修改到 Git 在线仓库。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看修改状态</span></span><br><span class="line">k8s-yaml[main*] % git status</span><br><span class="line">On branch main</span><br><span class="line">Your branch is up to date with &#x27;origin/main&#x27;.</span><br><span class="line"></span><br><span class="line">Changes not staged for commit:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)</span><br><span class="line">  (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory)</span><br><span class="line">modified:   mysql/single/mysql-cfm.yaml</span><br><span class="line"></span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br><span class="line"></span><br><span class="line">k8s-yaml[main*] % git diff</span><br><span class="line">diff --git a/mysql/single/mysql-cfm.yaml b/mysql/single/mysql-cfm.yaml</span><br><span class="line">index e24d96d..50d1778 100644</span><br><span class="line">--- a/mysql/single/mysql-cfm.yaml</span><br><span class="line">+++ b/mysql/single/mysql-cfm.yaml</span><br><span class="line">@@ -10,7 +10,7 @@ data:</span><br><span class="line">     lock_wait_timeout = 3600</span><br><span class="line">     open_files_limit    = 65535</span><br><span class="line">     back_log = 1024</span><br><span class="line">-    max_connections = 512</span><br><span class="line">+    max_connections = 1024</span><br><span class="line">     max_connect_errors = 1000000</span><br><span class="line">     table_open_cache = 1024</span><br><span class="line">     table_definition_cache = 1024</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交本地修改</span></span><br><span class="line">k8s-yaml[main*] % git commit -am &#x27;修改mysql-cnf中max_connections的值&#x27;</span><br><span class="line">[main 180f97a] 修改mysql-cnf中max_connections的值</span><br><span class="line"> 1 file changed, 1 insertion(+), 1 deletion(-)</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交到Github</span></span><br><span class="line">k8s-yaml[main] % git push</span><br><span class="line">Enter passphrase for key &#x27;/Users/z/.ssh/id_rsa&#x27;:</span><br><span class="line">Enumerating objects: 9, done.</span><br><span class="line">Counting objects: 100% (9/9), done.</span><br><span class="line">Delta compression using up to 8 threads</span><br><span class="line">Compressing objects: 100% (4/4), done.</span><br><span class="line">Writing objects: 100% (5/5), 447 bytes | 447.00 KiB/s, done.</span><br><span class="line">Total 5 (delta 2), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Resolving deltas: 100% (2/2), completed with 2 local objects.</span><br><span class="line">To github.com:devops/k8s-yaml.git</span><br><span class="line">   f5ba03b..180f97a  main -&gt; main</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步到Gitee</span></span><br><span class="line">k8s-yaml[main] % git push -u gitee</span><br><span class="line">Enumerating objects: 9, done.</span><br><span class="line">Counting objects: 100% (9/9), done.</span><br><span class="line">Delta compression using up to 8 threads</span><br><span class="line">Compressing objects: 100% (4/4), done.</span><br><span class="line">Writing objects: 100% (5/5), 447 bytes | 447.00 KiB/s, done.</span><br><span class="line">Total 5 (delta 2), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Powered by GITEE.COM [GNK-6.3]</span><br><span class="line">To https://gitee.com/zdevops/k8s-yaml.git</span><br><span class="line">   f5ba03b..180f97a  main -&gt; main</span><br><span class="line">Branch &#x27;main&#x27; set up to track remote branch &#x27;main&#x27; from &#x27;gitee&#x27;.</span><br></pre></td></tr></table></figure><p>登录运维管理节点，更新 Git 代码，并重新运行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 k8s-yaml]# git pull</span><br><span class="line">remote: Enumerating objects: 9, done.</span><br><span class="line">remote: Counting objects: 100% (9/9), done.</span><br><span class="line">remote: Compressing objects: 100% (4/4), done.</span><br><span class="line">remote: Total 5 (delta 2), reused 0 (delta 0), pack-reused 0</span><br><span class="line">Unpacking objects: 100% (5/5), done.</span><br><span class="line">From https://gitee.com/zdevops/k8s-yaml</span><br><span class="line">   f5ba03b..180f97a  main       -&gt; origin/main</span><br><span class="line">Updating f5ba03b..180f97a</span><br><span class="line">Fast-forward</span><br><span class="line"> mysql/single/mysql-cfm.yaml | 2 +-</span><br><span class="line"> 1 file changed, 1 insertion(+), 1 deletion(-)</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl apply -f mysql/single/</span><br><span class="line">configmap/mysql-cnf configured</span><br><span class="line">service/mysql-external unchanged</span><br><span class="line">secret/mysql-secret unchanged</span><br><span class="line">statefulset.apps/mysql configured</span><br><span class="line">service/mysql-headless unchanged</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看ConfigMap的变化</span></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl get configmaps mysql-cnf -n lstack -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  custom.cnf: |-</span><br><span class="line">    [mysqld]</span><br><span class="line">    #performance setttings</span><br><span class="line">    lock_wait_timeout = 3600</span><br><span class="line">    open_files_limit    = 65535</span><br><span class="line">    back_log = 1024</span><br><span class="line">    max_connections = 1024</span><br><span class="line">    max_connect_errors = 1000000</span><br><span class="line">    table_open_cache = 1024</span><br><span class="line">    table_definition_cache = 1024</span><br><span class="line">    thread_stack = 512K</span><br><span class="line">    sort_buffer_size = 4M</span><br><span class="line">    join_buffer_size = 4M</span><br><span class="line">    read_buffer_size = 8M</span><br><span class="line">    read_rnd_buffer_size = 4M</span><br><span class="line">    bulk_insert_buffer_size = 64M</span><br><span class="line">    thread_cache_size = 768</span><br><span class="line">    interactive_timeout = 600</span><br><span class="line">    wait_timeout = 600</span><br><span class="line">    tmp_table_size = 32M</span><br><span class="line">    max_heap_table_size = 32M</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:&#123;&quot;custom.cnf&quot;:&quot;[mysqld]\n#performance setttings\nlock_wait_timeout = 3600\nopen_files_limit    = 65535\nback_log = 1024\nmax_connections = 1024\nmax_connect_errors = 1000000\ntable_open_cache = 1024\ntable_definition_cache = 1024\nthread_stack = 512K\nsort_buffer_size = 4M\njoin_buffer_size = 4M\nread_buffer_size = 8M\nread_rnd_buffer_size = 4M\nbulk_insert_buffer_size = 64M\nthread_cache_size = 768\ninteractive_timeout = 600\nwait_timeout = 600\ntmp_table_size = 32M\nmax_heap_table_size = 32M&quot;&#125;,&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;mysql-cnf&quot;,&quot;namespace&quot;:&quot;lstack&quot;&#125;&#125;</span><br><span class="line">  creationTimestamp: &quot;2022-05-12T07:20:07Z&quot;</span><br><span class="line">  name: mysql-cnf</span><br><span class="line">  namespace: lstack</span><br><span class="line">  resourceVersion: &quot;8928391&quot;</span><br><span class="line">  uid: 1b7322cf-f11e-445d-a2ba-b42a90ade469</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启mysql pod使配置生效</span></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl delete -f mysql/single/mysql-sts.yaml </span><br><span class="line">statefulset.apps &quot;mysql&quot; deleted</span><br><span class="line">service &quot;mysql-headless&quot; deleted</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl apply -f mysql/single/mysql-sts.yaml </span><br><span class="line">statefulset.apps/mysql created</span><br><span class="line">service/mysql-headless created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看mysql容器内部配置是否更新</span></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# kubectl exec  mysql-0  -n lstack -- cat /etc/mysql/conf.d/custom.cnf</span><br><span class="line">[mysqld]</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">performance setttings</span></span><br><span class="line">lock_wait_timeout = 3600</span><br><span class="line">open_files_limit    = 65535</span><br><span class="line">back_log = 1024</span><br><span class="line">max_connections = 1024</span><br><span class="line">max_connect_errors = 1000000</span><br><span class="line">table_open_cache = 1024</span><br><span class="line">table_definition_cache = 1024</span><br><span class="line">thread_stack = 512K</span><br><span class="line">sort_buffer_size = 4M</span><br><span class="line">join_buffer_size = 4M</span><br><span class="line">read_buffer_size = 8M</span><br><span class="line">read_rnd_buffer_size = 4M</span><br><span class="line">bulk_insert_buffer_size = 64M</span><br><span class="line">thread_cache_size = 768</span><br><span class="line">interactive_timeout = 600</span><br><span class="line">wait_timeout = 600</span><br><span class="line">tmp_table_size = 32M</span><br></pre></td></tr></table></figure><p><strong>切记！</strong> 上面的例子只是让大家体验 GitOps，生产环境不要轻易重启数据库服务器，除非你知道自己在干什么。</p><p>现在经过验证，我们的 MySQL 的配置可用且比较稳定，我们把这个好的状态记录下来，避免以后修改变更弄坏了，再找不回原来正确的配置。</p><p>在我们的个人电脑上给当前的 Git 代码打个 Tag，记录当前的状态 (也可以通过在线仓库的管理界面操作)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打tag -a tag名字 -m tag描述</span></span><br><span class="line">k8s-yaml[main] % git tag -a v0.1  -m &#x27;mysql version v0.1&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看现有tag</span></span><br><span class="line">k8s-yaml[main] % git tag -l</span><br><span class="line">v0.1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看tag详细信息</span></span><br><span class="line">k8s-yaml[main] % git show v0.1</span><br><span class="line">tag v0.1</span><br><span class="line">Tagger: devops &lt;devops@163.com&gt;</span><br><span class="line">Date:   Thu May 12 18:15:34 2022 +0800</span><br><span class="line"></span><br><span class="line">mysql version v0.1</span><br><span class="line"></span><br><span class="line">commit 180f97ac96da504a0b46eb4871ef423f64fde093 (HEAD -&gt; main, tag: v0.1, origin/main, origin/HEAD, gitee/main)</span><br><span class="line">Author: devops &lt;devops@163.com&gt;</span><br><span class="line">Date:   Thu May 12 17:48:18 2022 +0800</span><br><span class="line"></span><br><span class="line">    修改mysql-cnf中max_connections的值</span><br><span class="line"></span><br><span class="line">diff --git a/mysql/single/mysql-cfm.yaml b/mysql/single/mysql-cfm.yaml</span><br><span class="line">index e24d96d..50d1778 100644</span><br><span class="line">--- a/mysql/single/mysql-cfm.yaml</span><br><span class="line">+++ b/mysql/single/mysql-cfm.yaml</span><br><span class="line">@@ -10,7 +10,7 @@ data:</span><br><span class="line">     lock_wait_timeout = 3600</span><br><span class="line">     open_files_limit    = 65535</span><br><span class="line">     back_log = 1024</span><br><span class="line">-    max_connections = 512</span><br><span class="line">+    max_connections = 1024</span><br><span class="line">     max_connect_errors = 1000000</span><br><span class="line">     table_open_cache = 1024</span><br><span class="line">     table_definition_cache = 1024</span><br><span class="line">     </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将tag推送到远程服务器</span></span><br><span class="line">k8s-yaml[main] % git push -u origin --tags</span><br><span class="line">Enter passphrase for key &#x27;/Users/z/.ssh/id_rsa&#x27;:</span><br><span class="line">Enumerating objects: 1, done.</span><br><span class="line">Counting objects: 100% (1/1), done.</span><br><span class="line">Writing objects: 100% (1/1), 157 bytes | 157.00 KiB/s, done.</span><br><span class="line">Total 1 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">To github.com:devops/k8s-yaml.git</span><br><span class="line"> * [new tag]         v0.1 -&gt; v0.1</span><br><span class="line"></span><br><span class="line">k8s-yaml[main] % git push -u gitee --tags</span><br><span class="line">Enumerating objects: 1, done.</span><br><span class="line">Counting objects: 100% (1/1), done.</span><br><span class="line">Writing objects: 100% (1/1), 157 bytes | 157.00 KiB/s, done.</span><br><span class="line">Total 1 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">remote: Powered by GITEE.COM [GNK-6.3]</span><br><span class="line">To https://gitee.com/zdevops/k8s-yaml.git</span><br><span class="line"> * [new tag]         v0.1 -&gt; v0.1</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">线上服务器验证（图略）</span></span><br></pre></td></tr></table></figure><p>运维管理服务器更新代码，并切换到指定 tag(<strong>注意！使用 Git 一定要养成每次操作前 git pull</strong> 这种习惯)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 更新代码</span></span></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# git pull</span><br><span class="line">remote: Enumerating objects: 1, done.</span><br><span class="line">remote: Counting objects: 100% (1/1), done.</span><br><span class="line">remote: Total 1 (delta 0), reused 0 (delta 0), pack-reused 0</span><br><span class="line">Unpacking objects: 100% (1/1), done.</span><br><span class="line">From https://gitee.com/zdevops/k8s-yaml</span><br><span class="line"> * [new tag]         v0.1       -&gt; v0.1</span><br><span class="line">Already up-to-date.</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# git status</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">On branch main</span></span><br><span class="line">nothing to commit, working directory clean</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 切换到v0.1</span></span></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# git checkout -b v0.1</span><br><span class="line">Switched to a new branch &#x27;v0.1&#x27;</span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 k8s-yaml]# git status</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">On branch v0.1</span></span><br><span class="line">nothing to commit, working directory clean</span><br></pre></td></tr></table></figure><p>通过上面的几波操作，我们可以看到，我们所有的配置变更都采用了 Git 管理，完整的记录了配置的全生命周期管理，通过给仓库打分支或是 tag，可以方便我们切换到任意已记录状态。</p><hr><h2 id="4-高可用部署-MySQL-预留占坑"><a href="#4-高可用部署-MySQL-预留占坑" class="headerlink" title="4. 高可用部署 MySQL(预留占坑)"></a>4. 高可用部署 MySQL(预留占坑)</h2><p>暂时没有高可用部署的需求，因此不涉及高可用模式的 MySQL 的部署，但是有一些思考留着占坑。</p><h3 id="4-1-目前的做法"><a href="#4-1-目前的做法" class="headerlink" title="4.1. 目前的做法"></a>4.1. 目前的做法</h3><ul><li>不给自己找麻烦，有高可用需求直接买云服务商的 RDS。</li><li>实在需要自己搭建，在 K8S 集群之外部署主从。</li></ul><h3 id="4-2-以后可能的方向"><a href="#4-2-以后可能的方向" class="headerlink" title="4.2. 以后可能的方向"></a>4.2. 以后可能的方向</h3><ul><li>K8S 上的 MySQL 主从部署</li><li>Operator</li><li>Helm</li></ul><hr><h2 id="5-遗留问题"><a href="#5-遗留问题" class="headerlink" title="5.  遗留问题"></a>5.  遗留问题</h2><p>此部分内容也是运维 MySQL 必备的技能，有些内容我也没有经验无法分享，有些内容会在 &lt;&lt; 基于 KubeSphere 的 Kubernetes 生产实践之路 &gt;&gt; 系列文档中介绍。</p><ul><li>MySQL 数据库备份</li><li>MySQL 高可用部署</li><li>MySQL 安全加固</li><li>MySQL 调优</li></ul><hr><h2 id="6-MySQL-性能-基准-测试"><a href="#6-MySQL-性能-基准-测试" class="headerlink" title="6. MySQL 性能 (基准) 测试"></a>6. MySQL 性能 (基准) 测试</h2><p>运维一定要做到对自己的运维环境<strong>心中有数</strong>，MySQL 上线前一定要进行性能 (基准测试)，有助于了解我们的数据库服务器能达到的理想状态。本次介绍的只是皮毛，只是告诉大家一些基本入门的知识，更细节、更深入的内容请参考其他更专业的文档。</p><h3 id="6-1-性能-基准-测试工具安装"><a href="#6-1-性能-基准-测试工具安装" class="headerlink" title="6.1. 性能 (基准) 测试工具安装"></a>6.1. 性能 (基准) 测试工具安装</h3><blockquote><p><strong>01-工具选型 (sysbench)</strong></p></blockquote><ul><li>云厂商展示自家数据库产品性能都用这个工具</li><li>据说很多 DBA 也喜欢用</li></ul><blockquote><p><strong>02-sysbench 工具安装</strong></p></blockquote><ul><li>安装工具</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入软件源</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">~</span>]<span class="comment"># curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash</span></span><br><span class="line"></span><br><span class="line"><span class="string">Detected</span> <span class="string">operating</span> <span class="string">system</span> <span class="string">as</span> <span class="string">centos/7.</span></span><br><span class="line"><span class="string">Checking</span> <span class="string">for</span> <span class="string">curl...</span></span><br><span class="line"><span class="string">Detected</span> <span class="string">curl...</span></span><br><span class="line"><span class="attr">Downloading repository file:</span> <span class="string">https://packagecloud.io/install/repositories/akopytov/sysbench/config_file.repo?os=centos&amp;dist=7&amp;source=script</span></span><br><span class="line"><span class="string">done.</span></span><br><span class="line"><span class="string">Installing</span> <span class="string">pygpgme</span> <span class="string">to</span> <span class="string">verify</span> <span class="string">GPG</span> <span class="string">signatures...</span></span><br><span class="line"><span class="attr">Loaded plugins:</span> <span class="string">fastestmirror</span></span><br><span class="line"><span class="string">Loading</span> <span class="string">mirror</span> <span class="string">speeds</span> <span class="string">from</span> <span class="string">cached</span> <span class="string">hostfile</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">base:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">centos-gluster9:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">extras:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">updates:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"><span class="string">akopytov_sysbench-source/signature</span>                                                 <span class="string">|</span>  <span class="number">833</span> <span class="string">B</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">Retrieving</span> <span class="string">key</span> <span class="string">from</span> <span class="string">https://packagecloud.io/akopytov/sysbench/gpgkey</span></span><br><span class="line"><span class="attr">Importing GPG key 0x04DCFD39:</span></span><br><span class="line"> <span class="attr">Userid     :</span> <span class="string">&quot;https://packagecloud.io/akopytov/sysbench-prerelease (https://packagecloud.io/docs#gpg_signing) &lt;support@packagecloud.io&gt;&quot;</span></span><br><span class="line"> <span class="attr">Fingerprint:</span> <span class="number">9789 </span><span class="string">8d69</span> <span class="string">f99e</span> <span class="string">e5ca</span> <span class="string">c462</span> <span class="string">a0f8</span> <span class="string">cf10</span> <span class="number">4890 </span><span class="string">04dc</span> <span class="string">fd39</span></span><br><span class="line"> <span class="attr">From       :</span> <span class="string">https://packagecloud.io/akopytov/sysbench/gpgkey</span></span><br><span class="line"><span class="string">akopytov_sysbench-source/signature</span>                                                 <span class="string">|</span> <span class="number">1.0</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:01</span> <span class="string">!!!</span> </span><br><span class="line"><span class="string">base</span>                                                                               <span class="string">|</span> <span class="number">3.6</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">centos-gluster9</span>                                                                    <span class="string">|</span> <span class="number">3.0</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">extras</span>                                                                             <span class="string">|</span> <span class="number">2.9</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">updates</span>                                                                            <span class="string">|</span> <span class="number">2.9</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">akopytov_sysbench-source/primary</span>                                                                                                <span class="string">|</span> <span class="number">2.0</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:09</span>     </span><br><span class="line"><span class="string">akopytov_sysbench-source</span>                                                                                                                         <span class="number">15</span><span class="string">/15</span></span><br><span class="line"><span class="string">Package</span> <span class="string">pygpgme-0.3-9.el7.x86_64</span> <span class="string">already</span> <span class="string">installed</span> <span class="string">and</span> <span class="string">latest</span> <span class="string">version</span></span><br><span class="line"><span class="string">Nothing</span> <span class="string">to</span> <span class="string">do</span></span><br><span class="line"><span class="string">Installing</span> <span class="string">yum-utils...</span></span><br><span class="line"><span class="attr">Loaded plugins:</span> <span class="string">fastestmirror</span></span><br><span class="line"><span class="string">Loading</span> <span class="string">mirror</span> <span class="string">speeds</span> <span class="string">from</span> <span class="string">cached</span> <span class="string">hostfile</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">base:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">centos-gluster9:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">extras:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">updates:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"><span class="string">Package</span> <span class="string">yum-utils-1.1.31-54.el7_8.noarch</span> <span class="string">already</span> <span class="string">installed</span> <span class="string">and</span> <span class="string">latest</span> <span class="string">version</span></span><br><span class="line"><span class="string">Nothing</span> <span class="string">to</span> <span class="string">do</span></span><br><span class="line"><span class="string">Generating</span> <span class="string">yum</span> <span class="string">cache</span> <span class="string">for</span> <span class="string">akopytov_sysbench...</span></span><br><span class="line"><span class="attr">Importing GPG key 0x04DCFD39:</span></span><br><span class="line"> <span class="attr">Userid     :</span> <span class="string">&quot;https://packagecloud.io/akopytov/sysbench-prerelease (https://packagecloud.io/docs#gpg_signing) &lt;support@packagecloud.io&gt;&quot;</span></span><br><span class="line"> <span class="attr">Fingerprint:</span> <span class="number">9789 </span><span class="string">8d69</span> <span class="string">f99e</span> <span class="string">e5ca</span> <span class="string">c462</span> <span class="string">a0f8</span> <span class="string">cf10</span> <span class="number">4890 </span><span class="string">04dc</span> <span class="string">fd39</span></span><br><span class="line"> <span class="attr">From       :</span> <span class="string">https://packagecloud.io/akopytov/sysbench/gpgkey</span></span><br><span class="line"><span class="string">Generating</span> <span class="string">yum</span> <span class="string">cache</span> <span class="string">for</span> <span class="string">akopytov_sysbench-source...</span></span><br><span class="line"></span><br><span class="line"><span class="string">The</span> <span class="string">repository</span> <span class="string">is</span> <span class="string">setup!</span> <span class="string">You</span> <span class="string">can</span> <span class="string">now</span> <span class="string">install</span> <span class="string">packages.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装sysbench</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">~</span>]<span class="comment"># yum install sysbench -y</span></span><br><span class="line"><span class="attr">Loaded plugins:</span> <span class="string">fastestmirror</span></span><br><span class="line"><span class="string">Loading</span> <span class="string">mirror</span> <span class="string">speeds</span> <span class="string">from</span> <span class="string">cached</span> <span class="string">hostfile</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">base:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">centos-gluster9:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">extras:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"> <span class="string">*</span> <span class="attr">updates:</span> <span class="string">mirrors.aliyun.com</span></span><br><span class="line"><span class="string">akopytov_sysbench/x86_64/signature</span>                                                                                  <span class="string">|</span>  <span class="number">833</span> <span class="string">B</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">akopytov_sysbench/x86_64/signature</span>                                                                                  <span class="string">|</span> <span class="number">1.0</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span> <span class="string">!!!</span> </span><br><span class="line"><span class="string">akopytov_sysbench-source/signature</span>                                                                                  <span class="string">|</span>  <span class="number">833</span> <span class="string">B</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">akopytov_sysbench-source/signature</span>                                                                                  <span class="string">|</span> <span class="number">1.0</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span> <span class="string">!!!</span> </span><br><span class="line"><span class="string">Resolving</span> <span class="string">Dependencies</span></span><br><span class="line"><span class="string">--&gt;</span> <span class="string">Running</span> <span class="string">transaction</span> <span class="string">check</span></span><br><span class="line"><span class="string">---&gt;</span> <span class="string">Package</span> <span class="string">sysbench.x86_64</span> <span class="number">0</span><span class="string">:1.0.20-1.el7</span> <span class="string">will</span> <span class="string">be</span> <span class="string">installed</span></span><br><span class="line"><span class="string">--&gt;</span> <span class="attr">Processing Dependency:</span> <span class="string">libpq.so.5()(64bit)</span> <span class="attr">for package:</span> <span class="string">sysbench-1.0.20-1.el7.x86_64</span></span><br><span class="line"><span class="string">--&gt;</span> <span class="string">Running</span> <span class="string">transaction</span> <span class="string">check</span></span><br><span class="line"><span class="string">---&gt;</span> <span class="string">Package</span> <span class="string">postgresql-libs.x86_64</span> <span class="number">0</span><span class="string">:9.2.24-7.el7_9</span> <span class="string">will</span> <span class="string">be</span> <span class="string">installed</span></span><br><span class="line"><span class="string">--&gt;</span> <span class="string">Finished</span> <span class="string">Dependency</span> <span class="string">Resolution</span></span><br><span class="line"></span><br><span class="line"><span class="string">Dependencies</span> <span class="string">Resolved</span></span><br><span class="line"></span><br><span class="line"><span class="string">===========================================================================================================================================</span></span><br><span class="line"> <span class="string">Package</span>                            <span class="string">Arch</span>                      <span class="string">Version</span>                           <span class="string">Repository</span>                            <span class="string">Size</span></span><br><span class="line"><span class="string">===========================================================================================================================================</span></span><br><span class="line"><span class="attr">Installing:</span></span><br><span class="line"> <span class="string">sysbench</span>                           <span class="string">x86_64</span>                    <span class="number">1.0</span><span class="number">.20</span><span class="number">-1.</span><span class="string">el7</span>                      <span class="string">akopytov_sysbench</span>                    <span class="number">430</span> <span class="string">k</span></span><br><span class="line"><span class="attr">Installing for dependencies:</span></span><br><span class="line"> <span class="string">postgresql-libs</span>                    <span class="string">x86_64</span>                    <span class="number">9.2</span><span class="number">.24</span><span class="number">-7.</span><span class="string">el7_9</span>                    <span class="string">updates</span>                              <span class="number">235</span> <span class="string">k</span></span><br><span class="line"></span><br><span class="line"><span class="string">Transaction</span> <span class="string">Summary</span></span><br><span class="line"><span class="string">===========================================================================================================================================</span></span><br><span class="line"><span class="string">Install</span>  <span class="number">1</span> <span class="string">Package</span> <span class="string">(+1</span> <span class="string">Dependent</span> <span class="string">package)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Total download size:</span> <span class="number">665</span> <span class="string">k</span></span><br><span class="line"><span class="attr">Installed size:</span> <span class="number">1.8</span> <span class="string">M</span></span><br><span class="line"><span class="attr">Downloading packages:</span></span><br><span class="line"><span class="string">(1/2):</span> <span class="string">postgresql-libs-9.2.24-7.el7_9.x86_64.rpm</span>                                                                    <span class="string">|</span> <span class="number">235</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:00</span>     </span><br><span class="line"><span class="string">(2/2):</span> <span class="string">sysbench-1.0.20-1.el7.x86_64.rpm</span>                                                                             <span class="string">|</span> <span class="number">430</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:03</span>     </span><br><span class="line"><span class="string">-------------------------------------------------------------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="string">Total</span>                                                                                                      <span class="number">204</span> <span class="string">kB/s</span> <span class="string">|</span> <span class="number">665</span> <span class="string">kB</span>  <span class="number">00</span><span class="string">:00:03</span>     </span><br><span class="line"><span class="string">Running</span> <span class="string">transaction</span> <span class="string">check</span></span><br><span class="line"><span class="string">Running</span> <span class="string">transaction</span> <span class="string">test</span></span><br><span class="line"><span class="string">Transaction</span> <span class="string">test</span> <span class="string">succeeded</span></span><br><span class="line"><span class="string">Running</span> <span class="string">transaction</span></span><br><span class="line">  <span class="attr">Installing :</span> <span class="string">postgresql-libs-9.2.24-7.el7_9.x86_64</span>                                                                                   <span class="number">1</span><span class="string">/2</span> </span><br><span class="line">  <span class="attr">Installing :</span> <span class="string">sysbench-1.0.20-1.el7.x86_64</span>                                                                                            <span class="number">2</span><span class="string">/2</span> </span><br><span class="line">  <span class="attr">Verifying  :</span> <span class="string">postgresql-libs-9.2.24-7.el7_9.x86_64</span>                                                                                   <span class="number">1</span><span class="string">/2</span> </span><br><span class="line">  <span class="attr">Verifying  :</span> <span class="string">sysbench-1.0.20-1.el7.x86_64</span>                                                                                            <span class="number">2</span><span class="string">/2</span> </span><br><span class="line"></span><br><span class="line"><span class="attr">Installed:</span></span><br><span class="line">  <span class="string">sysbench.x86_64</span> <span class="number">0</span><span class="string">:1.0.20-1.el7</span>                                                                                                           </span><br><span class="line"></span><br><span class="line"><span class="attr">Dependency Installed:</span></span><br><span class="line">  <span class="string">postgresql-libs.x86_64</span> <span class="number">0</span><span class="string">:9.2.24-7.el7_9</span>                                                                                                  </span><br><span class="line"></span><br><span class="line"><span class="string">Complete!</span></span><br></pre></td></tr></table></figure><ul><li>验证-执行命令查看版本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# sysbench --version</span><br><span class="line">sysbench 1.0.20</span><br></pre></td></tr></table></figure><h3 id="6-2-性能-基准-测试"><a href="#6-2-性能-基准-测试" class="headerlink" title="6.2. 性能 (基准) 测试"></a>6.2. 性能 (基准) 测试</h3><blockquote><p><strong>01-测试方案</strong></p></blockquote><ul><li><p>测试参数</p></li><li><table><thead><tr><th align="center">指标</th><th align="center">值</th></tr></thead><tbody><tr><td align="center">线程数</td><td align="center">8&#x2F;16&#x2F;32</td></tr><tr><td align="center">单表数据量</td><td align="center">100000</td></tr><tr><td align="center">表数量</td><td align="center">16</td></tr></tbody></table><p>性能指标</p><table><thead><tr><th align="center">指标</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">TPS</td><td align="center">Transactions Per Second ，即数据库每秒执行的事务数，以 commit 成功次数为准。</td></tr><tr><td align="center">QPS</td><td align="center">Queries Per Second ，即数据库每秒执行的 SQL 数（含 insert、select、update、delete 等）。</td></tr><tr><td align="center">RT</td><td align="center">Response Time ，响应时间。包括平均响应时间、最小响应时间、最大响应时间、每个响应时间的查询占比。比较需要重点关注的是，前 95-99% 的最大响应时间。因为它决定了大多数情况下的短板。</td></tr><tr><td align="center">Concurrency Threads</td><td align="center">并发量，每秒可处理的查询请求的数量。</td></tr></tbody></table></li></ul><blockquote><p><strong>02-准备测试数据</strong></p></blockquote><p>使用我们在 k8s 上创建的数据库，涉及数据库操作命令，需要<strong>终端</strong>登录到容器内运行。</p><p>提前创建测试用数据库 <strong>sbtest</strong>，并赋予 root 从任意 IP 远程管理所有数据库的权限。</p><p><strong>生产环境千万不要这么搞，一定要遵循最小化原则！</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">bash</span></span><br><span class="line">root@mysql-0:/# mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 4</span><br><span class="line">Server version: 5.7.38 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2022, Oracle and/or its affiliates.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">create database sbtest;</span></span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">grant all privileges on *.* to <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> identified by <span class="string">&#x27;P@88w0rd&#x27;</span> with grant option;</span></span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.02 sec)</span><br></pre></td></tr></table></figure><ul><li>测试数据库是否能连接</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装mysql客户端，下面的示例是在k8s节点上安装的，由于系统是最小化安装，所有会安装很多依赖。实际测试可以起一个mysql的pod或是用其他的mysql客户端工具。</span></span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 ~]# yum install mysql -y</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * centos-gluster9: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">akopytov_sysbench/x86_64/signature                                                                                  |  833 B  00:00:00     </span><br><span class="line">akopytov_sysbench/x86_64/signature                                                                                  | 1.0 kB  00:00:00 !!! </span><br><span class="line">akopytov_sysbench-source/signature                                                                                  |  833 B  00:00:00     </span><br><span class="line">akopytov_sysbench-source/signature                                                                                  | 1.0 kB  00:00:00 !!! </span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package mariadb.x86_64 1:5.5.68-1.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Sys::Hostname) <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(IPC::Open3) <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Getopt::Long) <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(File::Temp) <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Fcntl) <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Exporter) <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: /usr/bin/perl <span class="keyword">for</span> package: 1:mariadb-5.5.68-1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl.x86_64 4:5.16.3-299.el7_9 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl-libs = 4:5.16.3-299.el7_9 <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Socket) &gt;= 1.3 <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Scalar::Util) &gt;= 1.10 <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl-macros <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl-libs <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(threads::shared) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(threads) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(constant) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Time::Local) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Time::HiRes) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Storable) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Socket) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Scalar::Util) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Pod::Simple::XHTML) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Pod::Simple::Search) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Filter::Util::Call) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(File::Spec::Unix) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(File::Spec::Functions) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(File::Spec) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(File::Path) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Cwd) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Carp) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libperl.so()(64bit) <span class="keyword">for</span> package: 4:perl-5.16.3-299.el7_9.x86_64</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Exporter.noarch 0:5.68-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-File-Temp.noarch 0:0.23.01-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Getopt-Long.noarch 0:2.40-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Pod::Usage) &gt;= 1.14 <span class="keyword">for</span> package: perl-Getopt-Long-2.40-3.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Text::ParseWords) <span class="keyword">for</span> package: perl-Getopt-Long-2.40-3.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Carp.noarch 0:1.26-244.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-File-Path.noarch 0:2.09-2.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Filter.x86_64 0:1.49-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-PathTools.x86_64 0:3.40-5.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Pod-Simple.noarch 1:3.28-4.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Pod::Escapes) &gt;= 1.04 <span class="keyword">for</span> package: 1:perl-Pod-Simple-3.28-4.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Encode) <span class="keyword">for</span> package: 1:perl-Pod-Simple-3.28-4.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Pod-Usage.noarch 0:1.63-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(Pod::Text) &gt;= 3.15 <span class="keyword">for</span> package: perl-Pod-Usage-1.63-3.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl-Pod-Perldoc <span class="keyword">for</span> package: perl-Pod-Usage-1.63-3.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Scalar-List-Utils.x86_64 0:1.27-248.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Socket.x86_64 0:2.010-5.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Storable.x86_64 0:2.45-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Text-ParseWords.noarch 0:3.29-4.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Time-HiRes.x86_64 4:1.9725-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Time-Local.noarch 0:1.2300-2.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-constant.noarch 0:1.27-2.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-libs.x86_64 4:5.16.3-299.el7_9 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-macros.x86_64 4:5.16.3-299.el7_9 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-threads.x86_64 0:1.87-4.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-threads-shared.x86_64 0:1.43-6.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Encode.x86_64 0:2.51-7.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Pod-Escapes.noarch 1:1.04-299.el7_9 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-Pod-Perldoc.noarch 0:3.20-4.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(parent) <span class="keyword">for</span> package: perl-Pod-Perldoc-3.20-4.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: perl(HTTP::Tiny) <span class="keyword">for</span> package: perl-Pod-Perldoc-3.20-4.el7.noarch</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-podlators.noarch 0:2.5.1-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-HTTP-Tiny.noarch 0:0.033-3.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package perl-parent.noarch 1:0.225-244.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">===========================================================================================================================================</span><br><span class="line"> Package                                  Arch                     Version                                 Repository                 Size</span><br><span class="line">===========================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> mariadb                                  x86_64                   1:5.5.68-1.el7                          base                      8.8 M</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> perl                                     x86_64                   4:5.16.3-299.el7_9                      updates                   8.0 M</span><br><span class="line"> perl-Carp                                noarch                   1.26-244.el7                            base                       19 k</span><br><span class="line"> perl-Encode                              x86_64                   2.51-7.el7                              base                      1.5 M</span><br><span class="line"> perl-Exporter                            noarch                   5.68-3.el7                              base                       28 k</span><br><span class="line"> perl-File-Path                           noarch                   2.09-2.el7                              base                       26 k</span><br><span class="line"> perl-File-Temp                           noarch                   0.23.01-3.el7                           base                       56 k</span><br><span class="line"> perl-Filter                              x86_64                   1.49-3.el7                              base                       76 k</span><br><span class="line"> perl-Getopt-Long                         noarch                   2.40-3.el7                              base                       56 k</span><br><span class="line"> perl-HTTP-Tiny                           noarch                   0.033-3.el7                             base                       38 k</span><br><span class="line"> perl-PathTools                           x86_64                   3.40-5.el7                              base                       82 k</span><br><span class="line"> perl-Pod-Escapes                         noarch                   1:1.04-299.el7_9                        updates                    52 k</span><br><span class="line"> perl-Pod-Perldoc                         noarch                   3.20-4.el7                              base                       87 k</span><br><span class="line"> perl-Pod-Simple                          noarch                   1:3.28-4.el7                            base                      216 k</span><br><span class="line"> perl-Pod-Usage                           noarch                   1.63-3.el7                              base                       27 k</span><br><span class="line"> perl-Scalar-List-Utils                   x86_64                   1.27-248.el7                            base                       36 k</span><br><span class="line"> perl-Socket                              x86_64                   2.010-5.el7                             base                       49 k</span><br><span class="line"> perl-Storable                            x86_64                   2.45-3.el7                              base                       77 k</span><br><span class="line"> perl-Text-ParseWords                     noarch                   3.29-4.el7                              base                       14 k</span><br><span class="line"> perl-Time-HiRes                          x86_64                   4:1.9725-3.el7                          base                       45 k</span><br><span class="line"> perl-Time-Local                          noarch                   1.2300-2.el7                            base                       24 k</span><br><span class="line"> perl-constant                            noarch                   1.27-2.el7                              base                       19 k</span><br><span class="line"> perl-libs                                x86_64                   4:5.16.3-299.el7_9                      updates                   690 k</span><br><span class="line"> perl-macros                              x86_64                   4:5.16.3-299.el7_9                      updates                    44 k</span><br><span class="line"> perl-parent                              noarch                   1:0.225-244.el7                         base                       12 k</span><br><span class="line"> perl-podlators                           noarch                   2.5.1-3.el7                             base                      112 k</span><br><span class="line"> perl-threads                             x86_64                   1.87-4.el7                              base                       49 k</span><br><span class="line"> perl-threads-shared                      x86_64                   1.43-6.el7                              base                       39 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">===========================================================================================================================================</span><br><span class="line">Install  1 Package (+27 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 20 M</span><br><span class="line">Installed size: 85 M</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/28): perl-Carp-1.26-244.el7.noarch.rpm                                                                           |  19 kB  00:00:00     </span><br><span class="line">(2/28): perl-Encode-2.51-7.el7.x86_64.rpm                                                                           | 1.5 MB  00:00:00     </span><br><span class="line">(3/28): perl-Exporter-5.68-3.el7.noarch.rpm                                                                         |  28 kB  00:00:00     </span><br><span class="line">(4/28): perl-File-Path-2.09-2.el7.noarch.rpm                                                                        |  26 kB  00:00:00     </span><br><span class="line">(5/28): perl-File-Temp-0.23.01-3.el7.noarch.rpm                                                                     |  56 kB  00:00:00     </span><br><span class="line">(6/28): perl-Filter-1.49-3.el7.x86_64.rpm                                                                           |  76 kB  00:00:00     </span><br><span class="line">(7/28): perl-Getopt-Long-2.40-3.el7.noarch.rpm                                                                      |  56 kB  00:00:00     </span><br><span class="line">(8/28): perl-HTTP-Tiny-0.033-3.el7.noarch.rpm                                                                       |  38 kB  00:00:00     </span><br><span class="line">(9/28): perl-PathTools-3.40-5.el7.x86_64.rpm                                                                        |  82 kB  00:00:00     </span><br><span class="line">(10/28): perl-5.16.3-299.el7_9.x86_64.rpm                                                                           | 8.0 MB  00:00:00     </span><br><span class="line">(11/28): perl-Pod-Perldoc-3.20-4.el7.noarch.rpm                                                                     |  87 kB  00:00:00     </span><br><span class="line">(12/28): mariadb-5.5.68-1.el7.x86_64.rpm                                                                            | 8.8 MB  00:00:00     </span><br><span class="line">(13/28): perl-Pod-Escapes-1.04-299.el7_9.noarch.rpm                                                                 |  52 kB  00:00:00     </span><br><span class="line">(14/28): perl-Pod-Simple-3.28-4.el7.noarch.rpm                                                                      | 216 kB  00:00:00     </span><br><span class="line">(15/28): perl-Scalar-List-Utils-1.27-248.el7.x86_64.rpm                                                             |  36 kB  00:00:00     </span><br><span class="line">(16/28): perl-Socket-2.010-5.el7.x86_64.rpm                                                                         |  49 kB  00:00:00     </span><br><span class="line">(17/28): perl-Storable-2.45-3.el7.x86_64.rpm                                                                        |  77 kB  00:00:00     </span><br><span class="line">(18/28): perl-Text-ParseWords-3.29-4.el7.noarch.rpm                                                                 |  14 kB  00:00:00     </span><br><span class="line">(19/28): perl-Time-HiRes-1.9725-3.el7.x86_64.rpm                                                                    |  45 kB  00:00:00     </span><br><span class="line">(20/28): perl-Pod-Usage-1.63-3.el7.noarch.rpm                                                                       |  27 kB  00:00:00     </span><br><span class="line">(21/28): perl-Time-Local-1.2300-2.el7.noarch.rpm                                                                    |  24 kB  00:00:00     </span><br><span class="line">(22/28): perl-constant-1.27-2.el7.noarch.rpm                                                                        |  19 kB  00:00:00     </span><br><span class="line">(23/28): perl-podlators-2.5.1-3.el7.noarch.rpm                                                                      | 112 kB  00:00:00     </span><br><span class="line">(24/28): perl-threads-1.87-4.el7.x86_64.rpm                                                                         |  49 kB  00:00:00     </span><br><span class="line">(25/28): perl-threads-shared-1.43-6.el7.x86_64.rpm                                                                  |  39 kB  00:00:00     </span><br><span class="line">(26/28): perl-macros-5.16.3-299.el7_9.x86_64.rpm                                                                    |  44 kB  00:00:00     </span><br><span class="line">(27/28): perl-libs-5.16.3-299.el7_9.x86_64.rpm                                                                      | 690 kB  00:00:00     </span><br><span class="line">(28/28): perl-parent-0.225-244.el7.noarch.rpm                                                                       |  12 kB  00:00:00     </span><br><span class="line">-------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                                                       14 MB/s |  20 MB  00:00:01     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : 1:perl-parent-0.225-244.el7.noarch                                                                                     1/28 </span><br><span class="line">  Installing : perl-HTTP-Tiny-0.033-3.el7.noarch                                                                                      2/28 </span><br><span class="line">  Installing : perl-podlators-2.5.1-3.el7.noarch                                                                                      3/28 </span><br><span class="line">  Installing : perl-Pod-Perldoc-3.20-4.el7.noarch                                                                                     4/28 </span><br><span class="line">  Installing : 1:perl-Pod-Escapes-1.04-299.el7_9.noarch                                                                               5/28 </span><br><span class="line">  Installing : perl-Encode-2.51-7.el7.x86_64                                                                                          6/28 </span><br><span class="line">  Installing : perl-Text-ParseWords-3.29-4.el7.noarch                                                                                 7/28 </span><br><span class="line">  Installing : perl-Pod-Usage-1.63-3.el7.noarch                                                                                       8/28 </span><br><span class="line">  Installing : 4:perl-macros-5.16.3-299.el7_9.x86_64                                                                                  9/28 </span><br><span class="line">  Installing : perl-Storable-2.45-3.el7.x86_64                                                                                       10/28 </span><br><span class="line">  Installing : perl-Exporter-5.68-3.el7.noarch                                                                                       11/28 </span><br><span class="line">  Installing : perl-constant-1.27-2.el7.noarch                                                                                       12/28 </span><br><span class="line">  Installing : perl-Socket-2.010-5.el7.x86_64                                                                                        13/28 </span><br><span class="line">  Installing : perl-Time-Local-1.2300-2.el7.noarch                                                                                   14/28 </span><br><span class="line">  Installing : perl-Carp-1.26-244.el7.noarch                                                                                         15/28 </span><br><span class="line">  Installing : 4:perl-Time-HiRes-1.9725-3.el7.x86_64                                                                                 16/28 </span><br><span class="line">  Installing : perl-PathTools-3.40-5.el7.x86_64                                                                                      17/28 </span><br><span class="line">  Installing : perl-Scalar-List-Utils-1.27-248.el7.x86_64                                                                            18/28 </span><br><span class="line">  Installing : 1:perl-Pod-Simple-3.28-4.el7.noarch                                                                                   19/28 </span><br><span class="line">  Installing : perl-File-Temp-0.23.01-3.el7.noarch                                                                                   20/28 </span><br><span class="line">  Installing : perl-File-Path-2.09-2.el7.noarch                                                                                      21/28 </span><br><span class="line">  Installing : perl-threads-shared-1.43-6.el7.x86_64                                                                                 22/28 </span><br><span class="line">  Installing : perl-threads-1.87-4.el7.x86_64                                                                                        23/28 </span><br><span class="line">  Installing : perl-Filter-1.49-3.el7.x86_64                                                                                         24/28 </span><br><span class="line">  Installing : 4:perl-libs-5.16.3-299.el7_9.x86_64                                                                                   25/28 </span><br><span class="line">  Installing : perl-Getopt-Long-2.40-3.el7.noarch                                                                                    26/28 </span><br><span class="line">  Installing : 4:perl-5.16.3-299.el7_9.x86_64                                                                                        27/28 </span><br><span class="line">  Installing : 1:mariadb-5.5.68-1.el7.x86_64                                                                                         28/28 </span><br><span class="line">  Verifying  : perl-HTTP-Tiny-0.033-3.el7.noarch                                                                                      1/28 </span><br><span class="line">  Verifying  : perl-threads-shared-1.43-6.el7.x86_64                                                                                  2/28 </span><br><span class="line">  Verifying  : perl-Storable-2.45-3.el7.x86_64                                                                                        3/28 </span><br><span class="line">  Verifying  : perl-Exporter-5.68-3.el7.noarch                                                                                        4/28 </span><br><span class="line">  Verifying  : perl-constant-1.27-2.el7.noarch                                                                                        5/28 </span><br><span class="line">  Verifying  : perl-PathTools-3.40-5.el7.x86_64                                                                                       6/28 </span><br><span class="line">  Verifying  : perl-Socket-2.010-5.el7.x86_64                                                                                         7/28 </span><br><span class="line">  Verifying  : 1:perl-parent-0.225-244.el7.noarch                                                                                     8/28 </span><br><span class="line">  Verifying  : 4:perl-macros-5.16.3-299.el7_9.x86_64                                                                                  9/28 </span><br><span class="line">  Verifying  : perl-File-Temp-0.23.01-3.el7.noarch                                                                                   10/28 </span><br><span class="line">  Verifying  : 1:perl-Pod-Simple-3.28-4.el7.noarch                                                                                   11/28 </span><br><span class="line">  Verifying  : perl-Time-Local-1.2300-2.el7.noarch                                                                                   12/28 </span><br><span class="line">  Verifying  : 1:perl-Pod-Escapes-1.04-299.el7_9.noarch                                                                              13/28 </span><br><span class="line">  Verifying  : perl-Carp-1.26-244.el7.noarch                                                                                         14/28 </span><br><span class="line">  Verifying  : 4:perl-Time-HiRes-1.9725-3.el7.x86_64                                                                                 15/28 </span><br><span class="line">  Verifying  : perl-Scalar-List-Utils-1.27-248.el7.x86_64                                                                            16/28 </span><br><span class="line">  Verifying  : perl-Pod-Usage-1.63-3.el7.noarch                                                                                      17/28 </span><br><span class="line">  Verifying  : perl-Encode-2.51-7.el7.x86_64                                                                                         18/28 </span><br><span class="line">  Verifying  : perl-Pod-Perldoc-3.20-4.el7.noarch                                                                                    19/28 </span><br><span class="line">  Verifying  : perl-podlators-2.5.1-3.el7.noarch                                                                                     20/28 </span><br><span class="line">  Verifying  : 4:perl-5.16.3-299.el7_9.x86_64                                                                                        21/28 </span><br><span class="line">  Verifying  : perl-File-Path-2.09-2.el7.noarch                                                                                      22/28 </span><br><span class="line">  Verifying  : perl-threads-1.87-4.el7.x86_64                                                                                        23/28 </span><br><span class="line">  Verifying  : 1:mariadb-5.5.68-1.el7.x86_64                                                                                         24/28 </span><br><span class="line">  Verifying  : perl-Filter-1.49-3.el7.x86_64                                                                                         25/28 </span><br><span class="line">  Verifying  : perl-Getopt-Long-2.40-3.el7.noarch                                                                                    26/28 </span><br><span class="line">  Verifying  : perl-Text-ParseWords-3.29-4.el7.noarch                                                                                27/28 </span><br><span class="line">  Verifying  : 4:perl-libs-5.16.3-299.el7_9.x86_64                                                                                   28/28 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  mariadb.x86_64 1:5.5.68-1.el7                                                                                                            </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  perl.x86_64 4:5.16.3-299.el7_9            perl-Carp.noarch 0:1.26-244.el7              perl-Encode.x86_64 0:2.51-7.el7                 </span><br><span class="line">  perl-Exporter.noarch 0:5.68-3.el7         perl-File-Path.noarch 0:2.09-2.el7           perl-File-Temp.noarch 0:0.23.01-3.el7           </span><br><span class="line">  perl-Filter.x86_64 0:1.49-3.el7           perl-Getopt-Long.noarch 0:2.40-3.el7         perl-HTTP-Tiny.noarch 0:0.033-3.el7             </span><br><span class="line">  perl-PathTools.x86_64 0:3.40-5.el7        perl-Pod-Escapes.noarch 1:1.04-299.el7_9     perl-Pod-Perldoc.noarch 0:3.20-4.el7            </span><br><span class="line">  perl-Pod-Simple.noarch 1:3.28-4.el7       perl-Pod-Usage.noarch 0:1.63-3.el7           perl-Scalar-List-Utils.x86_64 0:1.27-248.el7    </span><br><span class="line">  perl-Socket.x86_64 0:2.010-5.el7          perl-Storable.x86_64 0:2.45-3.el7            perl-Text-ParseWords.noarch 0:3.29-4.el7        </span><br><span class="line">  perl-Time-HiRes.x86_64 4:1.9725-3.el7     perl-Time-Local.noarch 0:1.2300-2.el7        perl-constant.noarch 0:1.27-2.el7               </span><br><span class="line">  perl-libs.x86_64 4:5.16.3-299.el7_9       perl-macros.x86_64 4:5.16.3-299.el7_9        perl-parent.noarch 1:0.225-244.el7              </span><br><span class="line">  perl-podlators.noarch 0:2.5.1-3.el7       perl-threads.x86_64 0:1.87-4.el7             perl-threads-shared.x86_64 0:1.43-6.el7         </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试MySQL服务连通性 -h 是k8s节点的IP -P 是mysql外部服务的端口号</span></span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 ~]# mysql -h 192.168.9.91 -P 32529 -u root -p</span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 5</span><br><span class="line">Server version: 5.7.38 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt; </span><br></pre></td></tr></table></figure><ul><li>准备测试数据</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# sysbench --db-driver=mysql --mysql-host=192.168.9.91 --mysql-port=32529 --mysql-user=root --mysql-password=P@88w0rd --mysql-db=sbtest --table-size=100000 --tables=16 --threads=8 --events=999999999 --report-interval=10 --time=100 /usr/share/sysbench/oltp_common.lua prepare</span><br><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br><span class="line"></span><br><span class="line">Initializing worker threads...</span><br><span class="line"></span><br><span class="line">Creating table &#x27;sbtest6&#x27;...</span><br><span class="line">Creating table &#x27;sbtest2&#x27;...</span><br><span class="line">Creating table &#x27;sbtest8&#x27;...</span><br><span class="line">Creating table &#x27;sbtest3&#x27;...</span><br><span class="line">Creating table &#x27;sbtest7&#x27;...</span><br><span class="line">Creating table &#x27;sbtest5&#x27;...</span><br><span class="line">Creating table &#x27;sbtest1&#x27;...</span><br><span class="line">Creating table &#x27;sbtest4&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest3&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest6&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest1&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest4&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest7&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest5&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest2&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest8&#x27;</span><br><span class="line">Creating a secondary index on &#x27;sbtest3&#x27;...</span><br><span class="line">Creating table &#x27;sbtest11&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest11&#x27;</span><br><span class="line">Creating a secondary index on &#x27;sbtest5&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest1&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest6&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest4&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest7&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest2&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest8&#x27;...</span><br><span class="line">Creating table &#x27;sbtest13&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest13&#x27;</span><br><span class="line">Creating table &#x27;sbtest9&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest9&#x27;</span><br><span class="line">Creating table &#x27;sbtest14&#x27;...</span><br><span class="line">Creating table &#x27;sbtest12&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest14&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest12&#x27;</span><br><span class="line">Creating table &#x27;sbtest15&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest15&#x27;</span><br><span class="line">Creating table &#x27;sbtest16&#x27;...</span><br><span class="line">Creating table &#x27;sbtest10&#x27;...</span><br><span class="line">Inserting 100000 records into &#x27;sbtest16&#x27;</span><br><span class="line">Inserting 100000 records into &#x27;sbtest10&#x27;</span><br><span class="line">Creating a secondary index on &#x27;sbtest11&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest13&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest9&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest12&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest14&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest15&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest10&#x27;...</span><br><span class="line">Creating a secondary index on &#x27;sbtest16&#x27;...</span><br></pre></td></tr></table></figure><ul><li>执行测试-8 线程测试</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# sysbench --db-driver=mysql --mysql-host=192.168.9.91 --mysql-port=32529 --mysql-user=root --mysql-password=P@88w0rd --mysql-db=sbtest --table-size=100000 --tables=16 --threads=8 --events=999999999 --report-interval=10 --time=100  /usr/share/sysbench/oltp_read_write.lua run</span><br><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br><span class="line"></span><br><span class="line">Running the test with following options:</span><br><span class="line">Number of threads: 8</span><br><span class="line">Report intermediate results every 10 second(s)</span><br><span class="line">Initializing random number generator from current time</span><br><span class="line"></span><br><span class="line">Initializing worker threads...</span><br><span class="line"></span><br><span class="line">Threads started!</span><br><span class="line"></span><br><span class="line">[ 10s ] thds: 8 tps: 88.46 qps: 1782.38 (r/w/o: 1249.19/355.46/177.73) lat (ms,95%): 267.41 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 20s ] thds: 8 tps: 84.31 qps: 1678.47 (r/w/o: 1173.42/336.43/168.62) lat (ms,95%): 277.21 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 30s ] thds: 8 tps: 70.20 qps: 1413.82 (r/w/o: 990.21/283.20/140.40) lat (ms,95%): 369.77 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 40s ] thds: 8 tps: 47.30 qps: 946.00 (r/w/o: 662.20/189.20/94.60) lat (ms,95%): 484.44 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 50s ] thds: 8 tps: 43.80 qps: 875.99 (r/w/o: 613.19/175.20/87.60) lat (ms,95%): 484.44 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 60s ] thds: 8 tps: 60.70 qps: 1213.08 (r/w/o: 849.69/242.00/121.40) lat (ms,95%): 411.96 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 70s ] thds: 8 tps: 53.90 qps: 1078.22 (r/w/o: 754.42/216.00/107.80) lat (ms,95%): 376.49 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 80s ] thds: 8 tps: 56.49 qps: 1127.98 (r/w/o: 790.11/224.88/112.99) lat (ms,95%): 397.39 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 90s ] thds: 8 tps: 50.60 qps: 1014.59 (r/w/o: 709.56/203.82/101.21) lat (ms,95%): 434.83 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 100s ] thds: 8 tps: 54.70 qps: 1093.12 (r/w/o: 765.22/218.50/109.40) lat (ms,95%): 390.30 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">SQL statistics:</span><br><span class="line">    queries performed:</span><br><span class="line">        read:                            85582</span><br><span class="line">        write:                           24452</span><br><span class="line">        other:                           12226</span><br><span class="line">        total:                           122260</span><br><span class="line">    transactions:                        6113   (61.10 per sec.)</span><br><span class="line">    queries:                             122260 (1221.96 per sec.)</span><br><span class="line">    ignored errors:                      0      (0.00 per sec.)</span><br><span class="line">    reconnects:                          0      (0.00 per sec.)</span><br><span class="line"></span><br><span class="line">General statistics:</span><br><span class="line">    total time:                          100.0494s</span><br><span class="line">    total number of events:              6113</span><br><span class="line"></span><br><span class="line">Latency (ms):</span><br><span class="line">         min:                                   35.63</span><br><span class="line">         avg:                                  130.89</span><br><span class="line">         max:                                  951.86</span><br><span class="line">         95th percentile:                      390.30</span><br><span class="line">         sum:                               800129.59</span><br><span class="line"></span><br><span class="line">Threads fairness:</span><br><span class="line">    events (avg/stddev):           764.1250/4.14</span><br><span class="line">    execution time (avg/stddev):   100.0162/0.01</span><br></pre></td></tr></table></figure><ul><li><p>执行测试-16 线程测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# sysbench --db-driver=mysql --mysql-host=192.168.9.91 --mysql-port=32529 --mysql-user=root --mysql-password=P@88w0rd --mysql-db=sbtest --table-size=100000 --tables=16 --threads=16 --events=999999999 --report-interval=10 --time=100  /usr/share/sysbench/oltp_read_write.lua run</span><br><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br><span class="line"></span><br><span class="line">Running the test with following options:</span><br><span class="line">Number of threads: 16</span><br><span class="line">Report intermediate results every 10 second(s)</span><br><span class="line">Initializing random number generator from current time</span><br><span class="line"></span><br><span class="line">Initializing worker threads...</span><br><span class="line"></span><br><span class="line">Threads started!</span><br><span class="line"></span><br><span class="line">[ 10s ] thds: 16 tps: 114.41 qps: 2310.22 (r/w/o: 1621.18/458.63/230.41) lat (ms,95%): 369.77 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 20s ] thds: 16 tps: 106.35 qps: 2111.86 (r/w/o: 1474.74/424.41/212.71) lat (ms,95%): 383.33 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 30s ] thds: 16 tps: 80.40 qps: 1612.01 (r/w/o: 1129.21/322.00/160.80) lat (ms,95%): 623.33 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 40s ] thds: 16 tps: 63.40 qps: 1266.80 (r/w/o: 886.80/253.20/126.80) lat (ms,95%): 539.71 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 50s ] thds: 16 tps: 57.20 qps: 1145.91 (r/w/o: 802.74/228.78/114.39) lat (ms,95%): 549.52 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 60s ] thds: 16 tps: 69.91 qps: 1408.31 (r/w/o: 987.57/280.92/139.81) lat (ms,95%): 511.33 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 70s ] thds: 16 tps: 78.00 qps: 1547.22 (r/w/o: 1080.51/310.70/156.00) lat (ms,95%): 484.44 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 80s ] thds: 16 tps: 79.50 qps: 1599.87 (r/w/o: 1122.58/318.29/159.00) lat (ms,95%): 520.62 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 90s ] thds: 16 tps: 67.80 qps: 1354.83 (r/w/o: 947.62/271.61/135.60) lat (ms,95%): 539.71 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 100s ] thds: 16 tps: 73.90 qps: 1474.10 (r/w/o: 1030.80/295.50/147.80) lat (ms,95%): 502.20 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">SQL statistics:</span><br><span class="line">    queries performed:</span><br><span class="line">        read:                            110950</span><br><span class="line">        write:                           31700</span><br><span class="line">        other:                           15850</span><br><span class="line">        total:                           158500</span><br><span class="line">    transactions:                        7925   (79.00 per sec.)</span><br><span class="line">    queries:                             158500 (1580.05 per sec.)</span><br><span class="line">    ignored errors:                      0      (0.00 per sec.)</span><br><span class="line">    reconnects:                          0      (0.00 per sec.)</span><br><span class="line"></span><br><span class="line">General statistics:</span><br><span class="line">    total time:                          100.3103s</span><br><span class="line">    total number of events:              7925</span><br><span class="line"></span><br><span class="line">Latency (ms):</span><br><span class="line">         min:                                   41.24</span><br><span class="line">         avg:                                  202.44</span><br><span class="line">         max:                                 1198.81</span><br><span class="line">         95th percentile:                      511.33</span><br><span class="line">         sum:                              1604328.52</span><br><span class="line"></span><br><span class="line">Threads fairness:</span><br><span class="line">    events (avg/stddev):           495.3125/4.03</span><br><span class="line">    execution time (avg/stddev):   100.2705/0.03</span><br></pre></td></tr></table></figure></li><li><p>执行测试-32 线程测试</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# sysbench --db-driver=mysql --mysql-host=192.168.9.91 --mysql-port=32529 --mysql-user=root --mysql-password=P@88w0rd --mysql-db=sbtest --table-size=100000 --tables=16 --threads=32 --events=999999999 --report-interval=10 --time=100  /usr/share/sysbench/oltp_read_write.lua run</span><br><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br><span class="line"></span><br><span class="line">Running the test with following options:</span><br><span class="line">Number of threads: 32</span><br><span class="line">Report intermediate results every 10 second(s)</span><br><span class="line">Initializing random number generator from current time</span><br><span class="line"></span><br><span class="line">Initializing worker threads...</span><br><span class="line"></span><br><span class="line">Threads started!</span><br><span class="line"></span><br><span class="line">[ 10s ] thds: 32 tps: 140.10 qps: 2825.04 (r/w/o: 1981.25/560.39/283.39) lat (ms,95%): 450.77 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 20s ] thds: 32 tps: 124.41 qps: 2515.49 (r/w/o: 1763.43/503.24/248.82) lat (ms,95%): 549.52 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 30s ] thds: 32 tps: 95.90 qps: 1887.10 (r/w/o: 1316.70/378.60/191.80) lat (ms,95%): 733.00 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 40s ] thds: 32 tps: 81.80 qps: 1656.59 (r/w/o: 1164.89/328.10/163.60) lat (ms,95%): 707.07 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 50s ] thds: 32 tps: 82.60 qps: 1638.41 (r/w/o: 1143.51/329.70/165.20) lat (ms,95%): 657.93 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 60s ] thds: 32 tps: 94.34 qps: 1905.84 (r/w/o: 1336.62/380.65/188.58) lat (ms,95%): 623.33 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 70s ] thds: 32 tps: 87.86 qps: 1739.86 (r/w/o: 1215.31/348.73/175.82) lat (ms,95%): 634.66 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 80s ] thds: 32 tps: 84.40 qps: 1705.48 (r/w/o: 1196.49/340.20/168.80) lat (ms,95%): 759.88 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 90s ] thds: 32 tps: 80.50 qps: 1580.71 (r/w/o: 1101.70/318.00/161.00) lat (ms,95%): 612.21 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">[ 100s ] thds: 32 tps: 81.40 qps: 1661.90 (r/w/o: 1167.00/332.10/162.80) lat (ms,95%): 707.07 err/s: 0.00 reconn/s: 0.00</span><br><span class="line">SQL statistics:</span><br><span class="line">    queries performed:</span><br><span class="line">        read:                            133924</span><br><span class="line">        write:                           38264</span><br><span class="line">        other:                           19132</span><br><span class="line">        total:                           191320</span><br><span class="line">    transactions:                        9566   (95.33 per sec.)</span><br><span class="line">    queries:                             191320 (1906.56 per sec.)</span><br><span class="line">    ignored errors:                      0      (0.00 per sec.)</span><br><span class="line">    reconnects:                          0      (0.00 per sec.)</span><br><span class="line"></span><br><span class="line">General statistics:</span><br><span class="line">    total time:                          100.3457s</span><br><span class="line">    total number of events:              9566</span><br><span class="line"></span><br><span class="line">Latency (ms):</span><br><span class="line">         min:                                   51.94</span><br><span class="line">         avg:                                  335.14</span><br><span class="line">         max:                                 1405.78</span><br><span class="line">         95th percentile:                      657.93</span><br><span class="line">         sum:                              3205913.85</span><br><span class="line"></span><br><span class="line">Threads fairness:</span><br><span class="line">    events (avg/stddev):           298.9375/5.15</span><br><span class="line">    execution time (avg/stddev):   100.1848/0.14</span><br></pre></td></tr></table></figure><p>MySQL 容器性能监控图。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-lstack-statefulsets-mysql-74.png" alt="kubesphere-projects-lstack-statefulsets-mysql-74"></p><p>清理测试数据 (为了保证数据更精准，建议每次测试前都清理数据，准备数据，测试)。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# sysbench --db-driver=mysql --mysql-host=192.168.9.91 --mysql-port=32529 --mysql-user=root --mysql-password=P@88w0rd --mysql-db=sbtest --table-size=100000 --tables=16 --threads=32 --events=999999999 --report-interval=10 --time=100  /usr/share/sysbench/oltp_read_write.lua cleanup</span><br><span class="line">sysbench 1.0.20 (using bundled LuaJIT 2.1.0-beta2)</span><br><span class="line"></span><br><span class="line">Dropping table &#x27;sbtest1&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest2&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest3&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest4&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest5&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest6&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest7&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest8&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest9&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest10&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest11&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest12&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest13&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest14&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest15&#x27;...</span><br><span class="line">Dropping table &#x27;sbtest16&#x27;...</span><br></pre></td></tr></table></figure><blockquote><p><strong>04-测试结果</strong></p></blockquote><p>结果汇总对比。</p><table><thead><tr><th>压测线程数量</th><th>TPS</th><th>QPS</th><th>延迟</th></tr></thead><tbody><tr><td>8</td><td>61</td><td>1221</td><td>130</td></tr><tr><td>16</td><td>79</td><td>1580</td><td>202</td></tr><tr><td>32</td><td>95</td><td>1906</td><td>335</td></tr></tbody></table><p>建议根据测试结果，调优！</p><hr><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>本文详细介绍了 KubeSphere 图形化部署单节点 MySQL 上的安装配置过程，如何利用 KubeSphere 的图形化功能创建资源配置清单 YAML 文件的思路和具体操作过程，以后再部署其他在官网找不到详细配置指南的服务都可以借鉴这个方法。</p><p>本文还详细介绍了 Git 常用操作、如何将代码在多个在线代码仓库中存储并保持同步，还介绍了 GitOps 的基本概念并演示了如何用 GitOps 理念在原生 K8S 上部署 MySQL 服务。</p><p>最后，演示了 MySQL 常用性能测试工具 sysbench 的安装和基础使用。</p><p>我多年的一些运维经验和运维思路贯穿了全文。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li>都在文档里直接链接了</li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/k8s-yaml">https://github.com/devops/k8s-yaml</a></li><li>Gitee <a href="https://gitee.com/zdevops/k8s-yaml">https://gitee.com/zdevops/k8s-yaml</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p>About Me</p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-MySQL-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-MySQL-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s-MySQL 安装手</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-开启etcd监控</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-%E5%BC%80%E5%90%AFetcd%E7%9B%91%E6%8E%A7/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-%E5%BC%80%E5%90%AFetcd%E7%9B%91%E6%8E%A7/</id>
    <published>2023-09-22T01:38:09.240Z</published>
    <updated>2023-09-22T01:42:42.199Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于KubeSphere玩转k8s-开启etcd监控"><a href="#基于KubeSphere玩转k8s-开启etcd监控" class="headerlink" title="基于KubeSphere玩转k8s-开启etcd监控"></a>基于KubeSphere玩转k8s-开启etcd监控</h1><p><strong>大家好，我是老Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖(但不限于)以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文源于KubeSphere开源社区8群里的一个小伙伴@Jam提到的ectd监控没有数据，希望我帮忙看一下。本来我也是没有启用etcd监控的，但是既然小伙伴如此信任我提了要求了，那必须安排。所以才有了本文。</p><p>经研究发现，KubeSphere自带的集群状态监控中有etcd监控的页面展示，但是在KubeSphere3.2.1版本中，默认配置开启etcd监控后，集群状态中的etcd监控页面确实没有任何数据。本文将记录里解决该问题的排障之旅。</p><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li><strong>prometheus-operator</strong></li><li>KubeSphere开启etcd监控</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS&#x2F;ElasticSearch</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS&#x2F;ElasticSearch</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS&#x2F;ElasticSearch</td></tr></tbody></table><h2 id="2-KubeSphere-CRD开启etcd监控"><a href="#2-KubeSphere-CRD开启etcd监控" class="headerlink" title="2. KubeSphere CRD开启etcd监控"></a>2. KubeSphere CRD开启etcd监控</h2><h3 id="01-开启etcd监控配置"><a href="#01-开启etcd监控配置" class="headerlink" title="01. 开启etcd监控配置"></a>01. 开启etcd监控配置</h3><ol><li><p>编辑<strong>CRD</strong>中的<strong>ks-installer</strong>的YAML配置文件</p><ul><li><p>在YAML文件中，搜索 <strong>etcd</strong>，并将<strong>monitoring</strong>的<strong>false</strong> 改为 <strong>true</strong></p></li><li><pre><code class="yaml">etcd:  endpointIps: &#39;192.168.9.91,192.168.9.92,192.168.9.93&#39;  monitoring: true  port: 2379  tlsEnable: true<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2. 所有配置完成后，点击右下角的确定，保存配置。</span><br><span class="line"></span><br><span class="line">3. 在 kubectl 中执行以下命令检查安装过程</span><br><span class="line"></span><br><span class="line">   - ```shell</span><br><span class="line">     kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure></code></pre></li><li><p>结果不做展示。</p></li></ul></li><li><p>验证安装结果</p><ul><li>登录控制台，<strong>平台管理</strong>-&gt;<strong>集群管理</strong>-&gt;<strong>监控告警</strong>-&gt;<strong>集群状态</strong>，检查<strong>etcd监控</strong>标签页是否存在，如果存在，表明监控开启成功。</li></ul></li><li><p>虽然前面配置开启了，但是此时监控数据并不存在。同时，检查<strong>prometheus-k8s</strong>的pod会发现如下报错</p><ul><li><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-5.png" alt="etcd-monitoring-5"></li></ul></li><li><p>接下来我们会讲解原因和配置方法</p></li></ol><h2 id="3-问题解决过程记录"><a href="#3-问题解决过程记录" class="headerlink" title="3. 问题解决过程记录"></a>3. 问题解决过程记录</h2><h3 id="01-查找解决办法"><a href="#01-查找解决办法" class="headerlink" title="01. 查找解决办法"></a><strong>01. 查找解决办法</strong></h3><ol><li><p>查找官方论坛，关键词使用<strong>etcd</strong>找到了以下一篇看着比较接近的文档，打开来看看。</p><ul><li><blockquote><p><a href="https://kubesphere.com.cn/forum/d/1322-etcd-prometheus-2-11">etcd使用自签名证书，prometheus报错未知机构签发 #2.11</a></p></blockquote></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-1.png" alt="etcd-monitoring-1"></p></li><li><p>但是文档里并没有详细的问题解决过程，看的我是一头雾水，但是获得了很重要的配置步骤</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220419121600932.png" alt="image-20220419121600932"></p></li></ul></li><li><p>根据上面get到的关键点<strong>1</strong>，<strong>用外部etcd的证书生成secret</strong></p><ul><li><p>这条命令就是为了根据etcd的cert生成一个secret配置</p><ul><li>&#96;&#96;&#96;shell<h1 id="kubectl-n-kubesphere-monitoring-system-create-secret-generic-kube-etcd-client-certs-–from-file-x3D-etcd-client-ca-crt-x3D-x2F-etc-x2F-ssl-x2F-etcd-x2F-ssl-x2F-ca-pem-–from-file-x3D-etcd-client-crt-x3D-x2F-etc-x2F-ssl-x2F-etcd-x2F-ssl-x2F-admin-i-ezjb7gsk-pem-–from-file-x3D-etcd-client-key-x3D-x2F-etc-x2F-ssl-x2F-etcd-x2F-ssl-x2F-admin-i-ezjb7gsk-key-pem"><a href="#kubectl-n-kubesphere-monitoring-system-create-secret-generic-kube-etcd-client-certs-–from-file-x3D-etcd-client-ca-crt-x3D-x2F-etc-x2F-ssl-x2F-etcd-x2F-ssl-x2F-ca-pem-–from-file-x3D-etcd-client-crt-x3D-x2F-etc-x2F-ssl-x2F-etcd-x2F-ssl-x2F-admin-i-ezjb7gsk-pem-–from-file-x3D-etcd-client-key-x3D-x2F-etc-x2F-ssl-x2F-etcd-x2F-ssl-x2F-admin-i-ezjb7gsk-key-pem" class="headerlink" title="kubectl -n kubesphere-monitoring-system create secret generic kube-etcd-client-certs –from-file&#x3D;etcd-client-ca.crt&#x3D;&#x2F;etc&#x2F;ssl&#x2F;etcd&#x2F;ssl&#x2F;ca.pem –from-file&#x3D;etcd-client.crt&#x3D;&#x2F;etc&#x2F;ssl&#x2F;etcd&#x2F;ssl&#x2F;admin-i-ezjb7gsk.pem –from-file&#x3D;etcd-client.key&#x3D;&#x2F;etc&#x2F;ssl&#x2F;etcd&#x2F;ssl&#x2F;admin-i-ezjb7gsk-key.pem"></a>kubectl -n kubesphere-monitoring-system create secret generic kube-etcd-client-certs –from-file&#x3D;etcd-client-ca.crt&#x3D;&#x2F;etc&#x2F;ssl&#x2F;etcd&#x2F;ssl&#x2F;ca.pem –from-file&#x3D;etcd-client.crt&#x3D;&#x2F;etc&#x2F;ssl&#x2F;etcd&#x2F;ssl&#x2F;admin-i-ezjb7gsk.pem –from-file&#x3D;etcd-client.key&#x3D;&#x2F;etc&#x2F;ssl&#x2F;etcd&#x2F;ssl&#x2F;admin-i-ezjb7gsk-key.pem</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 先不急，先看看secret是否存在，如果不存在再根据命令生成。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get secrets -n kubesphere-monitoring-system </span><br><span class="line">  NAME                                         TYPE                                  DATA   AGE</span><br><span class="line">  additional-scrape-configs                    Opaque                                1      9d</span><br><span class="line">  alertmanager-main                            Opaque                                1      9d</span><br><span class="line">  alertmanager-main-generated                  Opaque                                1      9d</span><br><span class="line">  alertmanager-main-tls-assets                 Opaque                                0      9d</span><br><span class="line">  alertmanager-main-token-7b9xc                kubernetes.io/service-account-token   3      9d</span><br><span class="line">  default-token-tnxh7                          kubernetes.io/service-account-token   3      9d</span><br><span class="line">  kube-etcd-client-certs                       Opaque                                3      9d</span><br><span class="line">  kube-state-metrics-token-czbrg               kubernetes.io/service-account-token   3      9d</span><br><span class="line">  node-exporter-token-qrhl7                    kubernetes.io/service-account-token   3      9d</span><br><span class="line">  notification-manager-sa-token-lc6z4          kubernetes.io/service-account-token   3      9d</span><br><span class="line">  notification-manager-webhook-server-cert     kubernetes.io/tls                     2      9d</span><br><span class="line">  prometheus-k8s                               Opaque                                1      9d</span><br><span class="line">  prometheus-k8s-tls-assets                    Opaque                                0      9d</span><br><span class="line">  prometheus-k8s-token-7fk45                   kubernetes.io/service-account-token   3      9d</span><br><span class="line">  prometheus-operator-token-wlmcf              kubernetes.io/service-account-token   3      9d</span><br><span class="line">  sh.helm.release.v1.notification-manager.v1   helm.sh/release.v1                    1      9d</span><br></pre></td></tr></table></figure></li></ul></li><li><p>居然发现了<strong>kube-etcd-client-certs</strong></p></li><li><p>再看看具体内容, 发现该有的都有，一个不少。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get secrets -n kubesphere-monitoring-system kube-etcd-client-certs -o yamlapiVersion: v1data:  etcd-client-ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM5VENDQWQyZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFTTVJBd0RnWURWUVFERXdkbGRHTmsKTFdOaE1CNFhEVEl5TURRd09URTBNekl5TjFvWERUTXlNRFF3TmpFME16SXlOMW93RWpFUU1BNEdBMVVFQXhNSApaWFJqWkMxallUQ0NBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQU53SnpobDFPSVpyCkZYOUNsbER3czVVdnA5NkxHOHpxWkZGbmRGZVBlb1RrTXlFSVpESFRQM0lYSFhzaFFPNjF3VlpVd3VvMmJoeTcKdTBLbEFUcXZmZ1ZJTWE2MlpKTFVNcGwrendvMnFDcWpzbHd1b3RacHArTHVYaldYRTFOeWcwWi9MRmd3NDArOQpGSDV3Y2VWK0FhNjhETElKQWw4a0l6VktScVgraENjZGVTOFRWbDNVeS9PMWRkRFJGODExYzB6VTNteEF2Z0h5CmlxOFF0S2dBQ3E0L294N3RPRFRZUVNlVVdOa25tZTBLMituWmR6M1RveHpUamdIZ2FDVlFXVW5nNFNyMVlSYWwKV2owTGlET2tWb2l3TlFrSVd6ZnBrVXUrM2RJUGNPL29Wc0E3eEJLenhGdEp2dmthTGU1ZDd6a3p2d2xVdE1NYgp2NzNzNERqNU0yc0NBd0VBQWFOV01GUXdEZ1lEVlIwUEFRSC9CQVFEQWdLa01BOEdBMVVkRXdFQi93UUZNQU1CCkFmOHdIUVlEVlIwT0JCWUVGREh3WUNYcW90OG9oYWNZa1FBaHMrRjNSWW5tTUJJR0ExVWRFUVFMTUFtQ0IyVjAKWTJRdFkyRXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBS3l3SEJpVEkxYjExQjNrTDJNZFN0WGRaZ2ZNT05obApuZ1QyUjVuQWZISUVTZVRGNnpFbWh6QnBRb3ozMm1GbG1VdlRKMjdhdVk4UGh2cC9pT0pKbWZIZnY3RWcyYVpJCmlkK2w5YTJoQXFrMnVnNmV4NFpjUzgvOUxyTUV3SlhDOGZqeTA0OWdLQjIyMXFuSFh0Q3VyNE95MUFyMHBiUUwKaEQ4T0lpaExBbHpZNnIvQTlzVDYrNU12cy80OE5LeWN0Sy9KYzFhbVVQK0tnWXlPWDNWNXVsM096MFpIT2ptRAo5akIrdlNHUHM5REdrdnJEeFp4SDRIM0NhaTF5cHBlc29YVFZndS81UTFjcVlvdGNJalZpekx5eVNjZ1EzQ2ZqCmVvdnk3NW8vZUdiRmpYSmJQV0NncDhYV2RJWkVmcmNXMXZtWjZPZDVmcXIwblY5QVExekhueWs9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K  etcd-client.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQrVENDQXVHZ0F3SUJBZ0lJT2Y3Ky90T3NYa013RFFZSktvWklodmNOQVFFTEJRQXdFakVRTUE0R0ExVUUKQXhNSFpYUmpaQzFqWVRBZUZ3MHlNakEwTURreE5ETXlNamRhRncwek1qQTBNRFl4TkRNeU16QmFNQ1F4SWpBZwpCZ05WQkFNVEdXVjBZMlF0Ym05a1pTMXJjeTFyT0hNdGJXRnpkR1Z5TFRBd2dnRWlNQTBHQ1NxR1NJYjNEUUVCCkFRVUFBNElCRHdBd2dnRUtBb0lCQVFDN0NvS1dWKzJKeXRVRTc2VnhvU3lOZzZXOU4yRUlxaTA5UkQ3TThTYUMKZzNHSFZJcXRjWUZzWEhNSHNGeGkyc0ltRWdTblRQMU1sS2Y2Q2xoZ1llSUJqbHJjdWVGNzNDUW45dkw3bXdqMwpJVzV0cUJ4Z1BwRmpvc1FQcGs5eU5XWmpEVGJsbHJTbkZjTXNKekFEOXNIZjdiRWUrQTZJcnJDUnhLZGJWaVY1CnFveFR5THhJenF4c2NDMlMwclJCYk5YbHAzZFU1QStldGZhOUYxUFNCeDQxdmk1MXcvTnBVRkNOa2ZuaWhyZnUKcUVoYW0zNUdCbFYrRzd4ZENSVGt6K3h3V3IwdnhMUitueGZ5MElHL2hyYlIxL0RLbHo5Y3BnbHhTWUg5S3ZvbgpzVXRpemhQYXVsRFZIN2NFdTJGOWZuTHZlK2hZemt3c3hhS1RsQTFlQ2VEeEFnTUJBQUdqZ2dFL01JSUJPekFPCkJnTlZIUThCQWY4RUJBTUNCYUF3SFFZRFZSMGxCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01Bd0cKQTFVZEV3RUIvd1FDTUFBd0h3WURWUjBqQkJnd0ZvQVVNZkJnSmVxaTN5aUZweGlSQUNHejRYZEZpZVl3Z2RvRwpBMVVkRVFTQjBqQ0J6NElFWlhSalpJSVFaWFJqWkM1cmRXSmxMWE41YzNSbGJZSVVaWFJqWkM1cmRXSmxMWE41CmMzUmxiUzV6ZG1PQ0ltVjBZMlF1YTNWaVpTMXplWE4wWlcwdWMzWmpMbU5zZFhOMFpYSXViRzlqWVd5Q0QydHoKTFdzNGN5MXRZWE4wWlhJdE1JSVBhM010YXpoekxXMWhjM1JsY2kweGdnOXJjeTFyT0hNdGJXRnpkR1Z5TFRLQwpFMnhpTG10MVltVnpjR2hsY21VdWJHOWpZV3lDQ1d4dlkyRnNhRzl6ZEljRWZ3QUFBWWNRQUFBQUFBQUFBQUFBCkFBQUFBQUFBQVljRXdLZ0pXNGNFd0tnSlhJY0V3S2dKWFRBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQXZOR2gKdHdlTG1QS2F2YjVhOFoxU2sxQkFZdzZ6dEdHTnJGdzg2M1dKRVBEblFFa3duOFhJNGh4SU82UVV3eHJic1MweAp0YUg2ZmRKeFZZcEN5UXVrV3JldHpkZ05zMTVWYnlNdUlqVkJRMytGZnBRaDB5T25tUXlmRWc2UWZNdU5IWGpJCjZCdVp5M0p0S0tFZGZmUFh4U3VlMFV2TG5idlN6U0tVQkRIcy9nNVV0Q3cyeHVIVFU5bFdoQXY2dm1WQ08yQW4KZmc2MjAzMUpUNG9ya2F6c1hmdENOTlZqUmdIZ2pjQ0NDZkMwY1hSRVZTVFZqZUFaZU40ZUdtYWlRcFdEUWkxbApUVWZJMlE0dGRySlFsOXk0dDNKRDgrSmFLT0VJWkt3NWVWaTc3cUZobWR1MmFkRThkODc0aVBnN2ZEYmVFS2tWCkYxVWVKb3NKOFN3Z1psWTRpQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K  etcd-client.key: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFb3dJQkFBS0NBUUVBdXdxQ2xsZnRpY3JWQk8rbGNhRXNqWU9sdlRkaENLb3RQVVErelBFbWdvTnhoMVNLCnJYR0JiRnh6QjdCY1l0ckNKaElFcDB6OVRKU24rZ3BZWUdIaUFZNWEzTG5oZTl3a0ovYnkrNXNJOXlGdWJhZ2MKWUQ2Ulk2TEVENlpQY2pWbVl3MDI1WmEwcHhYRExDY3dBL2JCMysyeEh2Z09pSzZ3a2NTblcxWWxlYXFNVThpOApTTTZzYkhBdGt0SzBRV3pWNWFkM1ZPUVBuclgydlJkVDBnY2VOYjR1ZGNQemFWQlFqWkg1NG9hMzdxaElXcHQrClJnWlZmaHU4WFFrVTVNL3NjRnE5TDhTMGZwOFg4dENCdjRhMjBkZnd5cGMvWEtZSmNVbUIvU3I2SjdGTFlzNFQKMnJwUTFSKzNCTHRoZlg1eTczdm9XTTVNTE1XaWs1UU5YZ25nOFFJREFRQUJBb0lCQVFDamQ1c0x4SXNRMjFsegpOL0xUTFhhZnM0ZmRxQkhCSGVIdDRzQTBJeXB4OUdqN1NwTHM1UCtrOGVPQ3U4cnlocGdaNTdOemVDRUVsZ044Cnp4L1FGSndPbWhpbFFqdGtJZERqc0x0SjFJUndZQ0ovNmVYcTQ2UHpmV1IyL1BZQUxkVnZDalNKVVQ1UHJRQm4KalZRMGtxdDhodU0rMnJMeEdDT3ZNanpGNGJOYzhZZGFSOTI0c095Y1Q2UzI1Vzg3TklQWnVqY3VBUXIzaEE2bwpUbEdmVU44Q0hSM21jVnBIbEJ1NDhEeEpYaml2MkVKZTRHSmN2L0NWQTVqVGNNNlNoTjJuSGN3OGpHYVg0bGJtCjJYaktKemE0RStON3hGRXBRVEJRMUNqRGM1cndKY0tKUm9IQkxFUGtJVE5LWnNWSDlmK0tuNmpjQWtmOTZoWVkKKzY1TTMza1ZBb0dCQU5GMVdRNG4wcTE0YlpSY1FkbnFoWDdYT0pFbDBtOUZuYVhOTjNsb0M1SnNneGxkbXh5bgpRV1IvZkJVQnRaTUc5MmgzdTBheWUyaWdZdGtSc1pDV0wwL2VicmJGMWlmYXozR2Z1b3lSZWozMHVsRDJYY3phCmQzSEUwdVpTSVQrUkFSTTF1VjJUczVUSHJqUStIT3Z5cEpFQjFlSnY1L21LWmRpUTRtMzBGMDUzQW9HQkFPU1oKL21NWXd4V1Y4SFRtaENyNGsycDJQd1NLTHVrajhZaVJQZHhVSFpXWXdRTGFFRU1uSVVnUFJBSnFHc1VtWng5TApacDVjYXp3bW9ldDI0cXpGeVhkemFUMi96VGc1Rjg1d0FzRDl1WEZSWWYzc01OZ0VkazJkSmc1VGZmcWcrNlRQCjBla2VtWG9vSTYxTTc3VVFjWVdSVCtPWUtFd1V3dzZMcjJ3bGFKM1hBb0dBTzF3alVlU3RTeVllLy9XcFgrV2IKMFplUzIyZTVuSGxCTlRUVWJONjBzTmw1eWQyQ1VQdUJoOGF0VnBLMmI2V0F4aVZ3ZUplcWE3dFFhQzRnZ1ZaZQpzQ2JjZjRYUHJGblJnbVQvREVsS09IYTd1cWduYXgvYXkrNDR5cmNwM3dic0pCS01wdDF0L2xNY3BvZVgwTEppCk93b25JRllRaXVMUy9DNExUWmZvWnY4Q2dZQnIrMlhUajRYUE0zVlM4dlJwaStPdWZVNkZLWFRCUWU0OHNVYkUKUmFOMzM2RUVaTmNic1djaUw3dlRYQ1ZyRFJuWENYbmV3ZzhSYWJwQWpIYkVYK1VybklPUTNJSG0xZWt0NVhFWAprb0kvU2M3ODc4MmVySFRwY3ByZ1Y0WUJsbnRudlpjTkJCeEJQS2Fsbk5yNTcxdUFXVVNnWUdaZ2tjb1ZtOXZ3ClBMZHZId0tCZ0dYS2l5Y29zZzFuZHhkclQ0S05SSmdWZUd1M3ZqSjg4N0tQbThpbHB4alF3ekM2cjNRZDhYUWIKbGdWUnFBcG5mTnA1amM0WUZ5c2RvKzFhc2JrRTloczVUZk5sVUVtSWdvR3dxVnlmUkRiOEl0TklRQTBXZDZLdQpONy81UkZYRVlkUFR4YVhpNjl0cTZnRXp6cThTcnQyUUY5eEk5eG1EV0U5bGVEeDUwd1dZCi0tLS0tRU5EIFJTQSBQUklWQVRFIEtFWS0tLS0tCg==kind: Secretmetadata:  creationTimestamp: &quot;2022-04-09T14:34:37Z&quot;  name: kube-etcd-client-certs  namespace: kubesphere-monitoring-system  resourceVersion: &quot;856&quot;  uid: c74b122b-438d-4e40-8e1a-1b9445d4b3d5type: Opaque<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   - 看到这说明secrets暂时看着没问题，最起码资源配置存在，我们先继续往后排查，不行的话再回来。</span><br><span class="line"></span><br><span class="line">   - &gt; **在写文档的过程中，Jam反馈他的环境并没有这个secrets资源配置。可以按照上面的命令生成一个secrets，注意检查etcd密钥的实际路径**</span><br><span class="line"></span><br><span class="line">3. 根据上面get到的关键点**2**，**用外部etcd 各节点的ip 生成 endpoint **</span><br><span class="line"></span><br><span class="line">   - 先看看**prometheus-endpointsEtcd.yaml**文件是个啥</span><br><span class="line"></span><br><span class="line">   - **prometheus-endpointsEtcd.yaml**</span><br><span class="line"></span><br><span class="line">   - ```yaml</span><br><span class="line">     apiVersion: v1</span><br><span class="line">     kind: Endpoints</span><br><span class="line">     metadata:</span><br><span class="line">       labels:</span><br><span class="line">         k8s-app: etcd</span><br><span class="line">       name: etcd</span><br><span class="line">       namespace: kube-system</span><br><span class="line">     subsets:</span><br><span class="line">     - addresses:</span><br><span class="line">       - ip: 127.0.0.1</span><br><span class="line">       ports:</span><br><span class="line">       - name: metrics</span><br><span class="line">         port: 2379</span><br><span class="line">         protocol: TCP</span><br></pre></td></tr></table></figure></code></pre></li><li><p>再看看我们的kubernetes中有没有<strong>Endpoints</strong>资源</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get endpoints -n kubesphere-monitoring-system NAME                                      ENDPOINTS                                                                AGEalertmanager-main                         10.233.116.11:9093,10.233.117.10:9093,10.233.87.9:9093                   9dalertmanager-operated                     10.233.116.11:9094,10.233.117.10:9094,10.233.87.9:9094 + 6 more...       9dkube-state-metrics                        10.233.87.8:8443,10.233.87.8:9443                                        9dnode-exporter                             192.168.9.91:9100,192.168.9.92:9100,192.168.9.93:9100                    9dnotification-manager-controller-metrics   10.233.116.8:8443                                                        9dnotification-manager-svc                  10.233.116.13:19093,10.233.116.14:19093                                  9dnotification-manager-webhook              10.233.116.8:9443                                                        9dprometheus-k8s                            10.233.117.43:9090,10.233.87.160:9090                                    9dprometheus-operated                       10.233.117.43:9090,10.233.87.160:9090                                    9dprometheus-operator                       10.233.116.7:8443                                                        9dthanos-ruler-operated                     10.233.117.18:10902,10.233.87.17:10902,10.233.117.18:10901 + 1 more...   8d<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 居然没有跟**etcd**相关的Endpoints，需要新建？</span><br><span class="line"></span><br><span class="line">- 正要根据配置文件重新创建的时候，突然发现了自己的错误，惯性思维，被上面的命令带偏了，用错了命令空间，配置文件实例的命令空间是**kube-system**。</span><br><span class="line"></span><br><span class="line">- 再次在**kube-system**中查询，查询到了我们要的资源配置</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get endpoints -n kube-system  </span><br><span class="line">  NAME                          ENDPOINTS                                                              AGE</span><br><span class="line">  coredns                       10.233.117.2:53,10.233.117.3:53,10.233.117.2:53 + 3 more...            9d</span><br><span class="line">  etcd                          192.168.9.91:2379,192.168.9.92:2379,192.168.9.93:2379                  3d20h</span><br><span class="line">  kube-controller-manager-svc   192.168.9.91:10257,192.168.9.92:10257,192.168.9.93:10257               9d</span><br><span class="line">  kube-scheduler-svc            192.168.9.91:10259,192.168.9.92:10259,192.168.9.93:10259               9d</span><br><span class="line">  kubelet                       192.168.9.91:10250,192.168.9.92:10250,192.168.9.93:10250 + 6 more...   9d</span><br><span class="line">  openebs.io-local              &lt;none&gt;                                                                 9d</span><br></pre></td></tr></table></figure></code></pre></li><li><p>看看配置文件内容</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get endpoints etcd -n kube-system -o yamlapiVersion: v1kind: Endpointsmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Endpoints&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;k8s-app&quot;:&quot;etcd&quot;&#125;,&quot;name&quot;:&quot;etcd&quot;,&quot;namespace&quot;:&quot;kube-system&quot;&#125;,&quot;subsets&quot;:[&#123;&quot;addresses&quot;:[&#123;&quot;ip&quot;:&quot;192.168.9.91&quot;&#125;,&#123;&quot;ip&quot;:&quot;192.168.9.92&quot;&#125;,&#123;&quot;ip&quot;:&quot;192.168.9.93&quot;&#125;],&quot;ports&quot;:[&#123;&quot;name&quot;:&quot;metrics&quot;,&quot;port&quot;:2379,&quot;protocol&quot;:&quot;TCP&quot;&#125;]&#125;]&#125;  creationTimestamp: &quot;2022-04-15T08:24:18Z&quot;  labels:    k8s-app: etcd  name: etcd  namespace: kube-system  resourceVersion: &quot;1559305&quot;  uid: c6d0ee2c-a228-4ea8-8ef1-73b387030950subsets:- addresses:  - ip: 192.168.9.91  - ip: 192.168.9.92  - ip: 192.168.9.93  ports:  - name: metrics    port: 2379    protocol: TCP<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   - 配置文件看着也正确，那我们继续往下查</span><br><span class="line"></span><br><span class="line">4. 根据上面get到的关键点**3**，**生成利用上述 endpoint 的 etcd service**</span><br><span class="line"></span><br><span class="line">   - 先看看**prometheus-serviceEtcd.yaml**文件是个啥</span><br><span class="line"></span><br><span class="line">   - **prometheus-serviceEtcd.yaml**</span><br><span class="line"></span><br><span class="line">   - ```yaml</span><br><span class="line">     </span><br><span class="line">     apiVersion: v1</span><br><span class="line">     kind: Service</span><br><span class="line">     metadata:</span><br><span class="line">       labels:</span><br><span class="line">         k8s-app: etcd</span><br><span class="line">       name: etcd</span><br><span class="line">       namespace: kube-system</span><br><span class="line">     spec:</span><br><span class="line">       clusterIP: None</span><br><span class="line">       ports:</span><br><span class="line">       - name: metrics</span><br><span class="line">         port: 2379</span><br><span class="line">         targetPort: 2379</span><br><span class="line">       selector: null</span><br></pre></td></tr></table></figure></code></pre></li><li><p>再看看我们的kubernetes中有没有<strong>Service</strong>资源</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get service -n kube-system NAME                          TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                        AGEcoredns                       ClusterIP   10.233.0.3   &lt;none&gt;        53/UDP,53/TCP,9153/TCP         9detcd                          ClusterIP   None         &lt;none&gt;        2379/TCP                       3d21hkube-controller-manager-svc   ClusterIP   None         &lt;none&gt;        10257/TCP                      9dkube-scheduler-svc            ClusterIP   None         &lt;none&gt;        10259/TCP                      9dkubelet                       ClusterIP   None         &lt;none&gt;        10250/TCP,10255/TCP,4194/TCP   9d<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 看看资源配置详细内容</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get service etcd -n kube-system -o yaml</span><br><span class="line">  apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;k8s-app&quot;:&quot;etcd&quot;&#125;,&quot;name&quot;:&quot;etcd&quot;,&quot;namespace&quot;:&quot;kube-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;clusterIP&quot;:&quot;None&quot;,&quot;ports&quot;:[&#123;&quot;name&quot;:&quot;metrics&quot;,&quot;port&quot;:2379,&quot;targetPort&quot;:2379&#125;],&quot;selector&quot;:null&#125;&#125;</span><br><span class="line">    creationTimestamp: &quot;2022-04-15T08:24:18Z&quot;</span><br><span class="line">    labels:</span><br><span class="line">      k8s-app: etcd</span><br><span class="line">    name: etcd</span><br><span class="line">    namespace: kube-system</span><br><span class="line">    resourceVersion: &quot;1559307&quot;</span><br><span class="line">    uid: cfd92ee5-dbd1-4ee4-a4c4-d683ca7a41ea</span><br><span class="line">  spec:</span><br><span class="line">    clusterIP: None</span><br><span class="line">    clusterIPs:</span><br><span class="line">    - None</span><br><span class="line">    ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">    - IPv6</span><br><span class="line">    ipFamilyPolicy: RequireDualStack</span><br><span class="line">    ports:</span><br><span class="line">    - name: metrics</span><br><span class="line">      port: 2379</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 2379</span><br><span class="line">    sessionAffinity: None</span><br><span class="line">    type: ClusterIP</span><br><span class="line">  status:</span><br><span class="line">    loadBalancer: &#123;&#125;</span><br></pre></td></tr></table></figure></code></pre></li><li><p>配置文件看着正确，那我们继续往下查</p></li></ul></li><li><p>根据上面get到的关键点<strong>4</strong>，**生成用于抓取etcd数据的 ServiceMonitor **</p><ul><li><p>先看看<strong>prometheus-serviceMonitorEtcd.yaml</strong>文件是个啥</p></li><li><p><strong>prometheus-serviceMonitorEtcd.yaml</strong></p></li><li><pre><code class="yaml">apiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  labels:    k8s-app: etcd  name: etcd  namespace: kubesphere-monitoring-systemspec:  endpoints:  - interval: 1m    port: metrics    scheme: https    tlsConfig:      caFile: /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client-ca.crt      certFile: /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client.crt      keyFile: /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client.key      serverName: etcd.kube-system.svc.cluster.local  jobLabel: k8s-app  namespaceSelector:    matchNames:    - kube-system  selector:    matchLabels:      k8s-app: etcd<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 再看看我们的kubernetes中有没有**ServiceMonitor**资源</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get servicemonitor -n kubesphere-monitoring-system </span><br><span class="line">  NAME                      AGE</span><br><span class="line">  alertmanager              9d</span><br><span class="line">  coredns                   9d</span><br><span class="line">  devops-jenkins            8d</span><br><span class="line">  etcd                      3d21h</span><br><span class="line">  kube-apiserver            9d</span><br><span class="line">  kube-controller-manager   9d</span><br><span class="line">  kube-scheduler            9d</span><br><span class="line">  kube-state-metrics        9d</span><br><span class="line">  kubelet                   9d</span><br><span class="line">  node-exporter             9d</span><br><span class="line">  prometheus                9d</span><br><span class="line">  prometheus-operator       9d</span><br><span class="line">  s2i-operator              8d</span><br></pre></td></tr></table></figure></code></pre></li><li><p>看看资源配置详细内容</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get servicemonitor etcd -n kubesphere-monitoring-system -o yamlapiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;monitoring.coreos.com/v1&quot;,&quot;kind&quot;:&quot;ServiceMonitor&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;app.kubernetes.io/vendor&quot;:&quot;kubesphere&quot;,&quot;k8s-app&quot;:&quot;etcd&quot;&#125;,&quot;name&quot;:&quot;etcd&quot;,&quot;namespace&quot;:&quot;kubesphere-monitoring-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;endpoints&quot;:[&#123;&quot;interval&quot;:&quot;1m&quot;,&quot;port&quot;:&quot;metrics&quot;,&quot;scheme&quot;:&quot;https&quot;,&quot;tlsConfig&quot;:&#123;&quot;caFile&quot;:&quot;/etc/prometheus/secrets/kube-etcd-client-certs/etcd-client-ca.crt&quot;,&quot;certFile&quot;:&quot;/etc/prometheus/secrets/kube-etcd-client-certs/etcd-client.crt&quot;,&quot;keyFile&quot;:&quot;/etc/prometheus/secrets/kube-etcd-client-certs/etcd-client.key&quot;&#125;&#125;],&quot;jobLabel&quot;:&quot;k8s-app&quot;,&quot;namespaceSelector&quot;:&#123;&quot;matchNames&quot;:[&quot;kube-system&quot;]&#125;,&quot;selector&quot;:&#123;&quot;matchLabels&quot;:&#123;&quot;k8s-app&quot;:&quot;etcd&quot;&#125;&#125;&#125;&#125;  creationTimestamp: &quot;2022-04-15T08:24:18Z&quot;  generation: 1  labels:    app.kubernetes.io/vendor: kubesphere    k8s-app: etcd  name: etcd  namespace: kubesphere-monitoring-system  resourceVersion: &quot;1559308&quot;  uid: 386f16c0-74cd-4dbf-aa35-cc227062c881spec:  endpoints:  - interval: 1m    port: metrics    scheme: https    tlsConfig:      caFile: /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client-ca.crt      certFile: /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client.crt      keyFile: /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client.key  jobLabel: k8s-app  namespaceSelector:    matchNames:    - kube-system  selector:    matchLabels:      k8s-app: etcd<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   - 配置文件看着也正确，那我们继续往下查</span><br><span class="line"></span><br><span class="line">6. 查到现在我发现自己能查的都查了，该有的配置都有，那为啥还有问题呢，参考文档中也没有更详细的说明了。</span><br><span class="line"></span><br><span class="line">7. 这时我发现我忘记了一点，还有没看过POD的日志，赶紧去看看。</span><br><span class="line"></span><br><span class="line">   - 在**集群管理**-&gt;**应用负载**-&gt;**工作负载**-&gt;**有状态副本集**, 选择**kubesphere-monitoring-system**项目，找到**prometheus-k8s**</span><br><span class="line"></span><br><span class="line">   - ![etcd-monitoring-2](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-2.png)</span><br><span class="line"></span><br><span class="line">   - 点击**prometheus-k8s**，进入详细页面，点击容器组中的**prometheus-k8s-0**容器</span><br><span class="line"></span><br><span class="line">   - ![etcd-monitoring-3](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-3.png)</span><br><span class="line"></span><br><span class="line">   - 点击按钮**容器日志**，弹出容器日志页面</span><br><span class="line"></span><br><span class="line">   - ![etcd-monitoring-4](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-4.png)</span><br><span class="line"></span><br><span class="line">   - 这时会发现有大量的报错日志</span><br><span class="line"></span><br><span class="line">   - ![etcd-monitoring-5](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-5.png)</span><br><span class="line"></span><br><span class="line">   - 详细报错日志</span><br><span class="line"></span><br><span class="line">   - ```yaml</span><br><span class="line">     level=error ts=2022-04-19T06:49:08.169Z caller=manager.go:188 component=&quot;scrape manager&quot; msg=&quot;error creating new scrape pool&quot; err=&quot;error creating HTTP client: unable to load specified CA cert /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client-ca.crt: open /etc/prometheus/secrets/kube-etcd-client-certs/etcd-client-ca.crt: no such file or directory&quot; scrape_pool=kubesphere-monitoring-system/etcd/0</span><br></pre></td></tr></table></figure></code></pre></li><li><p>看到这我们发现了问题的原因，找不到文件**&#x2F;etc&#x2F;prometheus&#x2F;secrets&#x2F;kube-etcd-client-certs&#x2F;etcd-client-ca.crt**</p></li><li><p>打开pod的<strong>终端</strong>，进入系统里验证</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-6.png" alt="etcd-monitoring-6"></p></li><li><p>结果显示，整个文件夹都不存在</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220419145321885.png" alt="image-20220419145321885"></p></li><li><p>再去看一眼pod的配置，是否有secrets的配置</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-11.png" alt="etcd-monitoring-11"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-12.png" alt="etcd-monitoring-12"></p></li><li><p>看到这，<strong>实锤了</strong>，我认为我发现了问题的根本，也想到了问题的解决办法，那就是pod中没有挂载<strong>kube-etcd-client-certs</strong>这个secrets，那我们想办法挂载上，问题就能解决了？？？</p></li><li><p>在控制台中，找到我们的有状态副本集<strong>prometheus-k8s</strong>，点击<strong>更多操作</strong>-&gt;<strong>编辑设置</strong></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-7.png" alt="etcd-monitoring-7"></p></li><li><p>在<strong>存储卷</strong>中，<strong>挂载配置字典或保密字典</strong></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-8.png" alt="etcd-monitoring-8"></p></li><li><p>选择<strong>保密字典</strong>，只读挂载<strong>kube-etcd-client-certs</strong>到**&#x2F;etc&#x2F;prometheus&#x2F;secrets&#x2F;kube-etcd-client-certs**，最终确定。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-9.png" alt="etcd-monitoring-9"></p></li><li><p>点击确定后，你会发现pod开始重建，我以为这就可以了等着看效果就完了，结果。。。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-10.png" alt="etcd-monitoring-10"></p></li><li><p>待pod重建成功后，我以为一切都被我掌控了，肯定没有问题了。结果我发现，改过的配置又变回了原来的样子，pod中根本没有挂载我们想要的secrets，配置跟原来一样。</p></li><li><p>反复操作三次后，我崩溃了，幡然醒悟，我改的方法不对，这个是由<strong>prometheus-operator</strong>，单独修改不会配置不会生效的。</p></li></ul></li><li><p><strong>prometheus-operator</strong>，这玩意我以前没玩过，不了解技术细节，咋办。。。继续百度</p></li><li><p>百度</p><ul><li>关键字<strong>prometheus operator etcd</strong></li><li><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220419151317571.png" alt="image-20220419151317571"></li><li>第一名看了一眼，没啥帮助，不展示了，各位有兴趣的可以自己看</li><li>2分钟后打开了排名第二的文章，文章思路过程比较清晰，迅速下翻，看到第<strong>三</strong>点找到了我要的方法</li><li><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220419151544778.png" alt="image-20220419151544778"></li></ul></li><li><p>细节我也不知道，但是我们的目的是为了挂载secrets，既然这里提到了，那我们就去试试</p><ul><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl edit prometheuses -n kubesphere-monitoring-system<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  # Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,</span><br><span class="line">  # and an empty file will abort the edit. If an error occurs while saving this file will be</span><br><span class="line">  # reopened with the relevant failures.</span><br><span class="line">  #</span><br><span class="line">  apiVersion: monitoring.coreos.com/v1</span><br><span class="line">  kind: Prometheus</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">  ....</span><br></pre></td></tr></table></figure></code></pre></li><li><p>文件内容类似上面的，我们搜索secret，出现报错<strong>E486: Pattern not found: secret</strong></p></li><li><p>说明默认配置里没有secret的配置，我们自己添加,在文件78行左右加入</p></li><li><pre><code class="yaml">secrets:- kube-etcd-client-certs<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 最终效果类似(为了看的清楚，我加了行号)：</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  71   securityContext:</span><br><span class="line">  72     fsGroup: 0</span><br><span class="line">  73     runAsNonRoot: false</span><br><span class="line">  74     runAsUser: 0</span><br><span class="line">  75   serviceAccountName: prometheus-k8s</span><br><span class="line">  76   serviceMonitorNamespaceSelector: &#123;&#125;</span><br><span class="line">  77   serviceMonitorSelector: &#123;&#125;</span><br><span class="line">  78   secrets:</span><br><span class="line">  79   - kube-etcd-client-certs</span><br><span class="line">  80   storage:</span><br><span class="line">  81     volumeClaimTemplate:</span><br><span class="line">  82       spec:</span><br><span class="line">  83         resources:</span><br><span class="line">  84           requests:</span><br><span class="line">  85             storage: 20Gi</span><br><span class="line">  86   tolerations:</span><br><span class="line">  87   - effect: NoSchedule</span><br><span class="line">  88     key: dedicated</span><br><span class="line">  89     operator: Equal</span><br><span class="line">  90     value: monitoring</span><br><span class="line">  91   version: v2.26.0</span><br></pre></td></tr></table></figure></code></pre></li><li><p>保存退出</p></li><li><p>我们再去查看有状态副本集的配置，会发现多了一个保密字典的配置</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220419153245471.png" alt="image-20220419153245471"></p></li><li><p>再去看pod的具体配置，会发现pod的配置也多了保密字典的配置</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-13.png" alt="etcd-monitoring-13"></p></li><li><p>再看看pod的日子，发现也没有<strong>error</strong>了</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-14.png" alt="etcd-monitoring-14"></p></li><li><p>感觉问题都解决了，那我们去看看监控是否有图形了（<strong>还有点小期待呢</strong>）</p></li></ul></li><li><p>揭晓最终答案的时刻</p><ul><li><p>先来一张全景图</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-15.png" alt="etcd-monitoring-15"></p></li><li><p>再来几张局部高清图（后补的，刚开始没抓）</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-16.png" alt="etcd-monitoring-16"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-17.png" alt="etcd-monitoring-17"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-18.png" alt="etcd-monitoring-18"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-19.png" alt="etcd-monitoring-19"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-20.png" alt="etcd-monitoring-20"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-21.png" alt="etcd-monitoring-21"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/etcd-monitoring-22.png" alt="etcd-monitoring-22"></p></li></ul></li><li><p>至此，问题初步解决，不过还有很多细节需要我们在后面深入学习了解更深的底层知识。</p></li></ol><h2 id="4-Prometheus-Operator监控etcd的技术关键点"><a href="#4-Prometheus-Operator监控etcd的技术关键点" class="headerlink" title="4.  Prometheus-Operator监控etcd的技术关键点"></a>4.  Prometheus-Operator监控etcd的技术关键点</h2><h3 id="01-技术关键点"><a href="#01-技术关键点" class="headerlink" title="01. 技术关键点"></a>01. 技术关键点</h3><ol><li><p>etcd的安装方式</p><ul><li><p>kubesphere安装的etcd为二进制方式</p></li><li><p>验证方法如下</p></li><li><pre><code class="shell">## 看进程确认是二进制方式[root@ks-k8s-master-0 ~]# ps -ef | grep etcdroot      1158 56409  0 15:43 pts/0    00:00:00 grep --color=auto etcdroot     15301     1  6 Apr09 ?        15:35:08 /usr/local/bin/etcdroot     17247 17219 13 Apr09 ?        1-06:55:24 kube-apiserver --advertise-address=192.168.9.91 --allow-privileged=true --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100 --authorization-mode=Node,RBAC --bind-address=0.0.0.0 --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/ssl/etcd/ssl/ca.pem --etcd-certfile=/etc/ssl/etcd/ssl/node-ks-k8s-master-0.pem --etcd-keyfile=/etc/ssl/etcd/ssl/node-ks-k8s-master-0-key.pem --etcd-servers=https://192.168.9.91:2379,https://192.168.9.92:2379,https://192.168.9.93:2379 --feature-gates=CSIStorageCapacity=true,RotateKubeletServerCertificate=true,TTLAfterFinished=true,ExpandCSIVolumes=true --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-account-signing-key-file=/etc/kubernetes/pki/sa.key --service-cluster-ip-range=10.233.0.0/18 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key## 看ssl密钥文件有哪些[root@ks-k8s-master-0 ~]# ll /etc/ssl/etcd/ssl/total 80-rw------- 1 root root 1675 Apr  9 22:32 admin-ks-k8s-master-0-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 admin-ks-k8s-master-0.pem-rw------- 1 root root 1679 Apr  9 22:32 admin-ks-k8s-master-1-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 admin-ks-k8s-master-1.pem-rw------- 1 root root 1679 Apr  9 22:32 admin-ks-k8s-master-2-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 admin-ks-k8s-master-2.pem-rw------- 1 root root 1675 Apr  9 22:32 ca-key.pem-rw-r--r-- 1 root root 1086 Apr  9 22:32 ca.pem-rw------- 1 root root 1679 Apr  9 22:32 member-ks-k8s-master-0-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 member-ks-k8s-master-0.pem-rw------- 1 root root 1675 Apr  9 22:32 member-ks-k8s-master-1-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 member-ks-k8s-master-1.pem-rw------- 1 root root 1675 Apr  9 22:32 member-ks-k8s-master-2-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 member-ks-k8s-master-2.pem-rw------- 1 root root 1675 Apr  9 22:32 node-ks-k8s-master-0-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 node-ks-k8s-master-0.pem-rw------- 1 root root 1679 Apr  9 22:32 node-ks-k8s-master-1-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 node-ks-k8s-master-1.pem-rw------- 1 root root 1679 Apr  9 22:32 node-ks-k8s-master-2-key.pem-rw-r--r-- 1 root root 1440 Apr  9 22:32 node-ks-k8s-master-2.pem</code></pre></li></ul></li><li><p>prometheus-operator监控etcd的配置</p><ul><li><p>用外部etcd的证书生成secret</p></li><li><p>用外部etcd 各节点的ip 生成 endpoint </p></li><li><p>生成利用endpoint 的 etcd service</p></li><li><p>生成用于抓取etcd数据的 ServiceMonitor</p></li></ul></li></ol><h3 id="02-需要深入学习的地方（占位，待补充）"><a href="#02-需要深入学习的地方（占位，待补充）" class="headerlink" title="02. 需要深入学习的地方（占位，待补充）"></a>02. 需要深入学习的地方（占位，待补充）</h3><ol><li>prometheus-operator的实现原理和技术细节</li><li>kubesphere对于prometheus-operator的配置过程</li></ol><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>本文根据运维实际需求，介绍了开启etcd监控的正确姿势，同时也详细介绍了解决该问题的排障流程。有需要开启kubesphere3.2.1版本的etcd监控功能的小伙伴，可以参考本文进行配置。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><a href="https://kubesphere.com.cn/forum/d/1322-etcd-prometheus-2-11">etcd使用自签名证书，prometheus报错未知机构签发 #2.11</a></li><li><a href="https://www.cnblogs.com/lvcisco/p/12575608.html?ivk_sa=1024320u">https://www.cnblogs.com/lvcisco/p/12575608.html?ivk_sa=1024320u</a></li></ul><blockquote><p><strong>Get文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老Z手记</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p>About Me</p></blockquote><ul><li>昵称：老Z</li><li>坐标：山东济南</li><li>职业：运维架构师&#x2F;高级运维工程师&#x3D;<strong>运维</strong></li><li>关注的领域：云计算&#x2F;云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于KubeSphere玩转k8s-开启etcd监控&quot;&gt;&lt;a href=&quot;#基于KubeSphere玩转k8s-开启etcd监控&quot; class=&quot;headerlink&quot; title=&quot;基于KubeSphere玩转k8s-开启etcd监控&quot;&gt;&lt;/a&gt;基于KubeSp</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-ElasticSearch 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Elasticsearch%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-Elasticsearch%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.188Z</published>
    <updated>2023-09-22T01:42:26.663Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-ElasticSearch-安装手记"><a href="#基于-KubeSphere-玩转-k8s-ElasticSearch-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-ElasticSearch 安装手记"></a>基于 KubeSphere 玩转 k8s-ElasticSearch 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文接着上篇 <strong>&lt;&lt; 基于 KubeSphere 玩转 k8s-KubeSphere 初始化手记 &gt;&gt;</strong> ，继续玩转 KubeSphere、玩转 k8s。本文会介绍 KubeSphere 启用可插拔组件日志系统的安装和配置过程，由于采用了 Kubernetes 集群外部的 ElasticSearch 集群作为日志收集系统，因此，本文还会涉及 ElasticSearch 安装配置的实践。为了让大家不仅能掌握 ElasticSearch 手工安装部署的技能，同时也能 Get 到如何将手工安装部署文档转化成 Ansible 的 Playbooks，因此本文同时介绍了纯手工安装配置 ElasticSearch 和利用 Ansible 自动化安装配置 ElasticSearch。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：60 分</li><li>行：4000+</li><li>单词：25000+</li><li>字符：220000+</li><li>图片：50 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>ElasticSearch-手工安装配置</li><li>ElasticSearch-Ansible 自动安装配置</li><li>ElasticSearch-启用 http 认证配置</li><li>KubeSphere 启用可插拔日志组件</li><li>KubeSphere 对接外部不开启认证的 ElasticSearch</li><li>KubeSphere 对接外部开启认证的 ElasticSearch</li><li>Ansible 常用操作</li><li>Ansible Playbook编写</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200+100</td><td align="center">GlusterFS&#x2F;ElasticSearch</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200+100</td><td align="center">GlusterFS&#x2F;ElasticSearch</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200+100</td><td align="center">GlusterFS&#x2F;ElasticSearch</td></tr></tbody></table><h2 id="2-Ansible-配置"><a href="#2-Ansible-配置" class="headerlink" title="2. Ansible 配置"></a>2. Ansible 配置</h2><h3 id="01-增加-hosts-配置"><a href="#01-增加-hosts-配置" class="headerlink" title="01. 增加 hosts 配置"></a>01. 增加 hosts 配置</h3><p><strong>本系列文档中演示用的 ElasticSearch 和 GlusterFS 服务器复用，有条件的用户可以分开部署，注意调整 hosts 配置。</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hosts文件配置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主要增加glusterfs</span></span><br><span class="line">[<span class="string">k8s</span>]</span><br><span class="line"><span class="string">ks-k8s-master-0</span> <span class="string">ansible_ssh_host=192.168.9.91</span>  <span class="string">host_name=ks-k8s-master-0</span></span><br><span class="line"><span class="string">ks-k8s-master-1</span> <span class="string">ansible_ssh_host=192.168.9.92</span>  <span class="string">host_name=ks-k8s-master-1</span></span><br><span class="line"><span class="string">ks-k8s-master-2</span> <span class="string">ansible_ssh_host=192.168.9.93</span>  <span class="string">host_name=ks-k8s-master-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">glusterfs</span>]</span><br><span class="line"><span class="string">glusterfs-node-0</span> <span class="string">ansible_ssh_host=192.168.9.95</span> <span class="string">host_name=glusterfs-node-0</span></span><br><span class="line"><span class="string">glusterfs-node-1</span> <span class="string">ansible_ssh_host=192.168.9.96</span> <span class="string">host_name=glusterfs-node-1</span></span><br><span class="line"><span class="string">glusterfs-node-2</span> <span class="string">ansible_ssh_host=192.168.9.97</span> <span class="string">host_name=glusterfs-node-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">es</span>]</span><br><span class="line"><span class="string">es-node-0</span> <span class="string">ansible_ssh_host=192.168.9.95</span> <span class="string">host_name=es-node-0</span></span><br><span class="line"><span class="string">es-node-1</span> <span class="string">ansible_ssh_host=192.168.9.96</span> <span class="string">host_name=es-node-1</span></span><br><span class="line"><span class="string">es-node-2</span> <span class="string">ansible_ssh_host=192.168.9.97</span> <span class="string">host_name=es-node-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:children</span>]</span><br><span class="line"><span class="string">k8s</span></span><br><span class="line"><span class="string">glusterfs</span></span><br><span class="line"><span class="string">es</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:vars</span>]</span><br><span class="line"><span class="string">ansible_connection=paramiko</span></span><br><span class="line"><span class="string">ansible_ssh_user=root</span></span><br><span class="line"><span class="string">ansible_ssh_pass=password</span></span><br></pre></td></tr></table></figure><h2 id="3-ElasticSearch-安装配置"><a href="#3-ElasticSearch-安装配置" class="headerlink" title="3. ElasticSearch 安装配置"></a>3. ElasticSearch 安装配置</h2><h3 id="01-初始化配置"><a href="#01-初始化配置" class="headerlink" title="01. 初始化配置"></a>01. 初始化配置</h3><blockquote><p><strong>01-检测服务器连通性</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 检测服务器的连通性</span></span><br><span class="line">[root@zdevops-master /]# cd /data/ansible/ansible-zdevops/inventories/dev/</span><br><span class="line">[root@zdevops-master dev]# source /opt/ansible2.8/bin/activate</span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible -m ping es </span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">es-node-2 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">es-node-0 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-初始化服务器配置</strong></p></blockquote><p><strong>由于是复用的服务器，在 GlusterFS 安装配置时已经配置，因此本文忽略，实际中可根据需要执行以下命令</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook初始化服务器配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">(ansible2.8) [root@zdevops-master dev]<span class="comment"># ansible-playbook -l es ../../playbooks/init-base.yaml</span></span></span><br></pre></td></tr></table></figure><blockquote><p><strong>03-挂载数据盘</strong></p></blockquote><p><strong>本文新增一块硬盘 &#x2F;dev&#x2F;sdc, 格式化后挂载点为 &#x2F;data，作为 ElasticSearch 的数据存储目录，实际中请注意修改 ansible-playbook 的变量配置</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">由于是采用的虚拟机，在虚拟化上挂载磁盘后，先检查一下磁盘是否被操作系统识别</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 查看磁盘列表</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#x27;fdisk -l&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x00019df2</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     2099199     1048576   83  Linux</span><br><span class="line">/dev/sda2         2099200    83886079    40893440   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 214.7 GB, 214748364800 bytes, 419430400 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-root: 39.7 GB, 39720058880 bytes, 77578240 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 214.7 GB, 214748364800 bytes, 419430400 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x00019df2</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     2099199     1048576   83  Linux</span><br><span class="line">/dev/sda2         2099200    83886079    40893440   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-root: 39.7 GB, 39720058880 bytes, 77578240 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x00019df2</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     2099199     1048576   83  Linux</span><br><span class="line">/dev/sda2         2099200    83886079    40893440   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 214.7 GB, 214748364800 bytes, 419430400 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-root: 39.7 GB, 39720058880 bytes, 77578240 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上面的执行结果，发现并没有识别新磁盘</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用scsi的机制，触发磁盘扫描，识别新磁盘</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先查看现有的scsi磁盘信息</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#x27;cat /proc/scsi/scsi&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Attached devices:</span><br><span class="line">Host: scsi0 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00</span><br><span class="line">  Type:   CD-ROM                           ANSI  SCSI revision: 05</span><br><span class="line">Host: scsi2 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi2 Channel: 00 Id: 01 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Attached devices:</span><br><span class="line">Host: scsi0 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00</span><br><span class="line">  Type:   CD-ROM                           ANSI  SCSI revision: 05</span><br><span class="line">Host: scsi2 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi2 Channel: 00 Id: 01 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line"></span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Attached devices:</span><br><span class="line">Host: scsi0 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi0 Channel: 00 Id: 01 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi1 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00</span><br><span class="line">  Type:   CD-ROM                           ANSI  SCSI revision: 05</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">手动添加新磁盘，这里重点注意一下，es-node-2的scsi的顺序跟其他两个节点不一样，需要单独执行</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es-node-2 -m shell -a &quot;echo &#x27;scsi add-single-device 0 0 2 0&#x27; &gt;/proc/scsi/scsi&quot;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es-node-0,es-node-1 -m shell -a &quot;echo &#x27;scsi add-single-device 2 0 2 0&#x27; &gt;/proc/scsi/scsi&quot;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看新磁盘是否添加</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看scsi信息</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#x27;cat /proc/scsi/scsi&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Attached devices:</span><br><span class="line">Host: scsi0 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00</span><br><span class="line">  Type:   CD-ROM                           ANSI  SCSI revision: 05</span><br><span class="line">Host: scsi2 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi2 Channel: 00 Id: 01 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi2 Channel: 00 Id: 02 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line"></span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Attached devices:</span><br><span class="line">Host: scsi0 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi0 Channel: 00 Id: 01 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi1 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00</span><br><span class="line">  Type:   CD-ROM                           ANSI  SCSI revision: 05</span><br><span class="line">Host: scsi0 Channel: 00 Id: 02 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Attached devices:</span><br><span class="line">Host: scsi0 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00</span><br><span class="line">  Type:   CD-ROM                           ANSI  SCSI revision: 05</span><br><span class="line">Host: scsi2 Channel: 00 Id: 00 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi2 Channel: 00 Id: 01 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line">Host: scsi2 Channel: 00 Id: 02 Lun: 00</span><br><span class="line">  Vendor: VMware   Model: Virtual disk     Rev: 1.0 </span><br><span class="line">  Type:   Direct-Access                    ANSI  SCSI revision: 02</span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看fdisk信息</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#x27;fdisk -l&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x00019df2</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     2099199     1048576   83  Linux</span><br><span class="line">/dev/sda2         2099200    83886079    40893440   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 214.7 GB, 214748364800 bytes, 419430400 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-root: 39.7 GB, 39720058880 bytes, 77578240 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/sdc: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 214.7 GB, 214748364800 bytes, 419430400 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x00019df2</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     2099199     1048576   83  Linux</span><br><span class="line">/dev/sda2         2099200    83886079    40893440   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-root: 39.7 GB, 39720058880 bytes, 77578240 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/sdc: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"></span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x00019df2</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     2099199     1048576   83  Linux</span><br><span class="line">/dev/sda2         2099200    83886079    40893440   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 214.7 GB, 214748364800 bytes, 419430400 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-root: 39.7 GB, 39720058880 bytes, 77578240 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/sdc: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook格式化数据盘</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重点注意，一定要加-l参数指定es主机 利用-e参数替换默认的playbook的盘符和挂载点</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook -l es -e data_disk=sdc -e data_disk_path=&quot;/data&quot; ../../playbooks/init-disk.yaml</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [初始化磁盘.] *************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-数据磁盘分区.] *********************************************************************************************</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line"></span><br><span class="line">TASK [02-格式化数据磁盘.] ********************************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">TASK [03-挂载数据盘.] **********************************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">PLAY RECAP ****************************************************************************************************</span><br><span class="line">es-node-0                  : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">es-node-1                  : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">es-node-2                  : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>扩展说明-虚拟化上磁盘插槽详情</strong></li><li><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/esxi-scsi.png" alt="esxi-scsi"></li></ul><blockquote><p><strong>04-验证数据盘的挂载</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否格式化并挂载</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#x27;df -h&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 2.0G     0  2.0G   0% /dev</span><br><span class="line">tmpfs                    2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                    2.0G   73M  1.9G   4% /run</span><br><span class="line">tmpfs                    2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.6G   36G   5% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                    396M     0  396M   0% /run/user/0</span><br><span class="line">/dev/sdc1                100G   33M  100G   1% /data</span><br><span class="line"></span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 2.0G     0  2.0G   0% /dev</span><br><span class="line">tmpfs                    2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                    2.0G   89M  1.9G   5% /run</span><br><span class="line">tmpfs                    2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.6G   36G   5% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdc1                100G   33M  100G   1% /data</span><br><span class="line">tmpfs                    396M     0  396M   0% /run/user/0</span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 2.0G     0  2.0G   0% /dev</span><br><span class="line">tmpfs                    2.0G     0  2.0G   0% /dev/shm</span><br><span class="line">tmpfs                    2.0G  215M  1.8G  11% /run</span><br><span class="line">tmpfs                    2.0G     0  2.0G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.7G   36G   5% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                    396M     0  396M   0% /run/user/0</span><br><span class="line">/dev/sdc1                100G   33M  100G   1% /data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否配置自动挂载</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#x27;tail -1  /etc/fstab&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">es-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdc1 /data xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">es-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdc1 /data xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">es-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdc1 /data xfs defaults 0 0</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="02-ElasticSearch-安装配置-手工安装配置"><a href="#02-ElasticSearch-安装配置-手工安装配置" class="headerlink" title="02. ElasticSearch 安装配置-手工安装配置"></a>02. ElasticSearch 安装配置-手工安装配置</h3><p><strong>以下配置如无特殊说明，所有节点都要执行</strong></p><blockquote><p><strong>01-配置 yum 源</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@es-node-0 ~]# vi /etc/yum.repos.d/elasticsearch.repo</span><br><span class="line"></span><br><span class="line">[elasticsearch]</span><br><span class="line">baseurl=https://artifacts.elastic.co/packages/7.x/yum</span><br><span class="line">gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch</span><br><span class="line">gpgcheck=1</span><br><span class="line">enable=1</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-安装 ElasticSearch</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@es-node-0 ~]# yum install  elasticsearch -y</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-创建 elasticsearch 配置文件</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先备份初始的配置文件(运维必备习惯)</span></span><br><span class="line">[root@es-node-0 ~]# cp /etc/elasticsearch/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml.bak</span><br><span class="line"></span><br><span class="line">[root@es-node-0 ~]# vi /etc/elasticsearch/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">cluster.name: es-lstack</span><br><span class="line">node.name: es</span><br><span class="line">node.master: true</span><br><span class="line">path.data: /data01/elasticsearch/data</span><br><span class="line">path.logs: /data01/elasticsearch/logs</span><br><span class="line">network.host: 192.168.9.95#注意修改每个节点对应的的ip地址</span><br><span class="line">http.port: 9200</span><br><span class="line">discovery.seed_hosts: [&quot;192.168.9.95&quot;,&quot;192.168.9.96&quot;,&quot;192.168.9.97&quot;]#集群的每个节点地址</span><br><span class="line">cluster.initial_master_nodes: [&quot;es-node-0&quot;, &quot;es-node-1&quot;, &quot;es-node-2&quot;]#集群的每个节点名称</span><br><span class="line"></span><br><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line">xpack.security.transport.ssl.keystore.path: cert/es-node-0.p12#证书路径</span><br><span class="line">xpack.security.transport.ssl.truststore.path: cert/es-node-0.p12#证书路径</span><br></pre></td></tr></table></figure><blockquote><p><strong>04-创建 elasticsearch 数据文件目录</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@es-node-0 ~]# mkdir -p /data01/elasticsearch</span><br><span class="line">[root@es-node-0 ~]# chown -R elasticsearch.elasticsearch /data01/elasticsearch</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">证书目录</span></span><br><span class="line">[root@es-node-0 ~]# mkdir -p /etc/elasticsearch/cert/</span><br><span class="line">[root@es-node-0 ~]# chown -R elasticsearch.elasticsearch /etc/elasticsearch/cert/</span><br></pre></td></tr></table></figure><blockquote><p><strong>05-生成 instances 文件用来配置证书-开启认证可选配置 (在节点 1 中执行)</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在节点1中执行</span></span><br><span class="line">[root@es-node-0 ~]# vi /etc/elasticsearch/elasticsearch-instances.yml</span><br><span class="line"></span><br><span class="line">instances:</span><br><span class="line">  - name: &quot;es-node-0&quot;  #注意修改每个节点的ip地址</span><br><span class="line">    ip: </span><br><span class="line">      - &quot;192.168.2.163&quot;</span><br><span class="line">  - name: &quot;es-node-1&quot;</span><br><span class="line">    ip:</span><br><span class="line">      - &quot;192.168.2.124&quot;</span><br><span class="line">  - name: &quot;es-node-2&quot;</span><br><span class="line">    ip:</span><br><span class="line">      - &quot;192.168.2.141&quot;</span><br></pre></td></tr></table></figure><blockquote><p><strong>06-生成证书-开启认证可选配置 (在节点 1 中执行)</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@es-node-0 ~]# /usr/share/elasticsearch/bin/elasticsearch-certutil cert --silent --in /etc/elasticsearch/elasticsearch-instances.yml --out /etc/elasticsearch/elasticsearch-instances.zip --pass VD41fXmOvp5hGlPc  #这是密码（在接下来是需要使用的）</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压证书压缩包</span></span><br><span class="line">[root@es-node-0 ~]# cd  /etc/elasticsearch/</span><br><span class="line">[root@es-node-0 ~]# unzip elasticsearch-instances.zip</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将证书放到本机指定目录</span></span><br><span class="line"></span><br><span class="line">[root@es-node-0 ~]# cp es-node-0/es-node-0.p12 /etc/elasticsearch/cert/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制证书到其他的机器上</span></span><br><span class="line">[root@es-node-0 ~]# scp -r es-node-1/es-node-1.p12 root@192.168.9.96:/etc/elasticsearch/cert/</span><br><span class="line">[root@es-node-0 ~]# scp -r es-node-2/es-node-2.p12 root@192.168.9.97:/etc/elasticsearch/cert/</span><br></pre></td></tr></table></figure><blockquote><p><strong>07-配置 keystore-开启认证可选配置</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成 keystore 文件</span></span><br><span class="line">[root@es-node-0 ~]# /usr/share/elasticsearch/bin/elasticsearch-keystore create</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加配置项到 keystore 文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面两个命令，均需要输入生成证书命令中使用的的密码</span></span><br><span class="line">[root@es-node-0 ~]# /usr/share/elasticsearch/bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password</span><br><span class="line">[root@es-node-0 ~]# /usr/share/elasticsearch/bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建用户</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-r指定权限 superuser 超级权限</span></span><br><span class="line">[root@es-node-0 ~]# /usr/share/elasticsearch/bin/elasticsearch-users useradd lstack -p P@88w0rd -r superuser   </span><br></pre></td></tr></table></figure><blockquote><p><strong>08-启动并设置开机自动启动 elasticsearch 服务</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@es-node-0 ~]# systemctl enable elasticsearch &amp;&amp; systemctl start  elasticsearch</span><br></pre></td></tr></table></figure><blockquote><p><strong>09-测试访问</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ElasticSearch 不开启认证</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]#  curl 192.168.9.95:9200/_cat/nodes?</span><br><span class="line">192.168.9.97 49 69 6 0.03 0.29 0.21 cdfhilmrstw * es-node-2</span><br><span class="line">192.168.9.95 26 73 3 0.04 0.13 0.14 cdfhilmrstw - es-node-0</span><br><span class="line">192.168.9.96 37 66 4 0.01 0.10 0.11 cdfhilmrstw - es-node-1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ElasticSearch 开启认证</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]#  curl -ulstack:&#x27;P@88w0rd&#x27; 192.168.9.95:9200/_cat/nodes?</span><br><span class="line">192.168.9.97 49 69 6 0.03 0.29 0.21 cdfhilmrstw * es-node-2</span><br><span class="line">192.168.9.95 26 73 3 0.04 0.13 0.14 cdfhilmrstw - es-node-0</span><br><span class="line">192.168.9.96 37 66 4 0.01 0.10 0.11 cdfhilmrstw - es-node-1</span><br></pre></td></tr></table></figure><h3 id="03-ElasticSearch-安装配置-Ansible-自动安装配置"><a href="#03-ElasticSearch-安装配置-Ansible-自动安装配置" class="headerlink" title="03. ElasticSearch 安装配置-Ansible 自动安装配置"></a>03. ElasticSearch 安装配置-Ansible 自动安装配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 自动化安装配置 ElasticSearch</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/deploy-elasticsearch.yaml </span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [安装配置ElasticSearch.] *************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-配置yum源-配置elasticsearch软件源.] **************************************************************************</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">TASK [02-安装elasticsearch.] ************************************************************************************</span><br><span class="line">changed: [es-node-2]</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line"></span><br><span class="line">TASK [03-创建elasticsearch配置文件.] ********************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line">changed: [es-node-1]</span><br><span class="line"></span><br><span class="line">TASK [04-创建elasticsearch数据文件目录.] ******************************************************************************</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">PLAY [安装配置ElasticSearch SSL认证.] *******************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-生成ElasticSearch Instance文件用来配置ssl证书.] ****************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line"></span><br><span class="line">TASK [02-生成证书.] ***********************************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line"></span><br><span class="line">TASK [03-安装基本工具包.] ********************************************************************************************</span><br><span class="line">ok: [es-node-0] =&gt; (item=[u&#x27;unzip&#x27;])</span><br><span class="line"></span><br><span class="line">TASK [04-解压cert文件.] *******************************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line"></span><br><span class="line">TASK [05-从服务器获取cert配置文件.] *************************************************************************************</span><br><span class="line">changed: [es-node-0] =&gt; (item=es-node-0)</span><br><span class="line">changed: [es-node-0] =&gt; (item=es-node-1)</span><br><span class="line">changed: [es-node-0] =&gt; (item=es-node-2)</span><br><span class="line"></span><br><span class="line">PLAY [认证配置.] **************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-创建elasticsearch cert目录.] *****************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line">changed: [es-node-1]</span><br><span class="line"></span><br><span class="line">TASK [02-同步cert文件.] *******************************************************************************************</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">TASK [03-生成keystore文件.] ***************************************************************************************</span><br><span class="line">ok: [es-node-0]</span><br><span class="line">ok: [es-node-1]</span><br><span class="line">ok: [es-node-2]</span><br><span class="line"></span><br><span class="line">TASK [04-添加配置项到keystore文件.] ***********************************************************************************</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">TASK [05-创建用户并指定superuser权限.] *********************************************************************************</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">PLAY [终极配置.] **************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-启动并设置开机自动启动elasticsearch服务.] *************************************************************************</span><br><span class="line">changed: [es-node-1]</span><br><span class="line">changed: [es-node-0]</span><br><span class="line">changed: [es-node-2]</span><br><span class="line"></span><br><span class="line">PLAY RECAP ****************************************************************************************************</span><br><span class="line">es-node-0                  : ok=15   changed=13   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">es-node-1                  : ok=10   changed=9    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">es-node-2                  : ok=10   changed=9    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="04-ElasticSearch-常用运维命令"><a href="#04-ElasticSearch-常用运维命令" class="headerlink" title="04. ElasticSearch 常用运维命令"></a>04. ElasticSearch 常用运维命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看服务状态</span></span><br><span class="line">systemctl status elasticsearch.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动服务</span></span><br><span class="line">systemctl start elasticsearch.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">停止服务</span></span><br><span class="line">systemctl stop elasticsearch.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看简略的服务日志</span></span><br><span class="line">journalctl -u elasticsearch.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看详细的服务日志</span></span><br><span class="line">/data/elasticsearch/logs</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看gc日志</span></span><br><span class="line">/var/log/elasticsearch</span><br></pre></td></tr></table></figure><h3 id="05-ElasticSearch-调优"><a href="#05-ElasticSearch-调优" class="headerlink" title="05. ElasticSearch 调优"></a>05. ElasticSearch 调优</h3><p><strong>暂未调优，后续再补</strong></p><h2 id="4-KubeSphere-配置"><a href="#4-KubeSphere-配置" class="headerlink" title="4. KubeSphere 配置"></a>4. KubeSphere 配置</h2><p>本文后面的内容是一篇略显冗余的长文，之所以出现这个情况，是因为我自己配置疏忽导致的，具体疏忽在哪里下面到了具体环节的时候有重点标注。为了保留故事的完整性我后面就将错就错了，给大家展示了我排查故障、发现错误、改正错误的全流程。</p><h3 id="01-开启-KubeSphere-日志系统可插拔组件"><a href="#01-开启-KubeSphere-日志系统可插拔组件" class="headerlink" title="01. 开启 KubeSphere 日志系统可插拔组件"></a>01. 开启 KubeSphere 日志系统可插拔组件</h3><ol><li><p>编辑 <strong>CRD</strong> 中的 <strong>ks-installer</strong> 的 YAML 配置文件。</p><ul><li><p>在 YAML 文件中，搜索 <strong>logging,auditing,events</strong>，并将 <strong>enabled</strong> 的 <strong>false</strong> 改为 <strong>true</strong>。</p></li><li><p>&#96;&#96;&#96;yaml<br>logging:<br>  containerruntime: docker<br>  enabled: true<br>  logsidecar:<br>enabled: true<br>replicas: 2<br>events:<br>  enabled: true</p><p>auditing:<br>  enabled: true</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 在 YAML 文件中，搜索 **es**，将 **enabled** 的 **false** 改为 **true**。并修改外部的 es 服务器的信息。</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  es:</span><br><span class="line">    basicAuth:</span><br><span class="line">      enabled: true</span><br><span class="line">      password: &#x27;P@88w0rd&#x27;</span><br><span class="line">      username: &#x27;lstack&#x27;</span><br><span class="line">    elkPrefix: logstash</span><br><span class="line">    externalElasticsearchHost: &#x27;192.168.9.65&#x27;</span><br><span class="line">    externalElasticsearchPort: &#x27;9200&#x27;</span><br><span class="line">    logMaxAge: 7</span><br></pre></td></tr></table></figure></li></ul></li><li><p>所有配置完成后，点击右下角的确定，保存配置。</p></li><li><p>在 kubectl 中执行以下命令检查安装过程</p><ul><li>&#96;&#96;&#96;shell<br>kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app&#x3D;ks-install -o jsonpath&#x3D;’{.items[0].metadata.name}’) -f<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 看到如下状态，说明安装成功。</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  TASK [ks-core/prepare : KubeSphere | Generating kubeconfig-admin] **************</span><br><span class="line">  skipping: [localhost]</span><br><span class="line">  </span><br><span class="line">  PLAY RECAP *********************************************************************</span><br><span class="line">  localhost                  : ok=26   changed=14   unreachable=0    failed=0    skipped=12   rescued=0    ignored=0</span><br><span class="line">  </span><br><span class="line">  Start installing monitoring</span><br><span class="line">  Start installing multicluster</span><br><span class="line">  Start installing openpitrix</span><br><span class="line">  Start installing network</span><br><span class="line">  Start installing alerting</span><br><span class="line">  Start installing auditing</span><br><span class="line">  Start installing devops</span><br><span class="line">  Start installing events</span><br><span class="line">  Start installing logging</span><br><span class="line">  **************************************************</span><br><span class="line">  Waiting for all tasks to be completed ...</span><br><span class="line">  task alerting status is successful  (1/9)</span><br><span class="line">  task network status is successful  (2/9)</span><br><span class="line">  task multicluster status is successful  (3/9)</span><br><span class="line">  task openpitrix status is successful  (4/9)</span><br><span class="line">  task auditing status is successful  (5/9)</span><br><span class="line">  task logging status is successful  (6/9)</span><br><span class="line">  task events status is successful  (7/9)</span><br><span class="line">  task devops status is successful  (8/9)</span><br><span class="line">  task monitoring status is successful  (9/9)</span><br><span class="line">  **************************************************</span><br><span class="line">  Collecting installation results ...</span><br><span class="line">  #####################################################</span><br><span class="line">  ###              Welcome to KubeSphere!           ###</span><br><span class="line">  #####################################################</span><br><span class="line">  </span><br><span class="line">  Console: http://192.168.9.91:30880</span><br><span class="line">  Account: admin</span><br><span class="line">  Password: P@88w0rd</span><br><span class="line">  </span><br><span class="line">  NOTES：</span><br><span class="line">    1. After you log into the console, please check the</span><br><span class="line">       monitoring status of service components in</span><br><span class="line">       &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">       ready, please wait patiently until all components</span><br><span class="line">       are up and running.</span><br><span class="line">    2. Please change the default password after login.</span><br><span class="line">  </span><br><span class="line">  #####################################################</span><br><span class="line">  https://kubesphere.io             2022-04-15 11:54:50</span><br><span class="line">  #####################################################</span><br></pre></td></tr></table></figure></li></ul></li><li><p>验证安装结果。</p><blockquote><p><strong>01-日志系统组件</strong></p></blockquote><ul><li><p>登录控制台，<strong>平台管理</strong>-&gt;<strong>集群管理</strong>-&gt;<strong>系统组件</strong>，检查是否 <strong>日志</strong> 标签页中的所有组件都处于<strong>健康</strong>状态。如果是，表明组件安装成功。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-components-logging.png" alt="kubesphere-clusters-components-logging"></p></li><li><p>点击右下角的<strong>工具箱</strong>按钮，多出几个分析工具的菜单</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-components-logging-2.png" alt="kubesphere-clusters-components-logging-2"></p></li><li><p>在 kubectl 工具中查看。</p></li><li><pre><code class="shell">/ # kubectl get pod -n kubesphere-logging-systemNAME                                            READY   STATUS    RESTARTS   AGEfluent-bit-j5rvq                                1/1     Running   0          136mfluent-bit-tqrqs                                1/1     Running   0          136mfluent-bit-wv5hn                                1/1     Running   0          136mfluentbit-operator-745bf5559f-lgq9p             1/1     Running   0          137mks-events-exporter-59d48f6777-ncgpc             2/2     Running   0          133mks-events-operator-5944645757-kqt65             1/1     Running   0          134mks-events-ruler-575669b4-lnpxc                  2/2     Running   0          133mks-events-ruler-575669b4-mh2fn                  2/2     Running   0          133mkube-auditing-operator-84857bf967-kg7bs         1/1     Running   0          135mkube-auditing-webhook-deploy-64cfb8c9f8-c65cb   1/1     Running   0          134mkube-auditing-webhook-deploy-64cfb8c9f8-j8w5d   1/1     Running   0          134mlogsidecar-injector-deploy-5fb6fdc6dd-fv8vg     2/2     Running   0          134mlogsidecar-injector-deploy-5fb6fdc6dd-fxsbf     2/2     Running   0          134m<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; **02-问题说明**</span><br><span class="line"></span><br><span class="line">- 上面的验证，表面上看日志系统是配置成功了，但是实际上还是存在问题的，接下来我们继续深入验证。</span><br><span class="line"></span><br><span class="line">- 点击**工具箱**中的**容器日志查询**，会出现如下报错，说明我们的 es 对接并没有成功。</span><br><span class="line"></span><br><span class="line">- ![kubesphere-logging-error-1](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-logging-error-1.png)</span><br><span class="line"></span><br><span class="line">- 执行以下命令查看 Output 的配置，发现几个重要参数并没有变成我们想要的结果</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  / # kubectl get output -n kubesphere-logging-system es -o yaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Output</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;</span><br><span class="line">    creationTimestamp: &quot;2022-04-15T03:51:11Z&quot;</span><br><span class="line">    generation: 1</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: logging</span><br><span class="line">      logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">    name: es</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">    resourceVersion: &quot;1503226&quot;</span><br><span class="line">    uid: 1a60036f-9ad0-4a3c-bab1-e077102a2724</span><br><span class="line">  spec:</span><br><span class="line">    es:</span><br><span class="line">      generateID: true</span><br><span class="line">      host: elasticsearch-logging-data.kubesphere-logging-system.svc</span><br><span class="line">      logstashFormat: true</span><br><span class="line">      logstashPrefix: ks-logstash-log</span><br><span class="line">      port: 9200</span><br><span class="line">      timeKey: &#x27;@timestamp&#x27;</span><br><span class="line">    matchRegex: (?:kube|service)\.(.*)</span><br></pre></td></tr></table></figure></code></pre></li><li><p>也可以在 KubeSphere 控制台中查看 Output 的配置。</p></li><li><p>登录控制台，在<strong>集群管理</strong>-&gt;<strong>CRD</strong> 中 , 搜索 output。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-output.png" alt="kubesphere-crd-output"></p></li><li><p>点击 <strong>Output</strong>，进入 Output 详情页，会发现有 <strong>es</strong>、<strong>es-auditing</strong>、<strong>es-events</strong> 三种资源。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-output-1.png" alt="kubesphere-crd-output-1"></p></li><li><p>编辑 <strong>es</strong> 的 YAML 配置（点击右侧的三个竖点的图标，会弹出编辑 YAML 的选项），可以看到配置文件跟我们命令行输出的结果一致。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-output-es-1.png" alt="kubesphere-crd-output-es-1"></p></li><li><p>查看 fluent-bit 容器。</p></li><li><p>&#96;&#96;&#96;shell<br>&#x2F; # kubectl get pods -n kubesphere-logging-system<br>NAME                                            READY   STATUS    RESTARTS   AGE<br>fluent-bit-j5rvq                                1&#x2F;1     Running   0          3h34m<br>fluent-bit-vv8pb                                1&#x2F;1     Running   0          103s<br>fluent-bit-wv5hn                                1&#x2F;1     Running   0          3h34m<br>fluentbit-operator-745bf5559f-lgq9p             1&#x2F;1     Running   0          3h36m<br>ks-events-exporter-59d48f6777-ncgpc             2&#x2F;2     Running   0          3h32m<br>ks-events-operator-5944645757-kqt65             1&#x2F;1     Running   0          3h32m<br>ks-events-ruler-575669b4-lnpxc                  2&#x2F;2     Running   0          3h32m<br>ks-events-ruler-575669b4-mh2fn                  2&#x2F;2     Running   0          3h32m<br>kube-auditing-operator-84857bf967-kg7bs         1&#x2F;1     Running   0          3h33m<br>kube-auditing-webhook-deploy-64cfb8c9f8-c65cb   1&#x2F;1     Running   0          3h32m<br>kube-auditing-webhook-deploy-64cfb8c9f8-j8w5d   1&#x2F;1     Running   0          3h32m<br>logsidecar-injector-deploy-5fb6fdc6dd-fv8vg     2&#x2F;2     Running   0          3h32m<br>logsidecar-injector-deploy-5fb6fdc6dd-fxsbf     2&#x2F;2     Running   0          3h32m</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 查看 pod 的 log，也会发现大量的错误日志。</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  / # kubectl logs  fluent-bit-j5rvq -n kubesphere-logging-system </span><br><span class="line">  </span><br><span class="line">  ...</span><br><span class="line">   [2022/04/15 07:25:47] [ warn] [net] getaddrinfo(host=&#x27;elasticsearch-logging-data.kubesphere-logging-system.svc&#x27;, err=4): Domain name not found</span><br><span class="line">  </span><br><span class="line">   [2022/04/15 07:25:47] [ warn] [engine] failed to flush chunk &#x27;12-1650007543.816834850.flb&#x27;, retry in 6 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0)</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="02-外部-ElasticSearch-配置失败的解决过程"><a href="#02-外部-ElasticSearch-配置失败的解决过程" class="headerlink" title="02. 外部 ElasticSearch 配置失败的解决过程"></a>02. 外部 ElasticSearch 配置失败的解决过程</h3><p>下面我们想办法解决上面配置异常的问题。</p><ol><li><p>查找官方论坛，关键词使用<strong>外部 es</strong> 找到了以下一篇看着比较接近的文档，打开来看看。</p><ul><li><blockquote><p><a href="https://kubesphere.com.cn/forum/d/6455-321es">3.2.1 版本日志系统对接外部 ES 无法正常收集日志</a></p></blockquote></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/elasticsearch-error-1.png" alt="elasticsearch-error-1"></p></li><li><p>看了一遍文档，现象跟我的一摸一样，文档中也提到了解决方案，貌似提问的人按着配置文档配置成功了，那我们去看看文档中的解决方案</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420095405948.png" alt="image-20220420095405948"></p></li><li><p>跳转到<a href="https://kubesphere.io/zh/docs/faq/observability/logging/#%E5%A6%82%E4%BD%95%E5%B0%86%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%E6%94%B9%E4%B8%BA%E5%A4%96%E9%83%A8-elasticsearch-%E5%B9%B6%E5%85%B3%E9%97%AD%E5%86%85%E9%83%A8-elasticsearch">第一个参考链接</a>。</p></li><li><p>第一个参考链接里，有一节<strong>如何将日志存储改为外部 Elasticsearch 并关闭内部 Elasticsearch</strong>, 看了一遍就是介绍如何开启外部 es 的配置，跟我们之前在界面上编辑 <strong>ClusterConfiguration</strong> 是一样的。</p></li><li><p>但是第一个他这一步介绍了手工重新执行 <strong>ks-installer</strong> 的方法，我就假设我界面修改了配置，但是 <strong>ks-installer</strong> 没重新执行（实际上肯定已经执行了），我在手工执行一次。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl rollout restart deploy -n kubesphere-system ks-installerdeployment.apps/ks-installer restarted[root@ks-k8s-master-0 ~]# kubectl rollout status deploy -n kubesphere-system ks-installerdeployment &quot;ks-installer&quot; successfully rolled out<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line">- 然后发现并没有什么改变，问题依旧。</span><br><span class="line"></span><br><span class="line">- 跳转到[第二个参考链接](https://github.com/wenchajun/ks-installer/blob/master/roles/ks-logging/templates/custom-output-elasticsearch-logging.yaml.j2)，这里是告诉我们手工修改的配置方式，暂时先不考虑，总感觉很多人遇到了，肯定有更好的方案，我们继续看论坛帖子。</span><br><span class="line"></span><br><span class="line">- 然后我在刚才的搜索结果中找到了[外部 es 无法正常收集日志](https://kubesphere.com.cn/forum/d/6590-es/3)，这篇文档的最后那兄弟说参考[github 的文档](https://github.com/kubesphere/kubesphere/issues/4640)解决了问题，那我们去试试 .</span><br><span class="line"></span><br><span class="line">- ![image-20220420103039813](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420103039813.png)</span><br><span class="line"></span><br><span class="line">- 该解决方案中也是修改配置文件，但是有一点，需要删掉配置文件中原来的 es 相关的 status 配置后，再次重新执行 ks-installer</span><br><span class="line"></span><br><span class="line">- ![image-20220420103344968](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420103344968.png)</span><br><span class="line"></span><br><span class="line">- 既然有这一段话 那么我们去看看我们实际环境的配置 , 但是我们的环境中并没有 es 的配置，因为我们最早的时候就没有启用内置的 es 服务。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl edit cc -n kubesphere-system ks-installer</span><br><span class="line">  </span><br><span class="line">  events:</span><br><span class="line">    enabledTime: 2022-04-15T16:22:59CST</span><br><span class="line">    status: enabled</span><br><span class="line">  fluentbit:</span><br><span class="line">    enabledTime: 2022-04-15T16:19:46CST</span><br><span class="line">    status: enabled</span><br><span class="line">  logging:</span><br><span class="line">    enabledTime: 2022-04-15T16:22:59CST</span><br><span class="line">    status: enabled</span><br></pre></td></tr></table></figure></code></pre></li><li><p>但是啊，本着宁杀错的原则，那我们删了这几段试试看看，重新执行 <strong>ks-installer</strong>，看看效果。</p></li><li><p>执行下面的命令，查看安装过程，确实开始了重新配置的过程（过程没截图 , 截取了几个相近的配置过程）</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#39;&#123;.items[0].metadata.name&#125;&#39;) -f...TASK [common : KubeSphere | Deleting elasticsearch] ****************************skipping: [localhost]TASK [common : KubeSphere | Waiting for seconds] *******************************skipping: [localhost]TASK [common : KubeSphere | Deploying elasticsearch-logging] *******************skipping: [localhost]TASK [common : KubeSphere | Importing es status] *******************************skipping: [localhost]TASK [common : KubeSphere | Deploying elasticsearch-logging-curator] ***********changed: [localhost]TASK [common : KubeSphere | Getting fluentbit installation files] **************changed: [localhost]TASK [common : KubeSphere | Creating custom manifests] *************************changed: [localhost] =&gt; (item=&#123;&#39;path&#39;: &#39;fluentbit&#39;, &#39;file&#39;: &#39;custom-fluentbit-fluentBit.yaml&#39;&#125;)changed: [localhost] =&gt; (item=&#123;&#39;path&#39;: &#39;init&#39;, &#39;file&#39;: &#39;custom-fluentbit-operator-deployment.yaml&#39;&#125;)TASK [common : KubeSphere | Preparing fluentbit operator setup] ****************changed: [localhost]TASK [common : KubeSphere | Deploying new fluentbit operator] ******************changed: [localhost]TASK [common : KubeSphere | Importing fluentbit status] ************************changed: [localhost]<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 等到彻底执行完成后，我发现我又失望了，问题依旧 , 看了一眼 Output 的配置，没啥变化。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]#  kubectl get output -n kubesphere-logging-system es -oyaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Output</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;</span><br><span class="line">    creationTimestamp: &quot;2022-04-15T03:51:11Z&quot;</span><br><span class="line">    generation: 1</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: logging</span><br><span class="line">      logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">    name: es</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">    resourceVersion: &quot;1503226&quot;</span><br><span class="line">    uid: 1a60036f-9ad0-4a3c-bab1-e077102a2724</span><br><span class="line">  spec:</span><br><span class="line">    es:</span><br><span class="line">      generateID: true</span><br><span class="line">      host: elasticsearch-logging-data.kubesphere-logging-system.svc</span><br><span class="line">      logstashFormat: true</span><br><span class="line">      logstashPrefix: ks-logstash-log</span><br><span class="line">      port: 9200</span><br><span class="line">      timeKey: &#x27;@timestamp&#x27;</span><br><span class="line">    matchRegex: (?:kube|service)\.(.*)</span><br></pre></td></tr></table></figure></code></pre></li><li><p>看来上面提到的方法，应该可能只适用于<strong>原来开启过内置 es，后来又想换到外部 es 的场景</strong>。</p></li><li><p>那我们继续回来看<a href="https://kubesphere.com.cn/forum/d/6590-es/3">外部 es 无法正常收集日志</a>这篇文档，里面还提到了一个参考链接<a href="https://kubesphere.com.cn/forum/d/2450-kuspheredial-tcp-lookup-http-on-109601053-no-such-host/4">在使用 kusphere 的操作审计功能时，总有弹窗提示：dial tcp: lookup http on 10.96.0.10:53: no such host</a>.</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420111124760.png" alt="image-20220420111124760"></p></li><li><p>该文档中的描述跟我们的现象类似，但不完全相同，文中提到的问题可以通过修改 <strong>ConfigMap</strong> 来解决，文章最后那哥们也说解决成功了。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420111152382.png" alt="image-20220420111152382"></p></li><li><p>我们看看我们对应的 ConfigMap 配置。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get configmap kubesphere-config -n kubesphere-system -o yamlapiVersion: v1data:  kubesphere.yaml: |    authentication:      authenticateRateLimiterMaxTries: 10      authenticateRateLimiterDuration: 10m0s      loginHistoryRetentionPeriod: 168h      maximumClockSkew: 10s      multipleLogin: True      kubectlImage: kubesphere/kubectl:v1.21.0      jwtSecret: &quot;1xh3ldfKpJSzSmFCbi2HXXbw5dn4o4kv&quot;      oauthOptions:        clients:        - name: kubesphere          secret: kubesphere          redirectURIs:          - &#39;*&#39;    ldap:      host: openldap.kubesphere-system.svc:389      managerDN: cn=admin,dc=kubesphere,dc=io      managerPassword: admin      userSearchBase: ou=Users,dc=kubesphere,dc=io      groupSearchBase: ou=Groups,dc=kubesphere,dc=io    redis:      host: redis.kubesphere-system.svc      port: 6379      password: KUBESPHERE_REDIS_PASSWORD      db: 0    s3:      endpoint: http://minio.kubesphere-system.svc:9000      region: us-east-1      disableSSL: True      forcePathStyle: True      accessKeyID: openpitrixminioaccesskey      secretAccessKey: openpitrixminiosecretkey      bucket: s2i-binaries    network:      ippoolType: none    devops:      host: http://devops-jenkins.kubesphere-devops-system.svc/      username: admin      password: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFkbWluQGt1YmVzcGhlcmUuaW8iLCJ1c2VybmFtZSI6ImFkbWluIiwidG9rZW5fdHlwZSI6InN0YXRpY190b2tlbiJ9.DVnt9FY7UNu2Mvshh_46UMKhZG7_X7NPC-ClQ68ynB0      maxConnections: 100      endpoint: http://devops-apiserver.kubesphere-devops-system:9090    openpitrix:      s3:        endpoint: http://minio.kubesphere-system.svc:9000        region: us-east-1        disableSSL: True        forcePathStyle: True        accessKeyID: openpitrixminioaccesskey        secretAccessKey: openpitrixminiosecretkey        bucket: app-store    monitoring:      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090      enableGPUMonitoring: false    gpu:      kinds:      - resourceName: nvidia.com/gpu        resourceType: GPU        default: True    notification:      endpoint: http://notification-manager-svc.kubesphere-monitoring-system.svc:19093    logging:      host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200      basicAuth: True      username: &quot;lstack&quot;      password: &quot;P@88w0rd&quot;      indexPrefix: ks-logstash-log    events:      host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200      basicAuth: True      username: &quot;lstack&quot;      password: &quot;P@88w0rd&quot;      indexPrefix: ks-logstash-events    auditing:      enable: true      webhookURL: https://kube-auditing-webhook-svc.kubesphere-logging-system.svc:6443/audit/webhook/event      host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200      basicAuth: True      username: &quot;lstack&quot;      password: &quot;P@88w0rd&quot;      indexPrefix: ks-logstash-auditing    alerting:      prometheusEndpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090      thanosRulerEndpoint: http://thanos-ruler-operated.kubesphere-monitoring-system.svc:10902      thanosRuleResourceLabels: thanosruler=thanos-ruler,role=thanos-alerting-rules    gateway:      watchesPath: /var/helm-charts/watches.yaml      repository: kubesphere/nginx-ingress-controller      tag: v0.48.1      namespace: kubesphere-controls-systemkind: ConfigMapmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:&#123;&quot;kubesphere.yaml&quot;:&quot;authentication:\n  authenticateRateLimiterMaxTries: 10\n  authenticateRateLimiterDuration: 10m0s\n  loginHistoryRetentionPeriod: 168h\n  maximumClockSkew: 10s\n  multipleLogin: True\n  kubectlImage: kubesphere/kubectl:v1.21.0\n  jwtSecret: \&quot;1xh3ldfKpJSzSmFCbi2HXXbw5dn4o4kv\&quot;\n  oauthOptions:\n    clients:\n    - name: kubesphere\n      secret: kubesphere\n      redirectURIs:\n      - &#39;*&#39;\n\nldap:\n  host: openldap.kubesphere-system.svc:389\n  managerDN: cn=admin,dc=kubesphere,dc=io\n  managerPassword: admin\n  userSearchBase: ou=Users,dc=kubesphere,dc=io\n  groupSearchBase: ou=Groups,dc=kubesphere,dc=io\n\nredis:\n  host: redis.kubesphere-system.svc\n  port: 6379\n  password: KUBESPHERE_REDIS_PASSWORD\n  db: 0\n\n\ns3:\n  endpoint: http://minio.kubesphere-system.svc:9000\n  region: us-east-1\n  disableSSL: True\n  forcePathStyle: True\n  accessKeyID: openpitrixminioaccesskey\n  secretAccessKey: openpitrixminiosecretkey\n  bucket: s2i-binaries\n\nnetwork:\n  ippoolType: none\ndevops:\n  host: http://devops-jenkins.kubesphere-devops-system.svc/\n  username: admin\n  password: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFkbWluQGt1YmVzcGhlcmUuaW8iLCJ1c2VybmFtZSI6ImFkbWluIiwidG9rZW5fdHlwZSI6InN0YXRpY190b2tlbiJ9.DVnt9FY7UNu2Mvshh_46UMKhZG7_X7NPC-ClQ68ynB0\n  maxConnections: 100\n  endpoint: http://devops-apiserver.kubesphere-devops-system:9090\nopenpitrix:\n  s3:\n    endpoint: http://minio.kubesphere-system.svc:9000\n    region: us-east-1\n    disableSSL: True\n    forcePathStyle: True\n    accessKeyID: openpitrixminioaccesskey\n    secretAccessKey: openpitrixminiosecretkey\n    bucket: app-store\nmonitoring:\n  endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090\n  enableGPUMonitoring: false\ngpu:\n  kinds:\n  - resourceName: nvidia.com/gpu\n    resourceType: GPU\n    default: True\nnotification:\n  endpoint: http://notification-manager-svc.kubesphere-monitoring-system.svc:19093\nlogging:\n  host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200\n  basicAuth: True\n  username: \&quot;lstack\&quot;\n  password: \&quot;P@88w0rd\&quot;\n  indexPrefix: ks-logstash-log\nevents:\n  host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200\n  basicAuth: True\n  username: \&quot;lstack\&quot;\n  password: \&quot;P@88w0rd\&quot;\n  indexPrefix: ks-logstash-events\nauditing:\n  enable: true\n  webhookURL: https://kube-auditing-webhook-svc.kubesphere-logging-system.svc:6443/audit/webhook/event\n  host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200\n  basicAuth: True\n  username: \&quot;lstack\&quot;\n  password: \&quot;P@88w0rd\&quot;\n  indexPrefix: ks-logstash-auditing\n\nalerting:\n  prometheusEndpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090\n  thanosRulerEndpoint: http://thanos-ruler-operated.kubesphere-monitoring-system.svc:10902\n  thanosRuleResourceLabels: thanosruler=thanos-ruler,role=thanos-alerting-rules\n\n\ngateway:\n  watchesPath: /var/helm-charts/watches.yaml\n  repository: kubesphere/nginx-ingress-controller\n  tag: v0.48.1\n  namespace: kubesphere-controls-system\n&quot;&#125;,&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;kubesphere-config&quot;,&quot;namespace&quot;:&quot;kubesphere-system&quot;&#125;&#125;  creationTimestamp: &quot;2022-04-09T14:42:47Z&quot;  name: kubesphere-config  namespace: kubesphere-system  resourceVersion: &quot;1557079&quot;  uid: 2d45c34b-bc9d-43bd-a3d3-37b294393531<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   - 我们发现几个相关配置的 host 地址确实是错的跟我们之前发现的一样，而且这里并没有明确的 es 配置。对于技术细节了解不深的我，直觉告诉我这个方向应该是错的，暂时不选。</span><br><span class="line"></span><br><span class="line">   - 排查到此时，我的心里已经烦躁不安了，搞了两个小时的我此时不想再找下去了，直接放出最后一招，去改 [Output](https://github.com/kubesphere/ks-installer/blob/master/roles/ks-logging/templates/custom-output-elasticsearch-logging.yaml.j2) 文件看看(我们前文介绍的论坛中一个帖子提到的)。</span><br><span class="line"></span><br><span class="line">2. 问题排查第二环节，修改 Output 文件。</span><br><span class="line"></span><br><span class="line">   - 先看看参考模板 **custom-output-elasticsearch-logging.yaml.j2** 的样子。</span><br><span class="line"></span><br><span class="line">   - ```yaml</span><br><span class="line">     apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">     kind: Output</span><br><span class="line">     metadata:</span><br><span class="line">       name: es</span><br><span class="line">       namespace: kubesphere-logging-system</span><br><span class="line">       labels:</span><br><span class="line">         logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">         logging.kubesphere.io/component: &quot;logging&quot;</span><br><span class="line">     spec:</span><br><span class="line">       matchRegex: (?:kube|service)\.(.*)</span><br><span class="line">       es:</span><br><span class="line">         host: &quot;&#123;% if common.es.externalElasticsearchHost is defined and common.es.externalElasticsearchHost != &quot;&quot; %&#125;&#123;&#123; common.es.externalElasticsearchHost &#125;&#125;&#123;% else %&#125;elasticsearch-logging-data.kubesphere-logging-system.svc&#123;% endif %&#125;&quot;</span><br><span class="line">         port: &#123;% if common.es.externalElasticsearchPort is defined and common.es.externalElasticsearchPort != &quot;&quot; %&#125;&#123;&#123; common.es.externalElasticsearchPort &#125;&#125;&#123;% else %&#125;9200&#123;% endif %&#125;</span><br><span class="line">     </span><br><span class="line">     &#123;% if common.es.basicAuth is defined and common.es.basicAuth.enabled is defined and common.es.basicAuth.enabled %&#125;</span><br><span class="line">     &#123;% if common.es.basicAuth.username is defined and common.es.basicAuth.username != &quot;&quot; %&#125;</span><br><span class="line">         httpUser:</span><br><span class="line">           valueFrom:</span><br><span class="line">             secretKeyRef:</span><br><span class="line">               key: &quot;username&quot;</span><br><span class="line">               name: &quot;elasticsearch-credentials&quot;</span><br><span class="line">     &#123;% endif %&#125;</span><br><span class="line">     &#123;% if common.es.basicAuth.password is defined and common.es.basicAuth.password != &quot;&quot; %&#125;</span><br><span class="line">         httpPassword:</span><br><span class="line">           valueFrom:</span><br><span class="line">             secretKeyRef:</span><br><span class="line">               key: &quot;password&quot;</span><br><span class="line">               name: &quot;elasticsearch-credentials&quot;</span><br><span class="line">     &#123;% endif %&#125;</span><br><span class="line">     &#123;% endif %&#125;</span><br><span class="line">         generateID: true</span><br><span class="line">         logstashPrefix: &quot;ks-&#123;&#123; common.es.elkPrefix &#125;&#125;-log&quot;</span><br><span class="line">         logstashFormat: true</span><br><span class="line">         timeKey: &quot;@timestamp&quot;</span><br><span class="line">     &#123;% if common.es.externalElasticsearchProtocol is defined and common.es.externalElasticsearchProtocol == &quot;https&quot; %&#125;</span><br><span class="line">         tls:</span><br><span class="line">           verify: false</span><br><span class="line">     &#123;% endif %&#125;</span><br></pre></td></tr></table></figure></code></pre></li><li><p>小伙伴们你们看懂了么，好在我有 Ansible 的使用经验，之前也写过 Jinja2 的语法，否则暴脾气的我，又要拍桌子了。没看懂的也没关系，暂时先放着，我会在本文对应的直播视频中给大家讲解具体含义。</p></li><li><p>再来贴一次我们线上的配置。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get outputs -n kubesphere-logging-system es -o yamlapiVersion: logging.kubesphere.io/v1alpha2kind: Outputmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;  creationTimestamp: &quot;2022-04-15T03:51:11Z&quot;  generation: 1  labels:    logging.kubesphere.io/component: logging    logging.kubesphere.io/enabled: &quot;true&quot;  name: es  namespace: kubesphere-logging-system  resourceVersion: &quot;1503226&quot;  uid: 1a60036f-9ad0-4a3c-bab1-e077102a2724spec:  es:    generateID: true    host: elasticsearch-logging-data.kubesphere-logging-system.svc    logstashFormat: true    logstashPrefix: ks-logstash-log    port: 9200    timeKey: &#39;@timestamp&#39;  matchRegex: (?:kube|service)\.(.*)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 通过分析模板，发现如果开启认证的话，需要调用 **elasticsearch-credentials** 这个 secrets，所以我们先检查一下，这个 secret 是否存在。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get secrets elasticsearch-credentials -n kubesphere-logging-system </span><br><span class="line">  NAME                        TYPE                       DATA   AGE</span><br><span class="line">  elasticsearch-credentials   kubernetes.io/basic-auth   2      4d21h</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get secrets elasticsearch-credentials -n kubesphere-logging-system -o yaml</span><br><span class="line">  apiVersion: v1</span><br><span class="line">  data:</span><br><span class="line">    password: UEA4OHcwcmQ=</span><br><span class="line">    username: bHN0YWNr</span><br><span class="line">  kind: Secret</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: &quot;2022-04-15T05:56:51Z&quot;</span><br><span class="line">    name: elasticsearch-credentials</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">    resourceVersion: &quot;1528520&quot;</span><br><span class="line">    uid: d918b1e0-4562-490b-bed7-d1dce702589a</span><br><span class="line">  type: kubernetes.io/basic-auth</span><br></pre></td></tr></table></figure></code></pre></li><li><p>确认 secrets 存在，接下来我先把 Outpt 配置文件输出一份备份下来，然后再去修改配置文件。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get outputs -n kubesphere-logging-system es -o yaml &gt; es.output.yaml[root@ks-k8s-master-0 ~]# kubectl edit outputs -n kubesphere-logging-system es<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 修改后的内容如下：</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Output</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;</span><br><span class="line">    creationTimestamp: &quot;2022-04-15T03:51:11Z&quot;</span><br><span class="line">    generation: 1</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: logging</span><br><span class="line">      logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">    name: es</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">    resourceVersion: &quot;1503226&quot;</span><br><span class="line">    uid: 1a60036f-9ad0-4a3c-bab1-e077102a2724</span><br><span class="line">  spec:</span><br><span class="line">    es:</span><br><span class="line">      generateID: true</span><br><span class="line">      host: 192.168.9.95</span><br><span class="line">      port: 9200</span><br><span class="line">      httpUser:</span><br><span class="line">        valueFrom:</span><br><span class="line">          secretKeyRef:</span><br><span class="line">            key: &quot;username&quot;</span><br><span class="line">            name: &quot;elasticsearch-credentials&quot;</span><br><span class="line">      httpPassword:</span><br><span class="line">        valueFrom:</span><br><span class="line">          secretKeyRef:</span><br><span class="line">            key: &quot;password&quot;</span><br><span class="line">            name: &quot;elasticsearch-credentials&quot;</span><br><span class="line">      logstashFormat: true</span><br><span class="line">      logstashPrefix: ks-logstash-log</span><br><span class="line">      tls:</span><br><span class="line">        verify: false</span><br><span class="line">      timeKey: &#x27;@timestamp&#x27;</span><br><span class="line">    matchRegex: (?:kube|service)\.(.*)</span><br></pre></td></tr></table></figure></code></pre></li><li><p>配置文件改造完成后，保存退出</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]# kubectl edit outputs -n kubesphere-logging-system es</span><br><span class="line">output.logging.kubesphere.io/es edited</span><br></pre></td></tr></table></figure></li><li><p>再次查看 es 的 Output 的资源配置 , 发现已经有变化了</p><blockquote><p><strong>重点说明 : 本文写到最后的时候我发现我这步就做错了 , 配置文件我不应该加下面的参数，不加的话到这步为止就都 ok 了不会再有后面的内容了，为了故事的完整性就继续按错的写了！！！</strong></p><p>tls:<br>  verify: false</p></blockquote></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get outputs -n kubesphere-logging-system es -o yamlapiVersion: logging.kubesphere.io/v1alpha2kind: Outputmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;  creationTimestamp: &quot;2022-04-15T03:51:11Z&quot;  generation: 2  labels:    logging.kubesphere.io/component: logging    logging.kubesphere.io/enabled: &quot;true&quot;  name: es  namespace: kubesphere-logging-system  resourceVersion: &quot;2865406&quot;  uid: 1a60036f-9ad0-4a3c-bab1-e077102a2724spec:  es:    generateID: true    host: 192.168.9.95    httpPassword:      valueFrom:        secretKeyRef:          key: password          name: elasticsearch-credentials    httpUser:      valueFrom:        secretKeyRef:          key: username          name: elasticsearch-credentials    logstashFormat: true    logstashPrefix: ks-logstash-log    port: 9200    timeKey: &#39;@timestamp&#39;    tls:      verify: false  matchRegex: (?:kube|service)\.(.*)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 我们再看看 fluent-bit 的日志 (截取部分关键日志)</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl logs  fluent-bit-j5rvq -n kubesphere-logging-system</span><br><span class="line">  </span><br><span class="line">  [2022/04/20 03:43:19] [ warn] [net] getaddrinfo(host=&#x27;elasticsearch-logging-data.kubesphere-logging-system.svc&#x27;, err=4): Domain name not found</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:19] [ warn] [engine] failed to flush chunk &#x27;12-1650426197.168443930.flb&#x27;, retry in 8 seconds: task_id=1, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:23] [ warn] [net] getaddrinfo(host=&#x27;elasticsearch-logging-data.kubesphere-logging-system.svc&#x27;, err=4): Domain name not found</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:23] [ warn] [engine] chunk &#x27;12-1650426192.752749410.flb&#x27; cannot be retried: task_id=4, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:23] [ warn] [net] getaddrinfo(host=&#x27;elasticsearch-logging-data.kubesphere-logging-system.svc&#x27;, err=4): Domain name not found</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:23] [ warn] [engine] chunk &#x27;12-1650426187.71256663.flb&#x27; cannot be retried: task_id=0, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [engine] service stopped</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=416649 watch_fd=1</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=461549 watch_fd=2</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134582558 watch_fd=3</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268955529 watch_fd=5</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373423 watch_fd=6</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373208 watch_fd=7</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403716654 watch_fd=8</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583208 watch_fd=9</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=269010417 watch_fd=11</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403995814 watch_fd=13</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=962171 watch_fd=14</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134580575 watch_fd=16</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268955289 watch_fd=17</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403715964 watch_fd=18</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403855647 watch_fd=19</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=413299 watch_fd=20</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=375870 watch_fd=21</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134581094 watch_fd=22</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268956011 watch_fd=26</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373969 watch_fd=27</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403792092 watch_fd=28</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=412431 watch_fd=29</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134738124 watch_fd=30</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=467559 watch_fd=31</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403860482 watch_fd=32</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=463110 watch_fd=160</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=135190584 watch_fd=161</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134738131 watch_fd=162</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583424 watch_fd=173</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583425 watch_fd=177</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=466327 watch_fd=183</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=269514179 watch_fd=184</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:24] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=412659 watch_fd=186</span><br><span class="line">  </span><br><span class="line">   level=error msg=&quot;Fluent bit exited&quot; error=null</span><br><span class="line">  </span><br><span class="line">   level=info msg=backoff delay=1s</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;backoff timer done&quot; actual=1.000475459s expected=1s</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Fluent bit started&quot;</span><br><span class="line">  </span><br><span class="line">   Fluent Bit v1.8.3</span><br><span class="line">  </span><br><span class="line">   * Copyright (C) 2019-2021 The Fluent Bit Authors</span><br><span class="line">  </span><br><span class="line">   * Copyright (C) 2015-2018 Treasure Data</span><br><span class="line">  </span><br><span class="line">   * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd</span><br><span class="line">  </span><br><span class="line">   * https://fluentbit.io</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [engine] started (pid=18)</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [storage] version=1.1.1, initializing...</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [storage] in-memory</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [cmetrics] version=0.1.6</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:systemd:systemd.0] seek_cursor=s=5d0022eeaf454ba8a40dde2836de2f4d;i=963... OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:systemd:systemd.1] seek_cursor=s=5d0022eeaf454ba8a40dde2836de2f4d;i=96c... OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [filter:kubernetes:kubernetes.4] https=1 host=kubernetes.default.svc port=443</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [filter:kubernetes:kubernetes.4] local POD info OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [filter:kubernetes:kubernetes.4] testing connectivity with API server...</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [filter:kubernetes:kubernetes.4] connectivity OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [sp] stream processor started</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=416649 watch_fd=1 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_alertmanager-1a71f1d5b1136320644f3289e4b22544620db4a0d35a1ffec52bc534d729c358.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=461549 watch_fd=2 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_config-reloader-bc14c53008f1e800d6240a5b912239a3d5682c6dcb719f48c69b7e8ba5892e35.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134582558 watch_fd=3 name=/var/log/containers/calico-kube-controllers-75ddb95444-8xvf4_kube-system_calico-kube-controllers-dc90044aa0ce62e61dfb0842c8f2e5aa8d021738adffca847b003a5c9621512c.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583425 watch_fd=4 name=/var/log/containers/calico-node-pzvrj_kube-system_calico-node-f2f40fb9878e3328a4783ceb9c01eaed9edf24c85579ed87c7ffc2161779c3e2.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955529 watch_fd=5 name=/var/log/containers/calico-node-pzvrj_kube-system_flexvol-driver-abf59d8a7af22c683dfb0776a0835c719f41ef23446e912f82901a4fd9cf166f.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373423 watch_fd=6 name=/var/log/containers/calico-node-pzvrj_kube-system_install-cni-b3d49f2e9c03e63c3863d50365d2ade01dead979c90285c526ac0029b58411cd.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373208 watch_fd=7 name=/var/log/containers/calico-node-pzvrj_kube-system_upgrade-ipam-6d4425d7ea5302511df1c278f2b113ac8fdfa0a372e07b025e0a9b45d30129ac.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403716654 watch_fd=8 name=/var/log/containers/coredns-5495dd7c88-68k9b_kube-system_coredns-879c087a4c8717d0886e6603a63e9503a406d215cfe77941cbcc1cc7c138d010.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583208 watch_fd=9 name=/var/log/containers/coredns-5495dd7c88-z9q6j_kube-system_coredns-80cd4427410de02465b415683817a75674a95777ffc0929f93e87506b120ca59.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=466327 watch_fd=10 name=/var/log/containers/ks-apiserver-574966976-snfm4_kubesphere-system_ks-apiserver-8871a0cc18cfef4663a15680761e272efeafe061ea9a898319265a145b494b18.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269010417 watch_fd=11 name=/var/log/containers/ks-console-65f4d44d88-hzw9b_kubesphere-system_ks-console-f600455c3af064c53adc8eb7e5412505c4d0e50362ab11b8e59d2e71b552b0f1.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269514179 watch_fd=12 name=/var/log/containers/ks-controller-manager-79c7dc79f5-j9fz5_kubesphere-system_ks-controller-manager-a8c35247c7cda868d3c023616026515690d2fedf2abb0f9367d1dc338103f7af.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403995814 watch_fd=13 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_config-reloader-2d51bab0babdd47864ec235efdbd69d2075cc8bf72c3642449be69f68aa1f0d5.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=962171 watch_fd=14 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_events-ruler-da24092a12c4fc0d0aab8a02c7fc7cb1e0e82d15a924717222bdbadee7935c84.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583424 watch_fd=15 name=/var/log/containers/kube-apiserver-ks-k8s-master-0_kube-system_kube-apiserver-b4e97a525442956fe7612d27367a184ee09d65a56464149ec913ea004db0f1ef.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134580575 watch_fd=16 name=/var/log/containers/kube-controller-manager-ks-k8s-master-0_kube-system_kube-controller-manager-a07d1c5ed4108d98de2ba322b47939d5007c9d266a4ff558d57ec87ab10b2d54.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955289 watch_fd=17 name=/var/log/containers/kube-proxy-bc59k_kube-system_kube-proxy-79144efa6b42a0f9636132538cc4ade6665269fea5903f3e1e0be05f14376d7c.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403715964 watch_fd=18 name=/var/log/containers/kube-scheduler-ks-k8s-master-0_kube-system_kube-scheduler-1a2ffcf4000a9bb0fa526fcfa1970e69465dfe0bb4c635a4d95f50f2e27ef763.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403855647 watch_fd=19 name=/var/log/containers/minio-859cb4d777-mpsk9_kubesphere-system_minio-d76f9516fa485cd24851afccfb2c85fd74ce894ba580af98703704860e1c00ed.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=413299 watch_fd=20 name=/var/log/containers/node-exporter-wwrpf_kubesphere-monitoring-system_kube-rbac-proxy-e35229db1e46e8b7b0a7d5a3cd581107102a3531b31d2e32d7e787a118c82896.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=375870 watch_fd=21 name=/var/log/containers/node-exporter-wwrpf_kubesphere-monitoring-system_node-exporter-e5cc5a4cc937cf9de149dd25bd6e8441ca176bf26cb2a214dd0b47627e7d8861.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134581094 watch_fd=22 name=/var/log/containers/nodelocaldns-sp59h_kube-system_node-cache-8b5bdf5a116af255f979a4a349c168257b632d24805d5f257a642dd97b0d53a1.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=463110 watch_fd=23 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_config-reloader-1378a8d9cd7a96334cb15adeafb468497ece0a9a600a3193fb80b60bc5b7e9b5.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135190584 watch_fd=24 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_prometheus-26e94cf0828cd1bd9c5da45217b7f3e654a7a41ce0dc5943375b1644d1a6a002.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134738131 watch_fd=25 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_prometheus-97de8b484747bae4aeac54ffd9b75c1ddc9582a28c768ebc9be395390bd031c3.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268956011 watch_fd=26 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-kqrl5_kubesphere-system_config-init-0fb775710352218a66aec02ea2a736892c33df43dd4206e155e0bce6af4aba63.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373969 watch_fd=27 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-kqrl5_kubesphere-system_haproxy-6c15749c02904875f5c1a280a42a908baa074ccffd3365f40b2692b6fe60acf5.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403792092 watch_fd=28 name=/var/log/containers/redis-ha-server-2_kubesphere-system_config-init-fa7c66040a53bef1c3c9b1844a4b25870835a6147cd83abf914ebb129a036536.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=412431 watch_fd=29 name=/var/log/containers/redis-ha-server-2_kubesphere-system_redis-6b19bb18f79c55cca6022bd8caa13a33d8c57386897db47fc011fd9fbe589b8a.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134738124 watch_fd=30 name=/var/log/containers/redis-ha-server-2_kubesphere-system_sentinel-7b2cbde0a38f45b692dd1679912bb9ba4bdfc358667c32164592a0e7ab2a87a6.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=467559 watch_fd=31 name=/var/log/containers/thanos-ruler-kubesphere-1_kubesphere-monitoring-system_config-reloader-28aef566c79b3cc073a67787c6ad44902c88930f069ab26cf5657aa2d1235108.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403860482 watch_fd=32 name=/var/log/containers/thanos-ruler-kubesphere-1_kubesphere-monitoring-system_thanos-ruler-24cfbc7280d54f3289c4ae70d0bb25a4964dd2f759e8bddefad3cf92070b1903.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:25] [ info] [input:tail:tail.2] inotify_fs_add(): inode=412659 watch_fd=33 name=/var/log/containers/fluent-bit-vv8pb_kubesphere-logging-system_fluent-bit-dfd9ef652ece992d5f6b9a57c84288d19ebae1d8dcbd8618758f956e35370182.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:30] [ warn] [engine] failed to flush chunk &#x27;18-1650426205.971801521.flb&#x27;, retry in 9 seconds: task_id=1, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:30] [ warn] [engine] failed to flush chunk &#x27;18-1650426205.162979514.flb&#x27;, retry in 6 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:30] [ warn] [engine] failed to flush chunk &#x27;18-1650426206.629361363.flb&#x27;, retry in 9 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:35] [ warn] [engine] failed to flush chunk &#x27;18-1650426210.70782057.flb&#x27;, retry in 10 seconds: task_id=3, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:36] [ warn] [engine] chunk &#x27;18-1650426205.162979514.flb&#x27; cannot be retried: task_id=0, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:39] [ warn] [engine] chunk &#x27;18-1650426206.629361363.flb&#x27; cannot be retried: task_id=2, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:39] [ warn] [engine] chunk &#x27;18-1650426205.971801521.flb&#x27; cannot be retried: task_id=1, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/20 03:43:40] [ warn] [engine] failed to flush chunk &#x27;18-1650426215.131578181.flb&#x27;, retry in 11 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0)</span><br></pre></td></tr></table></figure></code></pre></li><li><p>分析日志发现 <strong>Domain name not found</strong> 这个报错已经不存在了，说明 es 地址配置变更了，但是还有其他报错我们继续分析。</p></li><li><p>我们发现现在运行的 <strong>fluent-bit</strong> 还是 5 天前创建的（好吧，可以看到这个事情已经困扰了我 5 天了），尝试使用<strong>重启大法</strong>，没准 pod 在初始创建的时候会做什么特殊操作呢。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit.png" alt="kubesphere-daemonsets-flunet-bit"></p></li><li><p>点击<strong>更多操作</strong>，<strong>重新创建</strong>。</p></li><li><p>不知道为啥 只给我重建了一个，不过先不管了，先看日志。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-1.png" alt="kubesphere-daemonsets-flunet-bit-1"></p></li><li><p>重建完成后，我们看看 pod 的新启动的日志 , 发现跟刚才差不多。</p></li><li><pre><code class="yaml"> level=info msg=&quot;Fluent bit started&quot; Fluent Bit v1.8.3 * Copyright (C) 2019-2021 The Fluent Bit Authors * Copyright (C) 2015-2018 Treasure Data * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io [2022/04/20 04:07:18] [ info] [engine] started (pid=15) [2022/04/20 04:07:18] [ info] [storage] version=1.1.1, initializing... [2022/04/20 04:07:18] [ info] [storage] in-memory [2022/04/20 04:07:18] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128 [2022/04/20 04:07:18] [ info] [cmetrics] version=0.1.6 [2022/04/20 04:07:18] [ info] [filter:kubernetes:kubernetes.4] https=1 host=kubernetes.default.svc port=443 [2022/04/20 04:07:18] [ info] [filter:kubernetes:kubernetes.4] local POD info OK [2022/04/20 04:07:18] [ info] [filter:kubernetes:kubernetes.4] testing connectivity with API server... [2022/04/20 04:07:18] [ info] [filter:kubernetes:kubernetes.4] connectivity OK [2022/04/20 04:07:18] [ info] [sp] stream processor started [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=438144 watch_fd=1 name=/var/log/containers/alertmanager-main-0_kubesphere-monitoring-system_alertmanager-da4bf030d6c508ccc7ae8b0d25e9a5d3f4167635b3b1e7c9132f43ca18e26759.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134775019 watch_fd=2 name=/var/log/containers/alertmanager-main-0_kubesphere-monitoring-system_config-reloader-0e9ea4d0750bec9cca7a04090fb8ead8d05101fa2fa86e36378c5305483895ad.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135308807 watch_fd=3 name=/var/log/containers/calico-node-grzs6_kube-system_calico-node-e110ff3989cef4695508721c54abe41c82b020e485a04d51ee067c3749b40ff0.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955566 watch_fd=4 name=/var/log/containers/calico-node-grzs6_kube-system_flexvol-driver-bf0279ba75c245f871727d85546e8e135b9c1647ca3af318a13b961c9ab63fef.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373353 watch_fd=5 name=/var/log/containers/calico-node-grzs6_kube-system_install-cni-2020df6843b42253a7fe3cc71db6a8c380f76dd719985daec3217155a3b99fb9.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955530 watch_fd=6 name=/var/log/containers/calico-node-grzs6_kube-system_upgrade-ipam-d31b5da3acd65ea3a1630576cf8a3527ce89f75a713331f0f79f173180ba2807.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134745703 watch_fd=7 name=/var/log/containers/default-http-backend-5bf68ff9b8-qmsqj_kubesphere-controls-system_default-http-backend-3024b370ba28e45f0d739157883e1c05b0450ca6dd6fac17ff86704c25e307df.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404112903 watch_fd=8 name=/var/log/containers/devops-27507060-slntp_kubesphere-devops-system_pipeline-run-gc-67341c0a99432db725e08104b44a9d3b47ab96df5622d7fa42cc03bb51772360.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404114497 watch_fd=9 name=/var/log/containers/devops-27507090-7b7n9_kubesphere-devops-system_pipeline-run-gc-23c2506ed4daa1f43fe43eb25a1b30a799afd4b1a41ead8f514197b9f0d321e1.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404114514 watch_fd=10 name=/var/log/containers/devops-27507120-bwgkg_kubesphere-devops-system_pipeline-run-gc-af8382bfca6e901ec451e15bb1fac7d89619e8c3c15e780672bb4824af823c19.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135613174 watch_fd=11 name=/var/log/containers/devops-controller-98975d478-td5xx_kubesphere-devops-system_init-config-156a981f1398223c968105b4feb24dbbcee97403844ca623159bfed4cd647e85.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135675036 watch_fd=12 name=/var/log/containers/devops-controller-98975d478-td5xx_kubesphere-devops-system_ks-devops-953f7eff3a2cef2ca441be9b57024286c1e058af6033de0a0d9453649e79fe8f.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404546115 watch_fd=13 name=/var/log/containers/devops-jenkins-5d744f66b9-cfnq5_kubesphere-devops-system_copy-default-config-8970ad7a6668683a6e73c80479b92e6cec3d8280add9983b6b911db708e2b46f.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135827943 watch_fd=14 name=/var/log/containers/devops-jenkins-5d744f66b9-cfnq5_kubesphere-devops-system_devops-jenkins-ebe951dce6b04d70e0982a50a27ea1c84c46f6fd5bb324f8d98a6d3c8d98f03d.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135304775 watch_fd=15 name=/var/log/containers/elasticsearch-logging-curator-elasticsearch-curator-275050tdf82_kubesphere-logging-system_elasticsearch-curator-150f0f2dfaf91b75c2f357d4a610c6ff435325bf7b6946d0972299d297c99aba.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=2740314 watch_fd=16 name=/var/log/containers/elasticsearch-logging-curator-elasticsearch-curator-275064gfsnt_kubesphere-logging-system_elasticsearch-curator-b057cc4fa0f64009cc4e8862b105275f5180dec25ffd85aafecd3e38b3fe8607.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=1448183 watch_fd=17 name=/var/log/containers/fluentbit-operator-745bf5559f-lgq9p_kubesphere-logging-system_fluentbit-operator-6e0515f3ec61269e573610598fb0fafa1f4b6c7b6c9737cc5149f4dce73f0726.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269964578 watch_fd=18 name=/var/log/containers/fluentbit-operator-745bf5559f-lgq9p_kubesphere-logging-system_setenv-160f20273aae37dead28b4ee01faaf8417e66c8679253218fa1d69f7f67d9986.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269092123 watch_fd=19 name=/var/log/containers/ks-apiserver-574966976-zlzdn_kubesphere-system_ks-apiserver-0f59c89e26d48f7e7a33434412136d6f2c6e36b3cb9a6c551b5921a9b3c648c3.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269001282 watch_fd=20 name=/var/log/containers/ks-console-65f4d44d88-6zh2n_kubesphere-system_ks-console-473625ee71e3c79256031c7e17b4c7e3cd8c01a32674dabcbc278b113759b86b.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403767194 watch_fd=21 name=/var/log/containers/ks-controller-manager-79c7dc79f5-b4887_kubesphere-system_ks-controller-manager-8c0f54653d9f6f3f5647cdf6c1491d7f3676a31ee06a61539d1ad22ac9a9f0e3.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404597475 watch_fd=22 name=/var/log/containers/ks-events-operator-5944645757-kqt65_kubesphere-logging-system_events-operator-2d6a462d820e369d58f4add588f2d8798579505db12141cd711c0df6b8adf323.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=2531381 watch_fd=23 name=/var/log/containers/ks-events-ruler-575669b4-lnpxc_kubesphere-logging-system_config-reloader-135d523190a321b1c1b5164f065f10bccb803d1a9b01cfa6c59285f00175fc0e.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=270078583 watch_fd=24 name=/var/log/containers/ks-events-ruler-575669b4-lnpxc_kubesphere-logging-system_events-ruler-0698fb3748bfa98dc345dfabcbd44eb456b71c36bdffb56222643a25040cd878.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134910338 watch_fd=25 name=/var/log/containers/kube-apiserver-ks-k8s-master-2_kube-system_kube-apiserver-06d36c6647da955d83f369af80185dfa57801bd6397c54b833595425abd937d1.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269993224 watch_fd=26 name=/var/log/containers/kube-auditing-operator-84857bf967-kg7bs_kubesphere-logging-system_kube-auditing-operator-086ff221b47aa055daea0bbde34869f53a266129b11c90e8123fb1d43506f46d.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373019 watch_fd=27 name=/var/log/containers/kube-controller-manager-ks-k8s-master-2_kube-system_kube-controller-manager-dc6148b02773d71cd3ae73afc259d8989fc8fa3d5497a1edc5fb6c28561e4b93.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134581155 watch_fd=28 name=/var/log/containers/kube-proxy-bzx69_kube-system_kube-proxy-d130696f10d7ea91f909720c178b90b68b553dce873030fba8e7daf8fcd1b26b.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134580882 watch_fd=29 name=/var/log/containers/kube-scheduler-ks-k8s-master-2_kube-system_kube-scheduler-7fe7efb1fbd3f599ebc530f7ca4379b02aa0bc0e8b23c269cee79bec36c6e103.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=664327 watch_fd=30 name=/var/log/containers/kubectl-admin-6667774bb-mv9fm_kubesphere-controls-system_kubectl-a15f90842b782a08fe6c5f944974e2551a5995bca4116d741537b7d9b7531ef1.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135322058 watch_fd=31 name=/var/log/containers/logsidecar-injector-deploy-5fb6fdc6dd-fxsbf_kubesphere-logging-system_config-reloader-7e5fb4de2d6433568d612d3092d23b38beca28a5089106ad84a5f9b33258c3fd.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404567916 watch_fd=32 name=/var/log/containers/logsidecar-injector-deploy-5fb6fdc6dd-fxsbf_kubesphere-logging-system_logsidecar-injector-5e0181bde98c6444d5de2e9aac6ab459bbf957c09edc1ba06be473d0e24ce21f.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134969612 watch_fd=33 name=/var/log/containers/node-exporter-8tldd_kubesphere-monitoring-system_kube-rbac-proxy-c6a4a0dc8ce6ef8f6b73a940ee8473e20c08c1b85fefb679003c4a08c1889c09.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134778346 watch_fd=34 name=/var/log/containers/node-exporter-8tldd_kubesphere-monitoring-system_node-exporter-c0458098c9d6d132a765c753b3a7edc23887ecd48e457be393fa359ca731eef2.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269110037 watch_fd=35 name=/var/log/containers/notification-manager-deployment-78664576cb-2zqhb_kubesphere-monitoring-system_notification-manager-8a6449e8a99c56341b5a196251b99c95893b49ccf7b97c239e1da6b5fe899aca.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135304736 watch_fd=36 name=/var/log/containers/notification-manager-deployment-78664576cb-2zqhb_kubesphere-monitoring-system_tenant-4851fb71b6d33755ea467a0745abb4f0c7757e840d18a3ab34b7c4d5bcb61fbb.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135203266 watch_fd=37 name=/var/log/containers/notification-manager-deployment-78664576cb-qdzg8_kubesphere-monitoring-system_notification-manager-26afc727ce8fff65033c5432d74fd8da02dc297de6d6f9013eca432a6ed14a67.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404111997 watch_fd=38 name=/var/log/containers/notification-manager-deployment-78664576cb-qdzg8_kubesphere-monitoring-system_tenant-b7dec63c57fdb165777eddc9ac3f33a3bbb8d752c5508e9bd64b53f7fa7c1667.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403837581 watch_fd=39 name=/var/log/containers/notification-manager-operator-7d44854f54-5x8ml_kubesphere-monitoring-system_kube-rbac-proxy-e7e058ebc7a31bfe48f950473ce4e5945ba63117b970c4817aed6f341fc6a1c5.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269104667 watch_fd=40 name=/var/log/containers/notification-manager-operator-7d44854f54-5x8ml_kubesphere-monitoring-system_notification-manager-operator-6cbd966b72900f3e53460e0f599d6f29e2d12d81e480ae091e951f3a718e26e1.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404140622 watch_fd=41 name=/var/log/containers/openldap-0_kubesphere-system_openldap-ha-34603befcd35f87ef4f343d4774193d968eb285669c68e617a6df561976b2c90.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404112865 watch_fd=42 name=/var/log/containers/openldap-0_kubesphere-system_openldap-ha-8bb8c1a38b9a28adee5ec2b98c64c44987f3958d5f649a2c0f8572988812edba.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135305918 watch_fd=43 name=/var/log/containers/openpitrix-import-job-56b4v_kubesphere-system_import-6b9e87ef772f7e985b172f6da40a44c14e3ebede2cb726299b1260b2f254772a.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135305893 watch_fd=44 name=/var/log/containers/openpitrix-import-job-56b4v_kubesphere-system_wait-apiserver-9d2f65fc31598f6bd4a3097919149d24b0fa8b7a26e2b3892b0486a38f8264d0.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=437223 watch_fd=45 name=/var/log/containers/prometheus-operator-5c5db79546-fhz5t_kubesphere-monitoring-system_kube-rbac-proxy-57f49887b2934e7989c4bdf830eb7c1f963f8ad9da453897e63545e541cfa1b1.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269001982 watch_fd=46 name=/var/log/containers/prometheus-operator-5c5db79546-fhz5t_kubesphere-monitoring-system_prometheus-operator-95c8b3de232d26e297314b8e37859c4c65dd46748467ff2bbf7d7b85df90858a.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403724186 watch_fd=47 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-jhxvc_kubesphere-system_config-init-10b5cff84fe2c3e566783fea86136e3f90d1e2fc87dcebd61cff74592d454e4b.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134685563 watch_fd=48 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-jhxvc_kubesphere-system_haproxy-dc89c72b1e221d94b82ee32bcb0eec43bbbade1c1dfa6ae6b8272b339c1014bf.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268975519 watch_fd=49 name=/var/log/containers/redis-ha-server-0_kubesphere-system_config-init-a24eeaae3519f7a0be9cb25a58f28676e978dbdcb155d64de83c6d2c564bcb84.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403761176 watch_fd=50 name=/var/log/containers/redis-ha-server-0_kubesphere-system_redis-1952b51c7b5bf653b3b4f308d0447fca0395267f654b42ad936f5446a8f0ba11.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403763877 watch_fd=51 name=/var/log/containers/redis-ha-server-0_kubesphere-system_sentinel-93ec7fdfd37546554e9ee20cad99fc79eb1120658f041c3ac3f8ae790ba9f3e0.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135616217 watch_fd=52 name=/var/log/containers/s2ioperator-0_kubesphere-devops-system_manager-ec0eef93d54b446690c5afb45fc20c145e8555f0efeac367b317ca3747e58a15.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268956363 watch_fd=53 name=/var/log/containers/snapshot-controller-0_kube-system_snapshot-controller-8efdaf2c22056e15431868c285909845a9a50220a8599428f13827c2a9999605.log [2022/04/20 04:07:18] [ info] [input:tail:tail.3] inotify_fs_add(): inode=270078314 watch_fd=1 name=/var/log/containers/kube-auditing-webhook-deploy-64cfb8c9f8-c65cb_kubesphere-logging-system_kube-auditing-webhook-2315ba3f2e910546235bebb5c2cef37419d6bbb6568f0073f94b7cc9cec5882e.log [2022/04/20 04:07:18] [ info] [input:tail:tail.3] inotify_fs_add(): inode=404597510 watch_fd=2 name=/var/log/containers/kube-auditing-webhook-deploy-64cfb8c9f8-j8w5d_kubesphere-logging-system_kube-auditing-webhook-27248c5f2dc6b8e16f178cb6028731bd4d752a99b558558b8cbc38ebc872996d.log [2022/04/20 04:07:18] [ info] [input:tail:tail.2] inotify_fs_add(): inode=404114523 watch_fd=54 name=/var/log/containers/fluent-bit-79w92_kubesphere-logging-system_fluent-bit-6fca993aec2186244af2f1632d8fcd563be88aeddf0f892fe05908712f4143e1.log [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427638.306801183.flb&#39;, retry in 10 seconds: task_id=0, input=systemd.0 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427638.921453506.flb&#39;, retry in 6 seconds: task_id=2, input=systemd.1 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427638.395905124.flb&#39;, retry in 6 seconds: task_id=1, input=systemd.1 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427639.998272919.flb&#39;, retry in 9 seconds: task_id=4, input=systemd.1 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427639.430712081.flb&#39;, retry in 10 seconds: task_id=3, input=systemd.1 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427638.433892561.flb&#39;, retry in 11 seconds: task_id=6, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427640.508747628.flb&#39;, retry in 8 seconds: task_id=5, input=systemd.1 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:22] [ warn] [engine] failed to flush chunk &#39;15-1650427638.591363944.flb&#39;, retry in 9 seconds: task_id=7, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:27] [ warn] [engine] failed to flush chunk &#39;15-1650427642.916578491.flb&#39;, retry in 10 seconds: task_id=8, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:28] [ warn] [engine] chunk &#39;15-1650427638.921453506.flb&#39; cannot be retried: task_id=2, input=systemd.1 &gt; output=es.0 [2022/04/20 04:07:28] [ warn] [engine] chunk &#39;15-1650427638.395905124.flb&#39; cannot be retried: task_id=1, input=systemd.1 &gt; output=es.0 [2022/04/20 04:07:30] [ warn] [engine] chunk &#39;15-1650427640.508747628.flb&#39; cannot be retried: task_id=5, input=systemd.1 &gt; output=es.0 [2022/04/20 04:07:31] [ warn] [engine] chunk &#39;15-1650427639.998272919.flb&#39; cannot be retried: task_id=4, input=systemd.1 &gt; output=es.0 [2022/04/20 04:07:31] [ warn] [engine] chunk &#39;15-1650427638.591363944.flb&#39; cannot be retried: task_id=7, input=tail.2 &gt; output=es.0 [2022/04/20 04:07:32] [ warn] [engine] failed to flush chunk &#39;15-1650427650.364418985.flb&#39;, retry in 7 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:32] [ warn] [engine] failed to flush chunk &#39;15-1650427647.894424287.flb&#39;, retry in 11 seconds: task_id=1, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:32] [ warn] [engine] failed to flush chunk &#39;15-1650427651.290039243.flb&#39;, retry in 11 seconds: task_id=4, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:32] [ warn] [engine] failed to flush chunk &#39;15-1650427652.113363794.flb&#39;, retry in 10 seconds: task_id=5, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:32] [ warn] [engine] chunk &#39;15-1650427638.306801183.flb&#39; cannot be retried: task_id=0, input=systemd.0 &gt; output=es.0 [2022/04/20 04:07:32] [ warn] [engine] chunk &#39;15-1650427639.430712081.flb&#39; cannot be retried: task_id=3, input=systemd.1 &gt; output=es.0 [2022/04/20 04:07:33] [ warn] [engine] chunk &#39;15-1650427638.433892561.flb&#39; cannot be retried: task_id=6, input=tail.2 &gt; output=es.0 [2022/04/20 04:07:37] [ warn] [engine] chunk &#39;15-1650427642.916578491.flb&#39; cannot be retried: task_id=8, input=tail.2 &gt; output=es.0 [2022/04/20 04:07:37] [ warn] [engine] failed to flush chunk &#39;15-1650427652.895622405.flb&#39;, retry in 10 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:39] [ warn] [engine] chunk &#39;15-1650427650.364418985.flb&#39; cannot be retried: task_id=2, input=tail.2 &gt; output=es.0 [2022/04/20 04:07:42] [ warn] [engine] chunk &#39;15-1650427652.113363794.flb&#39; cannot be retried: task_id=5, input=tail.2 &gt; output=es.0 [2022/04/20 04:07:42] [ warn] [engine] failed to flush chunk &#39;15-1650427657.894452234.flb&#39;, retry in 8 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:42] [ warn] [engine] failed to flush chunk &#39;15-1650427660.999669706.flb&#39;, retry in 8 seconds: task_id=3, input=tail.2 &gt; output=es.0 (out_id=0) [2022/04/20 04:07:43] [ warn] [engine] chunk &#39;15-1650427647.894424287.flb&#39; cannot be retried: task_id=1, input=tail.2 &gt; output=es.0 [2022/04/20 04:07:43] [ warn] [engine] chunk &#39;15-1650427651.290039243.flb&#39; cannot be retried: task_id=4, input=tail.2 &gt; output=es.0<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">3. 问题排查第三环节，检查 fluent-bit。</span><br><span class="line"></span><br><span class="line">   - 打开百度，搜索 **failed to flush chunk**。</span><br><span class="line"></span><br><span class="line">   - ![image-20220420163534855](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420163534855.png)</span><br><span class="line"></span><br><span class="line">   - 搜索出来的结果，凭直觉没啥用处，真不想说啥了，直接换人。</span><br><span class="line"></span><br><span class="line">   - 打开 **Bing**，搜索 **failed to flush chunk**。</span><br><span class="line"></span><br><span class="line">   - ![image-20220420163607854](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420163607854.png)</span><br><span class="line"></span><br><span class="line">   - 点开[第一个参考链接](https://github.com/fluent/fluent-bit/issues/3301), 看了一圈感觉就是再说需要开启一个参数 **Trace_Error On**，才能看的更清楚。</span><br><span class="line"></span><br><span class="line">   - 咱先不开启，先看看 fluentd-bit 是否跟 ES 服务器有通讯，通过 tcp 抓包可以看到是有数据推送的。</span><br><span class="line"></span><br><span class="line">   - ```shell</span><br><span class="line">     [root@glusterfs-node-0 logs]# tcpdump -i any port 9200 -s 0</span><br><span class="line">     tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">     listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes</span><br><span class="line">     14:42:31.713955 IP ks-k8s-master-1.57144 &gt; glusterfs-node-0.wap-wsp: Flags [S], seq 4284553181, win 28000, options [mss 1400,sackOK,TS val 1006807002 ecr 0,nop,wscale 7], length 0</span><br><span class="line">     14:42:31.713987 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57144: Flags [S.], seq 3050954572, ack 4284553182, win 28960, options [mss 1460,sackOK,TS val 1446355813 ecr 1006807002,nop,wscale 7], length 0</span><br><span class="line">     14:42:31.714478 IP ks-k8s-master-1.57144 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 1, win 219, options [nop,nop,TS val 1006807002 ecr 1446355813], length 0</span><br><span class="line">     14:42:31.714535 IP ks-k8s-master-1.57146 &gt; glusterfs-node-0.wap-wsp: Flags [S], seq 763700519, win 28000, options [mss 1400,sackOK,TS val 1006807002 ecr 0,nop,wscale 7], length 0</span><br><span class="line">     14:42:31.714562 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57146: Flags [S.], seq 141769299, ack 763700520, win 28960, options [mss 1460,sackOK,TS val 1446355813 ecr 1006807002,nop,wscale 7], length 0</span><br><span class="line">     14:42:31.714931 IP ks-k8s-master-1.57146 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 1, win 219, options [nop,nop,TS val 1006807003 ecr 1446355813], length 0</span><br><span class="line">     14:42:31.720484 IP ks-k8s-master-1.57144 &gt; glusterfs-node-0.wap-wsp: Flags [P.], seq 1:305, ack 1, win 219, options [nop,nop,TS val 1006807008 ecr 1446355813], length 304</span><br><span class="line">     14:42:31.720511 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57144: Flags [.], ack 305, win 235, options [nop,nop,TS val 1446355819 ecr 1006807008], length 0</span><br><span class="line">     14:42:31.720882 IP ks-k8s-master-1.57146 &gt; glusterfs-node-0.wap-wsp: Flags [P.], seq 1:305, ack 1, win 219, options [nop,nop,TS val 1006807008 ecr 1446355813], length 304</span><br><span class="line">     14:42:31.720915 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57146: Flags [.], ack 305, win 235, options [nop,nop,TS val 1446355820 ecr 1006807008], length 0</span><br><span class="line">     14:42:31.721259 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57146: Flags [P.], seq 1:706, ack 305, win 235, options [nop,nop,TS val 1446355820 ecr 1006807008], length 705</span><br><span class="line">     14:42:31.721272 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57144: Flags [P.], seq 1:750, ack 305, win 235, options [nop,nop,TS val 1446355820 ecr 1006807008], length 749</span><br><span class="line">     14:42:31.721327 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57146: Flags [F.], seq 706, ack 305, win 235, options [nop,nop,TS val 1446355820 ecr 1006807008], length 0</span><br><span class="line">     14:42:31.721356 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-1.57144: Flags [F.], seq 750, ack 305, win 235, options [nop,nop,TS val 1446355820 ecr 1006807008], length 0</span><br><span class="line">     14:42:31.721666 IP ks-k8s-master-1.57146 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 706, win 230, options [nop,nop,TS val 1006807009 ecr 1446355820], length 0</span><br><span class="line">     14:42:31.721707 IP ks-k8s-master-1.57144 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 750, win 231, options [nop,nop,TS val 1006807009 ecr 1446355820], length 0</span><br><span class="line">     14:42:31.721951 IP ks-k8s-master-1.57146 &gt; glusterfs-node-0.wap-wsp: Flags [R.], seq 305, ack 707, win 230, options [nop,nop,TS val 1006807009 ecr 1446355820], length 0</span><br><span class="line">     14:42:31.722011 IP ks-k8s-master-1.57144 &gt; glusterfs-node-0.wap-wsp: Flags [R.], seq 305, ack 751, win 231, options [nop,nop,TS val 1006807010 ecr 1446355820], length 0</span><br><span class="line">     14:42:31.846578 IP ks-k8s-master-2.34902 &gt; glusterfs-node-0.wap-wsp: Flags [S], seq 2846110148, win 28000, options [mss 1400,sackOK,TS val 1006745001 ecr 0,nop,wscale 7], length 0</span><br><span class="line">     14:42:31.846621 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-2.34902: Flags [S.], seq 2264454988, ack 2846110149, win 28960, options [mss 1460,sackOK,TS val 1446355945 ecr 1006745001,nop,wscale 7], length 0</span><br><span class="line">     14:42:31.847064 IP ks-k8s-master-2.34902 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 1, win 219, options [nop,nop,TS val 1006745002 ecr 1446355945], length 0</span><br><span class="line">     14:42:31.851910 IP ks-k8s-master-2.34902 &gt; glusterfs-node-0.wap-wsp: Flags [P.], seq 1:305, ack 1, win 219, options [nop,nop,TS val 1006745007 ecr 1446355945], length 304</span><br><span class="line">     14:42:31.851934 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-2.34902: Flags [.], ack 305, win 235, options [nop,nop,TS val 1446355951 ecr 1006745007], length 0</span><br><span class="line">     14:42:31.852261 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-2.34902: Flags [P.], seq 1:334, ack 305, win 235, options [nop,nop,TS val 1446355951 ecr 1006745007], length 333</span><br><span class="line">     14:42:31.852307 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-2.34902: Flags [F.], seq 334, ack 305, win 235, options [nop,nop,TS val 1446355951 ecr 1006745007], length 0</span><br><span class="line">     14:42:31.852575 IP ks-k8s-master-2.34902 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 334, win 228, options [nop,nop,TS val 1006745007 ecr 1446355951], length 0</span><br><span class="line">     14:42:31.852595 IP ks-k8s-master-2.34902 &gt; glusterfs-node-0.wap-wsp: Flags [R.], seq 305, ack 335, win 228, options [nop,nop,TS val 1006745007 ecr 1446355951], length 0</span><br><span class="line">     14:42:32.025492 IP ks-k8s-master-0.40940 &gt; glusterfs-node-0.wap-wsp: Flags [S], seq 2794210096, win 28000, options [mss 1400,sackOK,TS val 1006811001 ecr 0,nop,wscale 7], length 0</span><br><span class="line">     14:42:32.025534 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40940: Flags [S.], seq 3740534993, ack 2794210097, win 28960, options [mss 1460,sackOK,TS val 1446356124 ecr 1006811001,nop,wscale 7], length 0</span><br><span class="line">     14:42:32.026129 IP ks-k8s-master-0.40940 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 1, win 219, options [nop,nop,TS val 1006811002 ecr 1446356124], length 0</span><br><span class="line">     14:42:32.032593 IP ks-k8s-master-0.40940 &gt; glusterfs-node-0.wap-wsp: Flags [P.], seq 1:305, ack 1, win 219, options [nop,nop,TS val 1006811008 ecr 1446356124], length 304</span><br><span class="line">     14:42:32.032615 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40940: Flags [.], ack 305, win 235, options [nop,nop,TS val 1446356131 ecr 1006811008], length 0</span><br><span class="line">     14:42:32.033329 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40940: Flags [P.], seq 1:386, ack 305, win 235, options [nop,nop,TS val 1446356132 ecr 1006811008], length 385</span><br><span class="line">     14:42:32.033396 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40940: Flags [F.], seq 386, ack 305, win 235, options [nop,nop,TS val 1446356132 ecr 1006811008], length 0</span><br><span class="line">     14:42:32.033643 IP ks-k8s-master-0.40940 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 386, win 228, options [nop,nop,TS val 1006811010 ecr 1446356132], length 0</span><br><span class="line">     14:42:32.033718 IP ks-k8s-master-0.40940 &gt; glusterfs-node-0.wap-wsp: Flags [R.], seq 305, ack 387, win 228, options [nop,nop,TS val 1006811010 ecr 1446356132], length 0</span><br><span class="line">     14:42:33.025645 IP ks-k8s-master-0.40970 &gt; glusterfs-node-0.wap-wsp: Flags [S], seq 556017134, win 28000, options [mss 1400,sackOK,TS val 1006812001 ecr 0,nop,wscale 7], length 0</span><br><span class="line">     14:42:33.025700 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40970: Flags [S.], seq 3957625474, ack 556017135, win 28960, options [mss 1460,sackOK,TS val 1446357124 ecr 1006812001,nop,wscale 7], length 0</span><br><span class="line">     14:42:33.026255 IP ks-k8s-master-0.40970 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 1, win 219, options [nop,nop,TS val 1006812002 ecr 1446357124], length 0</span><br><span class="line">     14:42:33.031462 IP ks-k8s-master-0.40970 &gt; glusterfs-node-0.wap-wsp: Flags [P.], seq 1:305, ack 1, win 219, options [nop,nop,TS val 1006812007 ecr 1446357124], length 304</span><br><span class="line">     14:42:33.031493 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40970: Flags [.], ack 305, win 235, options [nop,nop,TS val 1446357130 ecr 1006812007], length 0</span><br><span class="line">     14:42:33.032411 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40970: Flags [P.], seq 1:676, ack 305, win 235, options [nop,nop,TS val 1446357131 ecr 1006812007], length 675</span><br><span class="line">     14:42:33.032547 IP glusterfs-node-0.wap-wsp &gt; ks-k8s-master-0.40970: Flags [F.], seq 676, ack 305, win 235, options [nop,nop,TS val 1446357131 ecr 1006812007], length 0</span><br><span class="line">     14:42:33.032789 IP ks-k8s-master-0.40970 &gt; glusterfs-node-0.wap-wsp: Flags [.], ack 676, win 230, options [nop,nop,TS val 1006812009 ecr 1446357131], length 0</span><br><span class="line">     14:42:33.032906 IP ks-k8s-master-0.40970 &gt; glusterfs-node-0.wap-wsp: Flags [R.], seq 305, ack 677, win 230, options [nop,nop,TS val 1006812009 ecr 1446357131], length 0</span><br><span class="line">     ^C</span><br><span class="line">     45 packets captured</span><br><span class="line">     45 packets received by filter</span><br><span class="line">     0 packets dropped by kernel</span><br></pre></td></tr></table></figure></code></pre></li><li><p>查看 es 集群中的 index 是否创建 , 结果发现索引并没有创建。</p></li><li><pre><code class="shell">[root@glusterfs-node-0 logs]# curl -ulstack:&#39;P@88w0rd&#39; 192.168.9.95:9200/_cat/indices?vhealth status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.sizegreen  open   .geoip_databases jOKPAu5-S3yv0rZdZx4ufw   1   1         40           38    107.2mb         69.3mb<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 那为啥没索引呢，默认日志是看不出来的，只能开启 elasticsearch 日志的 debug 模式了</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@glusterfs-node-0 logs]# curl -ulstack:&#x27;P@88w0rd&#x27; -H &quot;Content-Type: application/json&quot; -X PUT  192.168.9.95:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot; : &#123;&quot;logger._root&quot;:&quot;DEBUG&quot;&#125; &#125;&#x27;</span><br></pre></td></tr></table></figure></code></pre></li><li><p>开启以后日志就丰富了很多，我们找找有用的信息。</p></li><li><pre><code class="yaml">[2022-04-20T15:23:25,633][DEBUG][r.suppressed             ] [es-node-0] path: /bad-request, params: &#123;&#125;java.lang.IllegalArgumentException: invalid version format: &lt;8a&gt;-»&gt;¸Â×YÄÌ^Y^^HR·&lt;84&gt;ºÞ^@ÊËD!Ô^SÄÜA&lt;9c&gt;EÛº^@&gt;^S^B^S^C^S^AÀ,À0^@&lt;9f&gt;Ì©Ì¨ÌªÀ+À/^@&lt;9e&gt;À$À(^@KÀ#À&#39;^@GÀ[2022-04-20T15:23:25,630][DEBUG][r.suppressed             ] [es-node-0] path: /bad-request, params: &#123;&#125;java.lang.IllegalArgumentException: text is empty (possibly HTTP/0.9)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- **DEBUG** 级别的日志也就能看到这些了，再上个更狠的 TRACE 级别的，要是还不行就去开启 **Fluent-bit** 的参数。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@glusterfs-node-0 logs]# curl -ulstack:&#x27;P@88w0rd&#x27; -H &quot;Content-Type: application/json&quot; -X PUT  192.168.9.95:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot; : &#123;&quot;logger._root&quot;:&quot;TRACE&quot;&#125; &#125;&#x27;</span><br></pre></td></tr></table></figure></code></pre></li><li><p>分析日志，发现还是没有实质性的错误说明，也只是看到了错误的信息哪来的。</p></li><li><pre><code class="yaml">[2022-04-20T16:50:18,577][TRACE][o.e.h.HttpTracer         ] [es-node-0] [40714][null][GET][/bad-request] received request from [Netty4HttpChannel&#123;localAddress=/192.168.9.95:9200, remoteAddress=/192.168.9.93:34784&#125;]java.lang.IllegalArgumentException: invalid version format: ¸Ñ^AÐ^E1&lt;8b&gt;HU^R0&lt;88&gt;^[)¶ËQT=&lt;87&gt;&quot;&#125;Þ¥AËÉ³ZY^@&gt;^S^B^S^C^S^AÀ,À0^@&lt;9f&gt;Ì©Ì¨ÌªÀ+À/^@&lt;9e&gt;À$À(^@KÀ#À&#39;^@GÀ[2022-04-20T16:50:18,549][TRACE][o.e.h.HttpTracer         ] [es-node-0] [40713][null][GET][/bad-request] received request from [Netty4HttpChannel&#123;localAddress=/192.168.9.95:9200, remoteAddress=/192.168.9.92:49734&#125;]java.lang.IllegalArgumentException: text is empty (possibly HTTP/0.9)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 先把 ElasticSearch 的日志级别改回默认的 INFO，我们回去研究 **Fluent-bit**。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@glusterfs-node-0 logs]# curl -ulstack:&#x27;P@88w0rd&#x27; -H &quot;Content-Type: application/json&quot; -X PUT  192.168.9.95:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot; : &#123;&quot;logger._root&quot;:&quot;INFO&quot;&#125; &#125;&#x27;</span><br></pre></td></tr></table></figure></code></pre></li><li><p>返回 KubeSphere 的论坛，继续以关键字<strong>外部 es</strong> 搜索，发现一篇跟 fluent bit 有关的文档 ,<a href="https://kubesphere.com.cn/forum/d/5961-fluent-bit-0-es">安装 日志插件后， fluent bit 启动失败，查询日志一直是 0， 外部 es 也没有创建索引</a></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/elasticsearch-error-2.png" alt="elasticsearch-error-2"></p></li><li><p>该文中的 fluent 的报错信息跟我的不一样，先不管了，先看看他的配置跟我是否一样，文中解决方案跳转到了<a href="https://github.com/kubesphere/kubesphere/issues/4425">Github</a>。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420173658602.png" alt="image-20220420173658602"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220420173919350.png" alt="image-20220420173919350"></p></li><li><p>先看看我们有几个 inputs。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get inputs -n kubesphere-logging-system NAME            AGEdocker          5d5hkubelet         5d5htail            5d5htail-auditing   5d5htail-events     5d5h<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 先看看我们现在的 **tail** 配置。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl get inputs -n kubesphere-logging-system tail -o yaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Input</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Input&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;tail&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;tail&quot;:&#123;&quot;db&quot;:&quot;/fluent-bit/tail/pos.db&quot;,&quot;dbSync&quot;:&quot;Normal&quot;,&quot;excludePath&quot;:&quot;/var/log/containers/*_kubesphere-logging-system_events-exporter*.log,/var/log/containers/kube-auditing-webhook*_kubesphere-logging-system_kube-auditing-webhook*.log&quot;,&quot;memBufLimit&quot;:&quot;5MB&quot;,&quot;parser&quot;:&quot;docker&quot;,&quot;path&quot;:&quot;/var/log/containers/*.log&quot;,&quot;refreshIntervalSeconds&quot;:10,&quot;skipLongLines&quot;:true,&quot;tag&quot;:&quot;kube.*&quot;&#125;&#125;&#125;</span><br><span class="line">    creationTimestamp: &quot;2022-04-15T03:51:11Z&quot;</span><br><span class="line">    generation: 1</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: logging</span><br><span class="line">      logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">    name: tail</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">    resourceVersion: &quot;1503222&quot;</span><br><span class="line">    uid: fdf165ed-5a03-42ef-bb0b-6f625b194a3f</span><br><span class="line">  spec:</span><br><span class="line">    tail:</span><br><span class="line">      db: /fluent-bit/tail/pos.db</span><br><span class="line">      dbSync: Normal</span><br><span class="line">      excludePath: /var/log/containers/*_kubesphere-logging-system_events-exporter*.log,/var/log/containers/kube-auditing-webhook*_kubesphere-logging-system_kube-auditing-webhook*.log</span><br><span class="line">      memBufLimit: 5MB</span><br><span class="line">      parser: docker</span><br><span class="line">      path: /var/log/containers/*.log</span><br><span class="line">      refreshIntervalSeconds: 10</span><br><span class="line">      skipLongLines: true</span><br><span class="line">      tag: kube.*</span><br></pre></td></tr></table></figure></code></pre></li><li><p>看现在的配置，跟 github 上的对比，发现配置存在无需调整。</p></li><li><p>再看看我们现在的 <strong>filter-auditing</strong> 配置。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get  filters -n kubesphere-logging-system filter-auditing -o yamlapiVersion: logging.kubesphere.io/v1alpha2kind: Filtermetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Filter&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;auditing&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;filter-auditing&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;filters&quot;:[&#123;&quot;parser&quot;:&#123;&quot;keyName&quot;:&quot;log&quot;,&quot;parser&quot;:&quot;json&quot;&#125;&#125;,&#123;&quot;modify&quot;:&#123;&quot;conditions&quot;:[&#123;&quot;keyDoesNotExist&quot;:&#123;&quot;AuditID&quot;:&quot;&quot;&#125;&#125;],&quot;rules&quot;:[&#123;&quot;add&quot;:&#123;&quot;ignore&quot;:&quot;true&quot;&#125;&#125;]&#125;&#125;,&#123;&quot;grep&quot;:&#123;&quot;exclude&quot;:&quot;ignore true&quot;&#125;&#125;],&quot;match&quot;:&quot;kube_auditing&quot;&#125;&#125;  creationTimestamp: &quot;2022-04-15T03:51:23Z&quot;  generation: 1  labels:    logging.kubesphere.io/component: auditing    logging.kubesphere.io/enabled: &quot;true&quot;  name: filter-auditing  namespace: kubesphere-logging-system  resourceVersion: &quot;1503307&quot;  uid: f0e88853-dc14-41f9-bcbf-f1a49fd121cfspec:  filters:  - parser:      keyName: log      parser: json  - modify:      conditions:      - keyDoesNotExist:          AuditID: &quot;&quot;      rules:      - add:          ignore: &quot;true&quot;  - grep:      exclude: ignore true  match: kube_auditing<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   - 看现在的配置，跟 Github 上的对比，发现配置存在无需调整。</span><br><span class="line"></span><br><span class="line">   - 又无路可走了。。。清醒一下脑袋，进入下一环节。</span><br><span class="line"></span><br><span class="line">4. 问题排查第四环节，再探 Fluent-bit。</span><br><span class="line"></span><br><span class="line">   - 没其他思路了，把 Fluent-bit 的 Trace 开开吧。</span><br><span class="line"></span><br><span class="line">   - 找到我们的 fluent-bit-config 的 ConfigMap。</span><br><span class="line"></span><br><span class="line">   - ```shell</span><br><span class="line">     [root@ks-k8s-master-0 ~]# kubectl get secrets fluent-bit-config -n kubesphere-logging-system -o yaml</span><br><span class="line">     apiVersion: v1</span><br><span class="line">     data:</span><br><span class="line">       fluent-bit.conf: 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</span><br><span class="line">       parsers.conf: &quot;&quot;</span><br><span class="line">       systemd.lua: ZnVuY3Rpb24gYWRkX3RpbWUodGFnLCB0aW1lc3RhbXAsIHJlY29yZCkKICBuZXdfcmVjb3JkID0ge30KICB0aW1lU3RyID0gb3MuZGF0ZSgiISp0IiwgdGltZXN0YW1wWyJzZWMiXSkKICB0ID0gc3RyaW5nLmZvcm1hdCgiJTRkLSUwMmQtJTAyZFQlMDJkOiUwMmQ6JTAyZC4lc1oiLAoJCXRpbWVTdHJbInllYXIiXSwgdGltZVN0clsibW9udGgiXSwgdGltZVN0clsiZGF5Il0sCgkJdGltZVN0clsiaG91ciJdLCB0aW1lU3RyWyJtaW4iXSwgdGltZVN0clsic2VjIl0sCgkJdGltZXN0YW1wWyJuc2VjIl0pCiAga3ViZXJuZXRlcyA9IHt9CiAga3ViZXJuZXRlc1sicG9kX25hbWUiXSA9IHJlY29yZFsiX0hPU1ROQU1FIl0KICBrdWJlcm5ldGVzWyJjb250YWluZXJfbmFtZSJdID0gcmVjb3JkWyJTWVNMT0dfSURFTlRJRklFUiJdCiAga3ViZXJuZXRlc1sibmFtZXNwYWNlX25hbWUiXSA9ICJrdWJlLXN5c3RlbSIKICBuZXdfcmVjb3JkWyJ0aW1lIl0gPSB0CiAgbmV3X3JlY29yZFsibG9nIl0gPSByZWNvcmRbIk1FU1NBR0UiXQogIG5ld19yZWNvcmRbImt1YmVybmV0ZXMiXSA9IGt1YmVybmV0ZXMKICByZXR1cm4gMSwgdGltZXN0YW1wLCBuZXdfcmVjb3JkCmVuZA==</span><br><span class="line">     kind: Secret</span><br><span class="line">     metadata:</span><br><span class="line">       creationTimestamp: &quot;2022-04-15T03:49:33Z&quot;</span><br><span class="line">       name: fluent-bit-config</span><br><span class="line">       namespace: kubesphere-logging-system</span><br><span class="line">       ownerReferences:</span><br><span class="line">       - apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">         blockOwnerDeletion: true</span><br><span class="line">         controller: true</span><br><span class="line">         kind: FluentBitConfig</span><br><span class="line">         name: fluent-bit-config</span><br><span class="line">         uid: 8637b012-ed24-404f-b1bb-6404b0a18537</span><br><span class="line">       resourceVersion: &quot;2865407&quot;</span><br><span class="line">       uid: 66b56299-fb2c-435a-ae83-f21904656863</span><br><span class="line">     type: Opaque</span><br></pre></td></tr></table></figure></code></pre></li><li><p>居然没有明文，居然是加密的，这看个鬼啊。。。</p></li><li><p>不过，好在我们知道 k8s 里的好多字典都是 base64 加密的，而 base64 又是可以反解密的。我们解开试试。</p></li><li><p>先把 base64 加密过的字符串复制下来，新建一个文件 <strong>fluent-bit-config</strong></p></li><li><pre><code class="yaml">[root@ks-k8s-master-0 ~]# vi fluent-bit-config写入以下内容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<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 执行下面的命令将解密后的文件输出到 **fluent-bit-config.conf**。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# base64 -d fluent-bit-config &gt; fluent-bit-config.conf</span><br></pre></td></tr></table></figure></code></pre></li><li><p>看看输出的文件都有啥。</p></li><li><pre><code class="yaml">[root@ks-k8s-master-0 ~]# cat fluent-bit-config.conf [Service]    Parsers_File    parsers.conf[Input]    Name    systemd    Path    /var/log/journal    DB    /fluent-bit/tail/docker.db    DB.Sync    Normal    Tag    service.docker    Systemd_Filter    _SYSTEMD_UNIT=docker.service[Input]    Name    systemd    Path    /var/log/journal    DB    /fluent-bit/tail/kubelet.db    DB.Sync    Normal    Tag    service.kubelet    Systemd_Filter    _SYSTEMD_UNIT=kubelet.service[Input]    Name    tail    Path    /var/log/containers/*.log    Exclude_Path    /var/log/containers/*_kubesphere-logging-system_events-exporter*.log,/var/log/containers/kube-auditing-webhook*_kubesphere-logging-system_kube-auditing-webhook*.log    Refresh_Interval    10    Skip_Long_Lines    true    DB    /fluent-bit/tail/pos.db    DB.Sync    Normal    Mem_Buf_Limit    5MB    Parser    docker    Tag    kube.*[Input]    Name    tail    Path    /var/log/containers/kube-auditing-webhook*_kubesphere-logging-system_kube-auditing-webhook*.log    Refresh_Interval    10    Skip_Long_Lines    true    DB    /fluent-bit/tail/pos-auditing.db    DB.Sync    Normal    Mem_Buf_Limit    5MB    Parser    docker    Tag    kube_auditing[Input]    Name    tail    Path    /var/log/containers/*_kubesphere-logging-system_events-exporter*.log    Refresh_Interval    10    Skip_Long_Lines    true    DB    /fluent-bit/tail/pos-events.db    DB.Sync    Normal    Mem_Buf_Limit    5MB    Parser    docker    Tag    kube_events[Filter]    Name    parser    Match    kube_auditing    Key_Name    log    Parser    json[Filter]    Name    modify    Match    kube_auditing    Condition    Key_does_not_exist    AuditID        Add    ignore    true[Filter]    Name    grep    Match    kube_auditing    Exclude    ignore true[Filter]    Name    parser    Match    kube_events    Key_Name    log    Parser    json[Filter]    Name    kubernetes    Match    kube.*    Kube_URL    https://kubernetes.default.svc:443    Kube_CA_File    /var/run/secrets/kubernetes.io/serviceaccount/ca.crt    Kube_Token_File    /var/run/secrets/kubernetes.io/serviceaccount/token    Labels    false    Annotations    false[Filter]    Name    nest    Match    kube.*    Operation    lift    Nested_under    kubernetes    Add_prefix    kubernetes_[Filter]    Name    modify    Match    kube.*    Remove    stream    Remove    kubernetes_pod_id    Remove    kubernetes_host    Remove    kubernetes_container_hash[Filter]    Name    nest    Match    kube.*    Operation    nest    Wildcard    kubernetes_*    Nest_under    kubernetes    Remove_prefix    kubernetes_[Filter]    Name    lua    Match    service.*    script    /fluent-bit/config/systemd.lua    call    add_time    time_as_table    true[Output]    Name    es    Match_Regex    (?:kube|service)\.(.*)    Host    192.168.9.95    Port    9200    HTTP_User    lstack    HTTP_Passwd    P@88w0rd    Logstash_Format    true    Logstash_Prefix    ks-logstash-log    Time_Key    @timestamp    Generate_ID    true    tls    On    tls.verify    false[Output]    Name    es    Match    kube_auditing    Host    elasticsearch-logging-data.kubesphere-logging-system.svc    Port    9200    HTTP_User    lstack    HTTP_Passwd    P@88w0rd    Logstash_Format    true    Logstash_Prefix    ks-logstash-auditing    Generate_ID    true    tls    On    tls.verify    false[Output]    Name    es    Match    kube_events    Host    elasticsearch-logging-data.kubesphere-logging-system.svc    Port    9200    HTTP_User    lstack    HTTP_Passwd    P@88w0rd    Logstash_Format    true    Logstash_Prefix    ks-logstash-events    Generate_ID    true    tls    On    tls.verify    false<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 细节我们先不深究 (其实我也不知道啥意思)，我们直奔我们的目标，找到**[Output] Name 为 es** 且标有 **Match_Regex** 的配置，添加 **Trace_Error     On**。</span><br><span class="line"></span><br><span class="line">- 效果如下：</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  [Output]</span><br><span class="line">      Name    es</span><br><span class="line">      Match_Regex    (?:kube|service)\.(.*)</span><br><span class="line">      Host    192.168.9.95</span><br><span class="line">      Port    9200</span><br><span class="line">      HTTP_User    lstack</span><br><span class="line">      HTTP_Passwd    P@88w0rd</span><br><span class="line">      Logstash_Format    true</span><br><span class="line">      Logstash_Prefix    ks-logstash-log</span><br><span class="line">      Time_Key    @timestamp</span><br><span class="line">      Generate_ID    true</span><br><span class="line">      tls    On</span><br><span class="line">      tls.verify    false</span><br><span class="line">      Trace_Error     On</span><br></pre></td></tr></table></figure></code></pre></li><li><p>保存文件并退出，再将该文件中的内容进行 base64 编码。</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# base64 -w 0 fluent-bit-config.conf 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<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 先把输出结果复制下来。</span><br><span class="line"></span><br><span class="line">- 再来修改我们的 Fluent-bit 的配置文件的 secrets，修改 **fluent-bit.conf** 的值。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  k8s-master-0 ~]# kubectl kubectl edit secrets fluent-bit-config -n kubesphere-logging-system</span><br><span class="line">  secret/fluent-bit-config edited</span><br></pre></td></tr></table></figure></code></pre></li><li><p>然后我又崩溃了，修改完的配置又改回原来的样子了，看样子又是使用了 <strong>fluent-operator</strong> 不能直接修改 conf 文件，唉。。。</p></li><li><p>先折回 Output 的配置，把 <strong>es-auditing</strong> 和 <strong>es-events</strong> 的配置先改对了。</p></li><li><p>备份 <strong>es-auditing</strong> 和 <strong>es-events</strong> 的 Output 配置。</p></li><li><p>&#96;&#96;&#96;shell</p></li></ul></li></ol><p>  [root@ks-k8s-master-0 ~]#  kubectl get outputs -n kubesphere-logging-system es-auditing -o yaml &gt; es-auditing.output.yaml<br>     [root@ks-k8s-master-0 ~]#  kubectl get outputs -n kubesphere-logging-system es-events -o yaml &gt; es-events.output.yaml<br>     <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> - 先看看 **es-auditing** 的现状。</span><br><span class="line"></span><br><span class="line"> - ```shell</span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get outputs -n kubesphere-logging-system es-auditing -o yaml</span><br><span class="line">   apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">   kind: Output</span><br><span class="line">   metadata:</span><br><span class="line">     annotations:</span><br><span class="line">       kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">         &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;auditing&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es-auditing&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;httpPassword&quot;:&#123;&quot;valueFrom&quot;:&#123;&quot;secretKeyRef&quot;:&#123;&quot;key&quot;:&quot;password&quot;,&quot;name&quot;:&quot;elasticsearch-credentials&quot;&#125;&#125;&#125;,&quot;httpUser&quot;:&#123;&quot;valueFrom&quot;:&#123;&quot;secretKeyRef&quot;:&#123;&quot;key&quot;:&quot;username&quot;,&quot;name&quot;:&quot;elasticsearch-credentials&quot;&#125;&#125;&#125;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-auditing&quot;,&quot;port&quot;:9200,&quot;tls&quot;:&#123;&quot;verify&quot;:false&#125;&#125;,&quot;match&quot;:&quot;kube_auditing&quot;&#125;&#125;</span><br><span class="line">     creationTimestamp: &quot;2022-04-15T03:51:23Z&quot;</span><br><span class="line">     generation: 3</span><br><span class="line">     labels:</span><br><span class="line">       logging.kubesphere.io/component: auditing</span><br><span class="line">       logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">     name: es-auditing</span><br><span class="line">     namespace: kubesphere-logging-system</span><br><span class="line">     resourceVersion: &quot;1537731&quot;</span><br><span class="line">     uid: 42e31e0d-d641-48c0-8423-165a505b8124</span><br><span class="line">   spec:</span><br><span class="line">     es:</span><br><span class="line">       generateID: true</span><br><span class="line">       host: elasticsearch-logging-data.kubesphere-logging-system.svc</span><br><span class="line">       httpPassword:</span><br><span class="line">         valueFrom:</span><br><span class="line">           secretKeyRef:</span><br><span class="line">             key: password</span><br><span class="line">             name: elasticsearch-credentials</span><br><span class="line">       httpUser:</span><br><span class="line">         valueFrom:</span><br><span class="line">           secretKeyRef:</span><br><span class="line">             key: username</span><br><span class="line">             name: elasticsearch-credentials</span><br><span class="line">       logstashFormat: true</span><br><span class="line">       logstashPrefix: ks-logstash-auditing</span><br><span class="line">       port: 9200</span><br><span class="line">       tls:</span><br><span class="line">         verify: false</span><br><span class="line">     match: kube_auditing</span><br></pre></td></tr></table></figure></p><ul><li><p>分析上面的文件，发现只需要修改 <strong>host</strong> 地址就可以了，其他的都不需要，这可比上面修改 <strong>es</strong> 的配置舒服多了。</p></li><li><p>修改 <strong>es-auditing</strong> 的配置。</p></li><li><pre><code class="shell">  [root@ks-k8s-master-0 ~]# kubectl edit outputs -n kubesphere-logging-system es-auditing output.logging.kubesphere.io/es-auditing edited<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> - 修改后 , 再次查看，发现资源定义的内容如下：</span><br><span class="line"></span><br><span class="line"> - ```shell</span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get outputs -n kubesphere-logging-system es-auditing -o yaml</span><br><span class="line">   </span><br><span class="line">   apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">kind: Output</span><br><span class="line">   metadata:</span><br><span class="line">     annotations:</span><br><span class="line">       kubectl.kubernetes.io/last-applied-configuration: |</span><br><span class="line">         &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;auditing&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es-auditing&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;httpPassword&quot;:&#123;&quot;valueFrom&quot;:&#123;&quot;secretKeyRef&quot;:&#123;&quot;key&quot;:&quot;password&quot;,&quot;name&quot;:&quot;elasticsearch-credentials&quot;&#125;&#125;&#125;,&quot;httpUser&quot;:&#123;&quot;valueFrom&quot;:&#123;&quot;secretKeyRef&quot;:&#123;&quot;key&quot;:&quot;username&quot;,&quot;name&quot;:&quot;elasticsearch-credentials&quot;&#125;&#125;&#125;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-auditing&quot;,&quot;port&quot;:9200,&quot;tls&quot;:&#123;&quot;verify&quot;:false&#125;&#125;,&quot;match&quot;:&quot;kube_auditing&quot;&#125;&#125;</span><br><span class="line">     creationTimestamp: &quot;2022-04-15T03:51:23Z&quot;</span><br><span class="line">     generation: 4</span><br><span class="line">     labels:</span><br><span class="line">       logging.kubesphere.io/component: auditing</span><br><span class="line">       logging.kubesphere.io/enabled: &quot;true&quot;</span><br><span class="line">     name: es-auditing</span><br><span class="line">     namespace: kubesphere-logging-system</span><br><span class="line">     resourceVersion: &quot;3183473&quot;</span><br><span class="line">     uid: 42e31e0d-d641-48c0-8423-165a505b8124</span><br><span class="line">   spec:</span><br><span class="line">     es:</span><br><span class="line">       generateID: true</span><br><span class="line">       host: 192.168.9.95</span><br><span class="line">       httpPassword:</span><br><span class="line">         valueFrom:</span><br><span class="line">           secretKeyRef:</span><br><span class="line">             key: password</span><br><span class="line">             name: elasticsearch-credentials</span><br><span class="line">       httpUser:</span><br><span class="line">         valueFrom:</span><br><span class="line">           secretKeyRef:</span><br><span class="line">             key: username</span><br><span class="line">             name: elasticsearch-credentials</span><br><span class="line">       logstashFormat: true</span><br><span class="line">       logstashPrefix: ks-logstash-auditing</span><br><span class="line">       port: 9200</span><br><span class="line">       tls:</span><br><span class="line">         verify: false</span><br><span class="line">     match: kube_auditing</span><br></pre></td></tr></table></figure></code></pre></li><li><p>接下来修改 <strong>es-events</strong> 的配置，先看看 <strong>es-events</strong> 的现状。</p></li><li><p>&#96;&#96;&#96;shell<br>  [root@ks-k8s-master-0 ~]#  kubectl get outputs -n kubesphere-logging-system es-events -o yaml</p><p>apiVersion: logging.kubesphere.io&#x2F;v1alpha2</p></li></ul><p>  kind: Output<br>     metadata:<br>       annotations:<br>         kubectl.kubernetes.io&#x2F;last-applied-configuration: |<br>           {“apiVersion”:”logging.kubesphere.io&#x2F;v1alpha2”,”kind”:”Output”,”metadata”:{“annotations”:{},”labels”:{“logging.kubesphere.io&#x2F;component”:”events”,”logging.kubesphere.io&#x2F;enabled”:”true”},”name”:”es-events”,”namespace”:”kubesphere-logging-system”},”spec”:{“es”:{“generateID”:true,”host”:”elasticsearch-logging-data.kubesphere-logging-system.svc”,”httpPassword”:{“valueFrom”:{“secretKeyRef”:{“key”:”password”,”name”:”elasticsearch-credentials”}}},”httpUser”:{“valueFrom”:{“secretKeyRef”:{“key”:”username”,”name”:”elasticsearch-credentials”}}},”logstashFormat”:true,”logstashPrefix”:”ks-logstash-events”,”port”:9200,”tls”:{“verify”:false}},”match”:”kube_events”}}<br>       creationTimestamp: “2022-04-15T03:51:42Z”<br>       generation: 3<br>       labels:<br>         logging.kubesphere.io&#x2F;component: events<br>         logging.kubesphere.io&#x2F;enabled: “true”<br>       name: es-events<br>       namespace: kubesphere-logging-system<br>       resourceVersion: “1537778”<br>       uid: 02127aef-c69f-4578-b92a-8ecf73685240<br>     spec:<br>       es:<br>         generateID: true<br>         host: elasticsearch-logging-data.kubesphere-logging-system.svc<br>         httpPassword:<br>           valueFrom:<br>             secretKeyRef:<br>               key: password<br>               name: elasticsearch-credentials<br>         httpUser:<br>           valueFrom:<br>             secretKeyRef:<br>               key: username<br>               name: elasticsearch-credentials<br>         logstashFormat: true<br>         logstashPrefix: ks-logstash-events<br>         port: 9200<br>         tls:<br>           verify: false<br>       match: kube_events<br>     <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> - 分析上面的文件，发现一样只需要修改 **host** 地址就可以。</span><br><span class="line"></span><br><span class="line"> - 修改 **es-auditing** 的配置。</span><br><span class="line"></span><br><span class="line"> - ```shell</span><br><span class="line">[root@ks-k8s-master-0 ~]#  kubectl edit outputs -n kubesphere-logging-system es-events</span><br><span class="line">   output.logging.kubesphere.io/es-events edited</span><br></pre></td></tr></table></figure></p><ul><li><p>修改后 , 再次查看，发现资源定义的内容如下：</p></li><li><p>&#96;&#96;&#96;shell<br>  [root@ks-k8s-master-0 ~]#  kubectl get outputs -n kubesphere-logging-system es-events -o yaml</p><p>apiVersion: logging.kubesphere.io&#x2F;v1alpha2</p></li></ul><p>  kind: Output<br>     metadata:<br>       annotations:<br>         kubectl.kubernetes.io&#x2F;last-applied-configuration: |<br>           {“apiVersion”:”logging.kubesphere.io&#x2F;v1alpha2”,”kind”:”Output”,”metadata”:{“annotations”:{},”labels”:{“logging.kubesphere.io&#x2F;component”:”events”,”logging.kubesphere.io&#x2F;enabled”:”true”},”name”:”es-events”,”namespace”:”kubesphere-logging-system”},”spec”:{“es”:{“generateID”:true,”host”:”elasticsearch-logging-data.kubesphere-logging-system.svc”,”httpPassword”:{“valueFrom”:{“secretKeyRef”:{“key”:”password”,”name”:”elasticsearch-credentials”}}},”httpUser”:{“valueFrom”:{“secretKeyRef”:{“key”:”username”,”name”:”elasticsearch-credentials”}}},”logstashFormat”:true,”logstashPrefix”:”ks-logstash-events”,”port”:9200,”tls”:{“verify”:false}},”match”:”kube_events”}}<br>       creationTimestamp: “2022-04-15T03:51:42Z”<br>       generation: 4<br>       labels:<br>         logging.kubesphere.io&#x2F;component: events<br>         logging.kubesphere.io&#x2F;enabled: “true”<br>       name: es-events<br>       namespace: kubesphere-logging-system<br>       resourceVersion: “3184391”<br>       uid: 02127aef-c69f-4578-b92a-8ecf73685240<br>     spec:<br>       es:<br>         generateID: true<br>         host: 192.168.9.95<br>         httpPassword:<br>           valueFrom:<br>             secretKeyRef:<br>               key: password<br>               name: elasticsearch-credentials<br>         httpUser:<br>           valueFrom:<br>             secretKeyRef:<br>               key: username<br>               name: elasticsearch-credentials<br>         logstashFormat: true<br>         logstashPrefix: ks-logstash-events<br>         port: 9200<br>         tls:<br>           verify: false<br>       match: kube_events<br>     <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> - 我们再次重建 Fluent-bit，看看是否有奇迹。</span><br><span class="line"></span><br><span class="line"> - 其中一个 pod 重启后的日志如下。</span><br><span class="line"></span><br><span class="line"> - ```yaml</span><br><span class="line">容器日志</span><br><span class="line">   </span><br><span class="line">    level=info msg=&quot;Fluent bit started&quot;</span><br><span class="line"></span><br><span class="line">    Fluent Bit v1.8.3</span><br><span class="line"></span><br><span class="line">    * Copyright (C) 2019-2021 The Fluent Bit Authors</span><br><span class="line"></span><br><span class="line">    * Copyright (C) 2015-2018 Treasure Data</span><br><span class="line"></span><br><span class="line">    * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd</span><br><span class="line"></span><br><span class="line">    * https://fluentbit.io</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [engine] started (pid=16)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [storage] version=1.1.1, initializing...</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [storage] in-memory</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [cmetrics] version=0.1.6</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [filter:kubernetes:kubernetes.4] https=1 host=kubernetes.default.svc port=443</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [filter:kubernetes:kubernetes.4] local POD info OK</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [filter:kubernetes:kubernetes.4] testing connectivity with API server...</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [filter:kubernetes:kubernetes.4] connectivity OK</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [sp] stream processor started</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=416649 watch_fd=1 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_alertmanager-1a71f1d5b1136320644f3289e4b22544620db4a0d35a1ffec52bc534d729c358.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=461549 watch_fd=2 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_config-reloader-bc14c53008f1e800d6240a5b912239a3d5682c6dcb719f48c69b7e8ba5892e35.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134582558 watch_fd=3 name=/var/log/containers/calico-kube-controllers-75ddb95444-8xvf4_kube-system_calico-kube-controllers-dc90044aa0ce62e61dfb0842c8f2e5aa8d021738adffca847b003a5c9621512c.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955529 watch_fd=4 name=/var/log/containers/calico-node-pzvrj_kube-system_flexvol-driver-abf59d8a7af22c683dfb0776a0835c719f41ef23446e912f82901a4fd9cf166f.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373423 watch_fd=5 name=/var/log/containers/calico-node-pzvrj_kube-system_install-cni-b3d49f2e9c03e63c3863d50365d2ade01dead979c90285c526ac0029b58411cd.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373208 watch_fd=6 name=/var/log/containers/calico-node-pzvrj_kube-system_upgrade-ipam-6d4425d7ea5302511df1c278f2b113ac8fdfa0a372e07b025e0a9b45d30129ac.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403716654 watch_fd=7 name=/var/log/containers/coredns-5495dd7c88-68k9b_kube-system_coredns-879c087a4c8717d0886e6603a63e9503a406d215cfe77941cbcc1cc7c138d010.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583208 watch_fd=8 name=/var/log/containers/coredns-5495dd7c88-z9q6j_kube-system_coredns-80cd4427410de02465b415683817a75674a95777ffc0929f93e87506b120ca59.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=466327 watch_fd=9 name=/var/log/containers/ks-apiserver-574966976-snfm4_kubesphere-system_ks-apiserver-8871a0cc18cfef4663a15680761e272efeafe061ea9a898319265a145b494b18.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269010417 watch_fd=10 name=/var/log/containers/ks-console-65f4d44d88-hzw9b_kubesphere-system_ks-console-f600455c3af064c53adc8eb7e5412505c4d0e50362ab11b8e59d2e71b552b0f1.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269514179 watch_fd=11 name=/var/log/containers/ks-controller-manager-79c7dc79f5-j9fz5_kubesphere-system_ks-controller-manager-a8c35247c7cda868d3c023616026515690d2fedf2abb0f9367d1dc338103f7af.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403995814 watch_fd=12 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_config-reloader-2d51bab0babdd47864ec235efdbd69d2075cc8bf72c3642449be69f68aa1f0d5.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=962171 watch_fd=13 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_events-ruler-da24092a12c4fc0d0aab8a02c7fc7cb1e0e82d15a924717222bdbadee7935c84.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134580590 watch_fd=14 name=/var/log/containers/kube-apiserver-ks-k8s-master-0_kube-system_kube-apiserver-b4e97a525442956fe7612d27367a184ee09d65a56464149ec913ea004db0f1ef.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134580575 watch_fd=15 name=/var/log/containers/kube-controller-manager-ks-k8s-master-0_kube-system_kube-controller-manager-a07d1c5ed4108d98de2ba322b47939d5007c9d266a4ff558d57ec87ab10b2d54.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955289 watch_fd=16 name=/var/log/containers/kube-proxy-bc59k_kube-system_kube-proxy-79144efa6b42a0f9636132538cc4ade6665269fea5903f3e1e0be05f14376d7c.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403715964 watch_fd=17 name=/var/log/containers/kube-scheduler-ks-k8s-master-0_kube-system_kube-scheduler-1a2ffcf4000a9bb0fa526fcfa1970e69465dfe0bb4c635a4d95f50f2e27ef763.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403855647 watch_fd=18 name=/var/log/containers/minio-859cb4d777-mpsk9_kubesphere-system_minio-d76f9516fa485cd24851afccfb2c85fd74ce894ba580af98703704860e1c00ed.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=413299 watch_fd=19 name=/var/log/containers/node-exporter-wwrpf_kubesphere-monitoring-system_kube-rbac-proxy-e35229db1e46e8b7b0a7d5a3cd581107102a3531b31d2e32d7e787a118c82896.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=375870 watch_fd=20 name=/var/log/containers/node-exporter-wwrpf_kubesphere-monitoring-system_node-exporter-e5cc5a4cc937cf9de149dd25bd6e8441ca176bf26cb2a214dd0b47627e7d8861.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134581094 watch_fd=21 name=/var/log/containers/nodelocaldns-sp59h_kube-system_node-cache-8b5bdf5a116af255f979a4a349c168257b632d24805d5f257a642dd97b0d53a1.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=463110 watch_fd=22 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_config-reloader-1378a8d9cd7a96334cb15adeafb468497ece0a9a600a3193fb80b60bc5b7e9b5.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135190584 watch_fd=23 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_prometheus-26e94cf0828cd1bd9c5da45217b7f3e654a7a41ce0dc5943375b1644d1a6a002.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134738131 watch_fd=24 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_prometheus-97de8b484747bae4aeac54ffd9b75c1ddc9582a28c768ebc9be395390bd031c3.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268956011 watch_fd=25 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-kqrl5_kubesphere-system_config-init-0fb775710352218a66aec02ea2a736892c33df43dd4206e155e0bce6af4aba63.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373969 watch_fd=26 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-kqrl5_kubesphere-system_haproxy-6c15749c02904875f5c1a280a42a908baa074ccffd3365f40b2692b6fe60acf5.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403792092 watch_fd=27 name=/var/log/containers/redis-ha-server-2_kubesphere-system_config-init-fa7c66040a53bef1c3c9b1844a4b25870835a6147cd83abf914ebb129a036536.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=412431 watch_fd=28 name=/var/log/containers/redis-ha-server-2_kubesphere-system_redis-6b19bb18f79c55cca6022bd8caa13a33d8c57386897db47fc011fd9fbe589b8a.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134738124 watch_fd=29 name=/var/log/containers/redis-ha-server-2_kubesphere-system_sentinel-7b2cbde0a38f45b692dd1679912bb9ba4bdfc358667c32164592a0e7ab2a87a6.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=467559 watch_fd=30 name=/var/log/containers/thanos-ruler-kubesphere-1_kubesphere-monitoring-system_config-reloader-28aef566c79b3cc073a67787c6ad44902c88930f069ab26cf5657aa2d1235108.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403860482 watch_fd=31 name=/var/log/containers/thanos-ruler-kubesphere-1_kubesphere-monitoring-system_thanos-ruler-24cfbc7280d54f3289c4ae70d0bb25a4964dd2f759e8bddefad3cf92070b1903.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583426 watch_fd=32 name=/var/log/containers/calico-node-pzvrj_kube-system_calico-node-f2f40fb9878e3328a4783ceb9c01eaed9edf24c85579ed87c7ffc2161779c3e2.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:30] [ info] [input:tail:tail.2] inotify_fs_add(): inode=984530 watch_fd=33 name=/var/log/containers/fluent-bit-97khn_kubesphere-logging-system_fluent-bit-9cb8370106aed1e55ca9b9304662301a3ab4cbe6f543616cb5d1eec39d6f7b25.log</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:34] [ warn] [engine] failed to flush chunk &#x27;16-1650528150.277308324.flb&#x27;, retry in 8 seconds: task_id=0, input=systemd.0 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:34] [ warn] [engine] failed to flush chunk &#x27;16-1650528150.357492295.flb&#x27;, retry in 9 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:34] [ warn] [engine] failed to flush chunk &#x27;16-1650528150.296176788.flb&#x27;, retry in 6 seconds: task_id=1, input=systemd.1 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:34] [ warn] [engine] failed to flush chunk &#x27;16-1650528150.386272778.flb&#x27;, retry in 7 seconds: task_id=3, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:39] [ warn] [engine] failed to flush chunk &#x27;16-1650528158.305010058.flb&#x27;, retry in 10 seconds: task_id=4, input=systemd.1 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:39] [ warn] [engine] failed to flush chunk &#x27;16-1650528154.329523292.flb&#x27;, retry in 6 seconds: task_id=5, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:39] [ warn] [engine] failed to flush chunk &#x27;16-1650528154.753657988.flb&#x27;, retry in 9 seconds: task_id=6, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:39] [ warn] [engine] failed to flush chunk &#x27;16-1650528155.347169912.flb&#x27;, retry in 7 seconds: task_id=7, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:40] [ warn] [engine] chunk &#x27;16-1650528150.296176788.flb&#x27; cannot be retried: task_id=1, input=systemd.1 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:41] [ warn] [engine] chunk &#x27;16-1650528150.386272778.flb&#x27; cannot be retried: task_id=3, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:42] [ warn] [engine] chunk &#x27;16-1650528150.277308324.flb&#x27; cannot be retried: task_id=0, input=systemd.0 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:43] [ warn] [engine] chunk &#x27;16-1650528150.357492295.flb&#x27; cannot be retried: task_id=2, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:44] [ warn] [engine] failed to flush chunk &#x27;16-1650528159.328332342.flb&#x27;, retry in 7 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:45] [ warn] [engine] chunk &#x27;16-1650528154.329523292.flb&#x27; cannot be retried: task_id=5, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:46] [ warn] [engine] chunk &#x27;16-1650528155.347169912.flb&#x27; cannot be retried: task_id=7, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:48] [ warn] [engine] chunk &#x27;16-1650528154.753657988.flb&#x27; cannot be retried: task_id=6, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:49] [ warn] [engine] chunk &#x27;16-1650528158.305010058.flb&#x27; cannot be retried: task_id=4, input=systemd.1 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:49] [ warn] [engine] failed to flush chunk &#x27;16-1650528168.802004767.flb&#x27;, retry in 6 seconds: task_id=1, input=systemd.1 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:49] [ warn] [engine] failed to flush chunk &#x27;16-1650528164.324962334.flb&#x27;, retry in 6 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:51] [ warn] [engine] chunk &#x27;16-1650528159.328332342.flb&#x27; cannot be retried: task_id=0, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:54] [ warn] [engine] failed to flush chunk &#x27;16-1650528169.329511724.flb&#x27;, retry in 8 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:55] [ warn] [engine] chunk &#x27;16-1650528168.802004767.flb&#x27; cannot be retried: task_id=1, input=systemd.1 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:55] [ warn] [engine] chunk &#x27;16-1650528164.324962334.flb&#x27; cannot be retried: task_id=2, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:59] [ warn] [engine] failed to flush chunk &#x27;16-1650528179.232206869.flb&#x27;, retry in 8 seconds: task_id=1, input=systemd.1 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:59] [ warn] [engine] failed to flush chunk &#x27;16-1650528174.324611868.flb&#x27;, retry in 8 seconds: task_id=2, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:02:59] [ warn] [engine] failed to flush chunk &#x27;16-1650528174.430818290.flb&#x27;, retry in 7 seconds: task_id=3, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:03:02] [ warn] [engine] chunk &#x27;16-1650528169.329511724.flb&#x27; cannot be retried: task_id=0, input=tail.2 &gt; output=es.0</span><br><span class="line"></span><br><span class="line">    [2022/04/21 08:03:04] [ warn] [engine] failed to flush chunk &#x27;16-1650528179.322293412.flb&#x27;, retry in 7 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><ul><li><p>操作了一圈，又回到了原点，还是想办法开 Fluent-bit 的 Trace 日志吧，既然 Oupt 模板里没有对应参数，那么还是去底层解决吧。</p></li><li><p>首先我们要知道 KubeSphere 里部署的 Fluent-bit 采用了 <strong>fluent-operator</strong>，operator 里又专门定义了 Output 的类别的资源去对应 Fluent-bit 配置文件中的 output 章节。</p></li><li><p>那我们就去找到 fluent-operator 的官方网站，看看源码里<a href="https://github.com/fluent/fluent-operator/blob/master/charts/fluent-operator/crds/fluentbit.fluent.io_clusteroutputs.yaml">crds 中对于 output 资源如何定义的</a>（这里面就涉及 operator 的知识了，这个技能请自己 get 吧，细节我目前也不懂，所以也讲不出来）</p></li><li><p>打开资源定义文件后，在里面搜索关键词 <strong>traceError</strong>，注意一定是在 <strong>es</strong> 章节里的。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220422085824266.png" alt="image-20220422085824266"></p></li><li><p>有两个相关字段 <strong>traceError</strong> 和 <strong>traceOutput</strong>，这里看说明感觉 <strong>traceOutput</strong> 会更猛，但是前面有人说了开启 <strong>traceError</strong>，那咱就先试试 <strong>traceError</strong>，不行再来搞 <strong>traceOutput</strong>。</p></li><li><p>来吧，接着修改 es 的 output 文件 , 主要是在现有的配置文件中加入 <strong>traceError: true</strong>。</p></li><li><pre><code class="shell">  [root@ks-k8s-master-0 ~]# kubectl edit outputs -n kubesphere-logging-system esoutput.logging.kubesphere.io/es edited<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"> - 再用 base64 解码 secrets，看看配置文件是否有变化，这次我们换个简单的方式**一把输出**。</span><br><span class="line"></span><br><span class="line">   &gt; 你是不是要怼我了，既然有这么优雅的方式，之前为啥不用，呵呵，之前我也不会，是在前面搜索解决办法时无意中 Get 到的，[出处在这](https://banzaicloud.com/docs/one-eye/logging-operator/operation/troubleshooting/fluentbit/))。</span><br><span class="line"></span><br><span class="line"> - ```shell</span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get secret -n kubesphere-logging-system fluent-bit-config -o jsonpath=&quot;&#123;.data[&#x27;fluent-bit\.conf&#x27;]&#125;&quot; | base64 --decode</span><br><span class="line">   [Service]</span><br><span class="line">       Parsers_File    parsers.conf</span><br><span class="line">   [Input]</span><br><span class="line">       Name    systemd</span><br><span class="line">       Path    /var/log/journal</span><br><span class="line">       DB    /fluent-bit/tail/docker.db</span><br><span class="line">       DB.Sync    Normal</span><br><span class="line">       Tag    service.docker</span><br><span class="line">       Systemd_Filter    _SYSTEMD_UNIT=docker.service</span><br><span class="line">   [Input]</span><br><span class="line">       Name    systemd</span><br><span class="line">       Path    /var/log/journal</span><br><span class="line">       DB    /fluent-bit/tail/kubelet.db</span><br><span class="line">       DB.Sync    Normal</span><br><span class="line">       Tag    service.kubelet</span><br><span class="line">       Systemd_Filter    _SYSTEMD_UNIT=kubelet.service</span><br><span class="line">   [Input]</span><br><span class="line">       Name    tail</span><br><span class="line">       Path    /var/log/containers/*.log</span><br><span class="line">       Exclude_Path    /var/log/containers/*_kubesphere-logging-system_events-exporter*.log,/var/log/containers/kube-auditing-webhook*_kubesphere-logging-system_kube-auditing-webhook*.log</span><br><span class="line">       Refresh_Interval    10</span><br><span class="line">       Skip_Long_Lines    true</span><br><span class="line">       DB    /fluent-bit/tail/pos.db</span><br><span class="line">       DB.Sync    Normal</span><br><span class="line">       Mem_Buf_Limit    50MB</span><br><span class="line">       Parser    docker</span><br><span class="line">       Tag    kube.*</span><br><span class="line">   [Input]</span><br><span class="line">       Name    tail</span><br><span class="line">       Path    /var/log/containers/kube-auditing-webhook*_kubesphere-logging-system_kube-auditing-webhook*.log</span><br><span class="line">       Refresh_Interval    10</span><br><span class="line">       Skip_Long_Lines    true</span><br><span class="line">       DB    /fluent-bit/tail/pos-auditing.db</span><br><span class="line">       DB.Sync    Normal</span><br><span class="line">       Mem_Buf_Limit    50MB</span><br><span class="line">       Parser    docker</span><br><span class="line">       Tag    kube_auditing</span><br><span class="line">   [Input]</span><br><span class="line">       Name    tail</span><br><span class="line">       Path    /var/log/containers/*_kubesphere-logging-system_events-exporter*.log</span><br><span class="line">       Refresh_Interval    10</span><br><span class="line">       Skip_Long_Lines    true</span><br><span class="line">       DB    /fluent-bit/tail/pos-events.db</span><br><span class="line">       DB.Sync    Normal</span><br><span class="line">       Mem_Buf_Limit    50MB</span><br><span class="line">       Parser    docker</span><br><span class="line">       Tag    kube_events</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    parser</span><br><span class="line">       Match    kube_auditing</span><br><span class="line">       Key_Name    log</span><br><span class="line">       Parser    json</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    modify</span><br><span class="line">       Match    kube_auditing</span><br><span class="line">       Condition    Key_does_not_exist    AuditID    </span><br><span class="line">       Add    ignore    true</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    grep</span><br><span class="line">       Match    kube_auditing</span><br><span class="line">       Exclude    ignore true</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    parser</span><br><span class="line">       Match    kube_events</span><br><span class="line">       Key_Name    log</span><br><span class="line">       Parser    json</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    kubernetes</span><br><span class="line">       Match    kube.*</span><br><span class="line">       Kube_URL    https://kubernetes.default.svc:443</span><br><span class="line">       Kube_CA_File    /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">       Kube_Token_File    /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">       Labels    false</span><br><span class="line">       Annotations    false</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    nest</span><br><span class="line">       Match    kube.*</span><br><span class="line">       Operation    lift</span><br><span class="line">       Nested_under    kubernetes</span><br><span class="line">       Add_prefix    kubernetes_</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    modify</span><br><span class="line">       Match    kube.*</span><br><span class="line">       Remove    stream</span><br><span class="line">       Remove    kubernetes_pod_id</span><br><span class="line">       Remove    kubernetes_host</span><br><span class="line">       Remove    kubernetes_container_hash</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    nest</span><br><span class="line">       Match    kube.*</span><br><span class="line">       Operation    nest</span><br><span class="line">       Wildcard    kubernetes_*</span><br><span class="line">       Nest_under    kubernetes</span><br><span class="line">       Remove_prefix    kubernetes_</span><br><span class="line">   [Filter]</span><br><span class="line">       Name    lua</span><br><span class="line">       Match    service.*</span><br><span class="line">       script    /fluent-bit/config/systemd.lua</span><br><span class="line">       call    add_time</span><br><span class="line">       time_as_table    true</span><br><span class="line">   [Output]</span><br><span class="line">       Name    es</span><br><span class="line">       Match_Regex    (?:kube|service)\.(.*)</span><br><span class="line">       Host    192.168.9.95</span><br><span class="line">       Port    9200</span><br><span class="line">       HTTP_User    lstack</span><br><span class="line">       HTTP_Passwd    P@88w0rd</span><br><span class="line">       Logstash_Format    true</span><br><span class="line">       Logstash_Prefix    ks-logstash-log</span><br><span class="line">       Time_Key    @timestamp</span><br><span class="line">       Generate_ID    true</span><br><span class="line">       Trace_Error    true</span><br><span class="line">       tls    On</span><br><span class="line">       tls.verify    false</span><br><span class="line">   [Output]</span><br><span class="line">       Name    es</span><br><span class="line">       Match    kube_auditing</span><br><span class="line">       Host    192.168.9.95</span><br><span class="line">       Port    9200</span><br><span class="line">       HTTP_User    lstack</span><br><span class="line">       HTTP_Passwd    P@88w0rd</span><br><span class="line">       Logstash_Format    true</span><br><span class="line">       Logstash_Prefix    ks-logstash-auditing</span><br><span class="line">       Generate_ID    true</span><br><span class="line">       Trace_Error    true</span><br><span class="line">       tls    On</span><br><span class="line">       tls.verify    false</span><br><span class="line">   [Output]</span><br><span class="line">       Name    es</span><br><span class="line">       Match    kube_events</span><br><span class="line">       Host    192.168.9.95</span><br><span class="line">       Port    9200</span><br><span class="line">       HTTP_User    lstack</span><br><span class="line">       HTTP_Passwd    P@88w0rd</span><br><span class="line">       Logstash_Format    true</span><br><span class="line">       Logstash_Prefix    ks-logstash-events</span><br><span class="line">       Generate_ID    true</span><br><span class="line">       Trace_Error    true</span><br><span class="line">       tls    On</span><br><span class="line">       tls.verify    false</span><br></pre></td></tr></table></figure></code></pre></li><li><p>可以看到配置文件里已经存在了 <strong>Trace_Error    true</strong>，但是是否有效果、有变化呢？我们需要重建 <strong>Fluent-bit</strong> 的守护进程来看看。</p></li><li><p>登录控制台，<strong>集群管理</strong>-&gt;<strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>守护进程集</strong>，找到 <strong>fluent-bit</strong>，点击<strong>重新创建</strong>。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-2.png" alt="kubesphere-daemonsets-flunet-bit-2"></p></li><li><p>然后点击 <strong>fluent-bit</strong>，进入详情页面，可以看到有一个 pod 重建了（至于为什么其他的没变，咱先不说）。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-3.png" alt="kubesphere-daemonsets-flunet-bit-3"></p></li><li><p>进入新创建的 pod，咱看看日志输出有变化么！！！</p></li><li><p>&#96;&#96;&#96;yaml<br>   [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590190.748640950.flb’, retry in 6 seconds: task_id&#x3D;0, input&#x3D;systemd.0 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590190.792218570.flb’, retry in 6 seconds: task_id&#x3D;1, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590191.359045217.flb’, retry in 7 seconds: task_id&#x3D;2, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590191.862711494.flb’, retry in 8 seconds: task_id&#x3D;3, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590192.369644921.flb’, retry in 11 seconds: task_id&#x3D;4, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590192.873445035.flb’, retry in 7 seconds: task_id&#x3D;5, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590193.381872747.flb’, retry in 8 seconds: task_id&#x3D;6, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590193.897774507.flb’, retry in 9 seconds: task_id&#x3D;7, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590190.874190363.flb’, retry in 11 seconds: task_id&#x3D;8, input&#x3D;tail.2 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590190.980708345.flb’, retry in 8 seconds: task_id&#x3D;9, input&#x3D;tail.2 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:35] [ warn] [engine] failed to flush chunk ‘15-1650590194.547452615.flb’, retry in 9 seconds: task_id&#x3D;10, input&#x3D;tail.2 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:40] [ warn] [engine] failed to flush chunk ‘15-1650590195.289567444.flb’, retry in 11 seconds: task_id&#x3D;11, input&#x3D;systemd.1 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:40] [ warn] [engine] failed to flush chunk ‘15-1650590195.158774254.flb’, retry in 8 seconds: task_id&#x3D;12, input&#x3D;tail.2 &gt; output&#x3D;es.0 (out_id&#x3D;0)</p><p> [2022&#x2F;04&#x2F;22 01:16:41] [ warn] [engine] chunk ‘15-1650590190.748640950.flb’ cannot be retried: task_id&#x3D;0, input&#x3D;systemd.0 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:41] [ warn] [engine] chunk ‘15-1650590190.792218570.flb’ cannot be retried: task_id&#x3D;1, input&#x3D;systemd.1 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:42] [ warn] [engine] chunk ‘15-1650590191.359045217.flb’ cannot be retried: task_id&#x3D;2, input&#x3D;systemd.1 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:42] [ warn] [engine] chunk ‘15-1650590192.873445035.flb’ cannot be retried: task_id&#x3D;5, input&#x3D;systemd.1 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:43] [ warn] [engine] chunk ‘15-1650590191.862711494.flb’ cannot be retried: task_id&#x3D;3, input&#x3D;systemd.1 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:43] [ warn] [engine] chunk ‘15-1650590193.381872747.flb’ cannot be retried: task_id&#x3D;6, input&#x3D;systemd.1 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:43] [ warn] [engine] chunk ‘15-1650590190.980708345.flb’ cannot be retried: task_id&#x3D;9, input&#x3D;tail.2 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:44] [ warn] [engine] chunk ‘15-1650590193.897774507.flb’ cannot be retried: task_id&#x3D;7, input&#x3D;systemd.1 &gt; output&#x3D;es.0</p><p> [2022&#x2F;04&#x2F;22 01:16:44] [ warn] [engine] chunk ‘15-1650590194.547452615.flb’ cannot be retried: task_id&#x3D;10, input&#x3D;tail.2 &gt; output&#x3D;es.0</p></li></ul>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">   - 然而并没有什么 x 用，还是只有这些简单的输出，**说好的详细日志呢！！！**</span><br><span class="line"></span><br><span class="line">   - 既然 **traceError** 不行，那我们再去看看 **traceOutput**，细节不说了，总之配置完以后没啥变化。此时，我己经是**彻底崩溃**了，各种尝试都堵死了，到现在居然还没看到具体为啥。</span><br><span class="line"></span><br><span class="line">     &gt; **你们看文档这么点内容以为事情刚发生？？？实际上已经过去 3 天了！！！从这个事就能看出来，我其实很笨的）**</span><br><span class="line"></span><br><span class="line">   - 深度怀疑前面的两个参数，虽然配置上了，但是并没有生效，但是我有没有证据。暂时没有其他处理思路了。</span><br><span class="line"></span><br><span class="line">   - 放弃自查了，去各种群里问一圈，看看有没有现成的可以吃，然后我发现没朋友的可悲了，问了一圈居然没人搭理我，唉！！！</span><br><span class="line"></span><br><span class="line">5. 放弃后的第一次站起，继续搞起。</span><br><span class="line"></span><br><span class="line">   - 既然群里没找到答案，继续自力更生吧。</span><br><span class="line"></span><br><span class="line">   - 分析一波现状。</span><br><span class="line"></span><br><span class="line">   - Fluent-bit 日志报错关键词 **failed to flush chunk**，ElasticSearch 日志报错关键词 **java.lang.IllegalArgumentException: invalid version format** 和 **java.lang.IllegalArgumentException: text is empty**。</span><br><span class="line"></span><br><span class="line">   - ```yaml</span><br><span class="line">     [2022-04-22T09:57:10,374][DEBUG][r.suppressed             ] [es-node-0] path: /bad-request, params: &#123;&#125;</span><br><span class="line">     java.lang.IllegalArgumentException: invalid version format: C1®Þ\_¾L6Q&gt;À,À0©Ì¨ÌªÀ+À/$À(KÀ#À&#x27;GÀ</span><br><span class="line">             at io.netty.handler.codec.http.HttpVersion.&lt;init&gt;(HttpVersion.java:116) ~[netty-codec-http-4.1.66.Final.jar:4.1.66.Final]</span><br><span class="line">  </span><br><span class="line">     [2022-04-22T09:55:06,379][DEBUG][r.suppressed             ] [es-node-0] path: /bad-request, params: &#123;&#125;</span><br><span class="line">     java.lang.IllegalArgumentException: text is empty (possibly HTTP/0.9)</span><br><span class="line">             at io.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:65) ~[netty-codec-http-4.1.66.Final.jar:4.1.66.Final]</span><br></pre></td></tr></table></figure><ul><li><p>Fluent-bit 报错 <strong>failed to flush chunk</strong> 说明连接 elasticsearch 失败。</p></li><li><p>ElasticSearch 端的两个报错，说明 Fluent-bit 连接请求过来了，但是因为某种原因导致了 ElasticSearch 报错了。看报错应该是传递过来的数据不被 ElasticSearch 认可，也就是 <strong>invalid version format</strong> 和 <strong>text is empty</strong>。</p></li><li><p>我之前在两边开 <strong>Trace</strong>，也是为了找到 Fluent-bit 传递了啥，ElasticSeach 到底收了啥，但是两端都没有详细结果。</p></li><li><p>排查到现在我一直是在 es 采用 <strong>https</strong>协议并配置了认证的场景中测试的，我感觉这个问题可能出在 https 认证上，为了验证我的想法，我们将 es 改为 http 的协议，并取消认证。</p></li></ul><ol start="6"><li><p>将 es 改为 http 协议，验证一下 KubeSphere 日志系统是否正常。</p><ul><li><p>将 kubesphere 的日志系统停用，删除 Fluent-bit 的相关配置项</p></li><li><p><strong>平台管理</strong>-&gt;<strong>集群管理</strong>-&gt;<strong>CRD</strong>, 搜索 <strong>ClusterConfiguration</strong>，编辑 <strong>ks-installer</strong>, 按下面的修改后，点击确定。</p></li><li><pre><code class="yaml">auditing:  enabled: falseevents:  enabled: falselogging:  containerruntime: docker  enabled: false  logsidecar:    enabled: true    replicas: 2<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 打开工具箱中的 kubectl 工具，执行下面的命令观察执行过程，等待任务完成，细节不说了，上面都有。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  / # kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure></code></pre></li><li><p>执行完了，我们看看 KubeSphere 有啥变化，我预期的是跟这几个日志组件有关的服务配置都应该删除了才对。</p></li><li><p>但是，事与愿违，好像什么都没发生，之前的几个主角还在呢。至于为什么，暂时不要问我啊，我也不知道。。。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-4-0619543.png" alt="kubesphere-daemonsets-flunet-bit-4"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-5.png" alt="kubesphere-daemonsets-flunet-bit-5"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-6.png" alt="kubesphere-daemonsets-flunet-bit-6"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-7.png" alt="kubesphere-daemonsets-flunet-bit-7"></p></li><li><p><strong>工具箱</strong>中的容器日志查询也都在呢，只是报错不一样了，这个问题据说要重启 ks-apiserver 解决，暂时咱不管他。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-8.png" alt="kubesphere-daemonsets-flunet-bit-8"></p></li><li><p>没办法了，为了实验的准确性我只能强制赶你们走了，手动的把 Fluent-bit 的 operator 和守护进程集删掉，直接界面执行操作，比较简单，不截图了。</p></li><li><p>再把 <strong>CRD</strong> 中的 <strong>Output</strong> 和 <strong>Input</strong> 资源也删掉。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-delete-1.png" alt="kubesphere-crd-delete-1"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-delete-2.png" alt="kubesphere-crd-delete-2"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-delete-3.png" alt="kubesphere-crd-delete-3"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-delete-4.png" alt="kubesphere-crd-delete-4"></p></li><li><p>执行完上面的删除操作以后，我们会发现界面开始有了一些变化（也不排除是早期的操作延时导致的，先不深究了，可能以后也不会原因深究）。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-delete-5.png" alt="kubesphere-crd-delete-5"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-crd-delete-6.png" alt="kubesphere-crd-delete-6"></p></li><li><p>其实，测试验证的环境不删也就不删了，改改配置也是可以的，只是突然强迫症犯了，必须干掉。</p></li><li><p>确认全部删除后，我们开始重装 ElasticSearch。</p></li><li><p>利用 ansible 重新配置 elasticsearch（仅限于测试验证环境，有数据的生产环境就不要瞎搞了）。</p></li><li><pre><code class="shell"># 利用 ansible 卸载旧的 elasticsearch 并删除数据[root@zdevops-master ~]# cd /data/ansible/ansible-zdevops/inventories/dev[root@zdevops-master dev]# source /opt/ansible2.8/bin/activate(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#39;systemctl stop elasticsearch&#39;(ansible2.8) [root@zdevops-master dev]# ansible es -m shell -a &#39;yum remove -y elasticsearch&#39;(ansible2.8) [root@zdevops-master dev]# ansible es -m file -a &#39;path=/data/elasticsearch state=absent&#39;(ansible2.8) [root@zdevops-master dev]# ansible es -m file -a &#39;path=/etc/elasticsearch state=absent&#39;# 利用 ansible-playbook 安装 http 模式的 elasticsearch，注意-e 重新定义变量 elasticsearch_xpack_security_enabled 的值为 false(ansible2.8) [root@zdevops-master dev]# ansible-playbook -e elasticsearch_xpack_security_enabled=false ../../playbooks/deploy-elasticsearch.yaml /opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.  from cryptography.exceptions import InvalidSignaturePLAY [安装配置 ElasticSearch.] ********************************************************************************TASK [01-配置 yum 源-配置 elasticsearch 软件源 .] *********************************************************************ok: [es-node-1]ok: [es-node-0]ok: [es-node-2]TASK [02-安装 elasticsearch.] *******************************************************************************changed: [es-node-2]changed: [es-node-1]changed: [es-node-0]TASK [03-创建 elasticsearch 配置文件 .] ***************************************************************************changed: [es-node-0]changed: [es-node-2]changed: [es-node-1]TASK [04-创建 elasticsearch 数据文件目录 .] *************************************************************************changed: [es-node-0]changed: [es-node-2]changed: [es-node-1]PLAY [安装配置 ElasticSearch SSL 认证 .] **************************************************************************TASK [01-生成 ElasticSearch Instance 文件用来配置 ssl 证书 .] ***********************************************************skipping: [es-node-0]TASK [02-生成证书 .] ******************************************************************************************skipping: [es-node-0]TASK [03-安装基本工具包 .] ***************************************************************************************skipping: [es-node-0] =&gt; (item=[]) TASK [04-解压 cert 文件 .] **************************************************************************************skipping: [es-node-0]TASK [05-从服务器获取 cert 配置文件 .] ********************************************************************************skipping: [es-node-0] =&gt; (item=es-node-0) skipping: [es-node-0] =&gt; (item=es-node-1) skipping: [es-node-0] =&gt; (item=es-node-2) PLAY [认证配置 .] *********************************************************************************************TASK [01-创建 elasticsearch cert 目录 .] ************************************************************************skipping: [es-node-0]skipping: [es-node-1]skipping: [es-node-2]TASK [02-同步 cert 文件 .] **************************************************************************************skipping: [es-node-0]skipping: [es-node-1]skipping: [es-node-2]TASK [03-生成 keystore 文件 .] **********************************************************************************skipping: [es-node-0]skipping: [es-node-1]skipping: [es-node-2]TASK [04-添加配置项到 keystore 文件 .] ******************************************************************************skipping: [es-node-0]skipping: [es-node-1]skipping: [es-node-2]TASK [05-创建用户并指定 superuser 权限 .] ****************************************************************************skipping: [es-node-0]skipping: [es-node-1]skipping: [es-node-2]PLAY [终极配置 .] *********************************************************************************************TASK [01-启动并设置开机自动启动 elasticsearch 服务 .] ********************************************************************changed: [es-node-1]changed: [es-node-2]changed: [es-node-0]PLAY RECAP ***********************************************************************************************es-node-0                  : ok=5    changed=4    unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   es-node-1                  : ok=5    changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   es-node-2                  : ok=5    changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 查看 ElasticSearch 集群初始分片信息。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@glusterfs-node-0 ~]# curl  192.168.9.97:9200/_cat/indices?v</span><br><span class="line">  health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">  green  open   .geoip_databases DUibpJGVR66YyMiMxiUYpw   1   1          8            0     14.1mb            7mb</span><br></pre></td></tr></table></figure></code></pre></li><li><p><strong>平台管理</strong>-&gt;<strong>集群管理</strong>-&gt;<strong>CRD</strong>, 搜索 <strong>ClusterConfiguration</strong>，编辑 <strong>ks-installer</strong>, 按下面的修改后，点击确定。</p></li><li><pre><code class="yaml">auditing:  enabled: truees:  basicAuth:    enabled: false    password: &#39;&#39;    username: &#39;&#39;  elkPrefix: logstash  externalElasticsearchHost: 192.168.9.95  externalElasticsearchPort: 9200  logMaxAge: 7events:  enabled: truelogging:  containerruntime: docker  enabled: true  logsidecar:    enabled: true    replicas: 2<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 打开工具箱中的 kubectl 工具，执行下面的命令观察执行过程，等待任务完成，细节不说了，上面都有。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  / # kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure></code></pre></li><li><p>执行完以后，正常的话我们之前操作的资源应该都回归了，<strong>Output</strong>、<strong>Input</strong>、<strong>Fluent-bit</strong>，<strong>工具箱里的工具</strong>不截图了自己看一下吧。</p></li><li><p>但是我们会发现 <strong>Fluent-bit</strong> 的 pod 中还有如下报错。</p></li><li><pre><code class="yaml">[2022/04/22 15:20:20] [ warn] [net] getaddrinfo(host=&#39;elasticsearch-logging-data.kubesphere-logging-system.svc&#39;, err=4): Domain name not found[2022/04/22 15:20:20] [ warn] [net] getaddrinfo(host=&#39;elasticsearch-logging-data.kubesphere-logging-system.svc&#39;, err=4): Domain name not found<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 看到这个知道怎么搞了吧？不知道？？？去上面翻翻。</span><br><span class="line"></span><br><span class="line">- 依次修改 **Output** 中的 **es**、**es-auditing**、**es-events**，改后如下：</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Output</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: &gt;</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: logging</span><br><span class="line">      logging.kubesphere.io/enabled: &#x27;true&#x27;</span><br><span class="line">    name: es</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">  spec:</span><br><span class="line">    es:</span><br><span class="line">      generateID: true</span><br><span class="line">      host: 192.168.9.95</span><br><span class="line">      logstashFormat: true</span><br><span class="line">      logstashPrefix: ks-logstash-log</span><br><span class="line">      port: 9200</span><br><span class="line">      timeKey: &#x27;@timestamp&#x27;</span><br><span class="line">    matchRegex: &#x27;(?:kube|service)\.(.*)&#x27;</span><br></pre></td></tr></table></figure></code></pre></li><li><pre><code class="yaml">apiVersion: logging.kubesphere.io/v1alpha2kind: Outputmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: &gt;      &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;auditing&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es-auditing&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-auditing&quot;,&quot;port&quot;:9200&#125;,&quot;match&quot;:&quot;kube_auditing&quot;&#125;&#125;  labels:    logging.kubesphere.io/component: auditing    logging.kubesphere.io/enabled: &#39;true&#39;  name: es-auditing  namespace: kubesphere-logging-systemspec:  es:    generateID: true    host: 192.168.9.95    logstashFormat: true    logstashPrefix: ks-logstash-auditing    port: 9200  match: kube_auditing<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Output</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: &gt;</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;events&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es-events&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-events&quot;,&quot;port&quot;:9200&#125;,&quot;match&quot;:&quot;kube_events&quot;&#125;&#125;</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: events</span><br><span class="line">      logging.kubesphere.io/enabled: &#x27;true&#x27;</span><br><span class="line">    name: es-events</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">  spec:</span><br><span class="line">    es:</span><br><span class="line">      generateID: true</span><br><span class="line">      host: 192.168.9.95</span><br><span class="line">      logstashFormat: true</span><br><span class="line">      logstashPrefix: ks-logstash-events</span><br><span class="line">      port: 9200</span><br><span class="line">    match: kube_events</span><br></pre></td></tr></table></figure></code></pre></li><li><p>再去查看 Fluent-bit 容器的日志，你会发现 Fluent-bit 内部发现了配置文件的变化，并重启了 <strong>Fluent Bit</strong> 服务，且容器并没有重建。</p></li><li><pre><code class="yaml"> [2022/04/22 15:27:04] [engine] caught signal (SIGTERM) [2022/04/22 15:27:04] [ info] [input] pausing systemd.0 [2022/04/22 15:27:04] [ info] [input] pausing systemd.1 [2022/04/22 15:27:04] [ info] [input] pausing tail.2 [2022/04/22 15:27:04] [ info] [input] pausing tail.3 [2022/04/22 15:27:04] [ info] [input] pausing tail.4 level=info msg=&quot;Config file changed, stopping Fluent Bit&quot; level=info msg=&quot;Killed Fluent Bit&quot; level=info msg=&quot;Config file changed, stopped Fluent Bit&quot; level=info msg=&quot;Config file changed, stopping Fluent Bit&quot; [2022/04/22 15:27:04] [ warn] [engine] service will stop in 5 seconds level=info msg=&quot;Killed Fluent Bit&quot; level=info msg=&quot;Config file changed, stopped Fluent Bit&quot; level=info msg=&quot;Config file changed, stopping Fluent Bit&quot; level=info msg=&quot;Killed Fluent Bit&quot; level=info msg=&quot;Config file changed, stopped Fluent Bit&quot; [2022/04/22 15:27:09] [ info] [engine] service stopped [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=416649 watch_fd=1 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=461549 watch_fd=2 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134582558 watch_fd=3 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134581715 watch_fd=4 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268955529 watch_fd=5 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373423 watch_fd=6 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373208 watch_fd=7 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403716654 watch_fd=8 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583208 watch_fd=9 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583458 watch_fd=10 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=269010417 watch_fd=11 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=269628719 watch_fd=12 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403995814 watch_fd=13 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=962171 watch_fd=14 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583441 watch_fd=15 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134580575 watch_fd=16 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268955289 watch_fd=17 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403715964 watch_fd=18 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403855647 watch_fd=19 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=413299 watch_fd=20 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=375870 watch_fd=21 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134581094 watch_fd=22 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=463110 watch_fd=23 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=135190584 watch_fd=24 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134738131 watch_fd=25 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268956011 watch_fd=26 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373969 watch_fd=27 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403792092 watch_fd=28 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=412431 watch_fd=29 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134738124 watch_fd=30 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=467559 watch_fd=31 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403860482 watch_fd=32 [2022/04/22 15:27:09] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=997586 watch_fd=33 level=error msg=&quot;Fluent bit exited&quot; error=null level=info msg=backoff delay=1s level=info msg=&quot;backoff timer done&quot; actual=1.00029973s expected=1s level=info msg=&quot;Fluent bit started&quot; Fluent Bit v1.8.3 * Copyright (C) 2019-2021 The Fluent Bit Authors * Copyright (C) 2015-2018 Treasure Data * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io [2022/04/22 15:27:10] [ info] [engine] started (pid=30) [2022/04/22 15:27:10] [ info] [storage] version=1.1.1, initializing... [2022/04/22 15:27:10] [ info] [storage] in-memory [2022/04/22 15:27:10] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128 [2022/04/22 15:27:10] [ info] [cmetrics] version=0.1.6 [2022/04/22 15:27:10] [ info] [input:systemd:systemd.0] seek_cursor=s=5d0022eeaf454ba8a40dde2836de2f4d;i=b56... OK [2022/04/22 15:27:10] [ info] [input:systemd:systemd.1] seek_cursor=s=5d0022eeaf454ba8a40dde2836de2f4d;i=b5b... OK [2022/04/22 15:27:10] [ info] [filter:kubernetes:kubernetes.4] https=1 host=kubernetes.default.svc port=443 [2022/04/22 15:27:10] [ info] [filter:kubernetes:kubernetes.4] local POD info OK [2022/04/22 15:27:10] [ info] [filter:kubernetes:kubernetes.4] testing connectivity with API server... [2022/04/22 15:27:10] [ info] [filter:kubernetes:kubernetes.4] connectivity OK [2022/04/22 15:27:10] [ info] [sp] stream processor started [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=416649 watch_fd=1 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_alertmanager-1a71f1d5b1136320644f3289e4b22544620db4a0d35a1ffec52bc534d729c358.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=461549 watch_fd=2 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_config-reloader-bc14c53008f1e800d6240a5b912239a3d5682c6dcb719f48c69b7e8ba5892e35.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134582558 watch_fd=3 name=/var/log/containers/calico-kube-controllers-75ddb95444-8xvf4_kube-system_calico-kube-controllers-dc90044aa0ce62e61dfb0842c8f2e5aa8d021738adffca847b003a5c9621512c.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955529 watch_fd=4 name=/var/log/containers/calico-node-pzvrj_kube-system_flexvol-driver-abf59d8a7af22c683dfb0776a0835c719f41ef23446e912f82901a4fd9cf166f.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373423 watch_fd=5 name=/var/log/containers/calico-node-pzvrj_kube-system_install-cni-b3d49f2e9c03e63c3863d50365d2ade01dead979c90285c526ac0029b58411cd.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373208 watch_fd=6 name=/var/log/containers/calico-node-pzvrj_kube-system_upgrade-ipam-6d4425d7ea5302511df1c278f2b113ac8fdfa0a372e07b025e0a9b45d30129ac.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403716654 watch_fd=7 name=/var/log/containers/coredns-5495dd7c88-68k9b_kube-system_coredns-879c087a4c8717d0886e6603a63e9503a406d215cfe77941cbcc1cc7c138d010.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583208 watch_fd=8 name=/var/log/containers/coredns-5495dd7c88-z9q6j_kube-system_coredns-80cd4427410de02465b415683817a75674a95777ffc0929f93e87506b120ca59.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583458 watch_fd=9 name=/var/log/containers/ks-apiserver-5c68568694-w8xs6_kubesphere-system_ks-apiserver-b76c824251f298a17d7594eea392602cea7291e1b3e35ae35cefb4607e6e4cdf.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269010417 watch_fd=10 name=/var/log/containers/ks-console-65f4d44d88-hzw9b_kubesphere-system_ks-console-f600455c3af064c53adc8eb7e5412505c4d0e50362ab11b8e59d2e71b552b0f1.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269628719 watch_fd=11 name=/var/log/containers/ks-controller-manager-bf6b9bfb5-xfts6_kubesphere-system_ks-controller-manager-9c24833ae6bce8c0ff956db38b40d9acf0224ec364c317ebcefc7802d4d97855.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403995814 watch_fd=12 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_config-reloader-2d51bab0babdd47864ec235efdbd69d2075cc8bf72c3642449be69f68aa1f0d5.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=962171 watch_fd=13 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_events-ruler-da24092a12c4fc0d0aab8a02c7fc7cb1e0e82d15a924717222bdbadee7935c84.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134580575 watch_fd=14 name=/var/log/containers/kube-controller-manager-ks-k8s-master-0_kube-system_kube-controller-manager-a07d1c5ed4108d98de2ba322b47939d5007c9d266a4ff558d57ec87ab10b2d54.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955289 watch_fd=15 name=/var/log/containers/kube-proxy-bc59k_kube-system_kube-proxy-79144efa6b42a0f9636132538cc4ade6665269fea5903f3e1e0be05f14376d7c.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403715964 watch_fd=16 name=/var/log/containers/kube-scheduler-ks-k8s-master-0_kube-system_kube-scheduler-1a2ffcf4000a9bb0fa526fcfa1970e69465dfe0bb4c635a4d95f50f2e27ef763.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403855647 watch_fd=17 name=/var/log/containers/minio-859cb4d777-mpsk9_kubesphere-system_minio-d76f9516fa485cd24851afccfb2c85fd74ce894ba580af98703704860e1c00ed.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=413299 watch_fd=18 name=/var/log/containers/node-exporter-wwrpf_kubesphere-monitoring-system_kube-rbac-proxy-e35229db1e46e8b7b0a7d5a3cd581107102a3531b31d2e32d7e787a118c82896.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=375870 watch_fd=19 name=/var/log/containers/node-exporter-wwrpf_kubesphere-monitoring-system_node-exporter-e5cc5a4cc937cf9de149dd25bd6e8441ca176bf26cb2a214dd0b47627e7d8861.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134581094 watch_fd=20 name=/var/log/containers/nodelocaldns-sp59h_kube-system_node-cache-8b5bdf5a116af255f979a4a349c168257b632d24805d5f257a642dd97b0d53a1.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=463110 watch_fd=21 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_config-reloader-1378a8d9cd7a96334cb15adeafb468497ece0a9a600a3193fb80b60bc5b7e9b5.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=135190584 watch_fd=22 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_prometheus-26e94cf0828cd1bd9c5da45217b7f3e654a7a41ce0dc5943375b1644d1a6a002.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134738131 watch_fd=23 name=/var/log/containers/prometheus-k8s-0_kubesphere-monitoring-system_prometheus-97de8b484747bae4aeac54ffd9b75c1ddc9582a28c768ebc9be395390bd031c3.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268956011 watch_fd=24 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-kqrl5_kubesphere-system_config-init-0fb775710352218a66aec02ea2a736892c33df43dd4206e155e0bce6af4aba63.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373969 watch_fd=25 name=/var/log/containers/redis-ha-haproxy-868fdbddd4-kqrl5_kubesphere-system_haproxy-6c15749c02904875f5c1a280a42a908baa074ccffd3365f40b2692b6fe60acf5.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403792092 watch_fd=26 name=/var/log/containers/redis-ha-server-2_kubesphere-system_config-init-fa7c66040a53bef1c3c9b1844a4b25870835a6147cd83abf914ebb129a036536.log [2022/04/22 15:27:10] [ info] [input:tail:tail.2] inotify_fs_add(): inode=412431 watch_fd=27 name=/var/log/containers/redis-ha-server-2_kubesphere-system_redis-6b19bb18f79c55c<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- ![kubesphere-daemonsets-flunet-bit-9](https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-daemonsets-flunet-bit-9.png)</span><br><span class="line"></span><br><span class="line">- 分析日志发现，Fluent-bit 端没有错误信息了，再去 ElasticSearch 中查看索引。</span><br><span class="line"></span><br><span class="line">- **她来了她真的来了**, 真 xxx 不容易。</span><br><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  [root@glusterfs-node-0 ~]# curl  192.168.9.97:9200/_cat/indices?v</span><br><span class="line">  health status index                           uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">  green  open   .geoip_databases                DUibpJGVR66YyMiMxiUYpw   1   1         40            0     75.8mb         37.9mb</span><br><span class="line">  green  open   ks-logstash-log-2022.04.22      sG7rEJ2OT-27Kv6k0kq-CQ   1   1        486            0        1mb        529.7kb</span><br><span class="line">  green  open   ks-logstash-auditing-2022.04.22 x52Q_uEZRZ-yNYXPRmyWLg   1   1          1            0     37.4kb         18.7kb</span><br><span class="line">  green  open   ks-logstash-events-2022.04.22   AafsMv0bRd-xz_Uj_HlOag   1   1         10            0    149.5kb         74.6kb</span><br></pre></td></tr></table></figure></code></pre></li><li><p>再回来看看我们 KubeSphere 工具箱中的几个分析工具是否正常了？</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox.png" alt="kubesphere-toolbox"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-container.png" alt="kubesphere-toolbox-analysis-tools-container"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-audit.png" alt="kubesphere-toolbox-analysis-tools-audit"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-event.png" alt="kubesphere-toolbox-analysis-tools-event"></p></li><li><p>三个查询工具还是有异常弹窗，不慌！这个问题如何处理，我也是心中有数的。</p></li><li><p>这几天可不是白混的，论坛文档没少看，来打开 kubesphere 官方论坛，需要找到两篇文档结合来处理。</p></li><li><p>打开<a href="https://kubesphere.com.cn/forum/d/2450-kuspheredial-tcp-lookup-http-on-109601053-no-such-host/4">在使用 kusphere 的操作审计功能时，总有弹窗提示：dial tcp: lookup http on 10.96.0.10:53: no such host</a>，找到修改配置文件的命令（其实吧你改界面也行）</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220422235234281.png" alt="image-20220422235234281"></p></li><li><p>先来看看文档中的配置现状</p></li><li><pre><code class="shell">[root@ks-k8s-master-0 ~]# kubectl get configmap kubesphere-config -n kubesphere-system -o yamlapiVersion: v1data:  kubesphere.yaml: |    authentication:      authenticateRateLimiterMaxTries: 10      authenticateRateLimiterDuration: 10m0s      loginHistoryRetentionPeriod: 168h      maximumClockSkew: 10s      multipleLogin: True      kubectlImage: kubesphere/kubectl:v1.21.0      jwtSecret: &quot;1xh3ldfKpJSzSmFCbi2HXXbw5dn4o4kv&quot;      oauthOptions:        clients:        - name: kubesphere          secret: kubesphere          redirectURIs:          - &#39;*&#39;    ldap:      host: openldap.kubesphere-system.svc:389      managerDN: cn=admin,dc=kubesphere,dc=io      managerPassword: admin      userSearchBase: ou=Users,dc=kubesphere,dc=io      groupSearchBase: ou=Groups,dc=kubesphere,dc=io    redis:      host: redis.kubesphere-system.svc      port: 6379      password: KUBESPHERE_REDIS_PASSWORD      db: 0    s3:      endpoint: http://minio.kubesphere-system.svc:9000      region: us-east-1      disableSSL: True      forcePathStyle: True      accessKeyID: openpitrixminioaccesskey      secretAccessKey: openpitrixminiosecretkey      bucket: s2i-binaries    network:      ippoolType: none    devops:      host: http://devops-jenkins.kubesphere-devops-system.svc/      username: admin      password: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFkbWluQGt1YmVzcGhlcmUuaW8iLCJ1c2VybmFtZSI6ImFkbWluIiwidG9rZW5fdHlwZSI6InN0YXRpY190b2tlbiJ9.DVnt9FY7UNu2Mvshh_46UMKhZG7_X7NPC-ClQ68ynB0      maxConnections: 100      endpoint: http://devops-apiserver.kubesphere-devops-system:9090    openpitrix:      s3:        endpoint: http://minio.kubesphere-system.svc:9000        region: us-east-1        disableSSL: True        forcePathStyle: True        accessKeyID: openpitrixminioaccesskey        secretAccessKey: openpitrixminiosecretkey        bucket: app-store    monitoring:      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090      enableGPUMonitoring: false    gpu:      kinds:      - resourceName: nvidia.com/gpu        resourceType: GPU        default: True    notification:      endpoint: http://notification-manager-svc.kubesphere-monitoring-system.svc:19093    logging:      host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200      indexPrefix: ks-logstash-log    events:      host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200      indexPrefix: ks-logstash-events    auditing:      enable: true      webhookURL: https://kube-auditing-webhook-svc.kubesphere-logging-system.svc:6443/audit/webhook/event      host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200      indexPrefix: ks-logstash-auditing    alerting:      prometheusEndpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090      thanosRulerEndpoint: http://thanos-ruler-operated.kubesphere-monitoring-system.svc:10902      thanosRuleResourceLabels: thanosruler=thanos-ruler,role=thanos-alerting-rules    gateway:      watchesPath: /var/helm-charts/watches.yaml      repository: kubesphere/nginx-ingress-controller      tag: v0.48.1      namespace: kubesphere-controls-systemkind: ConfigMapmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: |      &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;data&quot;:&#123;&quot;kubesphere.yaml&quot;:&quot;authentication:\n  authenticateRateLimiterMaxTries: 10\n  authenticateRateLimiterDuration: 10m0s\n  loginHistoryRetentionPeriod: 168h\n  maximumClockSkew: 10s\n  multipleLogin: True\n  kubectlImage: kubesphere/kubectl:v1.21.0\n  jwtSecret: \&quot;1xh3ldfKpJSzSmFCbi2HXXbw5dn4o4kv\&quot;\n  oauthOptions:\n    clients:\n    - name: kubesphere\n      secret: kubesphere\n      redirectURIs:\n      - &#39;*&#39;\n\nldap:\n  host: openldap.kubesphere-system.svc:389\n  managerDN: cn=admin,dc=kubesphere,dc=io\n  managerPassword: admin\n  userSearchBase: ou=Users,dc=kubesphere,dc=io\n  groupSearchBase: ou=Groups,dc=kubesphere,dc=io\n\nredis:\n  host: redis.kubesphere-system.svc\n  port: 6379\n  password: KUBESPHERE_REDIS_PASSWORD\n  db: 0\n\n\ns3:\n  endpoint: http://minio.kubesphere-system.svc:9000\n  region: us-east-1\n  disableSSL: True\n  forcePathStyle: True\n  accessKeyID: openpitrixminioaccesskey\n  secretAccessKey: openpitrixminiosecretkey\n  bucket: s2i-binaries\n\nnetwork:\n  ippoolType: none\ndevops:\n  host: http://devops-jenkins.kubesphere-devops-system.svc/\n  username: admin\n  password: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImFkbWluQGt1YmVzcGhlcmUuaW8iLCJ1c2VybmFtZSI6ImFkbWluIiwidG9rZW5fdHlwZSI6InN0YXRpY190b2tlbiJ9.DVnt9FY7UNu2Mvshh_46UMKhZG7_X7NPC-ClQ68ynB0\n  maxConnections: 100\n  endpoint: http://devops-apiserver.kubesphere-devops-system:9090\nopenpitrix:\n  s3:\n    endpoint: http://minio.kubesphere-system.svc:9000\n    region: us-east-1\n    disableSSL: True\n    forcePathStyle: True\n    accessKeyID: openpitrixminioaccesskey\n    secretAccessKey: openpitrixminiosecretkey\n    bucket: app-store\nmonitoring:\n  endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090\n  enableGPUMonitoring: false\ngpu:\n  kinds:\n  - resourceName: nvidia.com/gpu\n    resourceType: GPU\n    default: True\nnotification:\n  endpoint: http://notification-manager-svc.kubesphere-monitoring-system.svc:19093\nlogging:\n  host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200\n  indexPrefix: ks-logstash-log\nevents:\n  host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200\n  indexPrefix: ks-logstash-events\nauditing:\n  enable: true\n  webhookURL: https://kube-auditing-webhook-svc.kubesphere-logging-system.svc:6443/audit/webhook/event\n  host: http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200\n  indexPrefix: ks-logstash-auditing\n\nalerting:\n  prometheusEndpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090\n  thanosRulerEndpoint: http://thanos-ruler-operated.kubesphere-monitoring-system.svc:10902\n  thanosRuleResourceLabels: thanosruler=thanos-ruler,role=thanos-alerting-rules\n\n\ngateway:\n  watchesPath: /var/helm-charts/watches.yaml\n  repository: kubesphere/nginx-ingress-controller\n  tag: v0.48.1\n  namespace: kubesphere-controls-system\n&quot;&#125;,&quot;kind&quot;:&quot;ConfigMap&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;kubesphere-config&quot;,&quot;namespace&quot;:&quot;kubesphere-system&quot;&#125;&#125;  creationTimestamp: &quot;2022-04-09T14:42:47Z&quot;  name: kubesphere-config  namespace: kubesphere-system  resourceVersion: &quot;3541275&quot;  uid: 2d45c34b-bc9d-43bd-a3d3-37b294393531<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 知道重点是啥了吧，把它 **http://elasticsearch-logging-data.kubesphere-logging-system.svc:9200** 全改成实际的 **ElasticSearch** 的地址</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl edit configmap kubesphere-config -n kubesphere-system</span><br><span class="line">  configmap/kubesphere-config edited</span><br><span class="line">  </span><br><span class="line">  # 可以在编辑模式使用 %s/elasticsearch-logging-data.kubesphere-logging-system.svc/192.168.9.95/g 批量替换</span><br><span class="line">  </span><br><span class="line">  # 实际修改内容如下</span><br><span class="line">  logging:</span><br><span class="line">    host: http://192.168.9.95:9200</span><br><span class="line">    indexPrefix: ks-logstash-log</span><br><span class="line">  events:</span><br><span class="line">    host: http://192.168.9.95:9200</span><br><span class="line">    indexPrefix: ks-logstash-events</span><br><span class="line">  auditing:</span><br><span class="line">    enable: true</span><br><span class="line">    webhookURL: https://kube-auditing-webhook-svc.kubesphere-logging-system.svc:6443/audit/webhook/event</span><br><span class="line">    host: http://192.168.9.95:9200</span><br><span class="line">    indexPrefix: ks-logstash-auditing</span><br></pre></td></tr></table></figure></code></pre></li><li><p>改完以后我发现，好像没啥变化，报错依旧。不过此时我也是不慌的。</p></li><li><p>继续打开第二篇文档，<a href="https://kubesphere.com.cn/forum/d/6614-es">使用外部 es 的问题</a>, 重点在图片上，红色字体的描述，这里提到了需要重启 ks-apiserver 才可以。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220423001514866.png" alt="image-20220423001514866"></p></li><li><p>我们再看看 ks-apiserver 的配置，确定也挂载了 kubesphere-config。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-ks-apiserver-2.png" alt="kubesphere-ks-apiserver-2"></p></li><li><p>我来重启一下 ks-apiserver 控制台，验证一下真伪。</p></li><li><p>控制台，<strong>集群管理</strong>-&gt;<strong>应用负载</strong>-&gt;<strong>工作负载</strong>-&gt;<strong>部署</strong>-&gt;<strong>ks-apiserver</strong>, 重启。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-ks-apiserver-0.png" alt="kubesphere-ks-apiserver-0"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-ks-apiserver-1.png" alt="kubesphere-ks-apiserver-1"></p></li><li><p>重启的时候，右上角会有报错，不用管它。全部重启完以后我们再看看工具箱中的几个日志分析工具。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-containe-1.png" alt="kubesphere-toolbox-analysis-tools-containe-1"></p></li><li><p>输入一个关键词，查询一下看看具体效果，而且从搜索框中还可以看到 kubesphere 日志系统支持的查询粒度。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-container-2.png" alt="kubesphere-toolbox-analysis-tools-container-2"></p></li><li><p>接下来在看看审计和事件功能。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-event-1.png" alt="kubesphere-toolbox-analysis-tools-event-1"></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-toolbox-analysis-tools-audit-1.png" alt="kubesphere-toolbox-analysis-tools-audit-1"></p></li><li><p>至此，KubeSphere 日志系统对接外部基于 Http 协议的 ElasticSearch 集群算是彻底完成了，该有的都有了，至于后面的使用效果，那只能线上持续观测了。</p></li><li><p>但是你们以为这就完了，打完收工么，想啥呢，还有一个大坑没填呢，HTTPS 的 ElasticSearch 还没搞定呢，继续搞它。</p></li></ul></li><li><p>继续我们的 ElasticSearch 的 HTTPS 配置之旅。</p><ul><li><p>通过上面的过程我们应该可以断定，KubeSphere 部署的 fluent-bit 对接 http 协议的 ES 是没有任何问题的，那问题就是出在 https 协议上。我们换个思路，先跑掉 Kubesphere 不说，先去看看原生的 Fluent-bit 对接 https 协议的 es 有啥套路。</p></li><li><p>搜索关键词 <strong>fluent-bit https elasticsearch</strong>。</p></li><li><p>各种搜索引擎都尝试过，都是大同小异，无非就是关掉 tls 验证，有的文档还提到了加上 ca 的配置。并没有解决问题的思路和方案（<strong>此时我还没有醒悟</strong>，我一开始方向就错了，后面细说），也就懒得截图了。</p></li><li><p>上面的关键词不行，我又换了一个思路 <strong>fluent-bit x-pack elasticsearch</strong>，毕竟我们的安全验证是启用了 x-pack 插件。</p></li><li><p>哈哈哈哈，别说我还真找到一篇有意义并帮我最终解决问题的文档，那就是<a href="https://vqiu.cn/efk-kube/">它</a></p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220428110517048.png" alt="image-20220428110517048"></p></li><li><p>此文档介绍的都是在 k8s 安装 es，但是这个不重要，配置文件都是有参考意义的，看看他的配置文件：</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/image-20220428110847858.png" alt="image-20220428110847858"></p></li><li><p>看到这个配置文件，我突然灵光一闪，这个配置里没有 tls 什么事啊。此时，我才幡然醒悟，其实我要的并不是 https 并不是 tls，我要的其实就是个 <strong>http 协议加上用户名和密码验证</strong>，这才是我真正的需求。</p></li><li><p>我一开始就走错了路，被 <strong>ClusterConfiguration</strong> 中的这个参数 <strong>externalElasticsearchProtocol: https</strong> 给坑了，此时我已经忘记从哪里看到的文档需要配置这个参数了，我是一个不记仇的人，我就不找后账了。</p></li><li><p>思路有了，来我们验证一波。</p></li><li><p>先 <strong>ClusterConfiguration</strong>-&gt;<strong>ks-installer</strong>, 编辑 YAML。确保配置文件中 es 的配置如下，如果存在 <strong>externalElasticsearchProtocol: https</strong> 一定要干掉它。</p></li><li><pre><code class="yaml">es:  basicAuth:    enabled: false    password: P@88w0rd    username: lstack  elkPrefix: logstash  externalElasticsearchHost: 192.168.9.95  externalElasticsearchPort: 9200  logMaxAge: 7</code></pre></li><li><p>修改完成后，点击<strong>确定</strong>，等待后台重新配置完成。</p></li><li><p>再去查看 <strong>Output</strong> 的几个配置文件，<strong>es</strong>、<strong>es-auditing</strong>、<strong>es-events</strong> 具体如下</p></li><li><pre><code class="yaml">apiVersion: logging.kubesphere.io/v1alpha2kind: Outputmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: &gt;      &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;logging&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-log&quot;,&quot;port&quot;:9200,&quot;timeKey&quot;:&quot;@timestamp&quot;&#125;,&quot;matchRegex&quot;:&quot;(?:kube|service)\\.(.*)&quot;&#125;&#125;  labels:    logging.kubesphere.io/component: logging    logging.kubesphere.io/enabled: &#39;true&#39;  name: es  namespace: kubesphere-logging-systemspec:  es:    generateID: true    host: 192.168.9.95    httpPassword:      valueFrom:        secretKeyRef:          key: password          name: elasticsearch-credentials    httpUser:      valueFrom:        secretKeyRef:          key: username          name: elasticsearch-credentials    logstashFormat: true    logstashPrefix: ks-logstash-log    port: 9200    timeKey: &#39;@timestamp&#39;  matchRegex: &#39;(?:kube|service)\.(.*)&#39;<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- ```yaml</span><br><span class="line">  apiVersion: logging.kubesphere.io/v1alpha2</span><br><span class="line">  kind: Output</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      kubectl.kubernetes.io/last-applied-configuration: &gt;</span><br><span class="line">        &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;auditing&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es-auditing&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-auditing&quot;,&quot;port&quot;:9200,&quot;tls&quot;:&#123;&quot;verify&quot;:false&#125;&#125;,&quot;match&quot;:&quot;kube_auditing&quot;&#125;&#125;</span><br><span class="line">    labels:</span><br><span class="line">      logging.kubesphere.io/component: auditing</span><br><span class="line">      logging.kubesphere.io/enabled: &#x27;true&#x27;</span><br><span class="line">    name: es-auditing</span><br><span class="line">    namespace: kubesphere-logging-system</span><br><span class="line">  spec:</span><br><span class="line">    es:</span><br><span class="line">      generateID: true</span><br><span class="line">      host: 192.168.9.95</span><br><span class="line">      httpPassword:</span><br><span class="line">        valueFrom:</span><br><span class="line">          secretKeyRef:</span><br><span class="line">            key: password</span><br><span class="line">            name: elasticsearch-credentials</span><br><span class="line">      httpUser:</span><br><span class="line">        valueFrom:</span><br><span class="line">          secretKeyRef:</span><br><span class="line">            key: username</span><br><span class="line">            name: elasticsearch-credentials</span><br><span class="line">      logstashFormat: true</span><br><span class="line">      logstashPrefix: ks-logstash-log</span><br><span class="line">      port: 9200</span><br><span class="line">    match: kube_auditing</span><br></pre></td></tr></table></figure></code></pre></li><li><pre><code class="yaml">apiVersion: logging.kubesphere.io/v1alpha2kind: Outputmetadata:  annotations:    kubectl.kubernetes.io/last-applied-configuration: &gt;      &#123;&quot;apiVersion&quot;:&quot;logging.kubesphere.io/v1alpha2&quot;,&quot;kind&quot;:&quot;Output&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;logging.kubesphere.io/component&quot;:&quot;events&quot;,&quot;logging.kubesphere.io/enabled&quot;:&quot;true&quot;&#125;,&quot;name&quot;:&quot;es-events&quot;,&quot;namespace&quot;:&quot;kubesphere-logging-system&quot;&#125;,&quot;spec&quot;:&#123;&quot;es&quot;:&#123;&quot;generateID&quot;:true,&quot;host&quot;:&quot;elasticsearch-logging-data.kubesphere-logging-system.svc&quot;,&quot;logstashFormat&quot;:true,&quot;logstashPrefix&quot;:&quot;ks-logstash-events&quot;,&quot;port&quot;:9200,&quot;tls&quot;:&#123;&quot;verify&quot;:false&#125;&#125;,&quot;match&quot;:&quot;kube_events&quot;&#125;&#125;  labels:    logging.kubesphere.io/component: events    logging.kubesphere.io/enabled: &#39;true&#39;  name: es-events  namespace: kubesphere-logging-systemspec:  es:    generateID: true    host: 192.168.9.95    httpPassword:      valueFrom:        secretKeyRef:          key: password          name: elasticsearch-credentials    httpUser:      valueFrom:        secretKeyRef:          key: username          name: elasticsearch-credentials    logstashFormat: true    logstashPrefix: ks-logstash-log    port: 9200  match: kube_events<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- Output 配置文件修改完成后，查看 fluent-bit 的容器 log，看看是否正常输出日志到 es 了，在日志输出里可以发现，修改配置文件之前，还是有大量的报错，修改配置文件后 fluent-bit 监测到配置文件发生变化，自动重启了服务，启动后，没有报错，说明日志可以正常输出 es。</span><br><span class="line"></span><br><span class="line">- ```shell</span><br><span class="line">  [root@ks-k8s-master-0 ~]# kubectl logs  fluent-bit-xq2jb -n kubesphere-logging-system</span><br><span class="line">  </span><br><span class="line">  [2022/04/28 02:58:19] [ warn] [engine] failed to flush chunk &#x27;39-1651114694.735704833.flb&#x27;, retry in 9 seconds: task_id=4, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:19] [ warn] [engine] failed to flush chunk &#x27;39-1651114695.509379382.flb&#x27;, retry in 10 seconds: task_id=5, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ warn] [engine] chunk &#x27;39-1651114693.743740772.flb&#x27; cannot be retried: task_id=2, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Config file changed, stopping Fluent Bit&quot;</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Killed Fluent Bit&quot;</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Config file changed, stopped Fluent Bit&quot;</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Config file changed, stopping Fluent Bit&quot;</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Killed Fluent Bit&quot;</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Config file changed, stopped Fluent Bit&quot;</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [engine] caught signal (SIGTERM)</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ info] [input] pausing systemd.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ info] [input] pausing systemd.1</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ info] [input] pausing tail.2</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ info] [input] pausing tail.3</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ info] [input] pausing tail.4</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ warn] [engine] service will stop in 5 seconds</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:20] [ warn] [engine] failed to flush chunk &#x27;39-1651114699.328367642.flb&#x27;, retry in 6 seconds: task_id=0, input=tail.2 &gt; output=es.0 (out_id=0)</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:23] [ warn] [engine] chunk &#x27;39-1651114689.327129623.flb&#x27; cannot be retried: task_id=1, input=tail.2 &gt; output=es.0</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [engine] service stopped</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=416649 watch_fd=1</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=461549 watch_fd=2</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134582558 watch_fd=3</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134581715 watch_fd=4</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268955529 watch_fd=5</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373423 watch_fd=6</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373208 watch_fd=7</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403716654 watch_fd=8</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583208 watch_fd=9</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=997310 watch_fd=10</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=269010417 watch_fd=11</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=984532 watch_fd=12</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403995814 watch_fd=13</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=962171 watch_fd=14</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134583424 watch_fd=15</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134580575 watch_fd=16</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268955289 watch_fd=17</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403715964 watch_fd=18</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403855647 watch_fd=19</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=413299 watch_fd=20</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=375870 watch_fd=21</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134581094 watch_fd=22</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=463110 watch_fd=23</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=135190584 watch_fd=24</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134738131 watch_fd=25</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=268956011 watch_fd=26</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=373969 watch_fd=27</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403792092 watch_fd=28</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=412431 watch_fd=29</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=134738124 watch_fd=30</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=467559 watch_fd=31</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=403860482 watch_fd=32</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:25] [ info] [input:tail:tail.2] inotify_fs_remove(): inode=997586 watch_fd=33</span><br><span class="line">  </span><br><span class="line">   level=error msg=&quot;Fluent bit exited&quot; error=null</span><br><span class="line">  </span><br><span class="line">   level=info msg=backoff delay=1s</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;backoff timer done&quot; actual=1.000167488s expected=1s</span><br><span class="line">  </span><br><span class="line">   level=info msg=&quot;Fluent bit started&quot;</span><br><span class="line">  </span><br><span class="line">   Fluent Bit v1.8.3</span><br><span class="line">  </span><br><span class="line">   * Copyright (C) 2019-2021 The Fluent Bit Authors</span><br><span class="line">  </span><br><span class="line">   * Copyright (C) 2015-2018 Treasure Data</span><br><span class="line">  </span><br><span class="line">   * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd</span><br><span class="line">  </span><br><span class="line">   * https://fluentbit.io</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [engine] started (pid=42)</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [storage] version=1.1.1, initializing...</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [storage] in-memory</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [cmetrics] version=0.1.6</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:systemd:systemd.0] seek_cursor=s=5d0022eeaf454ba8a40dde2836de2f4d;i=e3f... OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:systemd:systemd.1] seek_cursor=s=5d0022eeaf454ba8a40dde2836de2f4d;i=e47... OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [filter:kubernetes:kubernetes.4] https=1 host=kubernetes.default.svc port=443</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [filter:kubernetes:kubernetes.4] local POD info OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [filter:kubernetes:kubernetes.4] testing connectivity with API server...</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [filter:kubernetes:kubernetes.4] connectivity OK</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [sp] stream processor started</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=416649 watch_fd=1 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_alertmanager-1a71f1d5b1136320644f3289e4b22544620db4a0d35a1ffec52bc534d729c358.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=461549 watch_fd=2 name=/var/log/containers/alertmanager-main-2_kubesphere-monitoring-system_config-reloader-bc14c53008f1e800d6240a5b912239a3d5682c6dcb719f48c69b7e8ba5892e35.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134582558 watch_fd=3 name=/var/log/containers/calico-kube-controllers-75ddb95444-8xvf4_kube-system_calico-kube-controllers-dc90044aa0ce62e61dfb0842c8f2e5aa8d021738adffca847b003a5c9621512c.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134581715 watch_fd=4 name=/var/log/containers/calico-node-pzvrj_kube-system_calico-node-f2f40fb9878e3328a4783ceb9c01eaed9edf24c85579ed87c7ffc2161779c3e2.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=268955529 watch_fd=5 name=/var/log/containers/calico-node-pzvrj_kube-system_flexvol-driver-abf59d8a7af22c683dfb0776a0835c719f41ef23446e912f82901a4fd9cf166f.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373423 watch_fd=6 name=/var/log/containers/calico-node-pzvrj_kube-system_install-cni-b3d49f2e9c03e63c3863d50365d2ade01dead979c90285c526ac0029b58411cd.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=373208 watch_fd=7 name=/var/log/containers/calico-node-pzvrj_kube-system_upgrade-ipam-6d4425d7ea5302511df1c278f2b113ac8fdfa0a372e07b025e0a9b45d30129ac.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403716654 watch_fd=8 name=/var/log/containers/coredns-5495dd7c88-68k9b_kube-system_coredns-879c087a4c8717d0886e6603a63e9503a406d215cfe77941cbcc1cc7c138d010.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583208 watch_fd=9 name=/var/log/containers/coredns-5495dd7c88-z9q6j_kube-system_coredns-80cd4427410de02465b415683817a75674a95777ffc0929f93e87506b120ca59.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=997310 watch_fd=10 name=/var/log/containers/ks-apiserver-6554c5ddb4-tzvmf_kubesphere-system_ks-apiserver-9536d87a3fa484f71c1a22a8eb489ce67e5a072a4d3f2d38796220f192a32b4f.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=269010417 watch_fd=11 name=/var/log/containers/ks-console-65f4d44d88-hzw9b_kubesphere-system_ks-console-f600455c3af064c53adc8eb7e5412505c4d0e50362ab11b8e59d2e71b552b0f1.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=984532 watch_fd=12 name=/var/log/containers/ks-controller-manager-b575b54ff-8tx8m_kubesphere-system_ks-controller-manager-d11c9db1fc376410555fc4ac7de2fa46bb2aa963c2bcbd407fab46d017caf788.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=403995814 watch_fd=13 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_config-reloader-2d51bab0babdd47864ec235efdbd69d2075cc8bf72c3642449be69f68aa1f0d5.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=962171 watch_fd=14 name=/var/log/containers/ks-events-ruler-575669b4-mh2fn_kubesphere-logging-system_events-ruler-da24092a12c4fc0d0aab8a02c7fc7cb1e0e82d15a924717222bdbadee7935c84.log</span><br><span class="line">  </span><br><span class="line">   [2022/04/28 02:58:26] [ info] [input:tail:tail.2] inotify_fs_add(): inode=134583424 watch_fd=15 name=/var/log/containers/kube-apiserver-ks-k8s-master-0_kube-system_kube-apiserver-b4e97a525442956fe7612d27367a184ee09d65a56464149ec913ea004db0f1ef.log</span><br></pre></td></tr></table></figure></code></pre></li><li><p>再看看 es 里是否有索引了。</p></li><li><pre><code class="shell">[root@glusterfs-node-0 ~]# curl -ulstack:&#39;P@88w0rd&#39; 192.168.9.95:9200/_cat/indices?vhealth status index                      uuid                   pri rep docs.count docs.deleted store.size pri.store.sizegreen  open   .geoip_databases           VFDw1lkoQYiWeX-u7bMC1Q   1   1         40            0     75.5mb         37.7mbgreen  open   ks-logstash-log-2022.04.28 eu6citkMQ4aHpsHnLhj7IQ   1   1        407            0    394.6kb        164.4kb</code></pre></li><li><p>注意啊，此时工具箱里的分析工具还是会报错的。按着上面的操作方法，重启一下 ks-apiserver 就可以解决并看到相应的结果。</p></li></ul></li><li><p>至此，ElasticSearch 采用 http 协议不开启认证和开启认证两种方式的对接全部实现了，本文其实没有介绍 ElasticSearch 采用 HTTPS 协议的方式，后续如果真有需求再补充。</p></li></ol><h2 id="5-技术关键点梳理"><a href="#5-技术关键点梳理" class="headerlink" title="5. 技术关键点梳理"></a>5. 技术关键点梳理</h2><h3 id="01-技术关键点（留坑，待补充）"><a href="#01-技术关键点（留坑，待补充）" class="headerlink" title="01 技术关键点（留坑，待补充）"></a>01 技术关键点（留坑，待补充）</h3><ol><li>fluentbit-operator<ul><li>Input</li><li>Output</li></ul></li><li>ClusterConfiguration 的技术细节</li><li>ks-installer 的技术细节</li><li>ElasticSearch 的优化配置</li></ol><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>本文详细讲解了 ElasticSearch 基于 http 协议启用认证和不启用认证两种方式的集群安装部署过程，同时在 KubeSphere 中开启了可插拔的日志组件，并演示了与两种模式下的 ElasticSearch 集群对接以及对接过程中的遇坑、填坑的过程。本文的配置经验可直接用于生产环境。到此为止，我们 KubeSphere 和 Kubernetes 的安装配置和初始化已经全部完成，下一章开始，我们将开启利用 KubeSphere 在 Kubernetes 上安装配置各种常用服务的实践之旅。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li>太多了，大部分都在文中直接链接了</li><li><a href="https://github.com/fluent/fluent-operator/tree/master/charts/fluent-operator/crds">fluent-operator 官网</a></li><li><a href="https://ptran32.github.io/2020-08-12-send-k8s-logs-with-fluentbit/">https://ptran32.github.io/2020-08-12-send-k8s-logs-with-fluentbit/</a></li><li><a href="https://banzaicloud.com/docs/one-eye/logging-operator/operation/troubleshooting/fluentbit/">https://banzaicloud.com/docs/one-eye/logging-operator/operation/troubleshooting/fluentbit/</a></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p>About Me</p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-ElasticSearch-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-ElasticSearch-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere </summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-GlusterFS安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-GlusterFS%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-GlusterFS%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.152Z</published>
    <updated>2023-09-22T01:42:08.693Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于KubeSphere玩转k8s-GlusterFS安装手记"><a href="#基于KubeSphere玩转k8s-GlusterFS安装手记" class="headerlink" title="基于KubeSphere玩转k8s-GlusterFS安装手记"></a>基于KubeSphere玩转k8s-GlusterFS安装手记</h1><p><strong>大家好，我是老Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖(但不限于)以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文接着上篇 <strong>&lt;&lt;基于KubeSphere玩转k8s-KubeSphere初始化手记&gt;&gt;</strong> ，继续玩转KubeSphere、k8s，本期会讲解分布式存储GluterFS的安装部署以及与KubeSphere安装的k8s集群的对接配置。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：26 分</li><li>行：1895</li><li>单词：10056</li><li>字符：93833</li><li>图片：0 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>使用Ansible安装部署GlusterFS服务</li><li>使用Ansible安装部署Heketi服务</li><li>在k8s上命令行的方式对接GlusterFS</li><li>在KubeSphere上图形化方式对接GlusterFS</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdevops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr></tbody></table><blockquote><p><strong>演示环境涉及软件版本信息</strong></p></blockquote><ul><li>操作系统：<strong>CentOS-7.9-x86_64</strong></li><li>KubeSphere：<strong>3.2.1</strong></li><li>GlusterFS：<strong>9.5-1</strong></li><li>Ansible：<strong>2.8.20</strong></li></ul><hr><h2 id="2-Ansible配置"><a href="#2-Ansible配置" class="headerlink" title="2. Ansible配置"></a>2. Ansible配置</h2><h3 id="2-1-增加hosts配置"><a href="#2-1-增加hosts配置" class="headerlink" title="2.1. 增加hosts配置"></a>2.1. 增加hosts配置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hosts文件配置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主要增加glusterfs</span></span><br><span class="line">[<span class="string">k8s</span>]</span><br><span class="line"><span class="string">ks-k8s-master-0</span> <span class="string">ansible_ssh_host=192.168.9.91</span>  <span class="string">host_name=ks-k8s-master-0</span></span><br><span class="line"><span class="string">ks-k8s-master-1</span> <span class="string">ansible_ssh_host=192.168.9.92</span>  <span class="string">host_name=ks-k8s-master-1</span></span><br><span class="line"><span class="string">ks-k8s-master-2</span> <span class="string">ansible_ssh_host=192.168.9.93</span>  <span class="string">host_name=ks-k8s-master-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">glusterfs</span>]</span><br><span class="line"><span class="string">glusterfs-node-0</span> <span class="string">ansible_ssh_host=192.168.9.95</span> <span class="string">host_name=glusterfs-node-0</span></span><br><span class="line"><span class="string">glusterfs-node-1</span> <span class="string">ansible_ssh_host=192.168.9.96</span> <span class="string">host_name=glusterfs-node-1</span></span><br><span class="line"><span class="string">glusterfs-node-2</span> <span class="string">ansible_ssh_host=192.168.9.97</span> <span class="string">host_name=glusterfs-node-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:children</span>]</span><br><span class="line"><span class="string">k8s</span></span><br><span class="line"><span class="string">glusterfs</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:vars</span>]</span><br><span class="line"><span class="string">ansible_connection=paramiko</span></span><br><span class="line"><span class="string">ansible_ssh_user=root</span></span><br><span class="line"><span class="string">ansible_ssh_pass=password</span></span><br></pre></td></tr></table></figure><hr><h2 id="3-GlusterFS安装配置"><a href="#3-GlusterFS安装配置" class="headerlink" title="3. GlusterFS安装配置"></a>3. GlusterFS安装配置</h2><h3 id="3-1-检测服务器连通性"><a href="#3-1-检测服务器连通性" class="headerlink" title="3.1. 检测服务器连通性"></a>3.1. 检测服务器连通性</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 检测服务器的连通性</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs -m ping</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-2 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">glusterfs-node-1 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">glusterfs-node-0 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-初始化服务器配置"><a href="#3-2-初始化服务器配置" class="headerlink" title="3.2. 初始化服务器配置"></a>3.2. 初始化服务器配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化服务器配置</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/init-base.yaml -l glusterfs</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [初始化服务器配置.] *************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-停止并禁用firewalld服务.] **************************************************************************************</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line"></span><br><span class="line">TASK [02-配置主机名.] *************************************************************************************************</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [03-配置/etc/hosts.] ******************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">TASK [04-配置时区.] **************************************************************************************************</span><br><span class="line">ok: [glusterfs-node-1]</span><br><span class="line">ok: [glusterfs-node-2]</span><br><span class="line">ok: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统.] ************************************************************************************************</span><br><span class="line">skipping: [glusterfs-node-0]</span><br><span class="line">skipping: [glusterfs-node-1]</span><br><span class="line">skipping: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统后如果需要重启，则重启服务器.] **********************************************************************************</span><br><span class="line">skipping: [glusterfs-node-0]</span><br><span class="line">skipping: [glusterfs-node-1]</span><br><span class="line">skipping: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">TASK [05-等待服务器完成重启.] *********************************************************************************************</span><br><span class="line">skipping: [glusterfs-node-0]</span><br><span class="line">skipping: [glusterfs-node-1]</span><br><span class="line">skipping: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">PLAY [安装配置chrony服务器.] ********************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-安装chrony软件包.] *******************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [glusterfs-node-2] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [glusterfs-node-1] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line"></span><br><span class="line">TASK [02-配置chrony.conf.] *****************************************************************************************</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">TASK [03-确认chrony服务启动并实现开机自启.] ***********************************************************************************</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">TASK [04-查看chrony时间同步服务器列表(1).] **********************************************************************************</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [04-查看chrony时间同步服务器列表(2).] **********************************************************************************</span><br><span class="line">ok: [glusterfs-node-0] =&gt; &#123;</span><br><span class="line">    &quot;chronyc_out.stdout_lines&quot;: [</span><br><span class="line">        &quot;210 Number of sources = 1&quot;, </span><br><span class="line">        &quot;MS Name/IP address         Stratum Poll Reach LastRx Last sample               &quot;, </span><br><span class="line">        &quot;===============================================================================&quot;, </span><br><span class="line">        &quot;^? 114.118.7.161                 1   6     1     1   -1091s[ -1091s] +/- 5246us&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">ok: [glusterfs-node-1] =&gt; &#123;</span><br><span class="line">    &quot;chronyc_out.stdout_lines&quot;: [</span><br><span class="line">        &quot;210 Number of sources = 1&quot;, </span><br><span class="line">        &quot;MS Name/IP address         Stratum Poll Reach LastRx Last sample               &quot;, </span><br><span class="line">        &quot;===============================================================================&quot;, </span><br><span class="line">        &quot;^? 114.118.7.161                 1   6     1     1   -1092s[ -1092s] +/- 6411us&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">ok: [glusterfs-node-2] =&gt; &#123;</span><br><span class="line">    &quot;chronyc_out.stdout_lines&quot;: [</span><br><span class="line">        &quot;210 Number of sources = 1&quot;, </span><br><span class="line">        &quot;MS Name/IP address         Stratum Poll Reach LastRx Last sample               &quot;, </span><br><span class="line">        &quot;===============================================================================&quot;, </span><br><span class="line">        &quot;^? 114.118.7.161                 0   6     0     -     +0ns[   +0ns] +/-    0ns&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PLAY RECAP *******************************************************************************************************</span><br><span class="line">glusterfs-node-0           : ok=9    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">glusterfs-node-1           : ok=9    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">glusterfs-node-2           : ok=9    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0 </span><br></pre></td></tr></table></figure><p><strong>重点注意：ansible-playbook的 -l 参数，需要指定为glusterfs，因为init-base.yaml文件默认指定的是所有服务器都执行，不加-l就会把hosts文件里指定的所有服务器都初始化了。</strong></p><h3 id="3-3-安装GlusterFS服务"><a href="#3-3-安装GlusterFS服务" class="headerlink" title="3.3. 安装GlusterFS服务"></a>3.3. 安装GlusterFS服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook安装GlusterFS服务</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/deploy-glusterfs-server.yaml</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [安装配置GlusterFS服务.] ***********************************************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-安装glusterfs的repo配置.] *****************************************************************************************************************************</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [02-安装glusterfs-server.] *****************************************************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">TASK [03-启动并设置开机自动启动glusterd服务.] **************************************************************************************************************************</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">PLAY RECAP ************************************************************************************************************************************************</span><br><span class="line">glusterfs-node-0           : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">glusterfs-node-1           : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">glusterfs-node-2           : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br></pre></td></tr></table></figure><h3 id="3-4-验证GlusterFS服务状态"><a href="#3-4-验证GlusterFS服务状态" class="headerlink" title="3.4. 验证GlusterFS服务状态"></a>3.4. 验证GlusterFS服务状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证 GlusterFS 服务状态</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs -m shell -a &#x27;systemctl status glusterd&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">● glusterd.service - GlusterFS, a clustered file-system server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/glusterd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sat 2022-04-02 14:09:12 CST; 2min 26s ago</span><br><span class="line">     Docs: man:glusterd(8)</span><br><span class="line">  Process: 9760 ExecStart=/usr/sbin/glusterd -p /var/run/glusterd.pid --log-level $LOG_LEVEL $GLUSTERD_OPTIONS (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 9761 (glusterd)</span><br><span class="line">   CGroup: /system.slice/glusterd.service</span><br><span class="line">           └─9761 /usr/sbin/glusterd -p /var/run/glusterd.pid --log-level INFO</span><br><span class="line"></span><br><span class="line">Apr 02 14:09:12 localhost.localdomain systemd[1]: Starting GlusterFS, a clustered file-system server...</span><br><span class="line">Apr 02 14:09:12 localhost.localdomain systemd[1]: Started GlusterFS, a clustered file-system server.</span><br><span class="line"></span><br><span class="line">glusterfs-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">● glusterd.service - GlusterFS, a clustered file-system server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/glusterd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sat 2022-04-02 14:09:11 CST; 2min 26s ago</span><br><span class="line">     Docs: man:glusterd(8)</span><br><span class="line">  Process: 9747 ExecStart=/usr/sbin/glusterd -p /var/run/glusterd.pid --log-level $LOG_LEVEL $GLUSTERD_OPTIONS (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 9748 (glusterd)</span><br><span class="line">   CGroup: /system.slice/glusterd.service</span><br><span class="line">           └─9748 /usr/sbin/glusterd -p /var/run/glusterd.pid --log-level INFO</span><br><span class="line"></span><br><span class="line">Apr 02 14:09:11 localhost.localdomain systemd[1]: Starting GlusterFS, a clustered file-system server...</span><br><span class="line">Apr 02 14:09:11 localhost.localdomain systemd[1]: Started GlusterFS, a clustered file-system server.</span><br><span class="line"></span><br><span class="line">glusterfs-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">● glusterd.service - GlusterFS, a clustered file-system server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/glusterd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sat 2022-04-02 14:09:12 CST; 2min 26s ago</span><br><span class="line">     Docs: man:glusterd(8)</span><br><span class="line">  Process: 9867 ExecStart=/usr/sbin/glusterd -p /var/run/glusterd.pid --log-level $LOG_LEVEL $GLUSTERD_OPTIONS (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 9868 (glusterd)</span><br><span class="line">   CGroup: /system.slice/glusterd.service</span><br><span class="line">           └─9868 /usr/sbin/glusterd -p /var/run/glusterd.pid --log-level INFO</span><br><span class="line"></span><br><span class="line">Apr 02 14:09:12 localhost.localdomain systemd[1]: Starting GlusterFS, a clustered file-system server...</span><br><span class="line">Apr 02 14:09:12 localhost.localdomain systemd[1]: Started GlusterFS, a clustered file-system server.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible验证GlusterFS服务端口状态</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs -m shell -a &#x27;ss -ntlup | grep glusterd&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">tcp    LISTEN     0      128       *:24007                 *:*                   users:((&quot;glusterd&quot;,pid=9761,fd=10))</span><br><span class="line"></span><br><span class="line">glusterfs-node-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">tcp    LISTEN     0      128       *:24007                 *:*                   users:((&quot;glusterd&quot;,pid=9748,fd=10))</span><br><span class="line"></span><br><span class="line">glusterfs-node-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">tcp    LISTEN     0      128       *:24007                 *:*                   users:((&quot;glusterd&quot;,pid=9868,fd=10))</span><br></pre></td></tr></table></figure><h3 id="3-5-检测GlusterFS集群节点之间的连通性"><a href="#3-5-检测GlusterFS集群节点之间的连通性" class="headerlink" title="3.5. 检测GlusterFS集群节点之间的连通性"></a>3.5. 检测GlusterFS集群节点之间的连通性</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible验证GlusterFS集群节点之间的连通性</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">选择利用节点1 ping测节点2和节点3</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs-node-0 -m shell -a &#x27;ping glusterfs-node-1 -c 4&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">PING glusterfs-node-1 (192.168.9.96) 56(84) bytes of data.</span><br><span class="line">64 bytes from glusterfs-node-1 (192.168.9.96): icmp_seq=1 ttl=64 time=0.289 ms</span><br><span class="line">64 bytes from glusterfs-node-1 (192.168.9.96): icmp_seq=2 ttl=64 time=0.237 ms</span><br><span class="line">64 bytes from glusterfs-node-1 (192.168.9.96): icmp_seq=3 ttl=64 time=0.236 ms</span><br><span class="line">64 bytes from glusterfs-node-1 (192.168.9.96): icmp_seq=4 ttl=64 time=0.209 ms</span><br><span class="line"></span><br><span class="line">--- glusterfs-node-1 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.209/0.242/0.289/0.034 ms</span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs-node-0 -m shell -a &#x27;ping glusterfs-node-2 -c 4&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">PING glusterfs-node-2 (192.168.9.97) 56(84) bytes of data.</span><br><span class="line">64 bytes from glusterfs-node-2 (192.168.9.97): icmp_seq=1 ttl=64 time=0.223 ms</span><br><span class="line">64 bytes from glusterfs-node-2 (192.168.9.97): icmp_seq=2 ttl=64 time=0.297 ms</span><br><span class="line">64 bytes from glusterfs-node-2 (192.168.9.97): icmp_seq=3 ttl=64 time=0.269 ms</span><br><span class="line">64 bytes from glusterfs-node-2 (192.168.9.97): icmp_seq=4 ttl=64 time=0.268 ms</span><br><span class="line"></span><br><span class="line">--- glusterfs-node-2 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.223/0.264/0.297/0.028 ms</span><br></pre></td></tr></table></figure><h3 id="3-6-配置可信池-Configure-the-trusted-pool"><a href="#3-6-配置可信池-Configure-the-trusted-pool" class="headerlink" title="3.6. 配置可信池(Configure the trusted pool)"></a>3.6. 配置可信池(Configure the trusted pool)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible配置可信池(Configure the trusted pool)</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs-node-0 -m shell -a &#x27;gluster peer probe glusterfs-node-1&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">peer probe: success</span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs-node-0 -m shell -a &#x27;gluster peer probe glusterfs-node-2&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">peer probe: success</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible检查Peer状态</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible glusterfs-node-0 -m shell -a &#x27;gluster peer status&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">glusterfs-node-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Number of Peers: 2</span><br><span class="line"></span><br><span class="line">Hostname: glusterfs-node-1</span><br><span class="line">Uuid: 1759a580-d17f-4427-935c-50ad53f78c39</span><br><span class="line">State: Peer in Cluster (Connected)</span><br><span class="line"></span><br><span class="line">Hostname: glusterfs-node-2</span><br><span class="line">Uuid: cd56bacf-f62b-4310-b193-5c600cf75a6b</span><br><span class="line">State: Peer in Cluster (Connected)</span><br></pre></td></tr></table></figure><hr><h2 id="4-安装配置Heketi"><a href="#4-安装配置Heketi" class="headerlink" title="4. 安装配置Heketi"></a>4. 安装配置Heketi</h2><p><strong>在GlusterFs服务器中任选一个节点,这里选择节点1，glusterfs-node-0，也可以将Heketi独立部署</strong></p><h3 id="4-1-安装配置heketi服务"><a href="#4-1-安装配置heketi服务" class="headerlink" title="4.1. 安装配置heketi服务"></a>4.1. 安装配置heketi服务</h3><p><strong>安装配置heketi服务采用Ansible自动化部署，主要包括以下操作步骤</strong></p><ul><li>配置软件源</li><li>安装heketi和heketi-client</li><li>生成heketi管理用ssh-key，并配置服务器免密</li><li>创建heketi配置文件heketi.json</li><li>启动heketi服务并设置开机自启</li><li>创建topology.json配置文件</li><li>利用topoly.json配置文件创建集群</li><li>配置heketi管理用环境变量</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook安装配置heketi服务</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/deploy-glusterfs-heketi.yaml </span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [生成heketi服务使用的ssh管理密钥.] ****************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [生成ssh密钥] ******************************************************************************************************</span><br><span class="line">[WARNING]: Consider using the file module with state=directory rather than running &#x27;mkdir&#x27;.  If you need to use</span><br><span class="line">command because file is insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27;</span><br><span class="line">in ansible.cfg to get rid of this message.</span><br><span class="line"></span><br><span class="line">changed: [localhost]</span><br><span class="line"></span><br><span class="line">PLAY [配置heketi ssh密钥认证] *********************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [传送heketi认证ssh密钥] **********************************************************************************************</span><br><span class="line">changed: [glusterfs-node-1]</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line">changed: [glusterfs-node-2]</span><br><span class="line"></span><br><span class="line">PLAY [安装部署heketi.] **************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-安装glusterfs的repo配置.] ***************************************************************************************</span><br><span class="line">ok: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [02-安装heketi-server.] ******************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [03-复制ssh-key-pub] *********************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0] =&gt; (item=private_key)</span><br><span class="line">changed: [glusterfs-node-0] =&gt; (item=private_key.pub)</span><br><span class="line"></span><br><span class="line">TASK [04-创建heketi文件-heketi.json.] ***********************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [05-启动并设置开机自动启动heketi服务.] **************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [06-创建heketi文件-topology.json.] *********************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [07-根据topology.json创建集群] ***************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">TASK [08-配置heketi管理用环境变量] *******************************************************************************************</span><br><span class="line">changed: [glusterfs-node-0]</span><br><span class="line"></span><br><span class="line">PLAY RECAP **********************************************************************************************************</span><br><span class="line">glusterfs-node-0           : ok=9    changed=8    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">glusterfs-node-1           : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">glusterfs-node-2           : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">localhost                  : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0</span><br></pre></td></tr></table></figure><h3 id="4-2-检测服务状态"><a href="#4-2-检测服务状态" class="headerlink" title="4.2. 检测服务状态"></a>4.2. 检测服务状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh到glusterfs-node-0节点检测服务状态</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">(ansible2.8) [root@zdevops-master dev]<span class="comment"># ssh glusterfs-node-0</span></span></span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 ~]# systemctl status heketi -l</span><br><span class="line">● heketi.service - Heketi Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/heketi.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sun 2022-04-03 10:15:27 CST; 13min ago</span><br><span class="line"> Main PID: 16350 (heketi)</span><br><span class="line">   CGroup: /system.slice/heketi.service</span><br><span class="line">           └─16350 /usr/bin/heketi --config=/etc/heketi/heketi.json</span><br><span class="line"></span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: Main PID: 9748 (glusterd)</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: CGroup: /system.slice/glusterd.service</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: └─9748 /usr/sbin/glusterd -p /var/run/glusterd.pid --log-level INFO</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: Apr 02 14:09:11 localhost.localdomain systemd[1]: Starting GlusterFS, a clustered file-system server...</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: Apr 02 14:09:11 localhost.localdomain systemd[1]: Started GlusterFS, a clustered file-system server.</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: Apr 02 14:20:11 localhost.localdomain systemd[1]: [/usr/lib/systemd/system/glusterd.service:4] Unknown lvalue &#x27;StartLimitBurst&#x27; in section &#x27;Unit&#x27;</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: Apr 02 14:20:11 localhost.localdomain systemd[1]: [/usr/lib/systemd/system/glusterd.service:5] Unknown lvalue &#x27;StartLimitIntervalSec&#x27; in section &#x27;Unit&#x27;</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: ]: Stderr []</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: [heketi] INFO 2022/04/03 10:27:28 Periodic health check status: node da8f9ae974c342b5225265cd414ebe7f up=true</span><br><span class="line">Apr 03 10:27:28 glusterfs-node-0 heketi[16350]: [heketi] INFO 2022/04/03 10:27:28 Cleaned 0 nodes from health cache</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群列表</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli cluster list</span><br><span class="line">Clusters:</span><br><span class="line">Id:deb78837bdb066bd8adf51b59a7e6c7e [file][block]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群详细信息</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli cluster info deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Cluster id: deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Nodes:</span><br><span class="line">98a1975ca166134245e273849f8d345a</span><br><span class="line">c139bd449c952355a85a0e7d50754435</span><br><span class="line">da8f9ae974c342b5225265cd414ebe7f</span><br><span class="line">Volumes:</span><br><span class="line"></span><br><span class="line">Block: true</span><br><span class="line"></span><br><span class="line">File: true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群节点列表</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli node list</span><br><span class="line">Id:98a1975ca166134245e273849f8d345a     Cluster:deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Id:c139bd449c952355a85a0e7d50754435     Cluster:deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Id:da8f9ae974c342b5225265cd414ebe7f     Cluster:deb78837bdb066bd8adf51b59a7e6c7e</span><br></pre></td></tr></table></figure><h3 id="4-3-验证测试"><a href="#4-3-验证测试" class="headerlink" title="4.3. 验证测试"></a>4.3. 验证测试</h3><ul><li><strong>创建卷</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个2G大小3副本的卷</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli volume create --size=2 --replica=3</span><br><span class="line">Name: vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Size: 2</span><br><span class="line">Volume Id: 4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Cluster Id: deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Mount: 192.168.9.95:vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">Block: false</span><br><span class="line">Free Size: 0</span><br><span class="line">Reserved Size: 0</span><br><span class="line">Block Hosting Restriction: (none)</span><br><span class="line">Block Volumes: []</span><br><span class="line">Durability Type: replicate</span><br><span class="line">Distribute Count: 1</span><br><span class="line">Replica Count: 3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看创建的卷</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli volume list</span><br><span class="line">Id:4e6a0c0cdd8a4457cee30a2bb50c8dd5    Cluster:deb78837bdb066bd8adf51b59a7e6c7e    Name:vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看服务器挂载点</span></span><br><span class="line">[root@glusterfs-node-0 ~]# df -h</span><br><span class="line">Filesystem                                                                              Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                                                                                989M     0  989M   0% /dev</span><br><span class="line">tmpfs                                                                                  1000M     0 1000M   0% /dev/shm</span><br><span class="line">tmpfs                                                                                  1000M  8.9M  991M   1% /run</span><br><span class="line">tmpfs                                                                                  1000M     0 1000M   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root                                                                  37G  1.6G   36G   5% /</span><br><span class="line">/dev/sda1                                                                              1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                                                                                   200M     0  200M   0% /run/user/0</span><br><span class="line">/dev/mapper/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4-brick_93655a762cc3c2750aab395d7bb348a9  2.0G   33M  2.0G   2% /var/lib/heketi/mounts/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4/brick_93655a762cc3c2750aab395d7bb348a9</span><br></pre></td></tr></table></figure><ul><li><strong>挂载测试</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看卷的详细信息</span></span><br><span class="line">[root@glusterfs-node-0 ~]# heketi-cli volume info 4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Name: vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Size: 2</span><br><span class="line">Volume Id: 4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Cluster Id: deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Mount: 192.168.9.95:vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">Block: false</span><br><span class="line">Free Size: 0</span><br><span class="line">Reserved Size: 0</span><br><span class="line">Block Hosting Restriction: (none)</span><br><span class="line">Block Volumes: []</span><br><span class="line">Durability Type: replicate</span><br><span class="line">Distribute Count: 1</span><br><span class="line">Replica Count: 3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">挂载卷，mount命令中的192.168.9.95:vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5为上方heketi-cli volum info 卷<span class="built_in">id</span>查看卷详细信息时Mount的返回值</span></span><br><span class="line">[root@glusterfs-node-0 ~]# mount -t glusterfs 192.168.9.95:vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5 /mnt/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看挂载详情</span></span><br><span class="line">[root@glusterfs-node-0 ~]# df -h</span><br><span class="line">Filesystem                                                                              Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                                                                                989M     0  989M   0% /dev</span><br><span class="line">tmpfs                                                                                  1000M     0 1000M   0% /dev/shm</span><br><span class="line">tmpfs                                                                                  1000M  8.9M  991M   1% /run</span><br><span class="line">tmpfs                                                                                  1000M     0 1000M   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root                                                                  37G  1.6G   36G   5% /</span><br><span class="line">/dev/sda1                                                                              1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                                                                                   200M     0  200M   0% /run/user/0</span><br><span class="line">/dev/mapper/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4-brick_93655a762cc3c2750aab395d7bb348a9  2.0G   33M  2.0G   2% /var/lib/heketi/mounts/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4/brick_93655a762cc3c2750aab395d7bb348a9</span><br><span class="line">192.168.9.95:vol_4e6a0c0cdd8a4457cee30a2bb50c8dd5                                       2.0G   54M  2.0G   3% /mnt</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入文件测试</span></span><br><span class="line">[root@glusterfs-node-0 ~]# echo &quot;`date` test write&quot; &gt;&gt; /mnt/test.txt</span><br><span class="line">[root@glusterfs-node-0 ~]# cat /mnt/test.txt </span><br><span class="line">Sun Apr  3 10:53:17 CST 2022 test write</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">卸载卷</span></span><br><span class="line">[root@glusterfs-node-0 ~]# umount /mnt/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看卷卸载后服务器挂载情况</span></span><br><span class="line">[root@glusterfs-node-0 ~]# df -h</span><br><span class="line">Filesystem                                                                              Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                                                                                989M     0  989M   0% /dev</span><br><span class="line">tmpfs                                                                                  1000M     0 1000M   0% /dev/shm</span><br><span class="line">tmpfs                                                                                  1000M  8.9M  991M   1% /run</span><br><span class="line">tmpfs                                                                                  1000M     0 1000M   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root                                                                  37G  1.6G   36G   5% /</span><br><span class="line">/dev/sda1                                                                              1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                                                                                   200M     0  200M   0% /run/user/0</span><br><span class="line">/dev/mapper/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4-brick_93655a762cc3c2750aab395d7bb348a9  2.0G   33M  2.0G   2% /var/lib/heketi/mounts/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4/brick_93655a762cc3c2750aab395d7bb348a9</span><br></pre></td></tr></table></figure><ul><li><strong>底层详细信息查看</strong></li></ul><p><strong>可以看出底层vg和lv的创建详情，了解底层的分配细节</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 节点一 glusterfs-node-0</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的pv</span></span><br><span class="line">[root@glusterfs-node-0 ~]# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdb</span><br><span class="line">  VG Name               vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4</span><br><span class="line">  PV Size               200.00 GiB / not usable 132.00 MiB</span><br><span class="line">  Allocatable           yes </span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51167</span><br><span class="line">  Free PE               50649</span><br><span class="line">  Allocated PE          518</span><br><span class="line">  PV UUID               6Wtn9q-pE1L-qNdS-wT2N-oiNy-6UEL-1pUa9G</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的vg</span></span><br><span class="line">[root@glusterfs-node-0 ~]# vgdisplay </span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4</span><br><span class="line">  System ID             </span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        1</span><br><span class="line">  Metadata Sequence No  6</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                2</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                1</span><br><span class="line">  Act PV                1</span><br><span class="line">  VG Size               199.87 GiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51167</span><br><span class="line">  Alloc PE / Size       518 / 2.02 GiB</span><br><span class="line">  Free  PE / Size       50649 / &lt;197.85 GiB</span><br><span class="line">  VG UUID               JDyEl1-Rv2D-27zU-zDIo-DSD6-wq8z-23ypMI</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的lv</span></span><br><span class="line">[root@glusterfs-node-0 ~]# lvdisplay </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_93655a762cc3c2750aab395d7bb348a9</span><br><span class="line">  VG Name                vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4</span><br><span class="line">  LV UUID                09V7QE-CkNl-3MqO-hj92-ONTc-1OhH-Kp9gQL</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-0, 2022-04-03 10:35:23 +0800</span><br><span class="line">  LV Pool metadata       tp_93655a762cc3c2750aab395d7bb348a9_tmeta</span><br><span class="line">  LV Pool data           tp_93655a762cc3c2750aab395d7bb348a9_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Allocated pool data    0.70%</span><br><span class="line">  Allocated metadata     10.32%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:4</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4/brick_93655a762cc3c2750aab395d7bb348a9</span><br><span class="line">  LV Name                brick_93655a762cc3c2750aab395d7bb348a9</span><br><span class="line">  VG Name                vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4</span><br><span class="line">  LV UUID                8PzqIP-QeW7-LHQn-JEnf-v26v-sX02-yVtY80</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-0, 2022-04-03 10:35:24 +0800</span><br><span class="line">  LV Pool name           tp_93655a762cc3c2750aab395d7bb348a9</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Mapped size            0.70%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:6</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 节点二 glusterfs-node-1</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的pv</span></span><br><span class="line">[root@glusterfs-node-1 ~]# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdb</span><br><span class="line">  VG Name               vg_dd8b89e3ac92e364871ad1a288e089be</span><br><span class="line">  PV Size               200.00 GiB / not usable 132.00 MiB</span><br><span class="line">  Allocatable           yes </span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51167</span><br><span class="line">  Free PE               50649</span><br><span class="line">  Allocated PE          518</span><br><span class="line">  PV UUID               Xp02Bf-f3yP-ckuX-lwI3-hrYm-eDU8-4Ecn20</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的vg</span></span><br><span class="line">[root@glusterfs-node-1 ~]# vgdisplay </span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               vg_dd8b89e3ac92e364871ad1a288e089be</span><br><span class="line">  System ID             </span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        1</span><br><span class="line">  Metadata Sequence No  6</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                2</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                1</span><br><span class="line">  Act PV                1</span><br><span class="line">  VG Size               199.87 GiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51167</span><br><span class="line">  Alloc PE / Size       518 / 2.02 GiB</span><br><span class="line">  Free  PE / Size       50649 / &lt;197.85 GiB</span><br><span class="line">  VG UUID               kKhfyk-is0P-RiAk-N1Vo-C3Dl-7VcE-1sUhCo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的lv</span></span><br><span class="line">[root@glusterfs-node-1 ~]# lvdisplay </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_14db6032ee2ed1e69f394af585d59480</span><br><span class="line">  VG Name                vg_dd8b89e3ac92e364871ad1a288e089be</span><br><span class="line">  LV UUID                DvKgju-KVA9-L4mI-VhSj-Dyx1-bnBW-OHUSYH</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-1, 2022-04-03 10:35:23 +0800</span><br><span class="line">  LV Pool metadata       tp_14db6032ee2ed1e69f394af585d59480_tmeta</span><br><span class="line">  LV Pool data           tp_14db6032ee2ed1e69f394af585d59480_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Allocated pool data    0.70%</span><br><span class="line">  Allocated metadata     10.32%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:4</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_dd8b89e3ac92e364871ad1a288e089be/brick_b2c873001bcc768acecd63e970683e47</span><br><span class="line">  LV Name                brick_b2c873001bcc768acecd63e970683e47</span><br><span class="line">  VG Name                vg_dd8b89e3ac92e364871ad1a288e089be</span><br><span class="line">  LV UUID                khYq7l-NETa-FR0r-6lXc-I9BH-Yrxe-WjKdvS</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-1, 2022-04-03 10:35:23 +0800</span><br><span class="line">  LV Pool name           tp_14db6032ee2ed1e69f394af585d59480</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Mapped size            0.70%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:6</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 节点二 glusterfs-node-2</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的pv</span></span><br><span class="line">[root@glusterfs-node-2 ~]# pvdisplay</span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sdb</span><br><span class="line">  VG Name               vg_7fbd09414aeebd8c7a2415172089ee6d</span><br><span class="line">  PV Size               200.00 GiB / not usable 132.00 MiB</span><br><span class="line">  Allocatable           yes </span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51167</span><br><span class="line">  Free PE               50649</span><br><span class="line">  Allocated PE          518</span><br><span class="line">  PV UUID               IrBlOc-zygh-aDec-qbuh-ESpp-FtYK-99jhIG</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的vg</span></span><br><span class="line">[root@glusterfs-node-2 ~]# vgdisplay   </span><br><span class="line">  --- Volume group ---</span><br><span class="line">  VG Name               vg_7fbd09414aeebd8c7a2415172089ee6d</span><br><span class="line">  System ID             </span><br><span class="line">  Format                lvm2</span><br><span class="line">  Metadata Areas        1</span><br><span class="line">  Metadata Sequence No  6</span><br><span class="line">  VG Access             read/write</span><br><span class="line">  VG Status             resizable</span><br><span class="line">  MAX LV                0</span><br><span class="line">  Cur LV                2</span><br><span class="line">  Open LV               1</span><br><span class="line">  Max PV                0</span><br><span class="line">  Cur PV                1</span><br><span class="line">  Act PV                1</span><br><span class="line">  VG Size               199.87 GiB</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              51167</span><br><span class="line">  Alloc PE / Size       518 / 2.02 GiB</span><br><span class="line">  Free  PE / Size       50649 / &lt;197.85 GiB</span><br><span class="line">  VG UUID               FuCeOh-IqNy-dkbf-sito-UADP-24TV-gPCUTp</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点创建出的lv</span></span><br><span class="line">[root@glusterfs-node-2 ~]# lvdisplay   </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_f8b1b01bcd77125b7d17f2d78b744692</span><br><span class="line">  VG Name                vg_7fbd09414aeebd8c7a2415172089ee6d</span><br><span class="line">  LV UUID                aQjAyh-MHF3-s2Sp-vnZD-1A0f-u3BC-4vv82X</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-2, 2022-04-03 10:35:23 +0800</span><br><span class="line">  LV Pool metadata       tp_f8b1b01bcd77125b7d17f2d78b744692_tmeta</span><br><span class="line">  LV Pool data           tp_f8b1b01bcd77125b7d17f2d78b744692_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Allocated pool data    0.70%</span><br><span class="line">  Allocated metadata     10.32%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:4</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_7fbd09414aeebd8c7a2415172089ee6d/brick_f8b1b01bcd77125b7d17f2d78b744692</span><br><span class="line">  LV Name                brick_f8b1b01bcd77125b7d17f2d78b744692</span><br><span class="line">  VG Name                vg_7fbd09414aeebd8c7a2415172089ee6d</span><br><span class="line">  LV UUID                1FH1wP-Ktt6-JpJK-K3fD-b5uP-Lb5o-fk8odF</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-2, 2022-04-03 10:35:24 +0800</span><br><span class="line">  LV Pool name           tp_f8b1b01bcd77125b7d17f2d78b744692</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                2.00 GiB</span><br><span class="line">  Mapped size            0.70%</span><br><span class="line">  Current LE             512</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:6</span><br></pre></td></tr></table></figure><ul><li><strong>删除测试卷</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli volume delete 4e6a0c0cdd8a4457cee30a2bb50c8dd5</span><br><span class="line">Volume 4e6a0c0cdd8a4457cee30a2bb50c8dd5 deleted</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 ~]# df -h</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 989M     0  989M   0% /dev</span><br><span class="line">tmpfs                   1000M     0 1000M   0% /dev/shm</span><br><span class="line">tmpfs                   1000M  8.8M  991M   1% /run</span><br><span class="line">tmpfs                   1000M     0 1000M   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.6G   36G   5% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                    200M     0  200M   0% /run/user/0</span><br></pre></td></tr></table></figure><hr><h2 id="5-k8s集群对接GlusterFS-原生命令行"><a href="#5-k8s集群对接GlusterFS-原生命令行" class="headerlink" title="5. k8s集群对接GlusterFS-原生命令行"></a>5. k8s集群对接GlusterFS-原生命令行</h2><p><strong>所有操作都在k8s的master节点上执行,操作根目录为&#x2F;root&#x2F;zdevops</strong></p><h3 id="5-1-所有的k8s节点均安装glusterfs客户端"><a href="#5-1-所有的k8s节点均安装glusterfs客户端" class="headerlink" title="5.1. 所有的k8s节点均安装glusterfs客户端"></a>5.1. 所有的k8s节点均安装glusterfs客户端</h3><p><strong>此步骤可以忽略，ansible初始化时已安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 ~]#  yum install glusterfs-fuse -y</span><br></pre></td></tr></table></figure><h3 id="5-2-创建heketi使用的Secret的认证密码"><a href="#5-2-创建heketi使用的Secret的认证密码" class="headerlink" title="5.2. 创建heketi使用的Secret的认证密码"></a>5.2. 创建heketi使用的Secret的认证密码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建glusterfs目录,并切换到该目录</span></span><br><span class="line">[root@ks-k8s-master-0 zdevops]# mkdir /root/zdevops/glusterfs</span><br><span class="line">[root@ks-k8s-master-0 zdevops]# cd /root/zdevops/glusterfs/</span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# pwd</span><br><span class="line">/root/zdevops/glusterfs</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用<span class="built_in">base64</span>将密码转码生成Secret key使用的值,这里的密码为heketi配置文件中创建的用户密码</span></span><br><span class="line">[root@ks-k8s-master-0 zdevops]# echo -n &quot;admin@P@ssW0rd&quot; | base64</span><br><span class="line">YWRtaW5AUEBzc1cwcmQ=</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建secret定义文件</span></span><br><span class="line">[root@ks-k8s-master-0 zdevops]# vi heketi-secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: heketi-secret</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  key: YWRtaW5AUEBzc1cwcmQ=</span><br><span class="line">type: kubernetes.io/glusterfs</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">应用配置并查看</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl apply -f heketi-secret.yaml </span><br><span class="line">secret/heketi-secret created</span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl get secrets heketi-secret -n kube-system </span><br><span class="line">NAME            TYPE                      DATA   AGE</span><br><span class="line">heketi-secret   kubernetes.io/glusterfs   1      16s</span><br></pre></td></tr></table></figure><h3 id="5-3-创建StorageClass"><a href="#5-3-创建StorageClass" class="headerlink" title="5.3. 创建StorageClass"></a>5.3. 创建StorageClass</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建StorageClass定义文件</span></span><br><span class="line">[root@ks-k8s-master-0 zdevops]# vi heketi-storageclass.yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: glusterfs</span><br><span class="line">  namespace: kube-system</span><br><span class="line">parameters:</span><br><span class="line">  resturl: &quot;http://192.168.9.95:48080&quot;</span><br><span class="line">  clusterid: &quot;deb78837bdb066bd8adf51b59a7e6c7e&quot;</span><br><span class="line">  restauthenabled: &quot;true&quot; </span><br><span class="line">  restuser: &quot;admin&quot;</span><br><span class="line">  secretName: &quot;heketi-secret&quot;</span><br><span class="line">  secretNamespace: &quot;kube-system&quot;</span><br><span class="line">  volumetype: &quot;replicate:3&quot; </span><br><span class="line">provisioner: kubernetes.io/glusterfs</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">应用配置</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl apply -f heketi-storageclass.yaml </span><br><span class="line">storageclass.storage.k8s.io/glusterfs created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl get sc</span><br><span class="line">NAME              PROVISIONER               RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">glusterfs         kubernetes.io/glusterfs   Delete          Immediate              false                  12s</span><br><span class="line">local (default)   openebs.io/local          Delete          WaitForFirstConsumer   false                  142m</span><br></pre></td></tr></table></figure><ul><li><strong>parameters.resturl:</strong> heketi服务的地址</li><li><strong>parameters.clusterid:</strong> 在heketi节点使用heketi-cli cluster list命令返回的集群id</li><li><strong>parameters.restuser:</strong>  heketi.json配置文件中创建的用户名，默认admin</li><li><strong>parameters.secretName:</strong> k8s中Secret资源定义中的metadata.name</li><li><strong>parameters.secretNamespace:</strong> k8s中Secret资源定义中的metadata.namespace</li><li><strong>parameters.volumetype:</strong> 创建的卷类型和副本数，这里是3副本复制卷</li></ul><h3 id="5-4-创建pvc测试"><a href="#5-4-创建pvc测试" class="headerlink" title="5.4. 创建pvc测试"></a>5.4. 创建pvc测试</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建pvc定义文件</span></span><br><span class="line">[root@k8s-master-1 ~]# vi heketi-pvc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: heketi-pvc</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/glusterfs</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: &quot;glusterfs&quot;</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">应用配置</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl apply -f heketi-pvc.yaml </span><br><span class="line">persistentvolumeclaim/heketi-pvc created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl get pvc </span><br><span class="line">NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">heketi-pvc   Bound    pvc-019107e4-8cb1-44a7-940e-2ab2aecb1eac   1Gi        RWO            glusterfs      10s</span><br></pre></td></tr></table></figure><p><strong>注意创建的pvc的状态，如果是Pending，说明连接存储有问题</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl get pvc</span><br><span class="line">NAME         STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">heketi-pvc   Pending                                      glusterfs      6m38s</span><br></pre></td></tr></table></figure><h3 id="5-5-创建测试Pod挂载pvc"><a href="#5-5-创建测试Pod挂载pvc" class="headerlink" title="5.5. 创建测试Pod挂载pvc"></a>5.5. 创建测试Pod挂载pvc</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建pod定义文件</span></span><br><span class="line">[root@k8s-master-1 ~]# vi heketi-pod.yaml</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: heketi-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: heketi-container</span><br><span class="line">    image: busybox</span><br><span class="line">    command:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;3600&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: heketi-volume</span><br><span class="line">      mountPath: &quot;/pv-data&quot;</span><br><span class="line">      readOnly: false</span><br><span class="line">  volumes:</span><br><span class="line">  - name: heketi-volume</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: heketi-pvc</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">应用</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl apply -f heketi-pod.yaml </span><br><span class="line">pod/heketi-pod created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看pod状态，Running表示创建成功</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl get pods -o wide</span><br><span class="line">NAME         READY   STATUS    RESTARTS   AGE   IP             NODE              NOMINATED NODE   READINESS GATES</span><br><span class="line">heketi-pod   1/1     Running   0          22s   10.233.87.15   ks-k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看pod中磁盘挂载情况</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl exec heketi-pod -- df -h</span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">overlay                 199.9G      1.9G    198.0G   1% /</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /dev</span><br><span class="line">tmpfs                    15.7G         0     15.7G   0% /sys/fs/cgroup</span><br><span class="line">192.168.9.97:vol_53ca44e0e2f84f723d7c814812648d5e</span><br><span class="line">                       1014.0M     42.8M    971.2M   4% /pv-data</span><br><span class="line">/dev/mapper/centos-root</span><br><span class="line">                         37.0G      2.6G     34.4G   7% /dev/termination-log</span><br><span class="line">/dev/sdb1               199.9G      1.9G    198.0G   1% /etc/resolv.conf</span><br><span class="line">/dev/sdb1               199.9G      1.9G    198.0G   1% /etc/hostname</span><br><span class="line">/dev/mapper/centos-root</span><br><span class="line">                         37.0G      2.6G     34.4G   7% /etc/hosts</span><br><span class="line">shm                      64.0M         0     64.0M   0% /dev/shm</span><br><span class="line">tmpfs                    15.7G     12.0K     15.7G   0% /var/run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                    15.7G         0     15.7G   0% /proc/acpi</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/kcore</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/keys</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/timer_list</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/timer_stats</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/sched_debug</span><br><span class="line">tmpfs                    15.7G         0     15.7G   0% /proc/scsi</span><br><span class="line">tmpfs                    15.7G         0     15.7G   0% /sys/firmware </span><br></pre></td></tr></table></figure><h3 id="5-6-登录存储服务器查看底层变化"><a href="#5-6-登录存储服务器查看底层变化" class="headerlink" title="5.6. 登录存储服务器查看底层变化"></a>5.6. 登录存储服务器查看底层变化</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看卷的信息</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli volume list</span><br><span class="line">Id:53ca44e0e2f84f723d7c814812648d5e    Cluster:deb78837bdb066bd8adf51b59a7e6c7e    Name:vol_53ca44e0e2f84f723d7c814812648d5e</span><br><span class="line"></span><br><span class="line">[root@glusterfs-node-0 heketi]# heketi-cli volume info 53ca44e0e2f84f723d7c814812648d5e</span><br><span class="line">Name: vol_53ca44e0e2f84f723d7c814812648d5e</span><br><span class="line">Size: 1</span><br><span class="line">Volume Id: 53ca44e0e2f84f723d7c814812648d5e</span><br><span class="line">Cluster Id: deb78837bdb066bd8adf51b59a7e6c7e</span><br><span class="line">Mount: 192.168.9.95:vol_53ca44e0e2f84f723d7c814812648d5e</span><br><span class="line">Mount Options: backup-volfile-servers=192.168.9.97,192.168.9.96</span><br><span class="line">Block: false</span><br><span class="line">Free Size: 0</span><br><span class="line">Reserved Size: 0</span><br><span class="line">Block Hosting Restriction: (none)</span><br><span class="line">Block Volumes: []</span><br><span class="line">Durability Type: replicate</span><br><span class="line">Distribute Count: 1</span><br><span class="line">Replica Count: 3</span><br><span class="line">Snapshot Factor: 1.00</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看lvdisplay</span></span><br><span class="line">[root@glusterfs-node-0 heketi]# lvdisplay </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Name                tp_7c2c26b78219f2fecaf97c728d25bd10</span><br><span class="line">  VG Name                vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4</span><br><span class="line">  LV UUID                vHkLw6-mtUl-IbgH-CRXp-WTh4-cG1A-1RbqQa</span><br><span class="line">  LV Write Access        read/write (activated read only)</span><br><span class="line">  LV Creation host, time glusterfs-node-0, 2022-04-03 15:59:55 +0800</span><br><span class="line">  LV Pool metadata       tp_7c2c26b78219f2fecaf97c728d25bd10_tmeta</span><br><span class="line">  LV Pool data           tp_7c2c26b78219f2fecaf97c728d25bd10_tdata</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 2</span></span><br><span class="line">  LV Size                1.00 GiB</span><br><span class="line">  Allocated pool data    1.39%</span><br><span class="line">  Allocated metadata     10.45%</span><br><span class="line">  Current LE             256</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:4</span><br><span class="line"></span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4/brick_f16c9f2207b3cd3db901f4a801823079</span><br><span class="line">  LV Name                brick_f16c9f2207b3cd3db901f4a801823079</span><br><span class="line">  VG Name                vg_f07e0b11c6c8e4da5bbb24b0b11d7fd4</span><br><span class="line">  LV UUID                0Qurda-DDdZ-3SCo-7EKz-xSHc-mhgN-DDJyVr</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time glusterfs-node-0, 2022-04-03 15:59:56 +0800</span><br><span class="line">  LV Pool name           tp_7c2c26b78219f2fecaf97c728d25bd10</span><br><span class="line">  LV Status              available</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">open                 1</span></span><br><span class="line">  LV Size                1.00 GiB</span><br><span class="line">  Mapped size            1.39%</span><br><span class="line">  Current LE             256</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:6</span><br></pre></td></tr></table></figure><h3 id="5-7-清理测试资源"><a href="#5-7-清理测试资源" class="headerlink" title="5.7. 清理测试资源"></a>5.7. 清理测试资源</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清理测试的pod、pvc</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl delete -f heketi-pod.yaml </span><br><span class="line">pod &quot;heketi-pod&quot; deleted</span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl delete -f heketi-pvc.yaml </span><br><span class="line">persistentvolumeclaim &quot;heketi-pvc&quot; deleted</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意，由于本文还需要演示图形化配置，因此将storageclass、secret也清除了，实际使用时不需要。</span></span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl delete -f heketi-storageclass.yaml </span><br><span class="line">storageclass.storage.k8s.io &quot;glusterfs&quot; deleted</span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl delete -f heketi-secret.yaml </span><br><span class="line">secret &quot;heketi-secret&quot; deleted</span><br></pre></td></tr></table></figure><hr><h2 id="6-k8s集群对接GlusterFS-KubeSphere图形化配置"><a href="#6-k8s集群对接GlusterFS-KubeSphere图形化配置" class="headerlink" title="6. k8s集群对接GlusterFS-KubeSphere图形化配置"></a>6. k8s集群对接GlusterFS-KubeSphere图形化配置</h2><h3 id="6-1-创建密钥"><a href="#6-1-创建密钥" class="headerlink" title="6.1. 创建密钥"></a>6.1. 创建密钥</h3><p>平台管理-&gt;集群管理-&gt;配置-&gt;保密字典。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-plat.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-cluster.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-conf.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-secrets.png"></p><p>点击<strong>创建</strong>，创建保密字典。</p><ul><li><p>名称：heketi-secret</p></li><li><p>项目：kube-system</p></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-secrets-0.png"></p><ul><li><p>数据设置，类型选择Opaque-&gt; 添加数据-&gt;创建</p><ul><li>键：key</li><li>值：YWRtaW5AUEBzc1cwcmQ&#x3D;</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-secrets-1.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-secrets-2.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-secrets-3.png"></p></li></ul><h3 id="6-2-创建存储类型"><a href="#6-2-创建存储类型" class="headerlink" title="6.2. 创建存储类型"></a>6.2. 创建存储类型</h3><p>平台管理-&gt; 存储-&gt;存储类型-&gt;创建。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-0.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-1.png"></p><p>点击<strong>创建</strong>，创建存储类型。</p><ul><li>存储名称：glusterfs</li><li>存储类型：glusterfs</li><li>创建存储类型的详细信息<ul><li>存储卷扩容：是</li><li>回收机制：Delete</li><li>访问模式：ReadWriteOnce、ReadOnlyMany、ReadWriteMany</li><li>存储系统：kubernetes.io&#x2F;glusterfs</li><li>存储卷绑定模式：立即绑定</li><li>REST URL：192.168.9.95:48080</li><li>集群ID：deb78837bdb066bd8adf51b59a7e6c7e（heketi-cli cluster list命令返回的集群id ）</li><li>开启REST认证：是</li><li>REST用户：admin (heketi服务的admin用户)</li><li>密钥所属项目：kube-system</li><li>密钥名称：heketi-secret （上面创建的secert名称）</li><li>GID最小值：留空使用默认值</li><li>GID最大值：留空使用默认值</li><li>存储卷类型：replicate:3</li></ul></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-2.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-3.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-4.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-5.png"></p><p>查看存储类型是否创建成功。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-storageclasses-6.png"></p><h3 id="6-3-创建存储卷进行测试"><a href="#6-3-创建存储卷进行测试" class="headerlink" title="6.3. 创建存储卷进行测试"></a>6.3. 创建存储卷进行测试</h3><p>平台管理-&gt;存储-&gt;存储卷。</p><ul><li>名称：glusterfs-test （可自定义）</li><li>项目：default （可自定义）</li><li>存储类型：glusterfs</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-0.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-1.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-2.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-3.png"></p><h3 id="6-4-验证测试卷是否创建成功"><a href="#6-4-验证测试卷是否创建成功" class="headerlink" title="6.4. 验证测试卷是否创建成功"></a>6.4. 验证测试卷是否创建成功</h3><p><strong>正常情况下，准备就绪</strong>即为成功。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-glusterfs-9.jpg"></p><p><strong>但是写文档的时候创建失败了。</strong></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-4.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-5.png"></p><blockquote><p><strong>尝试解决</strong></p></blockquote><p>查看存储卷配置，发现都是大写，怀疑是否是参数名称的问题，尝试按手工配置的参数修改，结果修改报错。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-6.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-7.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-8.png"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kube-glusterfs-pvc-9.png"></p><h2 id="6-遗留问题"><a href="#6-遗留问题" class="headerlink" title="6. 遗留问题"></a>6. 遗留问题</h2><p>图形化对接GlusterFS失败，问题有待解决，不确定是否为BUG。</p><p>KubeSphere3.2.1版本，暂时请使用命令行的方式对接GlusterFS。</p><h2 id="7-常见问题"><a href="#7-常见问题" class="headerlink" title="7. 常见问题"></a>7. 常见问题</h2><h3 id="7-1-创建集群时报错解决办法"><a href="#7-1-创建集群时报错解决办法" class="headerlink" title="7.1. 创建集群时报错解决办法"></a>7.1. 创建集群时报错解决办法</h3><p><strong>如果数据盘不是新盘曾经被使用过，创建集群时会报错，可按下面的方法处理。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-node-0 ~]# heketi-cli topology load --json=/etc/heketi/topology.json</span><br><span class="line">Creating cluster ... ID: b89a07c2c6e8c533322591bf2a4aa613</span><br><span class="line">        Allowing file volumes on cluster.</span><br><span class="line">        Allowing block volumes on cluster.</span><br><span class="line">        Creating node 10.4.11.38 ... ID: 8bffed2d55f652a412c098ee31246559</span><br><span class="line">                Adding device /dev/sdb ... Unable to add device: Setup of device /dev/sdb failed (already initialized or contains data?):   Can&#x27;t initialize physical volume &quot;/dev/sdb&quot; of volume group &quot;vg_423c25b95cf33cb94fa192aedd325b26&quot; without -ff</span><br><span class="line">  /dev/sdb: physical volume not initialized.</span><br><span class="line">        Creating node 10.4.11.39 ... ID: 1218c773299856ebaef6f2461051640c</span><br><span class="line">                Adding device /dev/sdb ... Unable to add device: Setup of device /dev/sdb failed (already initialized or contains data?):   Can&#x27;t initialize physical volume &quot;/dev/sdb&quot; of volume group &quot;vg_564e3fb62e748f1451f387deb469541e&quot; without -ff</span><br><span class="line">  /dev/sdb: physical volume not initialized.</span><br><span class="line">        Creating node 10.4.11.40 ... ID: cf3ad692cc008e697eb68f2863843391</span><br><span class="line">                Adding device /dev/sdb ... Unable to add device: Setup of device /dev/sdb failed (already initialized or contains data?):   Can&#x27;t initialize physical volume &quot;/dev/sdb&quot; of volume group &quot;vg_5bc298db6e8cc335d545c96eed7150f0&quot; without -ff</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">所有glusterfs节点执行</span></span><br><span class="line">[root@glusterfs-node-0 ~]# mkfs.xfs -f /dev/sdb</span><br><span class="line">meta-data=/dev/sdb               isize=512    agcount=4, agsize=183105408 blks</span><br><span class="line">         =                       sectsz=4096  attr=2, projid32bit=1</span><br><span class="line">         =                       crc=1        finobt=0, sparse=0</span><br><span class="line">data     =                       bsize=4096   blocks=732421632, imaxpct=5</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br><span class="line">log      =internal log           bsize=4096   blocks=357627, version=2</span><br><span class="line">         =                       sectsz=4096  sunit=1 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br><span class="line">[root@glusterfs-node-0 ~]# pvcreate -ff --metadatasize=128M --dataalignment=256K /dev/sdb</span><br><span class="line">  Wiping xfs signature on /dev/sdb.</span><br><span class="line">  Physical volume &quot;/dev/sdb&quot; successfully created.</span><br></pre></td></tr></table></figure><h3 id="7-2-创建pvc时，状态为pending"><a href="#7-2-创建pvc时，状态为pending" class="headerlink" title="7.2. 创建pvc时，状态为pending"></a>7.2. 创建pvc时，状态为pending</h3><ul><li>问题现象</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl get pvc -o wide</span><br><span class="line">NAME         STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE     VOLUMEMODE</span><br><span class="line">heketi-pvc   Pending                                      glusterfs      6m10s   Filesystem</span><br><span class="line">[root@ks-k8s-master-0 glusterfs]# kubectl describe pvc heketi-pvc </span><br><span class="line">Name:          heketi-pvc</span><br><span class="line">Namespace:     default</span><br><span class="line">StorageClass:  glusterfs</span><br><span class="line">Status:        Pending</span><br><span class="line">Volume:        </span><br><span class="line">Labels:        &lt;none&gt;</span><br><span class="line">Annotations:   volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/glusterfs</span><br><span class="line">Finalizers:    [kubernetes.io/pvc-protection]</span><br><span class="line">Capacity:      </span><br><span class="line">Access Modes:  </span><br><span class="line">VolumeMode:    Filesystem</span><br><span class="line">Used By:       heketi-pod</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason              Age                   From                         Message</span><br><span class="line">  ----     ------              ----                  ----                         -------</span><br><span class="line">  Warning  ProvisioningFailed  22s (x10 over 6m18s)  persistentvolume-controller  Failed to provision volume with StorageClass &quot;glusterfs&quot;: failed to create volume: failed to create volume: see kube-controller-manager.log for details</span><br></pre></td></tr></table></figure><ul><li>解决方案</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1.heketi服务器地址错误，可以使用curl http://192.168.9.95:48080/hello测试,如果不同检查配置文件heketi-storageclass.yaml，检查网络</span></span><br><span class="line"></span><br><span class="line">[root@ks-k8s-master-0 ~]# curl http://192.168.9.95:48080/hello</span><br><span class="line">Hello from Heketi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2.时间不同步,会有如下<span class="built_in">log</span>，同步k8s和GlusterFS服务器的时间</span></span><br><span class="line">Apr  3 15:18:21 glusterfs-node-0 heketi: [jwt] ERROR 2022/04/03 15:18:21 heketi/middleware/jwt.go:73:middleware.(*HeketiJwtClaims).Valid: iat validation failed: Token used before issued, time now: 2022-04-03 15:18:21 +0800 CST, time issued: 2022-04-03 15:35:02 +0800 CST</span><br></pre></td></tr></table></figure><hr><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>以上内容详细记录了GlusterFS安装部署过程以及KubeSphere对接GlusterFS的全过程，部署过程中k8s命令行对接GlusterFS成功，但是在KubeSphere图形化对接的过程中出现异常，后续解决后，我再更新文档。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><p><a href="https://docs.gluster.org/en/latest/Quick-Start-Guide/Quickstart/">GlusterFS</a></p></li><li><p><a href="https://github.com/heketi/heketi">https://github.com/heketi/heketi</a></p></li></ul><blockquote><p><strong>Get文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p>About Me</p></blockquote><ul><li>昵称：老Z</li><li>坐标：山东济南</li><li>职业：运维架构师&#x2F;高级运维工程师&#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算&#x2F;云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于KubeSphere玩转k8s-GlusterFS安装手记&quot;&gt;&lt;a href=&quot;#基于KubeSphere玩转k8s-GlusterFS安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于KubeSphere玩转k8s-GlusterFS安装手</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-KubeSphere 初始化手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-KubeSphere%E5%88%9D%E5%A7%8B%E5%8C%96%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-KubeSphere%E5%88%9D%E5%A7%8B%E5%8C%96%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.114Z</published>
    <updated>2023-09-22T01:41:51.977Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-KubeSphere-初始化手记"><a href="#基于-KubeSphere-玩转-k8s-KubeSphere-初始化手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-KubeSphere 初始化手记"></a>基于 KubeSphere 玩转 k8s-KubeSphere 初始化手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>本文接着上篇 <strong>&lt;&lt; 基于 KubeSphere 玩转 k8s-KubeSphere 安装手记 &gt;&gt;</strong> ，继续玩转 KubeSphere、k8s，本期会讲解 KubeSphere 默认安装完成后的一些必要配置。同时，会初步探究一下执行这些必要配置后 k8s 底层发生了哪些变化。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：23 分</li><li>行：1513</li><li>单词：8626</li><li>字符：67982</li><li>图片：40 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>KubeSphere 更改默认管理用户的密码</li><li>KubeSphere 可插拔组件的启用和配置</li><li>KubeSphere 用户管理</li><li>KubeSphere 企业空间管理</li><li>KubeSphere 项目管理</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr></tbody></table><hr><h2 id="2-首次登陆配置"><a href="#2-首次登陆配置" class="headerlink" title="2. 首次登陆配置"></a>2. 首次登陆配置</h2><h3 id="2-1-更改默认用户密码"><a href="#2-1-更改默认用户密码" class="headerlink" title="2.1. 更改默认用户密码"></a>2.1. 更改默认用户密码</h3><p>浏览器打开 KubeSphere 管理界面。</p><p>弹出登陆页面，使用默认用户 <strong>admin</strong>，密码 <strong>P@88w0rd</strong>，登录。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-login-default.png" alt="kubesphere-login-default"></p><p>系统会提示你重置密码，按要求重置提交即可，当然你也可以选择<strong>稍后修改</strong>，登录以后再修改，但是<strong>工作环境</strong>强烈建议立即修改。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-login-reset.png" alt="kubesphere-login-reset"></p><p>登录后显示默认的登录页面，即<strong>工作台</strong>，该页面可以看到以下信息。</p><ul><li><p>平台信息：平台版本和集群数量</p></li><li><p>平台资源：最后更新时间、企业空间数量、用户数量</p></li><li><p>最近访问记录</p></li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-dashboard.png" alt="kubesphere-dashboard"></p><p>点击左上角的<strong>平台管理</strong>，选择<strong>集群管理</strong>，进入集群管理界面，进行我们接下来的配置。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-manage.png" alt="kubesphere-clusters-manage"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-overview.png" alt="kubesphere-clusters-overview"></p><hr><h2 id="3-启用可插拔组件"><a href="#3-启用可插拔组件" class="headerlink" title="3. 启用可插拔组件"></a>3. 启用可插拔组件</h2><h3 id="3-1-可插拔组件概述"><a href="#3-1-可插拔组件概述" class="headerlink" title="3.1. 可插拔组件概述"></a>3.1. 可插拔组件概述</h3><p>从 2.1.0 版本开始，KubeSphere 解耦了一些核心功能组件。这些组件设计成了可插拔式，您可以在安装之前或之后启用它们。如果您不启用它们，KubeSphere 会默认以最小化进行安装部署。</p><p>不同的可插拔组件部署在不同的命名空间中。您可以根据需求启用任意组件。强烈建议您安装这些可插拔组件来深度体验 KubeSphere 提供的全栈特性和功能。</p><p>有关如何启用每个组件的更多信息，请参见<a href="https://kubesphere.com.cn/docs/pluggable-components/overview/">官方文档</a>的各个教程。</p><h3 id="3-2-可插拔组件资源要求"><a href="#3-2-可插拔组件资源要求" class="headerlink" title="3.2. 可插拔组件资源要求"></a>3.2. 可插拔组件资源要求</h3><p>在您启用可插拔组件之前，请确保您的环境中有足够的资源 . 否则，可能会因为缺乏资源导致组件崩溃。具体参见下表：</p><ul><li><p><strong>CPU 和内存的资源请求和限制均指单个副本的要求。</strong></p></li><li><p><strong>官方列出的可插拔组件的资源需求，并不完整，没有涵盖所有组件，因此建议把服务器资源配置的尽可能大一些。</strong></p></li></ul><blockquote><p><strong>官方资源要求</strong></p></blockquote><ul><li><strong>KubeSphere 应用商店</strong></li></ul><table><thead><tr><th align="left">命名空间</th><th align="left">openpitrix-system</th></tr></thead><tbody><tr><td align="left">CPU 请求</td><td align="left">0.3 核</td></tr><tr><td align="left">CPU 限制</td><td align="left">无</td></tr><tr><td align="left">内存请求</td><td align="left">300 MiB</td></tr><tr><td align="left">内存限制</td><td align="left">无</td></tr><tr><td align="left">安装</td><td align="left">可选</td></tr><tr><td align="left">备注</td><td align="left">该组件可用于管理应用生命周期。建议安装。</td></tr></tbody></table><ul><li><strong>KubeSphere DevOps 系统</strong></li></ul><table><thead><tr><th align="left">命名空间</th><th align="left">kubesphere-devops-system</th><th align="left">kubesphere-devops-system</th></tr></thead><tbody><tr><td align="left">安装模式</td><td align="left">All-in-One 安装</td><td align="left">多节点安装</td></tr><tr><td align="left">CPU 请求</td><td align="left">34 m</td><td align="left">0.47 核</td></tr><tr><td align="left">CPU 限制</td><td align="left">无</td><td align="left">无</td></tr><tr><td align="left">内存请求</td><td align="left">2.69 G</td><td align="left">8.6 G</td></tr><tr><td align="left">内存限制</td><td align="left">无</td><td align="left">无</td></tr><tr><td align="left">安装</td><td align="left">可选</td><td align="left">可选</td></tr><tr><td align="left">备注</td><td align="left">提供一站式 DevOps 解决方案，包括 Jenkins 流水线、B2I 和 S2I。</td><td align="left">其中一个节点的内存必须大于 8 G。</td></tr></tbody></table><ul><li><strong>KubeSphere 监控系统</strong></li></ul><table><thead><tr><th>命名空间</th><th>kubesphere-monitoring-system</th><th>kubesphere-monitoring-system</th><th>kubesphere-monitoring-system</th></tr></thead><tbody><tr><td>子组件</td><td>2 x Prometheus</td><td>3 x Alertmanager</td><td>Notification Manager</td></tr><tr><td>CPU 请求</td><td>100 m</td><td>10 m</td><td>100 m</td></tr><tr><td>CPU 限制</td><td>4 core</td><td>无</td><td>500 m</td></tr><tr><td>内存请求</td><td>400 MiB</td><td>30 MiB</td><td>20 MiB</td></tr><tr><td>内存限制</td><td>8 GiB</td><td></td><td>1 GiB</td></tr><tr><td>安装</td><td>必需</td><td>必需</td><td>必需</td></tr><tr><td>备注</td><td>Prometheus 的内存消耗取决于集群大小。8 GiB 可满足 200 个节点 &#x2F;16,000 个容器组的集群规模。</td><td></td><td></td></tr></tbody></table><p><strong>KubeSphere 监控系统不是可插拔组件，会默认安装。</strong> 它与其他组件（例如日志系统）紧密关联，因此将其资源请求和限制也列在本页中，供您参考。</p><ul><li><strong>KubeSphere 日志系统</strong></li></ul><table><thead><tr><th>命名空间</th><th>kubesphere-logging-system</th><th>kubesphere-logging-system</th><th>kubesphere-logging-system</th><th>kubesphere-logging-system</th></tr></thead><tbody><tr><td>子组件</td><td>3 x Elasticsearch</td><td>fluent bit</td><td>kube-events</td><td>kube-auditing</td></tr><tr><td>CPU 请求</td><td>50 m</td><td>20 m</td><td>90 m</td><td>20 m</td></tr><tr><td>CPU 限制</td><td>1 core</td><td>200 m</td><td>900 m</td><td>200 m</td></tr><tr><td>内存请求</td><td>2 G</td><td>50 MiB</td><td>120 MiB</td><td>50 MiB</td></tr><tr><td>内存限制</td><td>无</td><td>100 MiB</td><td>1200 MiB</td><td>100 MiB</td></tr><tr><td>安装</td><td>可选</td><td>必需</td><td>可选</td><td>可选</td></tr><tr><td>备注</td><td>可选组件，用于存储日志数据。不建议在生产环境中使用内置 Elasticsearch。</td><td>日志收集代理。启用日志系统后，它是必需组件。</td><td>Kubernetes 事件收集、过滤、导出和告警。</td><td>Kubernetes 和 KubeSphere 审计日志收集、过滤和告警。</td></tr></tbody></table><ul><li><strong>KubeSphere 告警和通知</strong></li></ul><table><thead><tr><th>命名空间</th><th>kubesphere-alerting-system</th></tr></thead><tbody><tr><td>CPU 请求</td><td>0.08 core</td></tr><tr><td>CPU 限制</td><td>无</td></tr><tr><td>内存请求</td><td>80 M</td></tr><tr><td>内存限制</td><td>无</td></tr><tr><td>安装</td><td>可选</td></tr><tr><td>备注</td><td>告警和通知需要同时启用。</td></tr></tbody></table><ul><li><strong>KubeSphere 服务网格</strong></li></ul><table><thead><tr><th>命名空间</th><th>istio-system</th></tr></thead><tbody><tr><td>CPU 请求</td><td>1 core</td></tr><tr><td>CPU 限制</td><td>无</td></tr><tr><td>内存请求</td><td>3.5 G</td></tr><tr><td>内存限制</td><td>无</td></tr><tr><td>安装</td><td>可选</td></tr><tr><td>备注</td><td>支持灰度发布策略、流量拓扑、流量管理和分布式链路追踪。</td></tr></tbody></table><blockquote><p><strong>官方可插拔组件汇总</strong></p></blockquote><table><thead><tr><th>组件名称</th><th align="center">官方是否提供资源要求建议</th><th align="center">备注</th></tr></thead><tbody><tr><td>KubeSphere 应用商店</td><td align="center">是</td><td align="center">KubeSphere 在 <a href="https://github.com/openpitrix/openpitrix">OpenPitrix</a> 的基础上，为用户提供了一个基于 Helm 的应用商店，用于应用生命周期管理。</td></tr><tr><td>KubeSphere DevOps</td><td align="center">是</td><td align="center">基于 <a href="https://jenkins.io/">Jenkins</a> 的 KubeSphere DevOps 系统是专为 Kubernetes 中的 CI&#x2F;CD 工作流设计的，它还具有插件管理、<a href="https://kubesphere.com.cn/docs/project-user-guide/image-builder/binary-to-image/">Binary-to-Image (B2I)</a>、<a href="https://kubesphere.com.cn/docs/project-user-guide/image-builder/source-to-image/">Source-to-Image (S2I)</a>、代码依赖缓存、代码质量分析、流水线日志等功能。</td></tr><tr><td>KubeSphere 监控系统</td><td align="center">是</td><td align="center">KubeSphere 在 Prometheus 和 Alertmanager 的基础上构建了监控系统，不是可插拔组件，会默认安装。</td></tr><tr><td>KubeSphere 日志系统</td><td align="center">是</td><td align="center">KubeSphere 为日志收集、查询和管理提供了一个强大的、全面的、易于使用的日志系统。它涵盖了不同层级的日志，包括租户、基础设施资源和应用。</td></tr><tr><td>KubeSphere 告警系统</td><td align="center">是</td><td align="center">KubeSphere 中的告警系统与其主动式故障通知 (Proactive Failure Notification)  系统相结合，使用户可以基于告警策略了解感兴趣的活动。当达到某个指标的预定义阈值时，会向预先配置的收件人发出告警。因此，您需要预先配置通知方式，包括邮件、Slack、钉钉、企业微信和 Webhook。</td></tr><tr><td>KubeSphere 服务网格</td><td align="center">是</td><td align="center">KubeSphere 服务网格基于 <a href="https://istio.io/">Istio</a>，将微服务治理和流量管理可视化。</td></tr><tr><td><a href="https://kubesphere.com.cn/docs/pluggable-components/network-policy/">网络策略</a></td><td align="center">否</td><td align="center">网络策略是一种以应用为中心的结构，使您能够指定如何允许容器组通过网络与各种网络实体进行通信。</td></tr><tr><td><a href="https://kubesphere.com.cn/docs/pluggable-components/metrics-server/">Metrics Server</a></td><td align="center">否</td><td align="center">KubeSphere 支持用于<a href="https://kubesphere.com.cn/docs/project-user-guide/application-workloads/deployments/">部署</a>的容器组（Pod）弹性伸缩程序 (HPA)。在 KubeSphere 中，Metrics Server 控制着 HPA 是否启用。</td></tr><tr><td><a href="https://kubesphere.com.cn/docs/pluggable-components/service-topology/">服务拓扑图</a></td><td align="center">否</td><td align="center">您可以启用服务拓扑图以集成 <a href="https://www.weave.works/oss/scope/">Weave Scope</a>（Docker 和 Kubernetes 的可视化和监控工具）。</td></tr><tr><td><a href="https://kubesphere.com.cn/docs/pluggable-components/pod-ip-pools/">容器组 IP 池</a></td><td align="center">否</td><td align="center">容器组 IP 池用于规划容器组网络地址空间，每个容器组 IP 池之间的地址空间不能重叠。创建工作负载时，可选择特定的容器组 IP 池，这样创建出的容器组将从该容器组 IP 池中分配 IP 地址。</td></tr><tr><td><a href="https://kubesphere.com.cn/docs/pluggable-components/kubeedge/">KubeEdge</a></td><td align="center">否</td><td align="center"><a href="https://kubeedge.io/zh/">KubeEdge</a> 是一个开源系统，用于将容器化应用程序编排功能扩展到边缘的主机。KubeEdge 支持多个边缘协议，旨在对部署于云端和边端的应用程序与资源等进行统一管理。</td></tr></tbody></table><blockquote><p><strong>官方资源要求汇总</strong></p></blockquote><table><thead><tr><th>组件名称</th><th align="center">CPU 请求 (核)</th><th align="center">CPU 限制 (核)</th><th align="center">内存请求 (MiB)</th><th align="center">内存限制 (MiB)</th><th align="center">默认安装</th><th align="center">备注</th></tr></thead><tbody><tr><td>KubeSphere 应用商店</td><td align="center">0.3</td><td align="center">0</td><td align="center">300</td><td align="center">0</td><td align="center">否</td><td align="center">可选，建议安装</td></tr><tr><td>KubeSphere DevOps</td><td align="center">0.47</td><td align="center">0</td><td align="center">8600</td><td align="center">0</td><td align="center">否</td><td align="center">可选，建议安装</td></tr><tr><td>KubeSphere 监控系统-Prometheus</td><td align="center">0.1</td><td align="center">4</td><td align="center">400</td><td align="center">8000</td><td align="center">是</td><td align="center">2 台</td></tr><tr><td>KubeSphere 监控系统-Alertmanager</td><td align="center">0.01</td><td align="center">0</td><td align="center">30</td><td align="center">0</td><td align="center">是</td><td align="center">3 台</td></tr><tr><td>KubeSphere 监控系统-Notification Manager</td><td align="center">0.1</td><td align="center">0.5</td><td align="center">20</td><td align="center">1000</td><td align="center">是</td><td align="center"></td></tr><tr><td>KubeSphere 日志系统-Elasticsearch</td><td align="center">0.05</td><td align="center">1</td><td align="center">2000</td><td align="center">0</td><td align="center">否</td><td align="center">可选，生产不建议开启，建议外置</td></tr><tr><td>KubeSphere 日志系统-fluent bit</td><td align="center">0.02</td><td align="center">0.2</td><td align="center">50</td><td align="center">100</td><td align="center">否</td><td align="center">必须，启用日志系统后</td></tr><tr><td>KubeSphere 日志系统-kube-events</td><td align="center">0.09</td><td align="center">0.9</td><td align="center">120</td><td align="center">1200</td><td align="center">否</td><td align="center">可选</td></tr><tr><td>KubeSphere 日志系统-kube-auditing</td><td align="center">0.02</td><td align="center">0.2</td><td align="center">50</td><td align="center">100</td><td align="center">否</td><td align="center">可选</td></tr><tr><td>KubeSphere 告警系统</td><td align="center">0.08</td><td align="center">0</td><td align="center">80</td><td align="center">0</td><td align="center">否</td><td align="center">可选</td></tr><tr><td>KubeSphere 服务网格</td><td align="center">1</td><td align="center">0</td><td align="center">3500</td><td align="center">0</td><td align="center">否</td><td align="center">可选</td></tr><tr><td>合计</td><td align="center"><strong>2.24</strong></td><td align="center"><strong>8.66</strong></td><td align="center"><strong>15150</strong></td><td align="center"><strong>24910</strong></td><td align="center"></td><td align="center"></td></tr></tbody></table><blockquote><p><strong>本文启用插件资源要求汇总</strong></p></blockquote><table><thead><tr><th>组件名称</th><th align="center">CPU 请求 (核)</th><th align="center">CPU 限制 (核)</th><th align="center">内存请求 (MiB)</th><th align="center">内存限制 (MiB)</th><th align="center">是否启用</th><th align="center">备注</th></tr></thead><tbody><tr><td>KubeSphere 应用商店</td><td align="center">0.3</td><td align="center">0</td><td align="center">300</td><td align="center">0</td><td align="center">是</td><td align="center">必选</td></tr><tr><td>KubeSphere DevOps 系统</td><td align="center">0.47</td><td align="center">0</td><td align="center">8600</td><td align="center">0</td><td align="center">是</td><td align="center">必选</td></tr><tr><td>KubeSphere 监控系统-Prometheus</td><td align="center">0.1</td><td align="center">4</td><td align="center">400</td><td align="center">8000</td><td align="center">是</td><td align="center">默认已开</td></tr><tr><td>KubeSphere 监控系统-Alertmanager</td><td align="center">0.01</td><td align="center">0</td><td align="center">30</td><td align="center">0</td><td align="center">是</td><td align="center">默认已开</td></tr><tr><td>KubeSphere 监控系统-Notification Manager</td><td align="center">0.1</td><td align="center">0.5</td><td align="center">20</td><td align="center">1000</td><td align="center">是</td><td align="center">默认已开</td></tr><tr><td>KubeSphere 日志系统-Elasticsearch</td><td align="center">0.05</td><td align="center">1</td><td align="center">2000</td><td align="center">0</td><td align="center">否</td><td align="center">不开启，外部独立部署</td></tr><tr><td>KubeSphere 日志系统-fluent bit</td><td align="center">0.02</td><td align="center">0.2</td><td align="center">50</td><td align="center">100</td><td align="center">否</td><td align="center">暂时不开启，等外部的 Elasticsearch 部署完成后再开启</td></tr><tr><td>KubeSphere 日志系统-kube-events</td><td align="center">0.09</td><td align="center">0.9</td><td align="center">120</td><td align="center">1200</td><td align="center">否</td><td align="center">暂时不开启，等外部的 Elasticsearch 部署完成后再开启</td></tr><tr><td>KubeSphere 日志系统-kube-auditing</td><td align="center">0.02</td><td align="center">0.2</td><td align="center">50</td><td align="center">100</td><td align="center">否</td><td align="center">暂时不开启，等外部的 Elasticsearch 部署完成后再开启</td></tr><tr><td>KubeSphere 告警系统</td><td align="center">0.08</td><td align="center">0</td><td align="center">80</td><td align="center">0</td><td align="center">是</td><td align="center">可选，建议</td></tr><tr><td>KubeSphere 服务网格</td><td align="center">1</td><td align="center">0</td><td align="center">3500</td><td align="center">0</td><td align="center">否</td><td align="center">暂时不开启，等后期再考虑 , 生产环境计划使用服务网功能的建议开启</td></tr><tr><td>网络策略</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">否</td><td align="center">没有需求，暂时不开启</td></tr><tr><td>Metrics Server</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">否</td><td align="center">没有需求，暂时不开启</td></tr><tr><td>服务拓扑图</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">否</td><td align="center">没有需求，暂时不开启</td></tr><tr><td>容器组 IP 池</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">否</td><td align="center">没有需求，暂时不开启</td></tr><tr><td>KubeEdge</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">否</td><td align="center">没有需求，暂时不开启</td></tr><tr><td>合计</td><td align="center"><strong>1.06</strong></td><td align="center"><strong>5.36</strong></td><td align="center"><strong>9430</strong></td><td align="center"><strong>18010</strong></td><td align="center"></td><td align="center"></td></tr></tbody></table><h3 id="3-3-开启可插拔组件具体配置"><a href="#3-3-开启可插拔组件具体配置" class="headerlink" title="3.3. 开启可插拔组件具体配置"></a><strong>3.3. 开启可插拔组件具体配置</strong></h3><p>上文介绍了可插拔组件的概念、官方可用的可插拔组件、可插拔组件的资源要求等，下面开始介绍可插拔组件具体的开启配置方法。</p><p><strong>可插拔组件的启用可以在部署 KubeSphere 的配置文件中开启，也可以在安装完 KubeSphere 系统后再开启，本文介绍的是安装之后的启用方式</strong>。</p><p>使用 <strong>admin</strong> 用户登录控制台,点击左上角<strong>平台管理</strong>-&gt; 选择<strong>集群管理</strong>-&gt; 集群管理界面中，左侧菜单点击 <strong>CRD</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-crd.png" alt="kubesphere-clustesr-crd"></p><p>搜索栏中输入 <strong>clusterconfiguration</strong>，点击结果查看其详细页面。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-crd-clusterconfiguration.png" alt="kubesphere-clusters-crd-clusterconfiguration"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-crd-clusterconfiguration-1.png" alt="kubesphere-clusters-crd-clusterconfiguration-1"></p><p>在<strong>自定义资源</strong>中，点击 <strong>ks-installer</strong> 右侧的 <img src="https://kubesphere.com.cn/images/docs/zh-cn/enable-pluggable-components/kubesphere-app-store/three-dots.png" alt="img">，选择<strong>编辑 YAML</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-crd-clusterconfiguration-2.png" alt="kubesphere-clusters-crd-clusterconfiguration-2"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-crd-clusterconfiguration-3.png" alt="kubesphere-clusters-crd-clusterconfiguration-3"></p><p>在该 <strong>YAML</strong> 文件中，启用需要开启的可插拔组件。每个组件的详细启用方法如下：</p><blockquote><p><strong>KubeSphere 应用商店</strong></p></blockquote><p>在 YAML 文件中，搜索 <strong>openpitrix</strong>，并将 <strong>enabled</strong> 的 <strong>false</strong> 改为 <strong>true</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">openpitrix:</span></span><br><span class="line">  <span class="attr">store:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>KubeSphere DevOps</strong></p></blockquote><p>在 YAML 文件中，搜索 <strong>devops</strong>，将 <strong>enabled</strong> 的 <strong>false</strong> 改为 <strong>true</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">devops:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">jenkinsJavaOpts_MaxRAM:</span> <span class="string">2g</span></span><br><span class="line">  <span class="attr">jenkinsJavaOpts_Xms:</span> <span class="string">512m</span></span><br><span class="line">  <span class="attr">jenkinsJavaOpts_Xmx:</span> <span class="string">512m</span></span><br><span class="line">  <span class="attr">jenkinsMemoryLim:</span> <span class="string">2Gi</span></span><br><span class="line">  <span class="attr">jenkinsMemoryReq:</span> <span class="string">1500Mi</span></span><br><span class="line">  <span class="attr">jenkinsVolumeSize:</span> <span class="string">8Gi</span></span><br></pre></td></tr></table></figure><p><strong>其他参数使用了默认值，各位可以根据自己的服务器配置和业务规模做出适合的调整，主要就是控制内存和存储空间，业务规模大的一定要加大内存的分配</strong>。</p><blockquote><p><strong>KubeSphere 告警系统</strong></p></blockquote><p>在 YAML 文件中，搜寻 <strong>alerting</strong>，将 <strong>enabled</strong> 的 <strong>false</strong> 更改为 <strong>true</strong>。完成后，点击右下角的<strong>确定</strong>，保存配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">alerting:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>所有配置完成后，点击右下角的<strong>确定</strong>，保存配置。</p><p>点击<strong>控制台右下角</strong>的 <img src="https://kubesphere.com.cn/images/docs/zh-cn/enable-pluggable-components/kubesphere-app-store/hammer.png" alt="img"> 找到 kubectl 工具。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-kubectl.png" alt="kubesphere-kubectl"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-kubectl-1.png" alt="kubesphere-kubectl-1"></p><p>在 kubectl 中执行以下命令检查安装过程。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br></pre></td></tr></table></figure><p>看到如下状态，说明安装成功。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">PLAY</span> <span class="string">RECAP</span> <span class="string">*********************************************************************</span></span><br><span class="line"><span class="attr">localhost                  :</span> <span class="string">ok=26</span>   <span class="string">changed=14</span>   <span class="string">unreachable=0</span>    <span class="string">failed=0</span>    <span class="string">skipped=12</span>   <span class="string">rescued=0</span>    <span class="string">ignored=0</span></span><br><span class="line"></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">monitoring</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">multicluster</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">openpitrix</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">network</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">alerting</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">devops</span></span><br><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Waiting</span> <span class="string">for</span> <span class="string">all</span> <span class="string">tasks</span> <span class="string">to</span> <span class="string">be</span> <span class="string">completed</span> <span class="string">...</span></span><br><span class="line"><span class="string">task</span> <span class="string">alerting</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(1/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">network</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(2/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">multicluster</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(3/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">openpitrix</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(4/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">devops</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(5/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">monitoring</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(6/6)</span></span><br><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Collecting</span> <span class="string">installation</span> <span class="string">results</span> <span class="string">...</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="comment">###              Welcome to KubeSphere!           ###</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Console:</span> <span class="string">http://192.168.9.91:30880</span></span><br><span class="line"><span class="attr">Account:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">Password:</span> <span class="string">P@88w0rd</span></span><br><span class="line"></span><br><span class="line"><span class="string">NOTES：</span></span><br><span class="line">  <span class="number">1</span><span class="string">.</span> <span class="string">After</span> <span class="string">you</span> <span class="string">log</span> <span class="string">into</span> <span class="string">the</span> <span class="string">console,</span> <span class="string">please</span> <span class="string">check</span> <span class="string">the</span></span><br><span class="line">     <span class="string">monitoring</span> <span class="string">status</span> <span class="string">of</span> <span class="string">service</span> <span class="string">components</span> <span class="string">in</span></span><br><span class="line">     <span class="string">&quot;Cluster Management&quot;</span><span class="string">.</span> <span class="string">If</span> <span class="string">any</span> <span class="string">service</span> <span class="string">is</span> <span class="string">not</span></span><br><span class="line">     <span class="string">ready,</span> <span class="string">please</span> <span class="string">wait</span> <span class="string">patiently</span> <span class="string">until</span> <span class="string">all</span> <span class="string">components</span></span><br><span class="line">     <span class="string">are</span> <span class="string">up</span> <span class="string">and</span> <span class="string">running.</span></span><br><span class="line">  <span class="number">2</span><span class="string">.</span> <span class="string">Please</span> <span class="string">change</span> <span class="string">the</span> <span class="string">default</span> <span class="string">password</span> <span class="string">after</span> <span class="string">login.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="string">https://kubesphere.io</span>             <span class="number">2022-04-07 13:48:19</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br></pre></td></tr></table></figure><p>详细过程分析。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022-04-07T13:38:11+08:00</span> <span class="attr">INFO     :</span> <span class="string">EVENT</span> <span class="string">Kube</span> <span class="string">event</span> <span class="string">&#x27;3ededddf-6c59-48dc-a865-e38c7bdf6a3f&#x27;</span></span><br><span class="line"><span class="number">2022-04-07T13:38:11+08:00</span> <span class="attr">INFO     :</span> <span class="string">QUEUE</span> <span class="string">add</span> <span class="string">TASK_HOOK_RUN@KUBE_EVENTS</span> <span class="string">kubesphere/installRunner.py</span></span><br><span class="line"><span class="number">2022-04-07T13:38:11+08:00</span> <span class="attr">INFO     :</span> <span class="string">TASK_RUN</span> <span class="string">HookRun@KUBE_EVENTS</span> <span class="string">kubesphere/installRunner.py</span></span><br><span class="line"><span class="number">2022-04-07T13:38:11+08:00</span> <span class="attr">INFO     :</span> <span class="string">Running</span> <span class="string">hook</span> <span class="string">&#x27;kubesphere/installRunner.py&#x27;</span> <span class="string">binding</span> <span class="string">&#x27;KUBE_EVENTS&#x27;</span> <span class="string">...</span></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="literal">No</span> <span class="string">inventory</span> <span class="string">was</span> <span class="string">parsed,</span> <span class="string">only</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available</span></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="string">provided</span> <span class="string">hosts</span> <span class="string">list</span> <span class="string">is</span> <span class="string">empty,</span> <span class="string">only</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available.</span> <span class="string">Note</span> <span class="string">that</span></span><br><span class="line"><span class="string">the</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">does</span> <span class="string">not</span> <span class="string">match</span> <span class="string">&#x27;all&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> [<span class="string">localhost</span>] <span class="string">***************************************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Generating</span> <span class="string">images</span> <span class="string">list</span>] <span class="string">***************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Synchronizing</span> <span class="string">images</span>] <span class="string">*****************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">images&#x27;</span> <span class="string">namespace</span> <span class="string">override</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Configuring</span> <span class="string">defaults</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> <span class="string">&quot;Check roles/kubesphere-defaults/defaults/main.yml&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Stopping</span> <span class="string">if</span> <span class="string">Kubernetes</span> <span class="string">version</span> <span class="string">is</span> <span class="string">nonsupport</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;changed&quot;:</span> <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> <span class="string">&quot;All assertions passed&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">StorageClass</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Stopping</span> <span class="string">if</span> <span class="string">StorageClass</span> <span class="string">was</span> <span class="string">not</span> <span class="string">found</span>] <span class="string">********</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">default</span> <span class="string">StorageClass</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Stopping</span> <span class="string">if</span> <span class="string">default</span> <span class="string">StorageClass</span> <span class="string">was</span> <span class="string">not</span> <span class="string">found</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;changed&quot;:</span> <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> <span class="string">&quot;All assertions passed&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">KubeSphere</span> <span class="string">component</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">KubeSphere</span> <span class="string">component</span> <span class="string">version</span>] <span class="string">**********</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">preinstall :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">KubeSphere</span> <span class="string">component</span> <span class="string">version</span>] <span class="string">**********</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-openldap)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-redis)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-minio)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-openpitrix)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=elasticsearch-logging)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=elasticsearch-logging-curator)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=istio)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=istio-init)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=jaeger-operator)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-jenkins)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-sonarqube)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=logging-fluentbit-operator)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=uc)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=metrics-server)</span></span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> <span class="string">RECAP</span> <span class="string">*********************************************************************</span></span><br><span class="line"><span class="attr">localhost                  :</span> <span class="string">ok=7</span>    <span class="string">changed=4</span>    <span class="string">unreachable=0</span>    <span class="string">failed=0</span>    <span class="string">skipped=5</span>    <span class="string">rescued=0</span>    <span class="string">ignored=0</span></span><br><span class="line"></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="literal">No</span> <span class="string">inventory</span> <span class="string">was</span> <span class="string">parsed,</span> <span class="string">only</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available</span></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="string">provided</span> <span class="string">hosts</span> <span class="string">list</span> <span class="string">is</span> <span class="string">empty,</span> <span class="string">only</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available.</span> <span class="string">Note</span> <span class="string">that</span></span><br><span class="line"><span class="string">the</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">does</span> <span class="string">not</span> <span class="string">match</span> <span class="string">&#x27;all&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> [<span class="string">localhost</span>] <span class="string">***************************************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Generating</span> <span class="string">images</span> <span class="string">list</span>] <span class="string">***************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Synchronizing</span> <span class="string">images</span>] <span class="string">*****************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">images&#x27;</span> <span class="string">namespace</span> <span class="string">override</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Configuring</span> <span class="string">defaults</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> <span class="string">&quot;Check roles/kubesphere-defaults/defaults/main.yml&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">metrics-server</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">metrics-server :</span> <span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;file&#x27;:</span> <span class="string">&#x27;metrics-server.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">metrics-server :</span> <span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">Metrics-Server</span>] <span class="string">***************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Uninstalling</span> <span class="string">old</span> <span class="string">metrics-server</span>] <span class="string">************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Installing</span> <span class="string">new</span> <span class="string">metrics-server</span>] <span class="string">**************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">metrics-server :</span> <span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Waitting</span> <span class="string">for</span> <span class="string">metrics.k8s.io</span> <span class="string">ready</span>] <span class="string">*****</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">Metrics-Server</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">metrics-server</span> <span class="string">status</span>] <span class="string">************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> <span class="string">RECAP</span> <span class="string">*********************************************************************</span></span><br><span class="line"><span class="attr">localhost                  :</span> <span class="string">ok=1</span>    <span class="string">changed=0</span>    <span class="string">unreachable=0</span>    <span class="string">failed=0</span>    <span class="string">skipped=10</span>   <span class="string">rescued=0</span>    <span class="string">ignored=0</span></span><br><span class="line"></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="literal">No</span> <span class="string">inventory</span> <span class="string">was</span> <span class="string">parsed,</span> <span class="string">only</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available</span></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="string">provided</span> <span class="string">hosts</span> <span class="string">list</span> <span class="string">is</span> <span class="string">empty,</span> <span class="string">only</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available.</span> <span class="string">Note</span> <span class="string">that</span></span><br><span class="line"><span class="string">the</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">does</span> <span class="string">not</span> <span class="string">match</span> <span class="string">&#x27;all&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> [<span class="string">localhost</span>] <span class="string">***************************************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Generating</span> <span class="string">images</span> <span class="string">list</span>] <span class="string">***************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Synchronizing</span> <span class="string">images</span>] <span class="string">*****************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">images&#x27;</span> <span class="string">namespace</span> <span class="string">override</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Configuring</span> <span class="string">defaults</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> <span class="string">&quot;Check roles/kubesphere-defaults/defaults/main.yml&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">kube-node-lease</span> <span class="string">namespace</span>] <span class="string">****************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">system</span> <span class="string">namespaces</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">set_fact</span>] <span class="string">*******************************************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">debug</span>] <span class="string">**********************************************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> [</span><br><span class="line">        <span class="string">&quot;kubesphere-system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;kubesphere-controls-system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;kubesphere-monitoring-system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;kubesphere-monitoring-federated&quot;</span>,</span><br><span class="line">        <span class="string">&quot;kube-node-lease&quot;</span>,</span><br><span class="line">        <span class="string">&quot;kubesphere-devops-system&quot;</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">KubeSphere</span> <span class="string">namespace</span>] <span class="string">*********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-controls-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-monitoring-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-monitoring-federated)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kube-node-lease)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-devops-system)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Labeling</span> <span class="string">system-workspace</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=default)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kube-public)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kube-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-controls-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-monitoring-system)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-monitoring-federated)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kube-node-lease)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=kubesphere-devops-system)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Labeling</span> <span class="string">namespace</span> <span class="string">for</span> <span class="string">network</span> <span class="string">policy</span>] <span class="string">*************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">Kubernetes</span> <span class="string">master</span> <span class="string">num</span>] <span class="string">*********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">master</span> <span class="string">num</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">common</span> <span class="string">component</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=common)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">Kubernetes</span> <span class="string">version</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">common</span> <span class="string">component</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=snapshot-controller)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">snapshot</span> <span class="string">controller</span> <span class="string">values</span>] <span class="string">***************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-snapshot-controller&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-snapshot-controller.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Updating</span> <span class="string">snapshot</span> <span class="string">crd</span>] <span class="string">*****************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">snapshot</span> <span class="string">controller</span>] <span class="string">*********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">openpitrix</span> <span class="string">common</span> <span class="string">component</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">include_tasks</span>] <span class="string">**************************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;op&#x27;:</span> <span class="string">&#x27;openpitrix-db&#x27;</span><span class="string">,</span> <span class="attr">&#x27;ks&#x27;:</span> <span class="string">&#x27;mysql-pvc&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;op&#x27;:</span> <span class="string">&#x27;openpitrix-etcd&#x27;</span><span class="string">,</span> <span class="attr">&#x27;ks&#x27;:</span> <span class="string">&#x27;etcd-pvc&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Getting</span> <span class="string">PersistentVolumeName</span> <span class="string">(mysql)</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Getting</span> <span class="string">PersistentVolumeSize</span> <span class="string">(mysql)</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Setting</span> <span class="string">PersistentVolumeName</span> <span class="string">(mysql)</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Setting</span> <span class="string">PersistentVolumeSize</span> <span class="string">(mysql)</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Getting</span> <span class="string">PersistentVolumeName</span> <span class="string">(etcd)</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Getting</span> <span class="string">PersistentVolumeSize</span> <span class="string">(etcd)</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Setting</span> <span class="string">PersistentVolumeName</span> <span class="string">(etcd)</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Setting</span> <span class="string">PersistentVolumeSize</span> <span class="string">(etcd)</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">mysql</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">mysql</span> <span class="string">db</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">**************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">redis</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">redis</span> <span class="string">db</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">**************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">minio</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">minio</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">*****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">openldap</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">***********</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">openldap</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">**************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">etcd</span> <span class="string">db</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">etcd</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">redis</span> <span class="string">ha</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">***********</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">redis</span> <span class="string">ha</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">**************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">es-master</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">**********</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">es</span> <span class="string">master</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">es</span> <span class="string">data</span> <span class="string">PersistentVolumeClaim</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">es</span> <span class="string">data</span> <span class="string">pv</span> <span class="string">size</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">common</span> <span class="string">component</span> <span class="string">manifests</span>] <span class="string">************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;path&#x27;:</span> <span class="string">&#x27;redis&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;redis.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">etcd</span> <span class="string">and</span> <span class="string">mysql</span>] <span class="string">**************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=etcd.yaml)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=mysql.yaml)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">minio</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=minio-ha)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-minio&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-minio.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">minio</span>] <span class="string">************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">minio</span>] <span class="string">***********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">debug</span>] <span class="string">**********************************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">fail</span>] <span class="string">***********************************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">minio</span> <span class="string">status</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Generet</span> <span class="string">Random</span> <span class="string">password</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">Redis</span> <span class="string">Password</span> <span class="string">Secret</span>] <span class="string">********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">redis</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=redis-ha)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-redis&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-redis.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">old</span> <span class="string">redis</span> <span class="string">status</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deleting</span> <span class="string">and</span> <span class="string">backup</span> <span class="string">old</span> <span class="string">redis</span> <span class="string">svc</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">redis</span>] <span class="string">***********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">redis</span>] <span class="string">***********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=redis.yaml)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">redis</span> <span class="string">status</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">openldap</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">***************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=openldap-ha)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-openldap&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-openldap.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">status</span>] <span class="string">**********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Shutdown</span> <span class="string">ks-account</span>] <span class="string">*******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deleting</span> <span class="string">and</span> <span class="string">backup</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">svc</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">openldap</span>] <span class="string">*********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">openldap</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Loading</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">data</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">openldap-ha</span> <span class="string">status</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">openldap-ha</span> <span class="string">pod</span> <span class="string">list</span>] <span class="string">**********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">data</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Migrating</span> <span class="string">openldap</span> <span class="string">data</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Disabling</span> <span class="string">old</span> <span class="string">openldap</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Restarting</span> <span class="string">openldap</span>] <span class="string">*******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Restarting</span> <span class="string">ks-account</span>] <span class="string">*****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">openldap</span> <span class="string">status</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Generet</span> <span class="string">Random</span> <span class="string">password</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">Redis</span> <span class="string">Password</span> <span class="string">Secret</span>] <span class="string">********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">redis</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=redis-ha)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-redis&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-redis.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">old</span> <span class="string">redis</span> <span class="string">status</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deleting</span> <span class="string">and</span> <span class="string">backup</span> <span class="string">old</span> <span class="string">redis</span> <span class="string">svc</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">redis</span>] <span class="string">***********************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">redis</span>] <span class="string">***********************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=redis.yaml)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">redis</span> <span class="string">status</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">openldap</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">***************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=openldap-ha)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-openldap&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-openldap.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">status</span>] <span class="string">**********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Shutdown</span> <span class="string">ks-account</span>] <span class="string">*******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deleting</span> <span class="string">and</span> <span class="string">backup</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">svc</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">openldap</span>] <span class="string">*********************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">openldap</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Loading</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">data</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">openldap-ha</span> <span class="string">status</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">openldap-ha</span> <span class="string">pod</span> <span class="string">list</span>] <span class="string">**********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">old</span> <span class="string">openldap</span> <span class="string">data</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Migrating</span> <span class="string">openldap</span> <span class="string">data</span>] <span class="string">***************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Disabling</span> <span class="string">old</span> <span class="string">openldap</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Restarting</span> <span class="string">openldap</span>] <span class="string">*******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Restarting</span> <span class="string">ks-account</span>] <span class="string">*****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">openldap</span> <span class="string">status</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">minio</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=minio-ha)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">********************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-minio&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-minio.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">minio</span>] <span class="string">************************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">minio</span>] <span class="string">***********************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">debug</span>] <span class="string">**********************************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">fail</span>] <span class="string">***********************************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">minio</span> <span class="string">status</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">elasticsearch</span> <span class="string">and</span> <span class="string">curator</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">custom</span> <span class="string">manifests</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-elasticsearch&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-elasticsearch.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;name&#x27;:</span> <span class="string">&#x27;custom-values-elasticsearch-curator&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-elasticsearch-curator.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">elasticsearch</span> <span class="string">data</span> <span class="string">StatefulSet</span>] <span class="string">***********</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">elasticsearch</span> <span class="string">storageclass</span>] <span class="string">***************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Commenting</span> <span class="string">elasticsearch</span> <span class="string">storageclass</span> <span class="string">parameter</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">elasticsearch</span> <span class="string">credentials</span> <span class="string">secret</span>] <span class="string">*********</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">internal</span> <span class="string">es</span>] <span class="string">******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">elasticsearch-logging</span>] <span class="string">*******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">PersistentVolume</span> <span class="string">Name</span>] <span class="string">*********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Patching</span> <span class="string">PersistentVolume</span> <span class="string">(persistentVolumeReclaimPolicy)</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deleting</span> <span class="string">elasticsearch</span>] <span class="string">****************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Waiting</span> <span class="string">for</span> <span class="string">seconds</span>] <span class="string">*******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">elasticsearch-logging</span>] <span class="string">*******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">es</span> <span class="string">status</span>] <span class="string">*******************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">elasticsearch-logging-curator</span>] <span class="string">***********</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">fluentbit</span> <span class="string">installation</span> <span class="string">files</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">custom</span> <span class="string">manifests</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;path&#x27;:</span> <span class="string">&#x27;fluentbit&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-fluentbit-fluentBit.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;path&#x27;:</span> <span class="string">&#x27;init&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-fluentbit-operator-deployment.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Preparing</span> <span class="string">fluentbit</span> <span class="string">operator</span> <span class="string">setup</span>] <span class="string">****************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deploying</span> <span class="string">new</span> <span class="string">fluentbit</span> <span class="string">operator</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">fluentbit</span> <span class="string">status</span>] <span class="string">************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Setting</span> <span class="string">persistentVolumeReclaimPolicy</span> <span class="string">(mysql)</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">common :</span> <span class="string">Setting</span> <span class="string">persistentVolumeReclaimPolicy</span> <span class="string">(etcd)</span>] <span class="string">*******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> <span class="string">RECAP</span> <span class="string">*********************************************************************</span></span><br><span class="line"><span class="attr">localhost                  :</span> <span class="string">ok=45</span>   <span class="string">changed=32</span>   <span class="string">unreachable=0</span>    <span class="string">failed=0</span>    <span class="string">skipped=88</span>   <span class="string">rescued=0</span>    <span class="string">ignored=0</span></span><br><span class="line"></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="literal">No</span> <span class="string">inventory</span> <span class="string">was</span> <span class="string">parsed,</span> <span class="string">only</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available</span></span><br><span class="line">[<span class="string">WARNING</span>]<span class="string">:</span> <span class="string">provided</span> <span class="string">hosts</span> <span class="string">list</span> <span class="string">is</span> <span class="string">empty,</span> <span class="string">only</span> <span class="string">localhost</span> <span class="string">is</span> <span class="string">available.</span> <span class="string">Note</span> <span class="string">that</span></span><br><span class="line"><span class="string">the</span> <span class="string">implicit</span> <span class="string">localhost</span> <span class="string">does</span> <span class="string">not</span> <span class="string">match</span> <span class="string">&#x27;all&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> [<span class="string">localhost</span>] <span class="string">***************************************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Generating</span> <span class="string">images</span> <span class="string">list</span>] <span class="string">***************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">download :</span> <span class="string">Synchronizing</span> <span class="string">images</span>] <span class="string">*****************************************</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">images&#x27;</span> <span class="string">namespace</span> <span class="string">override</span>] <span class="string">***</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">kubesphere-defaults :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Configuring</span> <span class="string">defaults</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> &#123;</span><br><span class="line">    <span class="attr">&quot;msg&quot;:</span> <span class="string">&quot;Check roles/kubesphere-defaults/defaults/main.yml&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">KubeSphere</span> <span class="string">directory</span>] <span class="string">*********</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">installation</span> <span class="string">init</span> <span class="string">files</span>] <span class="string">*******</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=jwt-script)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">KubeSphere</span> <span class="string">Secret</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">KubeSphere</span> <span class="string">Secret</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">KubeSphere</span> <span class="string">Secret</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Enabling</span> <span class="string">Token</span> <span class="string">Script</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">KubeSphere</span> <span class="string">Token</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">KubeSphere</span> <span class="string">secrets</span>] <span class="string">***********</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Deleting</span> <span class="string">KubeSphere</span> <span class="string">secret</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/init-token :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">components</span> <span class="string">token</span>] <span class="string">*************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">Kubernetes</span> <span class="string">version</span>] <span class="string">***************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">Kubernetes</span> <span class="string">master</span> <span class="string">num</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">master</span> <span class="string">num</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Override</span> <span class="string">master</span> <span class="string">num</span>] <span class="string">**********************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Setting</span> <span class="string">enableHA</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">ks-core</span> <span class="string">Helm</span> <span class="string">Release</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">ks-core</span> <span class="string">Exsit</span>] <span class="string">*******************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Convert</span> <span class="string">ks-core</span> <span class="string">to</span> <span class="string">helm</span> <span class="string">mananged</span>] <span class="string">*********</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-controls-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;serviceaccounts&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;kubesphere-cluster-admin&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-controls-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;serviceaccounts&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;kubesphere-router-serviceaccount&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-controls-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;role&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;system:kubesphere-router-role&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-controls-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;rolebinding&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;nginx-ingress-role-nisa-binding&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-controls-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;deployment&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;default-http-backend&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-controls-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;service&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;default-http-backend&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;secrets&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-controller-manager-webhook-cert&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;serviceaccounts&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;kubesphere&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;configmaps&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-console-config&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;configmaps&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-router-config&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;configmaps&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;sample-bookinfo&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;clusterroles&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;system:kubesphere-router-clusterrole&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;clusterrolebindings&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;system:nginx-ingress-clusterrole-nisa-binding&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;clusterrolebindings&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;system:kubesphere-cluster-admin&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;clusterrolebindings&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;kubesphere&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;services&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-apiserver&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;services&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-console&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;services&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-controller-manager&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;deployments&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-apiserver&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;deployments&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-console&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;deployments&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;ks-controller-manager&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;validatingwebhookconfigurations&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;users.iam.kubesphere.io&#x27;</span><span class="string">,&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;validatingwebhookconfigurations&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;resourcesquotas.quota.kubesphere.io&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;validatingwebhookconfigurations&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;network.kubesphere.io&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;ns&#x27;:</span> <span class="string">&#x27;kubesphere-system&#x27;</span><span class="string">,</span> <span class="attr">&#x27;kind&#x27;:</span> <span class="string">&#x27;users.iam.kubesphere.io&#x27;</span><span class="string">,</span> <span class="attr">&#x27;resource&#x27;:</span> <span class="string">&#x27;admin&#x27;</span><span class="string">,</span> <span class="attr">&#x27;release&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Patch</span> <span class="string">admin</span> <span class="string">user</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">ks-core</span> <span class="string">helm</span> <span class="string">charts</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-core)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">manifests</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=&#123;&#x27;path&#x27;:</span> <span class="string">&#x27;ks-core&#x27;</span><span class="string">,</span> <span class="attr">&#x27;file&#x27;:</span> <span class="string">&#x27;custom-values-ks-core.yaml&#x27;</span><span class="string">&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Upgrade</span> <span class="string">CRDs</span>] <span class="string">*****************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/app_v1beta1_application.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/application.kubesphere.io_helmapplications.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/application.kubesphere.io_helmapplicationversions.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/application.kubesphere.io_helmcategories.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/application.kubesphere.io_helmreleases.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/application.kubesphere.io_helmrepos.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/cluster.kubesphere.io_clusters.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/gateway.kubesphere.io_gateways.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/gateway.kubesphere.io_nginxes.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_federatedrolebindings.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_federatedroles.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_federatedusers.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_globalrolebindings.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_globalroles.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_groupbindings.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_groups.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_loginrecords.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_rolebases.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_users.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_workspacerolebindings.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/iam.kubesphere.io_workspaceroles.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/network.kubesphere.io_ipamblocks.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/network.kubesphere.io_ipamhandles.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/network.kubesphere.io_ippools.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/network.kubesphere.io_namespacenetworkpolicies.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/quota.kubesphere.io_resourcequotas.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/servicemesh.kubesphere.io_servicepolicies.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/servicemesh.kubesphere.io_strategies.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/tenant.kubesphere.io_workspaces.yaml)</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=/kubesphere/kubesphere/ks-core/crds/tenant.kubesphere.io_workspacetemplates.yaml)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">ks-core</span>] <span class="string">*************************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/ks-core :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Importing</span> <span class="string">ks-core</span> <span class="string">status</span>] <span class="string">*****************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">core</span> <span class="string">components</span> <span class="string">(1)</span>] <span class="string">*************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">core</span> <span class="string">components</span> <span class="string">(2)</span>] <span class="string">*************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">core</span> <span class="string">components</span> <span class="string">(3)</span>] <span class="string">*************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Checking</span> <span class="string">core</span> <span class="string">components</span> <span class="string">(4)</span>] <span class="string">*************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Updating</span> <span class="string">ks-core</span> <span class="string">status</span>] <span class="string">******************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">set_fact</span>] <span class="string">**********************************************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Creating</span> <span class="string">KubeSphere</span> <span class="string">directory</span>] <span class="string">************</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Getting</span> <span class="string">installation</span> <span class="string">init</span> <span class="string">files</span>] <span class="string">**********</span></span><br><span class="line"><span class="attr">ok:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=ks-init)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Initing</span> <span class="string">KubeSphere</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=role-templates.yaml)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Generating</span> <span class="string">kubeconfig-admin</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> <span class="string">RECAP</span> <span class="string">*********************************************************************</span></span><br><span class="line"><span class="attr">localhost                  :</span> <span class="string">ok=26</span>   <span class="string">changed=14</span>   <span class="string">unreachable=0</span>    <span class="string">failed=0</span>    <span class="string">skipped=12</span>   <span class="string">rescued=0</span>    <span class="string">ignored=0</span></span><br><span class="line"></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">monitoring</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">multicluster</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">openpitrix</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">network</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">alerting</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">devops</span></span><br><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Waiting</span> <span class="string">for</span> <span class="string">all</span> <span class="string">tasks</span> <span class="string">to</span> <span class="string">be</span> <span class="string">completed</span> <span class="string">...</span></span><br><span class="line"><span class="string">task</span> <span class="string">alerting</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(1/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">network</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(2/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">multicluster</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(3/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">openpitrix</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(4/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">devops</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(5/6)</span></span><br><span class="line"><span class="string">task</span> <span class="string">monitoring</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(6/6)</span></span><br><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Collecting</span> <span class="string">installation</span> <span class="string">results</span> <span class="string">...</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="comment">###              Welcome to KubeSphere!           ###</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Console:</span> <span class="string">http://192.168.9.91:30880</span></span><br><span class="line"><span class="attr">Account:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">Password:</span> <span class="string">P@88w0rd</span></span><br><span class="line"></span><br><span class="line"><span class="string">NOTES：</span></span><br><span class="line">  <span class="number">1</span><span class="string">.</span> <span class="string">After</span> <span class="string">you</span> <span class="string">log</span> <span class="string">into</span> <span class="string">the</span> <span class="string">console,</span> <span class="string">please</span> <span class="string">check</span> <span class="string">the</span></span><br><span class="line">     <span class="string">monitoring</span> <span class="string">status</span> <span class="string">of</span> <span class="string">service</span> <span class="string">components</span> <span class="string">in</span></span><br><span class="line">     <span class="string">&quot;Cluster Management&quot;</span><span class="string">.</span> <span class="string">If</span> <span class="string">any</span> <span class="string">service</span> <span class="string">is</span> <span class="string">not</span></span><br><span class="line">     <span class="string">ready,</span> <span class="string">please</span> <span class="string">wait</span> <span class="string">patiently</span> <span class="string">until</span> <span class="string">all</span> <span class="string">components</span></span><br><span class="line">     <span class="string">are</span> <span class="string">up</span> <span class="string">and</span> <span class="string">running.</span></span><br><span class="line">  <span class="number">2</span><span class="string">.</span> <span class="string">Please</span> <span class="string">change</span> <span class="string">the</span> <span class="string">default</span> <span class="string">password</span> <span class="string">after</span> <span class="string">login.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="string">https://kubesphere.io</span>             <span class="number">2022-04-07 13:48:19</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br></pre></td></tr></table></figure><p>验证各个组件的安装结果(可以刷新页面也可以重新登录控制台)。</p><blockquote><p><strong>KubeSphere 应用商店</strong></p></blockquote><p>登录 <strong>KubeSphere</strong> 控制台，如果您能看到页面左上角的<strong>应用商店</strong>以及其中的应用，则说明安装成功。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-openpitrix.png" alt="kubesphere-openpitrix"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-openpitrix-1.png" alt="kubesphere-openpitrix-1"></p><blockquote><p><strong>KubeSphere DevOps 系统</strong></p></blockquote><p><strong>方法一：</strong> 登录控制台，<strong>平台管理</strong>-&gt;<strong>集群管理</strong>-&gt;<strong>系统组件</strong>，检查是否 <strong>DevOps</strong> 标签页中的所有组件都处于<strong>健康</strong>状态。如果是，表明组件安装成功。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-devops.png" alt="kubesphere-devops"></p><p><strong>方法二：</strong> 通过 kubectl 工具验证。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/ # kubectl get pod -n kubesphere-devops-system</span><br><span class="line">NAME                                READY   STATUS      RESTARTS   AGE</span><br><span class="line">devops-27488520-s52rq               0/1     Completed   0          4m16s</span><br><span class="line">devops-apiserver-7c6774fff5-qtnl2   1/1     Running     0          19m</span><br><span class="line">devops-controller-98975d478-nbcj9   1/1     Running     0          19m</span><br><span class="line">devops-jenkins-5d744f66b9-cfmrj     1/1     Running     0          19m</span><br><span class="line">s2ioperator-0                       1/1     Running     0          19m</span><br><span class="line">/ #</span><br></pre></td></tr></table></figure><blockquote><p><strong>KubeSphere 告警系统</strong></p></blockquote><p>登录控制台，<strong>平台管理</strong>-&gt;<strong>集群管理</strong>-&gt;<strong>监控告警</strong>，看到<strong>告警消息</strong>和<strong>告警策略</strong>菜单，则说明安装成功。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-alerts.png" alt="kubesphere-clusters-alerts"></p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-clusters-alert-rules.png" alt="kubesphere-clusters-alert-rules"></p><p>以上配置开启了本文用到的可插拔组件，其他组件我们后期根据需求开启。</p><hr><h2 id="4-多租户系统"><a href="#4-多租户系统" class="headerlink" title="4. 多租户系统"></a>4. 多租户系统</h2><h3 id="4-1-多租户系统架构"><a href="#4-1-多租户系统架构" class="headerlink" title="4.1. 多租户系统架构"></a>4.1. 多租户系统架构</h3><p>KubeSphere 的多租户系统分<strong>三个</strong>层级，即集群、企业空间和项目。KubeSphere 中的项目等同于 Kubernetes 的<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/namespaces/">命名空间</a>。</p><blockquote><p> <strong>架构</strong></p></blockquote><p><img src="https://kubesphere.com.cn/images/docs/zh-cn/access-control-and-account-management/multi-tanancy-in-kubesphere/multi-tenancy-architecture.png" alt="multi-tenancy-architecture"></p><ul><li><a href="https://kubesphere.com.cn/docs/workspace-administration/what-is-workspace/">企业空间</a>是最小的租户单元，企业空间提供了跨集群、跨项目（即 Kubernetes 中的命名空间）共享资源的能力。企业空间中的成员可以在授权集群中创建项目，并通过邀请授权的方式参与项目协同。</li><li><strong>用户</strong>是 KubeSphere 的帐户实例，可以被设置为平台层面的管理员参与集群的管理，也可以被添加到企业空间中参与项目协同。</li></ul><blockquote><p><strong>详情查看官方文档 <a href="https://kubesphere.com.cn/docs/access-control-and-account-management/multi-tenancy-in-kubesphere/">KubeSphere 中的多租户</a></strong></p></blockquote><h3 id="4-2-平台角色"><a href="#4-2-平台角色" class="headerlink" title="4.2. 平台角色"></a>4.2. 平台角色</h3><p>平台角色概览</p><p>以 admin 登录 KubeSphere Web 控制台</p><p>点击左上角的<strong>平台管理</strong>，然后选择<strong>访问控制</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-dashboard-access.png" alt="kubesphere-dashboard-access"></p><p>在左侧导航栏中，选择<strong>平台角色</strong>。四个内置角色的描述信息如下所示。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-roles.png" alt="kubesphere-access-roles"></p><p>内置角色说明。</p><table><thead><tr><th>内置角色</th><th>描述</th></tr></thead><tbody><tr><td><code>workspaces-manager</code></td><td>企业空间管理员，管理平台所有企业空间。</td></tr><tr><td><code>users-manager</code></td><td>用户管理员，管理平台所有用户。</td></tr><tr><td><code>platform-regular</code></td><td>平台普通用户，在被邀请加入企业空间或集群之前没有任何资源操作权限。</td></tr><tr><td><code>platform-admin</code></td><td>平台管理员，可以管理平台内的所有资源。</td></tr></tbody></table><p><strong>内置角色由 KubeSphere 自动创建，无法编辑或删除。</strong></p><p><strong>常用角色</strong>。</p><ul><li><strong>platform-regular：</strong> 新建的用户赋予该角色，由企业空间管理员，邀请进具体的企业空间管理对应的资源</li><li><strong>platform-admin：</strong> 管理员比较多的时候使用</li></ul><p>除了内置角色外，用户也可以根据需求创建自定义的角色，用兴趣的读者可以参考官方文档。</p><h3 id="4-3-用户管理"><a href="#4-3-用户管理" class="headerlink" title="4.3. 用户管理"></a>4.3. 用户管理</h3><blockquote><p><strong>创建用户</strong></p></blockquote><p>以 admin 登录 KubeSphere Web 控制台。</p><p>点击左上角的<strong>平台管理</strong>，然后选择<strong>访问控制</strong>。</p><p>在左侧导航栏中，选择<strong>用户</strong>页面，点击<strong>创建</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-accounts.png" alt="kubesphere-access-accounts"></p><p>在弹出的<strong>添加用户</strong>对话框中，填写必要（带有*号）信息，点击<strong>确定</strong>。</p><ul><li><p><strong>用户名：</strong> lstack </p><blockquote><p> 正好最近备案了一个域名，用来做图床，这里就用域名当用户名了，后面需要名称的地方也都用这个命名。</p></blockquote></li><li><p><strong>邮箱：</strong> 建议写实际可用的邮箱。</p></li><li><p><strong>平台角色：</strong> platform-regular，后期由管理员邀请加入具体的企业空间，获取相应的权限。</p></li><li><p><strong>密码：</strong> 密码必须包含数字、大写字母和小写字母，长度为 6 至 64 个字符。</p></li><li><p><strong>描述：</strong> 可选，生产环境建议填写有意义的描述，说明该用户的归属、权限等信息。</p></li><li><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-accounts-add.png" alt="kubesphere-access-accounts-add"></p></li></ul><p>新创建的用户将显示在<strong>用户</strong>中的用户列表中。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-accounts-list.png" alt="kubesphere-access-accounts-list"></p><p>接下来我们再创建一个<strong>管理员</strong>用户，日常管理使用，<strong>admin</strong> 用户可以把密码设置的超级复杂然后遗忘吧，省的别人惦记。</p><p>创建过程跟上文创建普通用户都是一样的，唯一的区别在于<strong>平台角色</strong>选择 <strong>platform-admin</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-accounts-add2.png" alt="kubesphere-access-accounts-add2"></p><hr><h2 id="5-企业空间管理"><a href="#5-企业空间管理" class="headerlink" title="5. 企业空间管理"></a>5. 企业空间管理</h2><h3 id="5-1-企业空间概述"><a href="#5-1-企业空间概述" class="headerlink" title="5.1. 企业空间概述"></a>5.1. 企业空间概述</h3><p>企业空间是用来管理 <a href="https://kubesphere.com.cn/docs/project-administration/">项目</a>、<a href="https://kubesphere.com.cn/docs/devops-user-guide/">DevOps 项目</a>、<a href="https://kubesphere.com.cn/docs/workspace-administration/upload-helm-based-application/">应用模板</a> 和应用仓库的一种逻辑单元。您可以在企业空间中控制资源访问权限，也可以安全地在团队内部分享资源。</p><p>最佳的做法是为租户（集群管理员除外）创建新的企业空间。同一名租户可以在多个企业空间中工作，并且多个租户可以通过不同方式访问同一个企业空间。</p><h3 id="5-2-企业空间管理"><a href="#5-2-企业空间管理" class="headerlink" title="5.2. 企业空间管理"></a>5.2. 企业空间管理</h3><blockquote><p><strong>创建企业空间</strong></p></blockquote><p>以 <strong>admin</strong> 登录 KubeSphere Web 控制台。</p><p>点击左上角的<strong>平台管理</strong>，然后选择<strong>访问控制</strong>。</p><p>在左侧导航栏中，选择<strong>企业空间</strong>页面，点击<strong>创建</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-workspaces.png" alt="kubesphere-access-workspaces"></p><p>在弹出的<strong>创建企业空间</strong>对话框中，填写必要的<strong>基本信息</strong>（带有*号），点击<strong>创建</strong>。</p><ul><li><strong>名称</strong>：企业空间名称，本文使用 <strong>lstack</strong></li><li><strong>别名</strong>：该企业空间的别名 (从未用过)。</li><li><strong>管理员</strong>：管理该企业空间的用户，本文选择刚创建的 <strong>lstack</strong> 用户</li><li><strong>描述</strong>：企业空间的简短介绍（建议填写）。</li></ul><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-workspaces-add.png" alt="kubesphere-access-workspaces-add">企业空间创建后将显示在企业空间列表中。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-access-workspaces-list.png" alt="kubesphere-access-workspaces-list"></p><p>点击该企业空间，可以在<strong>概览</strong>页面查看企业空间中的资源状态。后续对企业空间的操作多数也是在该页面完成。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-workspaces-overview.png" alt="kubesphere-workspaces-overview"></p><hr><h2 id="6-项目管理"><a href="#6-项目管理" class="headerlink" title="6. 项目管理"></a>6. 项目管理</h2><h3 id="6-1-项目管理"><a href="#6-1-项目管理" class="headerlink" title="6.1. 项目管理"></a>6.1. 项目管理</h3><p>KubeSphere 中的项目与 Kubernetes 中的 <strong>namespaces</strong> 相同，为资源提供了虚拟隔离。有关更多信息，请参见<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/namespaces/">命名空间</a>。</p><blockquote><p><strong>创建项目</strong></p></blockquote><p>以 <strong>lstack</strong> 登录 KubeSphere Web 控制台。</p><p><strong>第一次登录会提示你重置密码</strong></p><p>登录后默认显示企业空间<strong>概览</strong>页面。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-workspaces-user-overview.png" alt="kubesphere-workspaces-user-overview"></p><p>在左侧导航栏中，选择<strong>项目</strong>页面，点击<strong>创建</strong>。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-workspaces-projects.png" alt="kubesphere-workspaces-projects"></p><p>在弹出的<strong>创建项目</strong>对话框中，填写必要的<strong>信息</strong>（带有*号），点击<strong>确定</strong>。</p><ul><li><strong>名称</strong>：项目名称，本文使用 <strong>lstack</strong>。</li><li><strong>别名</strong>：该项目的别名 (从未用过)。</li><li><strong>描述</strong>：项目的简短介绍（建议填写）。</li></ul><p><strong>项目</strong>创建后将显示在项目列表中。</p><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-workspaces-projects-list.png" alt="kubesphere-workspaces-projects-list"></p><p>点击该<strong>项目</strong>，进入项目管理页面，默认显示<strong>概览</strong>页面。可以在该页面查看项目的资源状态。</p><p><strong>下面重点展示一下项目管理菜单的功能</strong></p><blockquote><p><strong>概览</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-overview.png" alt="kubesphere-projects-overview"></p><blockquote><p><strong>应用负载</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-applications.png" alt="kubesphere-projects-applications"></p><blockquote><p><strong>存储</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-volumes.png" alt="kubesphere-projects-volumes"></p><blockquote><p><strong>配置</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-secrets.png" alt="kubesphere-projects-secrets"></p><blockquote><p><strong>镜像构建器</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-s2ibuilders.png" alt="kubesphere-projects-s2ibuilders"></p><blockquote><p><strong>监控告警</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-alerts.png" alt="kubesphere-projects-alerts"></p><blockquote><p><strong>项目设置</strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubesphere-projects-base-info.png" alt="kubesphere-projects-base-info"></p><hr><h2 id="7-底层初探"><a href="#7-底层初探" class="headerlink" title="7. 底层初探"></a>7. 底层初探</h2><p>回顾一下我们上面做了哪些主要操作，探究一下 k8s 底层又有了哪些变化。</p><p>以下涉及 <strong>kubectl</strong> 的操作使用 <strong>admin</strong> 登录</p><blockquote><p><strong>启用可插拔组件-KubeSphere 应用商店</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 namespaces(结果跟官方说的居然不一样，官方说的是在 openpitrix-system)</span></span><br><span class="line"> </span><br><span class="line">/ # kubectl get namespaces</span><br><span class="line">NAME                              STATUS   AGE</span><br><span class="line">default                           Active   5d2h</span><br><span class="line">kube-node-lease                   Active   5d2h</span><br><span class="line">kube-public                       Active   5d2h</span><br><span class="line">kube-system                       Active   5d2h</span><br><span class="line">kubekey-system                    Active   5d2h</span><br><span class="line">kubesphere-controls-system        Active   5d2h</span><br><span class="line">kubesphere-devops-system          Active   26h</span><br><span class="line">kubesphere-devops-worker          Active   26h</span><br><span class="line">kubesphere-monitoring-federated   Active   5d2h</span><br><span class="line">kubesphere-monitoring-system      Active   5d2h</span><br><span class="line">kubesphere-system                 Active   5d2h</span><br><span class="line">lstack                            Active   84m</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 pods, 只有一个名称类似的，居然还是个 job</span></span><br><span class="line"> </span><br><span class="line">/ # kubectl get pods -A | grep -i openpitrix</span><br><span class="line">kubesphere-system              openpitrix-import-job-tz6gb                        0/1     Completed   0          26h</span><br><span class="line"> </span><br></pre></td></tr></table></figure><blockquote><p><strong>启用可插拔组件-KubeSphere DevOps</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 namespaces</span></span><br><span class="line">/ # kubectl get namespaces</span><br><span class="line">NAME                              STATUS   AGE</span><br><span class="line">default                           Active   5d2h</span><br><span class="line">kube-node-lease                   Active   5d2h</span><br><span class="line">kube-public                       Active   5d2h</span><br><span class="line">kube-system                       Active   5d2h</span><br><span class="line">kubekey-system                    Active   5d2h</span><br><span class="line">kubesphere-controls-system        Active   5d2h</span><br><span class="line">kubesphere-devops-system          Active   26h</span><br><span class="line">kubesphere-devops-worker          Active   26h</span><br><span class="line">kubesphere-monitoring-federated   Active   5d2h</span><br><span class="line">kubesphere-monitoring-system      Active   5d2h</span><br><span class="line">kubesphere-system                 Active   5d2h</span><br><span class="line">lstack                            Active   94m</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 deployments</span></span><br><span class="line">/ # kubectl get deployments -n kubesphere-devops-system</span><br><span class="line">NAME                READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">devops-apiserver    1/1     1            1           31h</span><br><span class="line">devops-controller   1/1     1            1           31h</span><br><span class="line">devops-jenkins      1/1     1            1           31h</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 statefulsets</span></span><br><span class="line">/ # kubectl get statefulsets -n kubesphere-devops-system</span><br><span class="line">NAME          READY   AGE</span><br><span class="line">s2ioperator   1/1     31h</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 services</span></span><br><span class="line">/ # kubectl get svc -n kubesphere-devops-system</span><br><span class="line">NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">devops-apiserver              ClusterIP   10.233.0.8      &lt;none&gt;        9090/TCP       31h</span><br><span class="line">devops-jenkins                NodePort    10.233.55.62    &lt;none&gt;        80:30180/TCP   31h</span><br><span class="line">devops-jenkins-agent          ClusterIP   10.233.36.52    &lt;none&gt;        50000/TCP      31h</span><br><span class="line">s2ioperator-metrics-service   ClusterIP   10.233.58.210   &lt;none&gt;        8080/TCP       31h</span><br><span class="line">s2ioperator-trigger-service   ClusterIP   10.233.10.208   &lt;none&gt;        8081/TCP       31h</span><br><span class="line">webhook-server-service        ClusterIP   10.233.31.138   &lt;none&gt;        443/TCP        31h</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 pods</span></span><br><span class="line">/ # kubectl get pods -n kubesphere-devops-system</span><br><span class="line">NAME                                READY   STATUS      RESTARTS   AGE</span><br><span class="line">devops-27490020-gxmjx               0/1     Completed   0          61m</span><br><span class="line">devops-27490050-qckmj               0/1     Completed   0          31m</span><br><span class="line">devops-27490080-vmfzc               0/1     Completed   0          68s</span><br><span class="line">devops-apiserver-7c6774fff5-qtnl2   1/1     Running     0          26h</span><br><span class="line">devops-controller-98975d478-nbcj9   1/1     Running     0          26h</span><br><span class="line">devops-jenkins-5d744f66b9-cfmrj     1/1     Running     0          26h</span><br><span class="line">s2ioperator-0                       1/1     Running     0          26h</span><br><span class="line">/ # kubectl get pods -n kubesphere-devops-worker</span><br><span class="line">No resources found in kubesphere-devops-worker namespace.</span><br></pre></td></tr></table></figure><blockquote><p><strong>启用可插拔组件-KubeSphere 告警系统</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找了一圈没找到，有待更新</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>创建用户</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # kubectl get users</span><br><span class="line">NAME     EMAIL                 STATUS</span><br><span class="line">admin    admin@kubesphere.io   Active</span><br><span class="line">lstack   z@lstack.cn           Active</span><br><span class="line">z        admin@lstack.cn       Active</span><br></pre></td></tr></table></figure><blockquote><p><strong>创建企业空间</strong></p></blockquote><p><strong>KubeSphere 的概念，k8s 中并没有对应资源</strong></p><blockquote><p><strong>创建项目</strong></p></blockquote><p><strong>项目等同于 namespaces</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">搜索 namespaces</span></span><br><span class="line">/ # kubectl get namespaces</span><br><span class="line">NAME                              STATUS   AGE</span><br><span class="line">default                           Active   5d2h</span><br><span class="line">kube-node-lease                   Active   5d2h</span><br><span class="line">kube-public                       Active   5d2h</span><br><span class="line">kube-system                       Active   5d2h</span><br><span class="line">kubekey-system                    Active   5d2h</span><br><span class="line">kubesphere-controls-system        Active   5d2h</span><br><span class="line">kubesphere-devops-system          Active   26h</span><br><span class="line">kubesphere-devops-worker          Active   26h</span><br><span class="line">kubesphere-monitoring-federated   Active   5d2h</span><br><span class="line">kubesphere-monitoring-system      Active   5d2h</span><br><span class="line">kubesphere-system                 Active   5d2h</span><br><span class="line">lstack                            Active   94m</span><br></pre></td></tr></table></figure><hr><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>本文详细介绍了 KubeSphere 默认安装后，需要执行的一系列操作。主要涉及可插拔组件管理、用户管理、企业空间管理、项目管理，并初步探究了 k8s 底层的变化，更深层的技术细节会在后面实际项目中进行探究。</p><p>本文在启用可插拔组件的配置中有一个重要的组件没有启用，那就是 <strong>KubeSphere 日志系统</strong>，该插件依赖于 <strong>Elasticsearch</strong>，KubeSphere 本身内置 <strong>Elasticsearch</strong> 组件的安装，但是不建议生产环境使用，为了更贴近于生产环境，我们下一期单独介绍 <strong>Elasticsearch</strong> 的安装配置以及与 KubeSphere 的对接配置。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><a href="https://kubesphere.com.cn/docs/pluggable-components/overview/">启用可插拔组件</a></li><li><a href="https://kubesphere.com.cn/docs/access-control-and-account-management/multi-tenancy-in-kubesphere/">KubeSphere 中的多租户</a></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p>About Me</p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-KubeSphere-初始化手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-KubeSphere-初始化手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>k8s-KubeSphere 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-KubeSphere%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s-on-kubesphere/k8s-KubeSphere%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.078Z</published>
    <updated>2023-09-22T01:41:27.684Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于-KubeSphere-玩转-k8s-KubeSphere-安装手记"><a href="#基于-KubeSphere-玩转-k8s-KubeSphere-安装手记" class="headerlink" title="基于 KubeSphere 玩转 k8s-KubeSphere 安装手记"></a>基于 KubeSphere 玩转 k8s-KubeSphere 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p> 本文是基于 KubeSphere 玩转 k8s 的开篇之作，主要记录了 KubeSphere 的安装配置过程。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：26 分</li><li>行：1895</li><li>单词：10056</li><li>字符：93833</li><li>图片：0 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li><p>定级：<strong>入门级</strong></p></li><li><p>使用 Ansible 进行 k8s 服务器初始化配置</p></li><li><p>使用 KubeKey 部署 KubeSphere 和 Kubernetes</p></li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdevops-master</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">ks-k8s-master-0</td><td align="center">192.168.9.91</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-1</td><td align="center">192.168.9.92</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">ks-k8s-master-2</td><td align="center">192.168.9.93</td><td align="center">8</td><td align="center">32</td><td align="center">40</td><td align="center">200</td><td align="center">KubeSphere&#x2F;k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">glusterfs-node-0</td><td align="center">192.168.9.95</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-1</td><td align="center">192.168.9.96</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr><tr><td align="center">glusterfs-node-2</td><td align="center">192.168.9.97</td><td align="center">4</td><td align="center">8</td><td align="center">40</td><td align="center">200</td><td align="center">GlusterFS</td></tr></tbody></table><hr><h2 id="2-Ansible-配置"><a href="#2-Ansible-配置" class="headerlink" title="2. Ansible 配置"></a>2. Ansible 配置</h2><h3 id="2-1-切换到-ansible-代码目录"><a href="#2-1-切换到-ansible-代码目录" class="headerlink" title="2.1.切换到 ansible 代码目录"></a>2.1.切换到 ansible 代码目录</h3>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master dev]# cd /data/ansible/ansible-zdevops/inventories/dev</span><br><span class="line">[root@zdevops-master dev]# source /opt/ansible2.8/bin/activate</span><br></pre></td></tr></table></figure><h3 id="2-2-初始-hosts-配置"><a href="#2-2-初始-hosts-配置" class="headerlink" title="2.2. 初始 hosts 配置"></a>2.2. 初始 hosts 配置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">k8s</span>]</span><br><span class="line"><span class="string">ks-k8s-master-0</span> <span class="string">ansible_ssh_host=192.168.9.91</span>  <span class="string">host_name=ks-k8s-master-0</span></span><br><span class="line"><span class="string">ks-k8s-master-1</span> <span class="string">ansible_ssh_host=192.168.9.92</span>  <span class="string">host_name=ks-k8s-master-1</span></span><br><span class="line"><span class="string">ks-k8s-master-2</span> <span class="string">ansible_ssh_host=192.168.9.93</span>  <span class="string">host_name=ks-k8s-master-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:children</span>]</span><br><span class="line"><span class="string">k8s</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:vars</span>]</span><br><span class="line"><span class="string">ansible_connection=paramiko</span></span><br><span class="line"><span class="string">ansible_ssh_user=root</span></span><br><span class="line"><span class="string">ansible_ssh_pass=password</span></span><br></pre></td></tr></table></figure><hr><h2 id="3-服务器初始化"><a href="#3-服务器初始化" class="headerlink" title="3. 服务器初始化"></a>3. 服务器初始化</h2><h3 id="3-1-检测服务器连通性"><a href="#3-1-检测服务器连通性" class="headerlink" title="3.1. 检测服务器连通性"></a>3.1. 检测服务器连通性</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible检测服务器的连通性</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -m ping</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ks-k8s-master-2 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">ks-k8s-master-0 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">ks-k8s-master-1 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-初始化服务器配置"><a href="#3-2-初始化服务器配置" class="headerlink" title="3.2. 初始化服务器配置"></a>3.2. 初始化服务器配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook初始化服务器配置</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/init-base.yaml</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [初始化服务器配置.] ********************************************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-停止并禁用firewalld服务.] *******************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [02-配置主机名.] ******************************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [03-配置时区.] *******************************************************************************************************************************</span><br><span class="line">ok: [ks-k8s-master-0]</span><br><span class="line">ok: [ks-k8s-master-1]</span><br><span class="line">ok: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [04-配置/etc/hosts.] ***********************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统.] *****************************************************************************************************************************</span><br><span class="line">skipping: [ks-k8s-master-0]</span><br><span class="line">skipping: [ks-k8s-master-1]</span><br><span class="line">skipping: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统后如果需要重启，则重启服务器.] ***************************************************************************************************************</span><br><span class="line">skipping: [ks-k8s-master-0]</span><br><span class="line">skipping: [ks-k8s-master-1]</span><br><span class="line">skipping: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [05-等待服务器完成重启.] **************************************************************************************************************************</span><br><span class="line">skipping: [ks-k8s-master-0]</span><br><span class="line">skipping: [ks-k8s-master-1]</span><br><span class="line">skipping: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">PLAY RECAP ************************************************************************************************************************************</span><br><span class="line">ks-k8s-master-0            : ok=4    changed=3    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">ks-k8s-master-1            : ok=4    changed=3    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">ks-k8s-master-2            : ok=4    changed=3    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible同步服务器时间</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -a &#x27;yum install ntpdate -y&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">[WARNING]: Consider using the yum module rather than running &#x27;yum&#x27;.  If you need to use command because yum is</span><br><span class="line">insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27; in ansible.cfg to get</span><br><span class="line">rid of this message.</span><br><span class="line"></span><br><span class="line">ks-k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.cn99.com</span><br><span class="line"> * centos-gluster9: mirrors.cn99.com</span><br><span class="line"> * extras: mirrors.ustc.edu.cn</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package        Arch          Version                         Repository   Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ntpdate        x86_64        4.2.6p5-29.el7.centos.2         base         87 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 87 k</span><br><span class="line">Installed size: 121 k</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                       1/1 </span><br><span class="line">  Verifying  : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                       1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2                                      </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">ks-k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.ustc.edu.cn</span><br><span class="line"> * centos-gluster9: mirrors.ustc.edu.cn</span><br><span class="line"> * extras: mirrors.ustc.edu.cn</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package        Arch          Version                         Repository   Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ntpdate        x86_64        4.2.6p5-29.el7.centos.2         base         87 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 87 k</span><br><span class="line">Installed size: 121 k</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                       1/1 </span><br><span class="line">  Verifying  : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                       1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2                                      </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">ks-k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.ustc.edu.cn</span><br><span class="line"> * centos-gluster9: mirrors.ustc.edu.cn</span><br><span class="line"> * extras: mirrors.ustc.edu.cn</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">================================================================================</span><br><span class="line"> Package        Arch          Version                         Repository   Size</span><br><span class="line">================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> ntpdate        x86_64        4.2.6p5-29.el7.centos.2         base         87 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 87 k</span><br><span class="line">Installed size: 121 k</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                       1/1 </span><br><span class="line">  Verifying  : ntpdate-4.2.6p5-29.el7.centos.2.x86_64                       1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  ntpdate.x86_64 0:4.2.6p5-29.el7.centos.2                                      </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible同步服务器时间</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -a &#x27;ntpdate ntp.api.bz&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ks-k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"> 3 Apr 15:45:03 ntpdate[16375]: step time server 114.118.7.161 offset 54.841204 sec</span><br><span class="line"></span><br><span class="line">ks-k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"> 3 Apr 15:45:04 ntpdate[9559]: step time server 114.118.7.161 offset 53.892187 sec</span><br><span class="line"></span><br><span class="line">ks-k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line"> 3 Apr 15:45:05 ntpdate[44869]: step time server 114.118.7.161 offset 54.899937 sec</span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -a &#x27;date&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ks-k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Sun Apr  3 15:45:19 CST 2022</span><br><span class="line"></span><br><span class="line">ks-k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Sun Apr  3 15:45:19 CST 2022</span><br><span class="line"></span><br><span class="line">ks-k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Sun Apr  3 15:45:21 CST 2022</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-3-挂载数据盘"><a href="#3-3-挂载数据盘" class="headerlink" title="3.3. 挂载数据盘"></a>3.3. 挂载数据盘</h3><p><strong>因为 Kubekey 安装的容器运行时，数据目录默认会在 &#x2F;var&#x2F;lib&#x2F;docker, 且目前无法自定义更改，因此提前规划将该目录挂载独立的数据盘。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook初始化主机数据盘</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/init-disk.yaml</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [初始化磁盘.] *********************************************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-数据磁盘分区.] *****************************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line"></span><br><span class="line">TASK [02-格式化数据磁盘.] ****************************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line"></span><br><span class="line">TASK [03-挂载数据盘.] ******************************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">PLAY RECAP ************************************************************************************************************************************</span><br><span class="line">ks-k8s-master-0            : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">ks-k8s-master-1            : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">ks-k8s-master-2            : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-4-验证数据盘的挂载"><a href="#3-4-验证数据盘的挂载" class="headerlink" title="3.4. 验证数据盘的挂载"></a>3.4. 验证数据盘的挂载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible验证数据盘是否格式化并挂载</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -m shell -a &#x27;df -h&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ks-k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                  16G     0   16G   0% /dev</span><br><span class="line">tmpfs                     16G     0   16G   0% /dev/shm</span><br><span class="line">tmpfs                     16G  8.8M   16G   1% /run</span><br><span class="line">tmpfs                     16G     0   16G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.4G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /var/lib/docker</span><br><span class="line">tmpfs                    3.2G     0  3.2G   0% /run/user/0</span><br><span class="line"></span><br><span class="line">ks-k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                  16G     0   16G   0% /dev</span><br><span class="line">tmpfs                     16G     0   16G   0% /dev/shm</span><br><span class="line">tmpfs                     16G  8.8M   16G   1% /run</span><br><span class="line">tmpfs                     16G     0   16G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.4G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /var/lib/docker</span><br><span class="line">tmpfs                    3.2G     0  3.2G   0% /run/user/0</span><br><span class="line"></span><br><span class="line">ks-k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                  16G     0   16G   0% /dev</span><br><span class="line">tmpfs                     16G     0   16G   0% /dev/shm</span><br><span class="line">tmpfs                     16G  8.8M   16G   1% /run</span><br><span class="line">tmpfs                     16G     0   16G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.4G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /var/lib/docker</span><br><span class="line">tmpfs                    3.2G     0  3.2G   0% /run/user/0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible验证数据盘是否配置自动挂载</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -m shell -a &#x27;tail -1  /etc/fstab&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">ks-k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /var/lib/docker xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">ks-k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /var/lib/docker xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">ks-k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /var/lib/docker xfs defaults 0 0</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="4-Kubernetes-基础依赖包安装"><a href="#4-Kubernetes-基础依赖包安装" class="headerlink" title="4. Kubernetes 基础依赖包安装"></a>4. Kubernetes 基础依赖包安装</h2><h3 id="4-1-安装基础依赖包"><a href="#4-1-安装基础依赖包" class="headerlink" title="4.1. 安装基础依赖包"></a>4.1. 安装基础依赖包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible-playbook安装kubernetes基础依赖包</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ansible-playbook中设置了启用GlusterFS存储的开关，默认开启,不需要的可以将参数设置为False</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/deploy-kubesphere.yaml</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [安装k8s基础环境.] *****************************************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-安装依赖包.] ******************************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line"></span><br><span class="line">TASK [02-安装GlusterFS软件仓库.] ********************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [02-安装GlusterFS客户端.] *********************************************************************************************************************</span><br><span class="line">changed: [ks-k8s-master-0]</span><br><span class="line">changed: [ks-k8s-master-1]</span><br><span class="line">changed: [ks-k8s-master-2]</span><br><span class="line"></span><br><span class="line">PLAY RECAP ************************************************************************************************************************************</span><br><span class="line">ks-k8s-master-0            : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">ks-k8s-master-1            : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">ks-k8s-master-2            : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用ansible验证GlusterFS软件是否安装</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible k8s -m shell -a &#x27;rpm -qa | grep glusterfs&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">[WARNING]: Consider using the yum, dnf or zypper module rather than running &#x27;rpm&#x27;.  If you need to use command because yum, dnf or zypper is</span><br><span class="line">insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27; in ansible.cfg to get rid of this message.</span><br><span class="line"></span><br><span class="line">ks-k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">glusterfs-9.5-1.el7.x86_64</span><br><span class="line">glusterfs-client-xlators-9.5-1.el7.x86_64</span><br><span class="line">glusterfs-fuse-9.5-1.el7.x86_64</span><br><span class="line">libglusterfs0-9.5-1.el7.x86_64</span><br><span class="line"></span><br><span class="line">ks-k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">glusterfs-9.5-1.el7.x86_64</span><br><span class="line">glusterfs-client-xlators-9.5-1.el7.x86_64</span><br><span class="line">glusterfs-fuse-9.5-1.el7.x86_64</span><br><span class="line">libglusterfs0-9.5-1.el7.x86_64</span><br><span class="line"></span><br><span class="line">ks-k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">glusterfs-9.5-1.el7.x86_64</span><br><span class="line">glusterfs-client-xlators-9.5-1.el7.x86_64</span><br><span class="line">glusterfs-fuse-9.5-1.el7.x86_64</span><br><span class="line">libglusterfs0-9.5-1.el7.x86_64</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="5-使用-KubeKey-部署-KubeSphere-和-Kubernetes"><a href="#5-使用-KubeKey-部署-KubeSphere-和-Kubernetes" class="headerlink" title="5. 使用 KubeKey 部署 KubeSphere 和 Kubernetes"></a>5. 使用 KubeKey 部署 KubeSphere 和 Kubernetes</h2><h3 id="5-1-下载-KubeKey"><a href="#5-1-下载-KubeKey" class="headerlink" title="5.1. 下载 KubeKey"></a>5.1. 下载 KubeKey</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录ks-k8s-master-0节点</span></span><br><span class="line">[root@zdevops-master dev]# ssh root@ks-k8s-master-0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">选择中文区下载(访问github受限时使用)</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# export KKZONE=cn</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载KubeKey</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# mkdir kubekey</span><br><span class="line">[root@ks-k8s-master-0 ~]# cd kubekey/</span><br><span class="line">[root@ks-k8s-master-0 kubekey]# curl -sfL https://get-kk.kubesphere.io | VERSION=v2.0.0 sh -</span><br><span class="line"></span><br><span class="line">Downloading kubekey v2.0.0 from https://kubernetes.pek3b.qingstor.com/kubekey/releases/download/v2.0.0/kubekey-v2.0.0-linux-amd64.tar.gz ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Kubekey v2.0.0 Download Complete!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">看看下载了哪些文件</span></span><br><span class="line">[root@ks-k8s-master-0 kubekey]# ls</span><br><span class="line">kk  kubekey-v2.0.0-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加可执行权限(可选，默认已经具有执行权限)</span></span><br><span class="line">[root@ks-master-0 kubekey]# chmod +x kk</span><br></pre></td></tr></table></figure><h3 id="5-2-部署-KubeSphere-和-Kubernetes"><a href="#5-2-部署-KubeSphere-和-Kubernetes" class="headerlink" title="5.2. 部署 KubeSphere 和 Kubernetes"></a>5.2. 部署 KubeSphere 和 Kubernetes</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前版本的KubeSphere支持的Kubernetes版本，从列表中选择一个需要的版本，不在列表中的版本不受支持</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">kubekey</span>]<span class="comment"># ./kk version --show-supported-k8s</span></span><br><span class="line"><span class="string">v1.15.12</span></span><br><span class="line"><span class="string">v1.16.8</span></span><br><span class="line"><span class="string">v1.16.10</span></span><br><span class="line"><span class="string">v1.16.12</span></span><br><span class="line"><span class="string">v1.16.13</span></span><br><span class="line"><span class="string">v1.17.0</span></span><br><span class="line"><span class="string">v1.17.4</span></span><br><span class="line"><span class="string">v1.17.5</span></span><br><span class="line"><span class="string">v1.17.6</span></span><br><span class="line"><span class="string">v1.17.7</span></span><br><span class="line"><span class="string">v1.17.8</span></span><br><span class="line"><span class="string">v1.17.9</span></span><br><span class="line"><span class="string">v1.18.3</span></span><br><span class="line"><span class="string">v1.18.5</span></span><br><span class="line"><span class="string">v1.18.6</span></span><br><span class="line"><span class="string">v1.18.8</span></span><br><span class="line"><span class="string">v1.19.0</span></span><br><span class="line"><span class="string">v1.19.8</span></span><br><span class="line"><span class="string">v1.19.9</span></span><br><span class="line"><span class="string">v1.20.4</span></span><br><span class="line"><span class="string">v1.20.6</span></span><br><span class="line"><span class="string">v1.20.10</span></span><br><span class="line"><span class="string">v1.21.4</span></span><br><span class="line"><span class="string">v1.21.5</span></span><br><span class="line"><span class="string">v1.22.1</span></span><br><span class="line"><span class="string">v1.23.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建集群配置文件，选择Kubernetesv 1.21.5</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">kubekey</span>]<span class="comment"># ./kk create config --with-kubesphere v3.2.1 --with-kubernetes v1.21.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上面的操作，会在当前目录生成config-sample.yaml配置文件</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">kubekey</span>]<span class="comment"># ll</span></span><br><span class="line"><span class="string">total</span> <span class="number">68480</span></span><br><span class="line"><span class="string">-rw-r--r--</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span>     <span class="number">4777 </span><span class="string">Apr</span>  <span class="number">3</span> <span class="number">12</span><span class="string">:59</span> <span class="string">config-sample.yaml</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="number">1001  </span><span class="number">121</span> <span class="number">53764096</span> <span class="string">Mar</span>  <span class="number">8</span> <span class="number">13</span><span class="string">:05</span> <span class="string">kk</span></span><br><span class="line"><span class="string">-rw-r--r--</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">16348932</span> <span class="string">Apr</span>  <span class="number">3</span> <span class="number">12</span><span class="string">:57</span> <span class="string">kubekey-v2.0.0-linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure><h3 id="5-3-编辑配置文件"><a href="#5-3-编辑配置文件" class="headerlink" title="5.3. 编辑配置文件"></a>5.3. 编辑配置文件</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vi config-sample.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubekey.kubesphere.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Cluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sample</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">ks-k8s-master-0</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.91</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.91</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">&quot;F@ywwpTj4bJtYwzpwCqD&quot;</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">ks-k8s-master-1</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.92</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.92</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">&quot;F@ywwpTj4bJtYwzpwCqD&quot;</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">ks-k8s-master-2</span>, <span class="attr">address:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.93</span>, <span class="attr">internalAddress:</span> <span class="number">192.168</span><span class="number">.9</span><span class="number">.93</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">&quot;F@ywwpTj4bJtYwzpwCqD&quot;</span>&#125;</span><br><span class="line">  <span class="attr">roleGroups:</span></span><br><span class="line">    <span class="attr">etcd:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">    <span class="attr">control-plane:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">    <span class="attr">worker:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-0</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ks-k8s-master-2</span></span><br><span class="line">  <span class="attr">controlPlaneEndpoint:</span></span><br><span class="line">    <span class="comment">## Internal loadbalancer for apiservers </span></span><br><span class="line">    <span class="attr">internalLoadbalancer:</span> <span class="string">haproxy</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">domain:</span> <span class="string">lb.kubesphere.local</span></span><br><span class="line">    <span class="attr">address:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6443</span></span><br><span class="line">  <span class="attr">kubernetes:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1.21.5</span></span><br><span class="line">    <span class="attr">clusterName:</span> <span class="string">cluster.local</span></span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">plugin:</span> <span class="string">calico</span></span><br><span class="line">    <span class="attr">kubePodsCIDR:</span> <span class="number">10.233</span><span class="number">.64</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">    <span class="attr">kubeServiceCIDR:</span> <span class="number">10.233</span><span class="number">.0</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">    <span class="comment">## multus support. https://github.com/k8snetworkplumbingwg/multus-cni</span></span><br><span class="line">    <span class="attr">multusCNI:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">plainHTTP:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">privateRegistry:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">namespaceOverride:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">registryMirrors:</span> []</span><br><span class="line">    <span class="attr">insecureRegistries:</span> []</span><br><span class="line">  <span class="attr">addons:</span> []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">installer.kubesphere.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ks-installer</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubesphere-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v3.2.1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">persistence:</span></span><br><span class="line">    <span class="attr">storageClass:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">authentication:</span></span><br><span class="line">    <span class="attr">jwtSecret:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">local_registry:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">namespace_override:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="comment"># dev_tag: &quot;&quot;</span></span><br><span class="line">  <span class="attr">etcd:</span></span><br><span class="line">    <span class="attr">monitoring:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">endpointIps:</span> <span class="string">localhost</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">2379</span></span><br><span class="line">    <span class="attr">tlsEnable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">common:</span></span><br><span class="line">    <span class="attr">core:</span></span><br><span class="line">      <span class="attr">console:</span></span><br><span class="line">        <span class="attr">enableMultiLogin:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">30880</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">    <span class="comment"># apiserver:</span></span><br><span class="line">    <span class="comment">#  resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># controllerManager:</span></span><br><span class="line">    <span class="comment">#  resources: &#123;&#125;</span></span><br><span class="line">    <span class="attr">redis:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">volumeSize:</span> <span class="string">2Gi</span></span><br><span class="line">    <span class="attr">openldap:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">volumeSize:</span> <span class="string">2Gi</span></span><br><span class="line">    <span class="attr">minio:</span></span><br><span class="line">      <span class="attr">volumeSize:</span> <span class="string">20Gi</span></span><br><span class="line">    <span class="attr">monitoring:</span></span><br><span class="line">      <span class="comment"># type: external</span></span><br><span class="line">      <span class="attr">endpoint:</span> <span class="string">http://prometheus-operated.kubesphere-monitoring-system.svc:9090</span></span><br><span class="line">      <span class="attr">GPUMonitoring:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">gpu:</span></span><br><span class="line">      <span class="attr">kinds:</span>         </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">resourceName:</span> <span class="string">&quot;nvidia.com/gpu&quot;</span></span><br><span class="line">        <span class="attr">resourceType:</span> <span class="string">&quot;GPU&quot;</span></span><br><span class="line">        <span class="attr">default:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">es:</span></span><br><span class="line">      <span class="comment"># master:</span></span><br><span class="line">      <span class="comment">#   volumeSize: 4Gi</span></span><br><span class="line">      <span class="comment">#   replicas: 1</span></span><br><span class="line">      <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">      <span class="comment"># data:</span></span><br><span class="line">      <span class="comment">#   volumeSize: 20Gi</span></span><br><span class="line">      <span class="comment">#   replicas: 1</span></span><br><span class="line">      <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">      <span class="attr">logMaxAge:</span> <span class="number">7</span></span><br><span class="line">      <span class="attr">elkPrefix:</span> <span class="string">logstash</span></span><br><span class="line">      <span class="attr">basicAuth:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="attr">password:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">      <span class="attr">externalElasticsearchHost:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">      <span class="attr">externalElasticsearchPort:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">alerting:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># thanosruler:</span></span><br><span class="line">    <span class="comment">#   replicas: 1</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">  <span class="attr">auditing:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># operator:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># webhook:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">  <span class="attr">devops:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">jenkinsMemoryLim:</span> <span class="string">2Gi</span></span><br><span class="line">    <span class="attr">jenkinsMemoryReq:</span> <span class="string">1500Mi</span></span><br><span class="line">    <span class="attr">jenkinsVolumeSize:</span> <span class="string">8Gi</span></span><br><span class="line">    <span class="attr">jenkinsJavaOpts_Xms:</span> <span class="string">512m</span></span><br><span class="line">    <span class="attr">jenkinsJavaOpts_Xmx:</span> <span class="string">512m</span></span><br><span class="line">    <span class="attr">jenkinsJavaOpts_MaxRAM:</span> <span class="string">2g</span></span><br><span class="line">  <span class="attr">events:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># operator:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># exporter:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># ruler:</span></span><br><span class="line">    <span class="comment">#   enabled: true</span></span><br><span class="line">    <span class="comment">#   replicas: 2</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">  <span class="attr">logging:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">containerruntime:</span> <span class="string">docker</span></span><br><span class="line">    <span class="attr">logsidecar:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">      <span class="comment"># resources: &#123;&#125;</span></span><br><span class="line">  <span class="attr">metrics_server:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">monitoring:</span></span><br><span class="line">    <span class="attr">storageClass:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="comment"># kube_rbac_proxy:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># kube_state_metrics:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># prometheus:</span></span><br><span class="line">    <span class="comment">#   replicas: 1</span></span><br><span class="line">    <span class="comment">#   volumeSize: 20Gi</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment">#   operator:</span></span><br><span class="line">    <span class="comment">#     resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment">#   adapter:</span></span><br><span class="line">    <span class="comment">#     resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># node_exporter:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># alertmanager:</span></span><br><span class="line">    <span class="comment">#   replicas: 1</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment"># notification_manager:</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment">#   operator:</span></span><br><span class="line">    <span class="comment">#     resources: &#123;&#125;</span></span><br><span class="line">    <span class="comment">#   proxy:</span></span><br><span class="line">    <span class="comment">#     resources: &#123;&#125;</span></span><br><span class="line">    <span class="attr">gpu:</span></span><br><span class="line">      <span class="attr">nvidia_dcgm_exporter:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">        <span class="comment"># resources: &#123;&#125;</span></span><br><span class="line">  <span class="attr">multicluster:</span></span><br><span class="line">    <span class="attr">clusterRole:</span> <span class="string">none</span> </span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">networkpolicy:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">ippool:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">none</span></span><br><span class="line">    <span class="attr">topology:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">none</span></span><br><span class="line">  <span class="attr">openpitrix:</span></span><br><span class="line">    <span class="attr">store:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">servicemesh:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">kubeedge:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span>   </span><br><span class="line">    <span class="attr">cloudCore:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span> &#123;<span class="attr">&quot;node-role.kubernetes.io/worker&quot;:</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">      <span class="attr">tolerations:</span> []</span><br><span class="line">      <span class="attr">cloudhubPort:</span> <span class="string">&quot;10000&quot;</span></span><br><span class="line">      <span class="attr">cloudhubQuicPort:</span> <span class="string">&quot;10001&quot;</span></span><br><span class="line">      <span class="attr">cloudhubHttpsPort:</span> <span class="string">&quot;10002&quot;</span></span><br><span class="line">      <span class="attr">cloudstreamPort:</span> <span class="string">&quot;10003&quot;</span></span><br><span class="line">      <span class="attr">tunnelPort:</span> <span class="string">&quot;10004&quot;</span></span><br><span class="line">      <span class="attr">cloudHub:</span></span><br><span class="line">        <span class="attr">advertiseAddress:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="attr">nodeLimit:</span> <span class="string">&quot;100&quot;</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">cloudhubNodePort:</span> <span class="string">&quot;30000&quot;</span></span><br><span class="line">        <span class="attr">cloudhubQuicNodePort:</span> <span class="string">&quot;30001&quot;</span></span><br><span class="line">        <span class="attr">cloudhubHttpsNodePort:</span> <span class="string">&quot;30002&quot;</span></span><br><span class="line">        <span class="attr">cloudstreamNodePort:</span> <span class="string">&quot;30003&quot;</span></span><br><span class="line">        <span class="attr">tunnelNodePort:</span> <span class="string">&quot;30004&quot;</span></span><br><span class="line">    <span class="attr">edgeWatcher:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span> &#123;<span class="attr">&quot;node-role.kubernetes.io/worker&quot;:</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">      <span class="attr">tolerations:</span> []</span><br><span class="line">      <span class="attr">edgeWatcherAgent:</span></span><br><span class="line">        <span class="attr">nodeSelector:</span> &#123;<span class="attr">&quot;node-role.kubernetes.io/worker&quot;:</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">        <span class="attr">tolerations:</span> []</span><br></pre></td></tr></table></figure><ul><li><strong>spec.hosts:</strong> 填写节点信息</li><li><strong>spec.roleGroups.etcd:</strong> 填写 etc 节点的 <strong>hosts.name</strong> 字段的值</li><li><strong>spec.roleGroups.control-plane:</strong> 填写 k8s master 节点的 **hosts.name 字段的值</li><li><strong>spec.roleGroups.worker:</strong> 填写 worker 节点的 **hosts.name 字段的值</li><li><strong>spec.controlPlaneEndpoint.internalLoadbalancer:</strong> 取消注释</li></ul><h3 id="5-4-开始安装-KubeSphere-和-kubernetes"><a href="#5-4-开始安装-KubeSphere-和-kubernetes" class="headerlink" title="5.4. 开始安装 KubeSphere 和 kubernetes"></a>5.4. 开始安装 KubeSphere 和 kubernetes</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用kk开始安装</span></span><br><span class="line">[root@ks-k8s-master-0 kubekey]# ./kk create cluster -f config-sample.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> _   __      _          _   __           </span><br><span class="line">| | / /     | |        | | / /           </span><br><span class="line">| |/ / _   _| |__   ___| |/ /  ___ _   _ </span><br><span class="line">|    \| | | | &#x27;_ \ / _ \    \ / _ \ | | |</span><br><span class="line">| |\  \ |_| | |_) |  __/ |\  \  __/ |_| |</span><br><span class="line">\_| \_/\__,_|_.__/ \___\_| \_/\___|\__, |</span><br><span class="line">                                    __/ |</span><br><span class="line">                                   |___/</span><br><span class="line"></span><br><span class="line">13:01:41 CST [NodePreCheckModule] A pre-check on nodes</span><br><span class="line">13:01:42 CST success: [ks-k8s-master-1]</span><br><span class="line">13:01:42 CST success: [ks-k8s-master-2]</span><br><span class="line">13:01:42 CST success: [ks-k8s-master-0]</span><br><span class="line">13:01:42 CST [ConfirmModule] Display confirmation form</span><br><span class="line">+-----------------+------+------+---------+----------+-------+-------+-----------+--------+--------+------------+-------------+------------------+--------------+</span><br><span class="line">| name            | sudo | curl | openssl | ebtables | socat | ipset | conntrack | chrony | docker | nfs client | ceph client | glusterfs client | time         |</span><br><span class="line">+-----------------+------+------+---------+----------+-------+-------+-----------+--------+--------+------------+-------------+------------------+--------------+</span><br><span class="line">| ks-k8s-master-0 | y    | y    | y       | y        | y     | y     | y         |        |        |            |             | y                | CST 13:01:42 |</span><br><span class="line">| ks-k8s-master-1 | y    | y    | y       | y        | y     | y     | y         |        |        |            |             | y                | CST 13:01:41 |</span><br><span class="line">| ks-k8s-master-2 | y    | y    | y       | y        | y     | y     | y         |        |        |            |             | y                | CST 13:01:41 |</span><br><span class="line">+-----------------+------+------+---------+----------+-------+-------+-----------+--------+--------+------------+-------------+------------------+--------------+</span><br><span class="line"></span><br><span class="line">This is a simple check of your environment.</span><br><span class="line">Before installation, you should ensure that your machines meet all requirements specified at</span><br><span class="line">https://github.com/kubesphere/kubekey#requirements-and-recommendations</span><br><span class="line"></span><br><span class="line">Continue this installation? [yes/no]: yes</span><br><span class="line">13:01:52 CST success: [LocalHost]</span><br><span class="line">13:01:52 CST [NodeBinariesModule] Download installation binaries</span><br><span class="line">13:01:52 CST message: [localhost]</span><br><span class="line">downloading amd64 kubeadm v1.21.5 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 42.7M  100 42.7M    0     0  1032k      0  0:00:42  0:00:42 --:--:-- 1199k</span><br><span class="line">13:02:36 CST message: [localhost]</span><br><span class="line">downloading amd64 kubelet v1.21.5 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  112M  100  112M    0     0  1025k      0  0:01:52  0:01:52 --:--:-- 1201k</span><br><span class="line">13:04:31 CST message: [localhost]</span><br><span class="line">downloading amd64 kubectl v1.21.5 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 44.4M  100 44.4M    0     0  1021k      0  0:00:44  0:00:44 --:--:-- 1067k</span><br><span class="line">13:05:16 CST message: [localhost]</span><br><span class="line">downloading amd64 helm v3.6.3 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 43.0M  100 43.0M    0     0  1009k      0  0:00:43  0:00:43 --:--:--  999k</span><br><span class="line">13:06:01 CST message: [localhost]</span><br><span class="line">downloading amd64 kubecni v0.9.1 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 37.9M  100 37.9M    0     0  1034k      0  0:00:37  0:00:37 --:--:-- 1190k</span><br><span class="line">13:06:39 CST message: [localhost]</span><br><span class="line">downloading amd64 docker 20.10.8 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 58.1M  100 58.1M    0     0  37.5M      0  0:00:01  0:00:01 --:--:-- 37.5M</span><br><span class="line">13:06:41 CST message: [localhost]</span><br><span class="line">downloading amd64 crictl v1.22.0 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 17.8M  100 17.8M    0     0  1046k      0  0:00:17  0:00:17 --:--:-- 1187k</span><br><span class="line">13:06:59 CST message: [localhost]</span><br><span class="line">downloading amd64 etcd v3.4.13 ...</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 16.5M  100 16.5M    0     0  1039k      0  0:00:16  0:00:16 --:--:-- 1135k</span><br><span class="line">13:07:16 CST success: [LocalHost]</span><br><span class="line">13:07:16 CST [ConfigureOSModule] Prepare to init OS</span><br><span class="line">13:07:18 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:18 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:18 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:18 CST [ConfigureOSModule] Generate init os script</span><br><span class="line">13:07:18 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:18 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:18 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:18 CST [ConfigureOSModule] Exec init os script</span><br><span class="line">13:07:21 CST stdout: [ks-k8s-master-1]</span><br><span class="line">setenforce: SELinux is disabled</span><br><span class="line">Disabled</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_local_reserved_ports = 30000-32767</span><br><span class="line">vm.max_map_count = 262144</span><br><span class="line">vm.swappiness = 1</span><br><span class="line">fs.inotify.max_user_instances = 524288</span><br><span class="line">kernel.pid_max = 65535</span><br><span class="line">no crontab for root</span><br><span class="line">13:07:22 CST stdout: [ks-k8s-master-0]</span><br><span class="line">setenforce: SELinux is disabled</span><br><span class="line">Disabled</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_local_reserved_ports = 30000-32767</span><br><span class="line">vm.max_map_count = 262144</span><br><span class="line">vm.swappiness = 1</span><br><span class="line">fs.inotify.max_user_instances = 524288</span><br><span class="line">kernel.pid_max = 65535</span><br><span class="line">no crontab for root</span><br><span class="line">13:07:22 CST stdout: [ks-k8s-master-2]</span><br><span class="line">setenforce: SELinux is disabled</span><br><span class="line">Disabled</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_local_reserved_ports = 30000-32767</span><br><span class="line">vm.max_map_count = 262144</span><br><span class="line">vm.swappiness = 1</span><br><span class="line">fs.inotify.max_user_instances = 524288</span><br><span class="line">kernel.pid_max = 65535</span><br><span class="line">no crontab for root</span><br><span class="line">13:07:22 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:22 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:22 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:22 CST [ConfigureOSModule] configure the ntp server for each node</span><br><span class="line">13:07:22 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:07:22 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:07:22 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:07:22 CST [KubernetesStatusModule] Get kubernetes cluster status</span><br><span class="line">13:07:25 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:25 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:25 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:25 CST [InstallContainerModule] Sync docker binaries</span><br><span class="line">13:07:31 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:31 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:31 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:31 CST [InstallContainerModule] Generate containerd service</span><br><span class="line">13:07:32 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:32 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:32 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:32 CST [InstallContainerModule] Enable containerd</span><br><span class="line">13:07:35 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:35 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:35 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:35 CST [InstallContainerModule] Generate docker service</span><br><span class="line">13:07:36 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:36 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:36 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:36 CST [InstallContainerModule] Generate docker config</span><br><span class="line">13:07:36 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:36 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:36 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:36 CST [InstallContainerModule] Enable docker</span><br><span class="line">13:07:38 CST success: [ks-k8s-master-0]</span><br><span class="line">13:07:38 CST success: [ks-k8s-master-1]</span><br><span class="line">13:07:38 CST success: [ks-k8s-master-2]</span><br><span class="line">13:07:38 CST [InstallContainerModule] Add auths to container runtime</span><br><span class="line">13:07:38 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:07:38 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:07:38 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:07:38 CST [PullModule] Start to pull images on all nodes</span><br><span class="line">13:07:38 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1</span><br><span class="line">13:07:38 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1</span><br><span class="line">13:07:38 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1</span><br><span class="line">13:07:39 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.21.5</span><br><span class="line">13:07:44 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.21.5</span><br><span class="line">13:07:44 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-apiserver:v1.21.5</span><br><span class="line">13:07:45 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.21.5</span><br><span class="line">13:07:51 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.21.5</span><br><span class="line">13:07:51 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controller-manager:v1.21.5</span><br><span class="line">13:07:52 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.21.5</span><br><span class="line">13:08:00 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.21.5</span><br><span class="line">13:08:01 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.21.5</span><br><span class="line">13:08:04 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-scheduler:v1.21.5</span><br><span class="line">13:08:05 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.21.5</span><br><span class="line">13:08:07 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/coredns:1.8.0</span><br><span class="line">13:08:07 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-proxy:v1.21.5</span><br><span class="line">13:08:11 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/k8s-dns-node-cache:1.15.12</span><br><span class="line">13:08:11 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/coredns:1.8.0</span><br><span class="line">13:08:14 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/coredns:1.8.0</span><br><span class="line">13:08:14 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/k8s-dns-node-cache:1.15.12</span><br><span class="line">13:08:17 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/k8s-dns-node-cache:1.15.12</span><br><span class="line">13:08:17 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controllers:v3.20.0</span><br><span class="line">13:08:21 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controllers:v3.20.0</span><br><span class="line">13:08:22 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/cni:v3.20.0</span><br><span class="line">13:08:23 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/kube-controllers:v3.20.0</span><br><span class="line">13:08:25 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/cni:v3.20.0</span><br><span class="line">13:08:28 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/cni:v3.20.0</span><br><span class="line">13:08:30 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/node:v3.20.0</span><br><span class="line">13:08:34 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/node:v3.20.0</span><br><span class="line">13:08:36 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/node:v3.20.0</span><br><span class="line">13:08:41 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/pod2daemon-flexvol:v3.20.0</span><br><span class="line">13:08:43 CST message: [ks-k8s-master-1]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/haproxy:2.3</span><br><span class="line">13:08:46 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/pod2daemon-flexvol:v3.20.0</span><br><span class="line">13:08:48 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/pod2daemon-flexvol:v3.20.0</span><br><span class="line">13:08:49 CST message: [ks-k8s-master-0]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/haproxy:2.3</span><br><span class="line">13:08:52 CST message: [ks-k8s-master-2]</span><br><span class="line">downloading image: registry.cn-beijing.aliyuncs.com/kubesphereio/haproxy:2.3</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:01 CST [ETCDPreCheckModule] Get etcd status</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:01 CST [CertsModule] Fetcd etcd certs</span><br><span class="line">13:09:01 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:01 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:09:01 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:09:01 CST [CertsModule] Generate etcd Certs</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] admin-ks-k8s-master-0 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] member-ks-k8s-master-0 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] node-ks-k8s-master-0 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] admin-ks-k8s-master-1 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] member-ks-k8s-master-1 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] node-ks-k8s-master-1 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] admin-ks-k8s-master-2 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] member-ks-k8s-master-2 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] node-ks-k8s-master-2 serving cert is signed for DNS names [etcd etcd.kube-system etcd.kube-system.svc etcd.kube-system.svc.cluster.local ks-k8s-master-0 ks-k8s-master-1 ks-k8s-master-2 lb.kubesphere.local localhost] and IPs [127.0.0.1 ::1 192.168.9.91 192.168.9.92 192.168.9.93]</span><br><span class="line">13:09:06 CST success: [LocalHost]</span><br><span class="line">13:09:06 CST [CertsModule] Synchronize certs file</span><br><span class="line">13:09:17 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:17 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:17 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:17 CST [CertsModule] Synchronize certs file to master</span><br><span class="line">13:09:17 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:09:17 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:09:17 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:09:17 CST [InstallETCDBinaryModule] Install etcd using binary</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:19 CST [InstallETCDBinaryModule] Generate etcd service</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:19 CST [InstallETCDBinaryModule] Generate access address</span><br><span class="line">13:09:19 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:09:19 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:09:19 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:19 CST [ETCDConfigureModule] Health check on exist etcd</span><br><span class="line">13:09:19 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:09:19 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:09:19 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:09:19 CST [ETCDConfigureModule] Generate etcd.env config on new etcd</span><br><span class="line">13:09:21 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:21 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:21 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:21 CST [ETCDConfigureModule] Refresh etcd.env config on all etcd</span><br><span class="line">13:09:22 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:22 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:22 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:22 CST [ETCDConfigureModule] Restart etcd</span><br><span class="line">13:09:26 CST stdout: [ks-k8s-master-1]</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /etc/systemd/system/etcd.service.</span><br><span class="line">13:09:26 CST stdout: [ks-k8s-master-2]</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /etc/systemd/system/etcd.service.</span><br><span class="line">13:09:26 CST stdout: [ks-k8s-master-0]</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/etcd.service to /etc/systemd/system/etcd.service.</span><br><span class="line">13:09:26 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:26 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:26 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:26 CST [ETCDConfigureModule] Health check on all etcd</span><br><span class="line">13:09:26 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:26 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:26 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:26 CST [ETCDConfigureModule] Refresh etcd.env config to exist mode on all etcd</span><br><span class="line">13:09:28 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:28 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:28 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:28 CST [ETCDConfigureModule] Health check on all etcd</span><br><span class="line">13:09:28 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:28 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:28 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:28 CST [ETCDBackupModule] Backup etcd data regularly</span><br><span class="line">13:09:35 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:35 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:35 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:35 CST [InstallKubeBinariesModule] Synchronize kubernetes binaries</span><br><span class="line">13:09:53 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:53 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:53 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:53 CST [InstallKubeBinariesModule] Synchronize kubelet</span><br><span class="line">13:09:53 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:53 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:53 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:53 CST [InstallKubeBinariesModule] Generate kubelet service</span><br><span class="line">13:09:54 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:54 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:54 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:54 CST [InstallKubeBinariesModule] Enable kubelet service</span><br><span class="line">13:09:54 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:54 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:54 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:54 CST [InstallKubeBinariesModule] Generate kubelet env</span><br><span class="line">13:09:55 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:55 CST success: [ks-k8s-master-1]</span><br><span class="line">13:09:55 CST success: [ks-k8s-master-2]</span><br><span class="line">13:09:55 CST [InitKubernetesModule] Generate kubeadm config</span><br><span class="line">13:09:55 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:09:55 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:09:55 CST success: [ks-k8s-master-0]</span><br><span class="line">13:09:55 CST [InitKubernetesModule] Init cluster using kubeadm</span><br><span class="line">13:10:28 CST stdout: [ks-k8s-master-0]</span><br><span class="line">W0403 13:09:55.943937    7632 utils.go:69] The recommended value for &quot;clusterDNS&quot; in &quot;KubeletConfiguration&quot; is: [10.233.0.10]; the provided value is: [169.254.25.10]</span><br><span class="line">[init] Using Kubernetes version: v1.21.5</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [ks-k8s-master-0 ks-k8s-master-0.cluster.local ks-k8s-master-1 ks-k8s-master-1.cluster.local ks-k8s-master-2 ks-k8s-master-2.cluster.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lb.kubesphere.local localhost] and IPs [10.233.0.1 192.168.9.91 127.0.0.1 192.168.9.92 192.168.9.93]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] External etcd mode: Skipping etcd/ca certificate authority generation</span><br><span class="line">[certs] External etcd mode: Skipping etcd/server certificate generation</span><br><span class="line">[certs] External etcd mode: Skipping etcd/peer certificate generation</span><br><span class="line">[certs] External etcd mode: Skipping etcd/healthcheck-client certificate generation</span><br><span class="line">[certs] External etcd mode: Skipping apiserver-etcd-client certificate generation</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 21.505575 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.21&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node ks-k8s-master-0 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node ks-k8s-master-0 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: trplud.imfongtz95d70seh</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of control-plane nodes by copying certificate authorities</span><br><span class="line">and service account keys on each node and then running the following as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join lb.kubesphere.local:6443 --token trplud.imfongtz95d70seh \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:952a8ef81ae3b4a1a05b5ef9f6b3772e5e9ffa3e8bd9881e189784d427fa085b \</span><br><span class="line">        --control-plane </span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join lb.kubesphere.local:6443 --token trplud.imfongtz95d70seh \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:952a8ef81ae3b4a1a05b5ef9f6b3772e5e9ffa3e8bd9881e189784d427fa085b</span><br><span class="line">13:10:28 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:28 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:28 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:28 CST [InitKubernetesModule] Copy admin.conf to ~/.kube/config</span><br><span class="line">13:10:29 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:29 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:29 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:29 CST [InitKubernetesModule] Remove master taint</span><br><span class="line">13:10:29 CST stdout: [ks-k8s-master-0]</span><br><span class="line">node/ks-k8s-master-0 untainted</span><br><span class="line">13:10:29 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:29 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:29 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:29 CST [InitKubernetesModule] Add worker label</span><br><span class="line">13:10:29 CST stdout: [ks-k8s-master-0]</span><br><span class="line">node/ks-k8s-master-0 labeled</span><br><span class="line">13:10:29 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:29 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:29 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:29 CST [ClusterDNSModule] Generate coredns service</span><br><span class="line">13:10:30 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:30 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:30 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:30 CST [ClusterDNSModule] Override coredns service</span><br><span class="line">13:10:30 CST stdout: [ks-k8s-master-0]</span><br><span class="line">service &quot;kube-dns&quot; deleted</span><br><span class="line">13:10:31 CST stdout: [ks-k8s-master-0]</span><br><span class="line">service/coredns created</span><br><span class="line">Warning: resource clusterroles/system:coredns is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns configured</span><br><span class="line">13:10:31 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:31 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:31 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:31 CST [ClusterDNSModule] Generate nodelocaldns</span><br><span class="line">13:10:31 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:31 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:31 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:31 CST [ClusterDNSModule] Deploy nodelocaldns</span><br><span class="line">13:10:32 CST stdout: [ks-k8s-master-0]</span><br><span class="line">serviceaccount/nodelocaldns created</span><br><span class="line">daemonset.apps/nodelocaldns created</span><br><span class="line">13:10:32 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:32 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:32 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:32 CST [ClusterDNSModule] Generate nodelocaldns configmap</span><br><span class="line">13:10:32 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:32 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:32 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:32 CST [ClusterDNSModule] Apply nodelocaldns configmap</span><br><span class="line">13:10:33 CST stdout: [ks-k8s-master-0]</span><br><span class="line">configmap/nodelocaldns created</span><br><span class="line">13:10:33 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:33 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:33 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:33 CST [KubernetesStatusModule] Get kubernetes cluster status</span><br><span class="line">13:10:33 CST stdout: [ks-k8s-master-0]</span><br><span class="line">v1.21.5</span><br><span class="line">13:10:33 CST stdout: [ks-k8s-master-0]</span><br><span class="line">ks-k8s-master-0   v1.21.5   [map[address:192.168.9.91 type:InternalIP] map[address:ks-k8s-master-0 type:Hostname]]</span><br><span class="line">13:10:35 CST stdout: [ks-k8s-master-0]</span><br><span class="line">I0403 13:10:35.044308    9697 version.go:254] remote version is much newer: v1.23.5; falling back to: stable-1.21</span><br><span class="line">[upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[upload-certs] Using certificate key:</span><br><span class="line">7f336d1ef4ba900e254f5503dd7f5ab9f94333939564155e74635ba0c74050b1</span><br><span class="line">13:10:36 CST stdout: [ks-k8s-master-0]</span><br><span class="line">secret/kubeadm-certs patched</span><br><span class="line">13:10:36 CST stdout: [ks-k8s-master-0]</span><br><span class="line">secret/kubeadm-certs patched</span><br><span class="line">13:10:36 CST stdout: [ks-k8s-master-0]</span><br><span class="line">secret/kubeadm-certs patched</span><br><span class="line">13:10:36 CST stdout: [ks-k8s-master-0]</span><br><span class="line">zf886x.zo915d50drm7r76g</span><br><span class="line">13:10:37 CST success: [ks-k8s-master-0]</span><br><span class="line">13:10:37 CST success: [ks-k8s-master-1]</span><br><span class="line">13:10:37 CST success: [ks-k8s-master-2]</span><br><span class="line">13:10:37 CST [JoinNodesModule] Generate kubeadm config</span><br><span class="line">13:10:37 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:10:37 CST success: [ks-k8s-master-1]</span><br><span class="line">13:10:37 CST success: [ks-k8s-master-2]</span><br><span class="line">13:10:37 CST [JoinNodesModule] Join control-plane node</span><br><span class="line">13:10:58 CST stdout: [ks-k8s-master-1]</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">W0403 13:10:43.690219    7522 utils.go:69] The recommended value for &quot;clusterDNS&quot; in &quot;KubeletConfiguration&quot; is: [10.233.0.10]; the provided value is: [169.254.25.10]</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[download-certs] Downloading the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [ks-k8s-master-0 ks-k8s-master-0.cluster.local ks-k8s-master-1 ks-k8s-master-1.cluster.local ks-k8s-master-2 ks-k8s-master-2.cluster.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lb.kubesphere.local localhost] and IPs [10.233.0.1 192.168.9.92 127.0.0.1 192.168.9.91 192.168.9.93]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[check-etcd] Skipping etcd check in external mode</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[control-plane-join] using external etcd - no local stacked instance added</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[mark-control-plane] Marking the node ks-k8s-master-1 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node ks-k8s-master-1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">        mkdir -p $HOME/.kube</span><br><span class="line">        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">        sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; to see this node join the cluster.</span><br><span class="line">13:10:59 CST stdout: [ks-k8s-master-2]</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">W0403 13:10:43.758537    7528 utils.go:69] The recommended value for &quot;clusterDNS&quot; in &quot;KubeletConfiguration&quot; is: [10.233.0.10]; the provided value is: [169.254.25.10]</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[download-certs] Downloading the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [ks-k8s-master-0 ks-k8s-master-0.cluster.local ks-k8s-master-1 ks-k8s-master-1.cluster.local ks-k8s-master-2 ks-k8s-master-2.cluster.local kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lb.kubesphere.local localhost] and IPs [10.233.0.1 192.168.9.93 127.0.0.1 192.168.9.91 192.168.9.92]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[check-etcd] Skipping etcd check in external mode</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[control-plane-join] using external etcd - no local stacked instance added</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[mark-control-plane] Marking the node ks-k8s-master-2 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node ks-k8s-master-2 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">        mkdir -p $HOME/.kube</span><br><span class="line">        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">        sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; to see this node join the cluster.</span><br><span class="line">13:10:59 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:10:59 CST success: [ks-k8s-master-1]</span><br><span class="line">13:10:59 CST success: [ks-k8s-master-2]</span><br><span class="line">13:10:59 CST [JoinNodesModule] Join worker node</span><br><span class="line">13:10:59 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:10:59 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:10:59 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:10:59 CST [JoinNodesModule] Copy admin.conf to ~/.kube/config</span><br><span class="line">13:11:00 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:00 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:00 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:00 CST [JoinNodesModule] Remove master taint</span><br><span class="line">13:11:00 CST stdout: [ks-k8s-master-1]</span><br><span class="line">node/ks-k8s-master-1 untainted</span><br><span class="line">13:11:01 CST stdout: [ks-k8s-master-2]</span><br><span class="line">node/ks-k8s-master-2 untainted</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST [JoinNodesModule] Add worker label to master</span><br><span class="line">13:11:01 CST stdout: [ks-k8s-master-1]</span><br><span class="line">node/ks-k8s-master-1 labeled</span><br><span class="line">13:11:01 CST stdout: [ks-k8s-master-2]</span><br><span class="line">node/ks-k8s-master-2 labeled</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST [JoinNodesModule] Synchronize kube config to worker</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST [JoinNodesModule] Add worker label to worker</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST [InternalLoadbalancerModule] Generate haproxy.cfg</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST [InternalLoadbalancerModule] Calculate the MD5 value according to haproxy.cfg</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST [InternalLoadbalancerModule] Generate haproxy manifest</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-0]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:01 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:01 CST [InternalLoadbalancerModule] Update kubelet config</span><br><span class="line">13:11:01 CST stdout: [ks-k8s-master-0]</span><br><span class="line">server: https://lb.kubesphere.local:6443</span><br><span class="line">13:11:01 CST stdout: [ks-k8s-master-1]</span><br><span class="line">server: https://lb.kubesphere.local:6443</span><br><span class="line">13:11:01 CST stdout: [ks-k8s-master-2]</span><br><span class="line">server: https://lb.kubesphere.local:6443</span><br><span class="line">13:11:02 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:02 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:02 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:02 CST [InternalLoadbalancerModule] Update kube-proxy configmap</span><br><span class="line">13:11:03 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:03 CST [InternalLoadbalancerModule] Update /etc/hosts</span><br><span class="line">13:11:03 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:03 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:03 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:03 CST [DeployNetworkPluginModule] Generate calico</span><br><span class="line">13:11:04 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:04 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:04 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:04 CST [DeployNetworkPluginModule] Deploy calico</span><br><span class="line">13:11:05 CST stdout: [ks-k8s-master-0]</span><br><span class="line">configmap/calico-config created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">daemonset.apps/calico-node created</span><br><span class="line">serviceaccount/calico-node created</span><br><span class="line">deployment.apps/calico-kube-controllers created</span><br><span class="line">serviceaccount/calico-kube-controllers created</span><br><span class="line">Warning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget</span><br><span class="line">poddisruptionbudget.policy/calico-kube-controllers created</span><br><span class="line">13:11:05 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:05 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:05 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:05 CST [ConfigureKubernetesModule] Configure kubernetes</span><br><span class="line">13:11:05 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:05 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:05 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:05 CST [ChownModule] Chown user $HOME/.kube dir</span><br><span class="line">13:11:06 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:06 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:06 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:06 CST [AutoRenewCertsModule] Generate k8s certs renew script</span><br><span class="line">13:11:06 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:06 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:06 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:06 CST [AutoRenewCertsModule] Generate k8s certs renew service</span><br><span class="line">13:11:07 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:07 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:07 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:07 CST [AutoRenewCertsModule] Generate k8s certs renew timer</span><br><span class="line">13:11:07 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:07 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:07 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:07 CST [AutoRenewCertsModule] Enable k8s certs renew service</span><br><span class="line">13:11:08 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:08 CST success: [ks-k8s-master-1]</span><br><span class="line">13:11:08 CST success: [ks-k8s-master-2]</span><br><span class="line">13:11:08 CST [SaveKubeConfigModule] Save kube config as a configmap</span><br><span class="line">13:11:08 CST success: [LocalHost]</span><br><span class="line">13:11:08 CST [AddonsModule] Install addons</span><br><span class="line">13:11:08 CST success: [LocalHost]</span><br><span class="line">13:11:08 CST [DeployStorageClassModule] Generate OpenEBS manifest</span><br><span class="line">13:11:08 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:08 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:08 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:08 CST [DeployStorageClassModule] Deploy OpenEBS as cluster default StorageClass</span><br><span class="line">13:11:09 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:09 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:09 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:09 CST [DeployKubeSphereModule] Generate KubeSphere ks-installer crd manifests</span><br><span class="line">13:11:10 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:10 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:10 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:10 CST [DeployKubeSphereModule] Apply ks-installer</span><br><span class="line">13:11:11 CST stdout: [ks-k8s-master-0]</span><br><span class="line">namespace/kubesphere-system created</span><br><span class="line">serviceaccount/ks-installer created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/clusterconfigurations.installer.kubesphere.io created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/ks-installer created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/ks-installer created</span><br><span class="line">deployment.apps/ks-installer created</span><br><span class="line">13:11:11 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:11 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:11 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:11 CST [DeployKubeSphereModule] Add config to ks-installer manifests</span><br><span class="line">13:11:11 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:11 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:11 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:11 CST [DeployKubeSphereModule] Create the kubesphere namespace</span><br><span class="line">13:11:12 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:12 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:12 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:12 CST [DeployKubeSphereModule] Setup ks-installer config</span><br><span class="line">13:11:12 CST stdout: [ks-k8s-master-0]</span><br><span class="line">secret/kube-etcd-client-certs created</span><br><span class="line">13:11:12 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:12 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:12 CST success: [ks-k8s-master-0]</span><br><span class="line">13:11:12 CST [DeployKubeSphereModule] Apply ks-installer</span><br><span class="line">13:11:18 CST stdout: [ks-k8s-master-0]</span><br><span class="line">namespace/kubesphere-system unchanged</span><br><span class="line">serviceaccount/ks-installer unchanged</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/clusterconfigurations.installer.kubesphere.io unchanged</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/ks-installer unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/ks-installer unchanged</span><br><span class="line">deployment.apps/ks-installer unchanged</span><br><span class="line">clusterconfiguration.installer.kubesphere.io/ks-installer created</span><br><span class="line">13:11:18 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:11:18 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:11:18 CST success: [ks-k8s-master-0]</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##              Welcome to KubeSphere!           ###</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"></span><br><span class="line">Console: http://192.168.9.91:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you log into the console, please check the</span><br><span class="line">     monitoring status of service components in</span><br><span class="line">     &quot;Cluster Management&quot;. If any service is not</span><br><span class="line">     ready, please wait patiently until all components </span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line">https://kubesphere.io             2022-04-03 13:27:48</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line">13:27:51 CST skipped: [ks-k8s-master-2]</span><br><span class="line">13:27:51 CST skipped: [ks-k8s-master-1]</span><br><span class="line">13:27:51 CST success: [ks-k8s-master-0]</span><br><span class="line">13:27:51 CST Pipeline[CreateClusterPipeline] execute successful</span><br><span class="line">Installation is complete.</span><br><span class="line"></span><br><span class="line">Please check the result using the command:</span><br><span class="line"></span><br><span class="line">        kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>安装开始时间：13:01:41</strong></li><li><strong>安装完成时间： 13:27:51</strong></li><li><strong>安装总用时 : 26:10</strong></li></ul><h3 id="5-5-验证安装"><a href="#5-5-验证安装" class="headerlink" title="5.5. 验证安装"></a>5.5. 验证安装</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行以下命令查看安装日志</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-1</span> <span class="string">~</span>]<span class="comment"># kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只要看到&quot;Welcome to KubeSphere!&quot;,说明安装成功</span></span><br><span class="line"><span class="comment"># 截取以下内容，看看详细效果</span></span><br><span class="line"></span><br><span class="line"><span class="string">.......</span></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Initing</span> <span class="string">KubeSphere</span>] <span class="string">***********************</span></span><br><span class="line"><span class="attr">changed:</span> [<span class="string">localhost</span>] <span class="string">=&gt;</span> <span class="string">(item=role-templates.yaml)</span></span><br><span class="line"></span><br><span class="line"><span class="string">TASK</span> [<span class="attr">ks-core/prepare :</span> <span class="string">KubeSphere</span> <span class="string">|</span> <span class="string">Generating</span> <span class="string">kubeconfig-admin</span>] <span class="string">**************</span></span><br><span class="line"><span class="attr">skipping:</span> [<span class="string">localhost</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">PLAY</span> <span class="string">RECAP</span> <span class="string">*********************************************************************</span></span><br><span class="line"><span class="attr">localhost                  :</span> <span class="string">ok=25</span>   <span class="string">changed=18</span>   <span class="string">unreachable=0</span>    <span class="string">failed=0</span>    <span class="string">skipped=13</span>   <span class="string">rescued=0</span>    <span class="string">ignored=0</span>   </span><br><span class="line"></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">monitoring</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">multicluster</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">openpitrix</span></span><br><span class="line"><span class="string">Start</span> <span class="string">installing</span> <span class="string">network</span></span><br><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Waiting</span> <span class="string">for</span> <span class="string">all</span> <span class="string">tasks</span> <span class="string">to</span> <span class="string">be</span> <span class="string">completed</span> <span class="string">...</span></span><br><span class="line"><span class="string">task</span> <span class="string">network</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(1/4)</span></span><br><span class="line"><span class="string">task</span> <span class="string">openpitrix</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(2/4)</span></span><br><span class="line"><span class="string">task</span> <span class="string">multicluster</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(3/4)</span></span><br><span class="line"><span class="string">task</span> <span class="string">monitoring</span> <span class="string">status</span> <span class="string">is</span> <span class="string">successful</span>  <span class="string">(4/4)</span></span><br><span class="line"><span class="string">**************************************************</span></span><br><span class="line"><span class="string">Collecting</span> <span class="string">installation</span> <span class="string">results</span> <span class="string">...</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="comment">###              Welcome to KubeSphere!           ###</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Console:</span> <span class="string">http://192.168.9.91:30880</span></span><br><span class="line"><span class="attr">Account:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">Password:</span> <span class="string">P@88w0rd</span></span><br><span class="line"></span><br><span class="line"><span class="string">NOTES：</span></span><br><span class="line">  <span class="number">1</span><span class="string">.</span> <span class="string">After</span> <span class="string">you</span> <span class="string">log</span> <span class="string">into</span> <span class="string">the</span> <span class="string">console,</span> <span class="string">please</span> <span class="string">check</span> <span class="string">the</span></span><br><span class="line">     <span class="string">monitoring</span> <span class="string">status</span> <span class="string">of</span> <span class="string">service</span> <span class="string">components</span> <span class="string">in</span></span><br><span class="line">     <span class="string">&quot;Cluster Management&quot;</span><span class="string">.</span> <span class="string">If</span> <span class="string">any</span> <span class="string">service</span> <span class="string">is</span> <span class="string">not</span></span><br><span class="line">     <span class="string">ready,</span> <span class="string">please</span> <span class="string">wait</span> <span class="string">patiently</span> <span class="string">until</span> <span class="string">all</span> <span class="string">components</span> </span><br><span class="line">     <span class="string">are</span> <span class="string">up</span> <span class="string">and</span> <span class="string">running.</span></span><br><span class="line">  <span class="number">2</span><span class="string">.</span> <span class="string">Please</span> <span class="string">change</span> <span class="string">the</span> <span class="string">default</span> <span class="string">password</span> <span class="string">after</span> <span class="string">login.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="string">https://kubesphere.io</span>             <span class="number">2022-04-03 13:27:48</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="5-6-查看-k8s-节点信息"><a href="#5-6-查看-k8s-节点信息" class="headerlink" title="5.6. 查看 k8s 节点信息"></a>5.6. 查看 k8s 节点信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 kubekey]# kubectl get nodes -o wide</span><br><span class="line">NAME              STATUS   ROLES                         AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">ks-k8s-master-0   Ready    control-plane,master,worker   90m   v1.21.5   192.168.9.91   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   docker://20.10.8</span><br><span class="line">ks-k8s-master-1   Ready    control-plane,master,worker   90m   v1.21.5   192.168.9.92   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   docker://20.10.8</span><br><span class="line">ks-k8s-master-2   Ready    control-plane,master,worker   90m   v1.21.5   192.168.9.93   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   docker://20.10.8</span><br></pre></td></tr></table></figure><h3 id="5-7-配置-bash-自动补全功能"><a href="#5-7-配置-bash-自动补全功能" class="headerlink" title="5.7. 配置 bash 自动补全功能"></a>5.7. 配置 bash 自动补全功能</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 zdevops]# yum install bash-completion</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.cn99.com</span><br><span class="line"> * centos-gluster9: mirrors.cn99.com</span><br><span class="line"> * extras: mirrors.ustc.edu.cn</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package bash-completion.noarch 1:2.1-8.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">=====================================================================================================================</span><br><span class="line"> Package                          Arch                    Version                        Repository             Size</span><br><span class="line">=====================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> bash-completion                  noarch                  1:2.1-8.el7                    base                   87 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">=====================================================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 87 k</span><br><span class="line">Installed size: 263 k</span><br><span class="line">Is this ok [y/d/N]: y</span><br><span class="line">Downloading packages:</span><br><span class="line">bash-completion-2.1-8.el7.noarch.rpm                                                          |  87 kB  00:00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : 1:bash-completion-2.1-8.el7.noarch                                                                1/1 </span><br><span class="line">  Verifying  : 1:bash-completion-2.1-8.el7.noarch                                                                1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  bash-completion.noarch 1:2.1-8.el7                                                                                 </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl 补全脚本导入（<span class="built_in">source</span>）到 shell 会话中，两种方法二选一</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方法一：当前用户</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方法二：系统全局</span></span><br><span class="line">kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl &gt; /dev/null</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">本文选择第一种，使<span class="built_in">source</span>生效</span></span><br><span class="line">[root@ks-k8s-master-0 ~]# source ~/.bashrc </span><br><span class="line">[root@ks-k8s-master-0 ~]# kubectl get n</span><br><span class="line">namespacenetworkpolicies.network.kubesphere.io   networksets.crd.projectcalico.org</span><br><span class="line">namespaces                                       nginxes.gateway.kubesphere.io</span><br><span class="line">networkpolicies.crd.projectcalico.org            nodes</span><br><span class="line">networkpolicies.networking.k8s.io                notificationmanagers.notification.kubesphere.io</span><br></pre></td></tr></table></figure><hr><h2 id="6-深入探究"><a href="#6-深入探究" class="headerlink" title="6. 深入探究"></a>6. 深入探究</h2><h3 id="6-1-docker-的安装方式及位置"><a href="#6-1-docker-的安装方式及位置" class="headerlink" title="6.1. docker 的安装方式及位置"></a>6.1. docker 的安装方式及位置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二进制的方式安装</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装路径</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-1</span> <span class="string">~</span>]<span class="comment"># ls -l /usr/bin/docker*</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="number">1000 </span><span class="number">1000 </span><span class="number">52883072</span> <span class="string">Jul</span> <span class="number">31</span>  <span class="number">2021</span> <span class="string">/usr/bin/docker</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="number">1000 </span><span class="number">1000 </span><span class="number">64758664</span> <span class="string">Jul</span> <span class="number">31</span>  <span class="number">2021</span> <span class="string">/usr/bin/dockerd</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="number">1000 </span><span class="number">1000   </span><span class="number">708616</span> <span class="string">Jul</span> <span class="number">31</span>  <span class="number">2021</span> <span class="string">/usr/bin/docker-init</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="number">1000 </span><span class="number">1000  </span><span class="number">2784649</span> <span class="string">Jul</span> <span class="number">31</span>  <span class="number">2021</span> <span class="string">/usr/bin/docker-proxy</span></span><br></pre></td></tr></table></figure><h3 id="6-2-kubenetes-如何安装的？装了什么组件？"><a href="#6-2-kubenetes-如何安装的？装了什么组件？" class="headerlink" title="6.2. kubenetes 如何安装的？装了什么组件？"></a>6.2. kubenetes 如何安装的？装了什么组件？</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二进制的方式安装</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装路径及文件</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">kubekey</span>]<span class="comment"># ll -R /usr/local/bin/ </span></span><br><span class="line"><span class="string">/usr/local/bin/:</span></span><br><span class="line"><span class="string">total</span> <span class="number">289488</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">23847904</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">etcd</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">17620576</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">etcdctl</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">45113344</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">helm</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">44851200</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">kubeadm</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">46645248</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">kubectl</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">118353264</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">kubelet</span></span><br><span class="line"><span class="string">drwxr-xr-x</span> <span class="number">2</span> <span class="string">kube</span> <span class="string">root</span>        <span class="number">71</span> <span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:44</span> <span class="string">kube-scripts</span></span><br><span class="line"></span><br><span class="line"><span class="string">/usr/local/bin/kube-scripts:</span></span><br><span class="line"><span class="string">total</span> <span class="number">16</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">1410 </span><span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:42</span> <span class="string">etcd-backup.sh</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">4877 </span><span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:39</span> <span class="string">initOS.sh</span></span><br><span class="line"><span class="string">-rwxr-xr-x</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">1120 </span><span class="string">Apr</span>  <span class="number">1</span> <span class="number">22</span><span class="string">:44</span> <span class="string">k8s-certs-renew.sh</span></span><br></pre></td></tr></table></figure><h3 id="6-3-Kubekey-在-x2F-etc-x2F-hosts-文件中写了啥"><a href="#6-3-Kubekey-在-x2F-etc-x2F-hosts-文件中写了啥" class="headerlink" title="6.3. Kubekey 在 &#x2F;etc&#x2F;hosts 文件中写了啥?"></a>6.3. Kubekey 在 &#x2F;etc&#x2F;hosts 文件中写了啥?</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 kubekey]# cat /etc/hosts</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Ansible managed: modified on 2022-04-02 15:47:07 by root on zdevops-master</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.9.91   ks-k8s-master-0</span><br><span class="line">192.168.9.92   ks-k8s-master-1</span><br><span class="line">192.168.9.93   ks-k8s-master-2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubekey hosts BEGIN</span></span><br><span class="line">192.168.9.91  ks-k8s-master-0.cluster.local ks-k8s-master-0</span><br><span class="line">192.168.9.92  ks-k8s-master-1.cluster.local ks-k8s-master-1</span><br><span class="line">192.168.9.93  ks-k8s-master-2.cluster.local ks-k8s-master-2</span><br><span class="line">127.0.0.1 lb.kubesphere.local</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubekey hosts END</span></span><br></pre></td></tr></table></figure><h3 id="6-4-KubeSphere-服务相关的容器有哪些？"><a href="#6-4-KubeSphere-服务相关的容器有哪些？" class="headerlink" title="6.4. KubeSphere 服务相关的容器有哪些？"></a>6.4. KubeSphere 服务相关的容器有哪些？</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">[root@ks-k8s-master-0 kubekey]# docker ps -a  | grep kube</span><br><span class="line">56ddba114660   6d6859d1a42a                                                &quot;/bin/prometheus --w…&quot;   34 minutes ago      Up 34 minutes                            k8s_prometheus_prometheus-k8s-0_kubesphere-monitoring-system_549a26f4-ef11-4715-9d9a-f15e500cf0d0_1</span><br><span class="line">7ceb9c282c6a   kubesphere/prometheus-config-reloader                       &quot;/bin/prometheus-con…&quot;   34 minutes ago      Up 34 minutes                            k8s_config-reloader_prometheus-k8s-0_kubesphere-monitoring-system_549a26f4-ef11-4715-9d9a-f15e500cf0d0_0</span><br><span class="line">3bca88f44041   kubesphere/prometheus-config-reloader                       &quot;/bin/prometheus-con…&quot;   34 minutes ago      Up 34 minutes                            k8s_config-reloader_alertmanager-main-0_kubesphere-monitoring-system_a947da3d-a4ae-41ea-8c6a-50229f7f65da_0</span><br><span class="line">0390dded2f54   kubesphere/ks-controller-manager                            &quot;controller-manager …&quot;   34 minutes ago      Up 34 minutes                            k8s_ks-controller-manager_ks-controller-manager-b79cb6bf7-m582v_kubesphere-system_19f804ff-699b-420d-b93e-c8acb431f500_0</span><br><span class="line">d23fdaaf857c   kubesphere/ks-apiserver                                     &quot;ks-apiserver --logt…&quot;   34 minutes ago      Up 34 minutes                            k8s_ks-apiserver_ks-apiserver-86d89d546d-zfmnr_kubesphere-system_dddd8ec7-d98b-4e1d-9844-d93654ce9221_0</span><br><span class="line">937a52985d89   prom/prometheus                                             &quot;/bin/prometheus --w…&quot;   38 minutes ago      Exited (2) 38 minutes ago                k8s_prometheus_prometheus-k8s-0_kubesphere-monitoring-system_549a26f4-ef11-4715-9d9a-f15e500cf0d0_0</span><br><span class="line">72ef61f1dbfb   prom/alertmanager                                           &quot;/bin/alertmanager -…&quot;   39 minutes ago      Up 39 minutes                            k8s_alertmanager_alertmanager-main-0_kubesphere-monitoring-system_a947da3d-a4ae-41ea-8c6a-50229f7f65da_0</span><br><span class="line">de84038cf90f   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 40 minutes ago      Up 40 minutes                            k8s_POD_ks-controller-manager-b79cb6bf7-m582v_kubesphere-system_19f804ff-699b-420d-b93e-c8acb431f500_0</span><br><span class="line">035e8a1c6d1d   kubesphere/kubectl                                          &quot;entrypoint.sh&quot;          41 minutes ago      Up 41 minutes                            k8s_kubectl_kubectl-admin-6667774bb-wlqwz_kubesphere-controls-system_478f1f6a-45b9-49ef-b31f-a5a89b324ede_0</span><br><span class="line">7ffcec7b74c5   kubesphere/notification-manager-operator                    &quot;/notification-manag…&quot;   41 minutes ago      Up 41 minutes                            k8s_notification-manager-operator_notification-manager-operator-7d44854f54-86h4h_kubesphere-monitoring-system_6877a826-b2f9-4036-b390-f06f253aa66d_0</span><br><span class="line">02db40d5d3c0   kubesphere/kube-rbac-proxy                                  &quot;/usr/local/bin/kube…&quot;   48 minutes ago      Up 48 minutes                            k8s_kube-rbac-proxy_node-exporter-6ppnb_kubesphere-monitoring-system_ec7e1bf5-8a50-4121-9613-8ef371878520_0</span><br><span class="line">335e3c541d4b   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 49 minutes ago      Up 49 minutes                            k8s_POD_prometheus-k8s-0_kubesphere-monitoring-system_549a26f4-ef11-4715-9d9a-f15e500cf0d0_0</span><br><span class="line">04744197c675   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 49 minutes ago      Up 49 minutes                            k8s_POD_alertmanager-main-0_kubesphere-monitoring-system_a947da3d-a4ae-41ea-8c6a-50229f7f65da_0</span><br><span class="line">231dba777bb3   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 51 minutes ago      Up 51 minutes                            k8s_POD_kubectl-admin-6667774bb-wlqwz_kubesphere-controls-system_478f1f6a-45b9-49ef-b31f-a5a89b324ede_0</span><br><span class="line">a5e1e46a07a5   kubesphere/kube-rbac-proxy                                  &quot;/usr/local/bin/kube…&quot;   54 minutes ago      Up 54 minutes                            k8s_kube-rbac-proxy_notification-manager-operator-7d44854f54-86h4h_kubesphere-monitoring-system_6877a826-b2f9-4036-b390-f06f253aa66d_0</span><br><span class="line">4badbd31f179   prom/node-exporter                                          &quot;/bin/node_exporter …&quot;   57 minutes ago      Up 57 minutes                            k8s_node-exporter_node-exporter-6ppnb_kubesphere-monitoring-system_ec7e1bf5-8a50-4121-9613-8ef371878520_0</span><br><span class="line">cb7bd4bb9810   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 57 minutes ago      Up 57 minutes                            k8s_POD_ks-apiserver-86d89d546d-zfmnr_kubesphere-system_dddd8ec7-d98b-4e1d-9844-d93654ce9221_0</span><br><span class="line">984b880a1f7f   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 58 minutes ago      Up 58 minutes                            k8s_POD_notification-manager-operator-7d44854f54-86h4h_kubesphere-monitoring-system_6877a826-b2f9-4036-b390-f06f253aa66d_0</span><br><span class="line">93dff8857db9   kubesphere/ks-console                                       &quot;docker-entrypoint.s…&quot;   58 minutes ago      Up 58 minutes                            k8s_ks-console_ks-console-65f4d44d88-fwzfc_kubesphere-system_4ab1e0a4-1072-4092-a845-9aa3941553ee_0</span><br><span class="line">c366e1f3a0e2   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 59 minutes ago      Up 59 minutes                            k8s_POD_node-exporter-6ppnb_kubesphere-monitoring-system_ec7e1bf5-8a50-4121-9613-8ef371878520_0</span><br><span class="line">26699c22f650   d38a50cc542f                                                &quot;redis-sentinel /dat…&quot;   About an hour ago   Up About an hour                         k8s_sentinel_redis-ha-server-2_kubesphere-system_df05d5d6-630b-45a9-a015-97c30823de53_0</span><br><span class="line">364c2c3d8823   d38a50cc542f                                                &quot;redis-server /data/…&quot;   About an hour ago   Up About an hour                         k8s_redis_redis-ha-server-2_kubesphere-system_df05d5d6-630b-45a9-a015-97c30823de53_0</span><br><span class="line">436bf5c496fc   redis                                                       &quot;sh /readonly-config…&quot;   About an hour ago   Exited (0) About an hour ago             k8s_config-init_redis-ha-server-2_kubesphere-system_df05d5d6-630b-45a9-a015-97c30823de53_0</span><br><span class="line">73012183fd42   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_ks-console-65f4d44d88-fwzfc_kubesphere-system_4ab1e0a4-1072-4092-a845-9aa3941553ee_0</span><br><span class="line">ca75bf407ee9   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_redis-ha-server-2_kubesphere-system_df05d5d6-630b-45a9-a015-97c30823de53_0</span><br><span class="line">a95f9a97136c   96ae905008ca                                                &quot;docker-entrypoint.s…&quot;   About an hour ago   Up About an hour                         k8s_haproxy_redis-ha-haproxy-868fdbddd4-dxvhm_kubesphere-system_ef25d617-6889-4034-94cb-252bb29060f2_0</span><br><span class="line">0bb2f6953698   haproxy                                                     &quot;sh /readonly/haprox…&quot;   About an hour ago   Exited (0) About an hour ago             k8s_config-init_redis-ha-haproxy-868fdbddd4-dxvhm_kubesphere-system_ef25d617-6889-4034-94cb-252bb29060f2_0</span><br><span class="line">0838d2f5444e   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_redis-ha-haproxy-868fdbddd4-dxvhm_kubesphere-system_ef25d617-6889-4034-94cb-252bb29060f2_0</span><br><span class="line">3cd3b1e17b27   296a6d5035e2                                                &quot;/coredns -conf /etc…&quot;   About an hour ago   Up About an hour                         k8s_coredns_coredns-5495dd7c88-7vjlg_kube-system_4d096853-74fd-4663-8a21-c65890b68ba3_0</span><br><span class="line">331ae9233ef5   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_coredns-5495dd7c88-7vjlg_kube-system_4d096853-74fd-4663-8a21-c65890b68ba3_0</span><br><span class="line">3b054ee84a01   76ba70f4748f                                                &quot;/usr/bin/kube-contr…&quot;   About an hour ago   Up About an hour                         k8s_calico-kube-controllers_calico-kube-controllers-75ddb95444-66rw7_kube-system_0c1002c4-79c1-41d7-8568-a64480282f85_0</span><br><span class="line">23f172aa5773   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_calico-kube-controllers-75ddb95444-66rw7_kube-system_0c1002c4-79c1-41d7-8568-a64480282f85_0</span><br><span class="line">b97121f67a86   5ef66b403f4f                                                &quot;start_runit&quot;            About an hour ago   Up About an hour                         k8s_calico-node_calico-node-xbrv2_kube-system_8bec7710-5b02-4578-88e4-480b922f9f0b_0</span><br><span class="line">6272abcdf59d   5991877ebc11                                                &quot;/usr/local/bin/flex…&quot;   About an hour ago   Exited (0) About an hour ago             k8s_flexvol-driver_calico-node-xbrv2_kube-system_8bec7710-5b02-4578-88e4-480b922f9f0b_0</span><br><span class="line">a8bfccda4a11   4945b742b8e6                                                &quot;/opt/cni/bin/install&quot;   About an hour ago   Exited (0) About an hour ago             k8s_install-cni_calico-node-xbrv2_kube-system_8bec7710-5b02-4578-88e4-480b922f9f0b_0</span><br><span class="line">e8cf1cc8bcb6   e08abd2be730                                                &quot;/usr/local/bin/kube…&quot;   About an hour ago   Up About an hour                         k8s_kube-proxy_kube-proxy-7hnl8_kube-system_c26e2c08-73e7-4c57-9517-d217a5f880f6_0</span><br><span class="line">84ae94f60fbf   4945b742b8e6                                                &quot;/opt/cni/bin/calico…&quot;   About an hour ago   Exited (0) About an hour ago             k8s_upgrade-ipam_calico-node-xbrv2_kube-system_8bec7710-5b02-4578-88e4-480b922f9f0b_0</span><br><span class="line">bfed559ac954   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_kube-proxy-7hnl8_kube-system_c26e2c08-73e7-4c57-9517-d217a5f880f6_0</span><br><span class="line">bc425f4adf1d   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_calico-node-xbrv2_kube-system_8bec7710-5b02-4578-88e4-480b922f9f0b_0</span><br><span class="line">260286005d9c   5340ba194ec9                                                &quot;/node-cache -locali…&quot;   About an hour ago   Up About an hour                         k8s_node-cache_nodelocaldns-w9v4t_kube-system_72389909-2262-4807-8adc-dc8a3326c7b9_0</span><br><span class="line">90e2561dc91f   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_nodelocaldns-w9v4t_kube-system_72389909-2262-4807-8adc-dc8a3326c7b9_0</span><br><span class="line">4a74d116f0c5   7b2ac941d4c3                                                &quot;kube-apiserver --ad…&quot;   About an hour ago   Up About an hour                         k8s_kube-apiserver_kube-apiserver-ks-k8s-master-0_kube-system_a3a95f029d9aa45f7c1c87b8542a6e7c_0</span><br><span class="line">ecfca7a100a0   184ef4d127b4                                                &quot;kube-controller-man…&quot;   About an hour ago   Up About an hour                         k8s_kube-controller-manager_kube-controller-manager-ks-k8s-master-0_kube-system_b5a94fe882e6fcf23fa73eca1735fbd8_0</span><br><span class="line">ff5a86654de9   8e60ea3644d6                                                &quot;kube-scheduler --au…&quot;   About an hour ago   Up About an hour                         k8s_kube-scheduler_kube-scheduler-ks-k8s-master-0_kube-system_86823db35b1fcd1d3c94e2622324bafa_0</span><br><span class="line">1b5afb3c81c4   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_kube-apiserver-ks-k8s-master-0_kube-system_a3a95f029d9aa45f7c1c87b8542a6e7c_0</span><br><span class="line">50693fd0c9d1   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_kube-scheduler-ks-k8s-master-0_kube-system_86823db35b1fcd1d3c94e2622324bafa_0</span><br><span class="line">9d5c77fdae7e   registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.4.1   &quot;/pause&quot;                 About an hour ago   Up About an hour                         k8s_POD_kube-controller-manager-ks-k8s-master-0_kube-system_b5a94fe882e6fcf23fa73eca1735fbd8_0</span><br><span class="line">[root@ks-k8s-master-0 kubekey]# docker ps -a  | grep kube | wc -l</span><br><span class="line">47</span><br><span class="line">[root@ks-k8s-master-0 kubekey]# docker ps -a  | grep kube | grep Up |wc -l</span><br><span class="line">41</span><br><span class="line">[root@ks-k8s-master-0 kubekey]# docker ps -a  | grep kube | grep Exited |wc -l</span><br><span class="line">6</span><br></pre></td></tr></table></figure><hr><h2 id="7-常见问题"><a href="#7-常见问题" class="headerlink" title="7. 常见问题"></a>7. 常见问题</h2><blockquote><p><strong>问题 1</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 报错信息</span></span><br><span class="line">[<span class="string">root@ks-k8s-master-0</span> <span class="string">kubekey</span>]<span class="comment"># ./kk create cluster -f config-sample.yaml</span></span><br><span class="line"><span class="string">You</span> <span class="string">cannot</span> <span class="string">set</span> <span class="string">up</span> <span class="string">the</span> <span class="string">internal</span> <span class="string">load</span> <span class="string">balancer</span> <span class="string">and</span> <span class="string">the</span> <span class="string">LB</span> <span class="string">address</span> <span class="string">at</span> <span class="string">the</span> <span class="string">same</span> <span class="string">time.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决方案</span></span><br><span class="line"><span class="attr">address:</span> <span class="string">&quot;192.168.9.90&quot;</span> <span class="string">参数改为</span> <span class="attr">address:</span> <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>问题 2</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 报错信息</span></span><br><span class="line">22:18:52 CST message: [LocalHost]</span><br><span class="line">Failed to download kubeadm binary: curl -L -o /root/kubekey/kubekey/kube/v1.22.8/amd64/kubeadm https://storage.googleapis.com/kubernetes-release/release/v1.22.8/bin/linux/amd64/kubeadm error: No SHA256 found for kubeadm. v1.22.8 is not supported. </span><br><span class="line">22:18:52 CST failed: [LocalHost]</span><br><span class="line">error: Pipeline[CreateClusterPipeline] execute failed: Module[NodeBinariesModule] exec failed: </span><br><span class="line">failed: [LocalHost] [DownloadBinaries] exec failed after 1 retires: Failed to download kubeadm binary: curl -L -o /root/kubekey/kubekey/kube/v1.22.8/amd64/kubeadm https://storage.googleapis.com/kubernetes-release/release/v1.22.8/bin/linux/amd64/kubeadm error: No SHA256 found for kubeadm. v1.22.8 is not supported. </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解决方案</span></span><br><span class="line">目前3.2.1的版本不支持k8s v1.22.8，利用kk version --show-supported-k8s查看支持的版本，更换支持的版本，重新执行安装命令。</span><br></pre></td></tr></table></figure><hr><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>以上内容详细记录了 KubeSphere 安装 K8S 的全过程。</p><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p>About Me</p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于-KubeSphere-玩转-k8s-KubeSphere-安装手记&quot;&gt;&lt;a href=&quot;#基于-KubeSphere-玩转-k8s-KubeSphere-安装手记&quot; class=&quot;headerlink&quot; title=&quot;基于 KubeSphere 玩转 k8s</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 安装手记</title>
    <link href="https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s/Kubernetes%20%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/"/>
    <id>https://lhhxs.github.io/2023/09/22/%E8%BF%90%E7%BB%B4/k8s/Kubernetes%20%E5%AE%89%E8%A3%85%E6%89%8B%E8%AE%B0/</id>
    <published>2023-09-22T01:38:09.021Z</published>
    <updated>2023-09-22T03:50:07.662Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-v1-24-安装手记"><a href="#Kubernetes-v1-24-安装手记" class="headerlink" title="Kubernetes v1.24 安装手记"></a>Kubernetes v1.24 安装手记</h1><p><strong>大家好，我是老 Z！</strong></p><blockquote><p>本系列文档是我在云原生技术领域的学习和运维实践的手记，<strong>用输出倒逼输入</strong>是一种高效的学习方法，能够快速积累经验和提高技术，只有把学到的知识写出来并能够让其他人理解，才能说明真正掌握了这项知识。</p><p>如果你喜欢本文，请分享给你的小伙伴！</p></blockquote><p><strong>本系列文档内容涵盖 (但不限于) 以下技术领域：</strong></p><blockquote><ul><li><p><strong>KubeSphere</strong></p></li><li><p><strong>Kubernetes</strong></p></li><li><p><strong>Ansible</strong></p></li><li><p><strong>自动化运维</strong></p></li><li><p><strong>CNCF 技术栈</strong></p></li></ul></blockquote><h2 id="1-本文简介"><a href="#1-本文简介" class="headerlink" title="1. 本文简介"></a>1. 本文简介</h2><p>Kubernetes v1.24.0 在 2022-05-03 正式发布了，不再支持 Docker 作为容器运行时，纯纯的使用 Containerd 安装部署。网友都说安装不易，我也体验一把，难易程度到底如何。因此，本文内容只适合于学习测试环境，生产环境<strong>绝对</strong>不能用。</p><p>本文涉及单控制节点和高可用三控制节点 Kubernetes 集群的安装部署。</p><blockquote><p><strong>本文知识量</strong></p></blockquote><ul><li>阅读时长：25 分</li><li>行：1912</li><li>单词：9461</li><li>字符：86896</li><li>图片：1 张</li></ul><blockquote><p><strong>本文知识点</strong></p></blockquote><ul><li>定级：<strong>入门级</strong></li><li>Kubernetes 1.24</li><li>Containers 常用操作</li><li>Ansible 日常使用</li></ul><blockquote><p><strong>演示服务器配置</strong></p></blockquote><table><thead><tr><th align="center">主机名</th><th align="center">操作系统类型版本</th><th align="center">IP</th><th align="center">CPU</th><th align="center">内存</th><th align="center">系统盘</th><th align="center">数据盘</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">zdeops-master</td><td align="center">CentOS7.9x64</td><td align="center">192.168.9.9</td><td align="center">2</td><td align="center">4</td><td align="center">40</td><td align="center">200</td><td align="center">Ansible 运维控制节点</td></tr><tr><td align="center">k8s-master-0</td><td align="center">CentOS7.9x64</td><td align="center">192.168.9.61</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200</td><td align="center">k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">k8s-master-1</td><td align="center">CentOS7.9x64</td><td align="center">192.168.9.62</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200</td><td align="center">k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">k8s-master-2</td><td align="center">CentOS7.9x64</td><td align="center">192.168.9.63</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200</td><td align="center">k8s-master&#x2F;k8s-worker</td></tr><tr><td align="center">k8s-worker-0</td><td align="center">CentOS7.9x64</td><td align="center">192.168.9.65</td><td align="center">4</td><td align="center">16</td><td align="center">40</td><td align="center">200</td><td align="center">k8s-worker</td></tr></tbody></table><hr><h2 id="2-Ansible-配置"><a href="#2-Ansible-配置" class="headerlink" title="2. Ansible 配置"></a>2. Ansible 配置</h2><h3 id="2-1-切换到-ansible-代码目录"><a href="#2-1-切换到-ansible-代码目录" class="headerlink" title="2.1. 切换到 ansible 代码目录"></a>2.1. 切换到 ansible 代码目录</h3>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@zdevops-master dev]# cd /data/ansible/ansible-zdevops/inventories/dev</span><br><span class="line">[root@zdevops-master dev]# source /opt/ansible2.8/bin/activate</span><br></pre></td></tr></table></figure><h3 id="2-2-编辑-hosts-配置文件"><a href="#2-2-编辑-hosts-配置文件" class="headerlink" title="2.2. 编辑 hosts 配置文件"></a>2.2. 编辑 hosts 配置文件</h3><blockquote><p><strong>01-编辑 k8s.hosts</strong></p></blockquote><p><strong>这里演示的是 3master、1worker 的部署架构的初始化，单控的去掉 2 个 master 即可。</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">k8s_master</span>]</span><br><span class="line"><span class="string">k8s-master-0</span> <span class="string">ansible_ssh_host=192.168.9.61</span>  <span class="string">host_name=k8s-master-0</span></span><br><span class="line"><span class="string">k8s-master-1</span> <span class="string">ansible_ssh_host=192.168.9.62</span>  <span class="string">host_name=k8s-master-1</span></span><br><span class="line"><span class="string">k8s-master-2</span> <span class="string">ansible_ssh_host=192.168.9.63</span>  <span class="string">host_name=k8s-master-2</span></span><br><span class="line"></span><br><span class="line">[<span class="string">k8s_worker</span>]</span><br><span class="line"><span class="string">k8s-worker-0</span> <span class="string">ansible_ssh_host=192.168.9.65</span> <span class="string">host_name=k8s-worker-0</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:children</span>]</span><br><span class="line"><span class="string">k8s_master</span></span><br><span class="line"><span class="string">k8s_worker</span></span><br><span class="line"></span><br><span class="line">[<span class="string">servers:vars</span>]</span><br><span class="line"><span class="string">ansible_connection=paramiko</span></span><br><span class="line"><span class="string">ansible_ssh_user=root</span></span><br><span class="line"><span class="string">ansible_ssh_pass=F@ywwpTj4bJtYwzpwCqD</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="3-K8S-服务器初始化"><a href="#3-K8S-服务器初始化" class="headerlink" title="3. K8S 服务器初始化"></a>3. K8S 服务器初始化</h2><p><strong>这里演示的是 3master、1worker 的部署架构的初始化，单控的命令一样只是 hosts 文件中去掉 2 个 master 即可。</strong></p><h3 id="3-1-检测服务器连通性"><a href="#3-1-检测服务器连通性" class="headerlink" title="3.1. 检测服务器连通性"></a>3.1. 检测服务器连通性</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 检测服务器的连通性</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible servers -m ping -i k8s-hosts </span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">k8s-master-0 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">k8s-master-2 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">k8s-worker-0 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">k8s-master-1 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-初始化服务器配置"><a href="#3-2-初始化服务器配置" class="headerlink" title="3.2. 初始化服务器配置"></a>3.2. 初始化服务器配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化服务器配置</span></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/init-base.yaml -i k8s-hosts </span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">PLAY [初始化服务器配置.] *************************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-停止并禁用firewalld服务.] **************************************************************************************************</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [02-配置主机名.] *************************************************************************************************************</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line"></span><br><span class="line">TASK [03-配置/etc/hosts.] ******************************************************************************************************</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line"></span><br><span class="line">TASK [04-配置时区.] **************************************************************************************************************</span><br><span class="line">ok: [k8s-master-1]</span><br><span class="line">ok: [k8s-worker-0]</span><br><span class="line">ok: [k8s-master-0]</span><br><span class="line">ok: [k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统.] ************************************************************************************************************</span><br><span class="line">skipping: [k8s-master-0]</span><br><span class="line">skipping: [k8s-master-1]</span><br><span class="line">skipping: [k8s-master-2]</span><br><span class="line">skipping: [k8s-worker-0]</span><br><span class="line"></span><br><span class="line">TASK [05-升级操作系统后如果需要重启，则重启服务器.] **********************************************************************************************</span><br><span class="line">skipping: [k8s-master-0]</span><br><span class="line">skipping: [k8s-master-1]</span><br><span class="line">skipping: [k8s-master-2]</span><br><span class="line">skipping: [k8s-worker-0]</span><br><span class="line"></span><br><span class="line">TASK [05-等待服务器完成重启.] *********************************************************************************************************</span><br><span class="line">skipping: [k8s-master-0]</span><br><span class="line">skipping: [k8s-master-1]</span><br><span class="line">skipping: [k8s-master-2]</span><br><span class="line">skipping: [k8s-worker-0]</span><br><span class="line"></span><br><span class="line">PLAY [安装配置chrony服务器.] ********************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-安装chrony软件包.] *******************************************************************************************************</span><br><span class="line">changed: [k8s-master-1] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [k8s-worker-0] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [k8s-master-2] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line">changed: [k8s-master-0] =&gt; (item=[u&#x27;chrony&#x27;])</span><br><span class="line"></span><br><span class="line">TASK [02-配置chrony.conf.] *****************************************************************************************************</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [03-确认chrony服务启动并实现开机自启.] ***********************************************************************************************</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line"></span><br><span class="line">PLAY RECAP *******************************************************************************************************************</span><br><span class="line">k8s-master-0               : ok=0    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">k8s-master-1               : ok=0    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">k8s-master-2               : ok=0    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   </span><br><span class="line">k8s-worker-0                 : ok=0    changed=7    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0</span><br></pre></td></tr></table></figure><h3 id="3-3-挂载数据盘"><a href="#3-3-挂载数据盘" class="headerlink" title="3.3. 挂载数据盘"></a>3.3. 挂载数据盘</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible-playbook 初始化主机数据盘</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意 -e data_disk_path=<span class="string">&quot;/data&quot;</span> 指定挂载目录</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible-playbook ../../playbooks/init-disk.yaml -i k8s-hosts -e data_disk_path=&quot;/data&quot;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PLAY [初始化磁盘.] ****************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [01-数据磁盘分区.] ************************************************************************************************</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [02-格式化数据磁盘.] ***********************************************************************************************</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line"></span><br><span class="line">TASK [03-挂载数据盘.] *************************************************************************************************</span><br><span class="line">changed: [k8s-master-0]</span><br><span class="line">changed: [k8s-master-2]</span><br><span class="line">changed: [k8s-worker-0]</span><br><span class="line">changed: [k8s-master-1]</span><br><span class="line"></span><br><span class="line">PLAY RECAP *******************************************************************************************************</span><br><span class="line">k8s-master-0               : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">k8s-master-1               : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">k8s-master-2               : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   </span><br><span class="line">k8s-worker-0               : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0</span><br></pre></td></tr></table></figure><h3 id="3-4-验证数据盘的挂载"><a href="#3-4-验证数据盘的挂载" class="headerlink" title="3.4. 验证数据盘的挂载"></a>3.4. 验证数据盘的挂载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否格式化并挂载</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]#  ansible -i k8s-hosts servers -m shell -a &#x27;df -h&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line"></span><br><span class="line">k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 7.9G     0  7.9G   0% /dev</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /dev/shm</span><br><span class="line">tmpfs                    7.9G  8.8M  7.9G   1% /run</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.5G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /data</span><br><span class="line">tmpfs                    1.6G     0  1.6G   0% /run/user/0</span><br><span class="line"></span><br><span class="line">k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 7.9G     0  7.9G   0% /dev</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /dev/shm</span><br><span class="line">tmpfs                    7.9G  8.8M  7.9G   1% /run</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.5G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /data</span><br><span class="line">tmpfs                    1.6G     0  1.6G   0% /run/user/0</span><br><span class="line"></span><br><span class="line">k8s-worker-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 7.9G     0  7.9G   0% /dev</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /dev/shm</span><br><span class="line">tmpfs                    7.9G  8.8M  7.9G   1% /run</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.5G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /data</span><br><span class="line">tmpfs                    1.6G     0  1.6G   0% /run/user/0</span><br><span class="line"></span><br><span class="line">k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                 7.9G     0  7.9G   0% /dev</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /dev/shm</span><br><span class="line">tmpfs                    7.9G  8.8M  7.9G   1% /run</span><br><span class="line">tmpfs                    7.9G     0  7.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root   37G  1.5G   36G   4% /</span><br><span class="line">/dev/sda1               1014M  168M  847M  17% /boot</span><br><span class="line">tmpfs                    1.6G     0  1.6G   0% /run/user/0</span><br><span class="line">/dev/sdb1                200G   33M  200G   1% /data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">利用 ansible 验证数据盘是否配置自动挂载</span></span><br><span class="line"></span><br><span class="line">(ansible2.8) [root@zdevops-master dev]# ansible -i k8s-hosts servers -m shell -a &#x27;tail -1  /etc/fstab&#x27;</span><br><span class="line">/opt/ansible2.8/lib/python2.7/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.</span><br><span class="line">  from cryptography.exceptions import InvalidSignature</span><br><span class="line">k8s-master-2 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /data xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">k8s-master-1 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /data xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">k8s-master-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /data xfs defaults 0 0</span><br><span class="line"></span><br><span class="line">k8s-worker-0 | CHANGED | rc=0 &gt;&gt;</span><br><span class="line">/dev/sdb1 /data xfs defaults 0 0</span><br></pre></td></tr></table></figure><hr><h2 id="4-K8S-节点通用配置"><a href="#4-K8S-节点通用配置" class="headerlink" title="4. K8S 节点通用配置"></a>4. K8S 节点通用配置</h2><h3 id="4-1-系统基础配置"><a href="#4-1-系统基础配置" class="headerlink" title="4.1. 系统基础配置"></a>4.1. 系统基础配置</h3><blockquote><p><strong>01-关闭 swap</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# swapoff -a</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-确认 MAC 地址和 product_uuid 对于每个节点都是唯一的</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">MAC</span></span><br><span class="line">[root@k8s-master-0 ~]# ip link</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000</span><br><span class="line">    link/ether 00:50:56:85:67:89 brd ff:ff:ff:ff:ff:ff</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">product_uuid</span></span><br><span class="line">[root@k8s-master-0 ~]# cat /sys/class/dmi/id/product_uuid </span><br><span class="line">4205AB12-9DD3-9174-D108-6CB2B1FC169D</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-关闭 SELinux(系统初始化时已关闭)</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set SELinux <span class="keyword">in</span> permissive mode (effectively disabling it)</span></span><br><span class="line">[root@k8s-master-0 ~]# setenforce 0</span><br><span class="line">[root@k8s-master-0 ~]# sed -i &#x27;s/^SELINUX=enforcing$/SELINUX=permissive/&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure><h3 id="4-2-安装容器运行时-Container-runtimes-containerd"><a href="#4-2-安装容器运行时-Container-runtimes-containerd" class="headerlink" title="4.2. 安装容器运行时 (Container runtimes)-containerd"></a>4.2. 安装容器运行时 (Container runtimes)-containerd</h3><blockquote><p><strong>01-安装配置前提条件</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">必须执行，否则后面init集群的时候会报错</span></span><br><span class="line">[root@k8s-master-0 ~]# modprobe overlay</span><br><span class="line">[root@k8s-master-0 ~]# modprobe br_netfilter</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sysctl params required by setup, params persist across reboots</span></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Apply sysctl params without reboot</span></span><br><span class="line">[root@k8s-master-0 ~]# sysctl --system</span><br><span class="line">* Applying /usr/lib/sysctl.d/00-system.conf ...</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 0</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 0</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 0</span><br><span class="line">* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...</span><br><span class="line">kernel.yama.ptrace_scope = 0</span><br><span class="line">* Applying /usr/lib/sysctl.d/50-default.conf ...</span><br><span class="line">kernel.sysrq = 16</span><br><span class="line">kernel.core_uses_pid = 1</span><br><span class="line">kernel.kptr_restrict = 1</span><br><span class="line">net.ipv4.conf.default.rp_filter = 1</span><br><span class="line">net.ipv4.conf.all.rp_filter = 1</span><br><span class="line">net.ipv4.conf.default.accept_source_route = 0</span><br><span class="line">net.ipv4.conf.all.accept_source_route = 0</span><br><span class="line">net.ipv4.conf.default.promote_secondaries = 1</span><br><span class="line">net.ipv4.conf.all.promote_secondaries = 1</span><br><span class="line">fs.protected_hardlinks = 1</span><br><span class="line">fs.protected_symlinks = 1</span><br><span class="line">* Applying /etc/sysctl.d/99-sysctl.conf ...</span><br><span class="line">* Applying /etc/sysctl.d/k8s.conf ...</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">* Applying /etc/sysctl.conf ...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用下面的命令从指定的配置文件加载也可以</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">[root@k8s-master-0 ~]<span class="comment"># sysctl -p /etc/sysctl.d/k8s.conf</span></span> </span><br></pre></td></tr></table></figure><blockquote><p><strong>02-安装 Containerd</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置软件源</span></span><br><span class="line">[root@k8s-master-0 ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">adding repo from: http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">grabbing file http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">repo saved to /etc/yum.repos.d/docker-ce.repo</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# ls /etc/yum.repos.d/</span><br><span class="line">CentOS-Base.repo  CentOS-Debuginfo.repo  CentOS-Media.repo    CentOS-Vault.repo          docker-ce.repo</span><br><span class="line">CentOS-CR.repo    CentOS-fasttrack.repo  CentOS-Sources.repo  CentOS-x86_64-kernel.repo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查找可用的 containerd 包</span></span><br><span class="line">[root@k8s-master-0 ~]# yum search containerd</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">============================================ N/S matched: containerd =============================================</span><br><span class="line">containerd.io.x86_64 : An industry-standard container runtime</span><br><span class="line"></span><br><span class="line">  Name and summary matches only, use &quot;search all&quot; for everything.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装 containerd</span></span><br><span class="line">[root@k8s-master-0 ~]# yum install containerd.io -y</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package containerd.io.x86_64 0:1.6.4-3.1.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: container-selinux &gt;= 2:2.74 <span class="keyword">for</span> package: containerd.io-1.6.4-3.1.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: policycoreutils-python <span class="keyword">for</span> package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package policycoreutils-python.x86_64 0:2.5-34.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: setools-libs &gt;= 3.3.8-4 <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libsemanage-python &gt;= 2.5-14 <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: audit-libs-python &gt;= 2.1.3-4 <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: python-IPy <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libqpol.so.1(VERS_1.4)(64bit) <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libqpol.so.1(VERS_1.2)(64bit) <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libcgroup <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libapol.so.4(VERS_4.0)(64bit) <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: checkpolicy <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libqpol.so.1()(64bit) <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libapol.so.4()(64bit) <span class="keyword">for</span> package: policycoreutils-python-2.5-34.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package audit-libs-python.x86_64 0:2.8.5-4.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package checkpolicy.x86_64 0:2.5-8.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package libcgroup.x86_64 0:0.41-21.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package libsemanage-python.x86_64 0:2.5-14.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package python-IPy.noarch 0:0.75-6.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package setools-libs.x86_64 0:3.3.8-4.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">==================================================================================================================</span><br><span class="line"> Package                        Arch           Version                             Repository                Size</span><br><span class="line">==================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> containerd.io                  x86_64         1.6.4-3.1.el7                       docker-ce-stable          33 M</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> audit-libs-python              x86_64         2.8.5-4.el7                         base                      76 k</span><br><span class="line"> checkpolicy                    x86_64         2.5-8.el7                           base                     295 k</span><br><span class="line"> container-selinux              noarch         2:2.119.2-1.911c772.el7_8           extras                    40 k</span><br><span class="line"> libcgroup                      x86_64         0.41-21.el7                         base                      66 k</span><br><span class="line"> libsemanage-python             x86_64         2.5-14.el7                          base                     113 k</span><br><span class="line"> policycoreutils-python         x86_64         2.5-34.el7                          base                     457 k</span><br><span class="line"> python-IPy                     noarch         0.75-6.el7                          base                      32 k</span><br><span class="line"> setools-libs                   x86_64         3.3.8-4.el7                         base                     620 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==================================================================================================================</span><br><span class="line">Install  1 Package (+8 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 35 M</span><br><span class="line">Installed size: 130 M</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/9): container-selinux-2.119.2-1.911c772.el7_8.noarch.rpm                                |  40 kB  00:00:00     </span><br><span class="line">(2/9): audit-libs-python-2.8.5-4.el7.x86_64.rpm                                            |  76 kB  00:00:00     </span><br><span class="line">(3/9): libcgroup-0.41-21.el7.x86_64.rpm                                                    |  66 kB  00:00:00     </span><br><span class="line">(4/9): checkpolicy-2.5-8.el7.x86_64.rpm                                                    | 295 kB  00:00:00     </span><br><span class="line">(5/9): libsemanage-python-2.5-14.el7.x86_64.rpm                                            | 113 kB  00:00:00     </span><br><span class="line">(6/9): python-IPy-0.75-6.el7.noarch.rpm                                                    |  32 kB  00:00:00     </span><br><span class="line">(7/9): policycoreutils-python-2.5-34.el7.x86_64.rpm                                        | 457 kB  00:00:00     </span><br><span class="line">(8/9): setools-libs-3.3.8-4.el7.x86_64.rpm                                                 | 620 kB  00:00:00     </span><br><span class="line">warning: /var/cache/yum/x86_64/7/docker-ce-stable/packages/containerd.io-1.6.4-3.1.el7.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 621e9f35: NOKEY</span><br><span class="line">Public key for containerd.io-1.6.4-3.1.el7.x86_64.rpm is not installed</span><br><span class="line">(9/9): containerd.io-1.6.4-3.1.el7.x86_64.rpm                                              |  33 MB  00:00:21     </span><br><span class="line">------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                             1.6 MB/s |  35 MB  00:00:21     </span><br><span class="line">Retrieving key from https://mirrors.aliyun.com/docker-ce/linux/centos/gpg</span><br><span class="line">Importing GPG key 0x621E9F35:</span><br><span class="line"> Userid     : &quot;Docker Release (CE rpm) &lt;docker@docker.com&gt;&quot;</span><br><span class="line"> Fingerprint: 060a 61c5 1b55 8a7f 742b 77aa c52f eb6b 621e 9f35</span><br><span class="line"> From       : https://mirrors.aliyun.com/docker-ce/linux/centos/gpg</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : setools-libs-3.3.8-4.el7.x86_64                                                                1/9 </span><br><span class="line">  Installing : libcgroup-0.41-21.el7.x86_64                                                                   2/9 </span><br><span class="line">  Installing : audit-libs-python-2.8.5-4.el7.x86_64                                                           3/9 </span><br><span class="line">  Installing : python-IPy-0.75-6.el7.noarch                                                                   4/9 </span><br><span class="line">  Installing : libsemanage-python-2.5-14.el7.x86_64                                                           5/9 </span><br><span class="line">  Installing : checkpolicy-2.5-8.el7.x86_64                                                                   6/9 </span><br><span class="line">  Installing : policycoreutils-python-2.5-34.el7.x86_64                                                       7/9 </span><br><span class="line">  Installing : 2:container-selinux-2.119.2-1.911c772.el7_8.noarch                                             8/9 </span><br><span class="line">setsebool:  SELinux is disabled.</span><br><span class="line">  Installing : containerd.io-1.6.4-3.1.el7.x86_64                                                             9/9 </span><br><span class="line">  Verifying  : checkpolicy-2.5-8.el7.x86_64                                                                   1/9 </span><br><span class="line">  Verifying  : libsemanage-python-2.5-14.el7.x86_64                                                           2/9 </span><br><span class="line">  Verifying  : 2:container-selinux-2.119.2-1.911c772.el7_8.noarch                                             3/9 </span><br><span class="line">  Verifying  : python-IPy-0.75-6.el7.noarch                                                                   4/9 </span><br><span class="line">  Verifying  : containerd.io-1.6.4-3.1.el7.x86_64                                                             5/9 </span><br><span class="line">  Verifying  : policycoreutils-python-2.5-34.el7.x86_64                                                       6/9 </span><br><span class="line">  Verifying  : audit-libs-python-2.8.5-4.el7.x86_64                                                           7/9 </span><br><span class="line">  Verifying  : libcgroup-0.41-21.el7.x86_64                                                                   8/9 </span><br><span class="line">  Verifying  : setools-libs-3.3.8-4.el7.x86_64                                                                9/9 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  containerd.io.x86_64 0:1.6.4-3.1.el7                                                                            </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  audit-libs-python.x86_64 0:2.8.5-4.el7                      checkpolicy.x86_64 0:2.5-8.el7                     </span><br><span class="line">  container-selinux.noarch 2:2.119.2-1.911c772.el7_8          libcgroup.x86_64 0:0.41-21.el7                     </span><br><span class="line">  libsemanage-python.x86_64 0:2.5-14.el7                      policycoreutils-python.x86_64 0:2.5-34.el7         </span><br><span class="line">  python-IPy.noarch 0:0.75-6.el7                              setools-libs.x86_64 0:3.3.8-4.el7                  </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-配置 containerd</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">备份默认配置文件，并生成一份更全的默认配置文件</span></span><br><span class="line">[root@k8s-master-0 ~]# cp /etc/containerd/config.toml /etc/containerd/config.toml.ori</span><br><span class="line">[root@k8s-master-0 ~]# containerd  config default &gt; /etc/containerd/config.toml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">替换默认的 sandbox_image</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sandbox_image = <span class="string">&quot;k8s.gcr.io/pause:3.6&quot;</span> 为 <span class="string">&quot;registry.aliyuncs.com/google_containers/pause:3.6&quot;</span></span></span><br><span class="line">[root@k8s-master-0 ~]# sed -i &#x27;s#k8s.gcr.io#registry.aliyuncs.com/google_containers#g&#x27; /etc/containerd/config.toml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置 systemd cgroup driver</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改下面配置中的 SystemdCgroup = <span class="literal">false</span> 为<span class="literal">true</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.runc]</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> ...</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> [plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.containerd.runtimes.runc.options]</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   SystemdCgroup = <span class="literal">true</span></span></span><br><span class="line">[root@k8s-master-0 ~]# sed -i &#x27;s/SystemdCgroup = false/SystemdCgroup = true/g&#x27; /etc/containerd/config.toml </span><br><span class="line">    </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置 containerd的存储路径</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改 root = <span class="string">&quot;/var/lib/containerd&quot;</span>为root = <span class="string">&quot;/data/containerd&quot;</span></span></span><br><span class="line">[root@k8s-master-0 ~]# sed -i &#x27;s#root = &quot;/var/lib/containerd&quot;#root = &quot;/data/containerd&quot;#g&#x27; /etc/containerd/config.toml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">强烈建议修改后，<span class="built_in">cat</span> /etc/containerd/config.toml，查看修改结果是否正确</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>04-启动 containerd 并设置开机自启</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# systemctl daemon-reload</span><br><span class="line">[root@k8s-master-0 ~]# systemctl enable --now containerd</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/containerd.service to /usr/lib/systemd/system/containerd.service.</span><br></pre></td></tr></table></figure><blockquote><p><strong>05-验证 containerd</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看服务状态</span></span><br><span class="line">[root@k8s-master-0 ~]# systemctl status containerd</span><br><span class="line">● containerd.service - containerd container runtime</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Tue 2022-05-17 16:09:43 CST; 1min 21s ago</span><br><span class="line">     Docs: https://containerd.io</span><br><span class="line"> Main PID: 17217 (containerd)</span><br><span class="line">   CGroup: /system.slice/containerd.service</span><br><span class="line">           └─17217 /usr/bin/containerd</span><br><span class="line"></span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155226321+08:00&quot; level=error msg=...fig&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155410134+08:00&quot; level=info msg=&quot;...ent&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155526261+08:00&quot; level=info msg=&quot;...ate&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155628084+08:00&quot; level=info msg=s...trpc</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155691927+08:00&quot; level=info msg=&quot;...tor&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155723856+08:00&quot; level=info msg=s...sock</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155737042+08:00&quot; level=info msg=&quot;...cer&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155809298+08:00&quot; level=info msg=&quot;...ult&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155837948+08:00&quot; level=info msg=&quot;...ver&quot;</span><br><span class="line">May 17 16:09:43 k8s-master-0 containerd[17217]: time=&quot;2022-05-17T16:09:43.155867943+08:00&quot; level=info msg=&quot;...57s&quot;</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看进程和端口</span></span><br><span class="line">[root@k8s-master-0 ~]# ps -ef | grep containerd</span><br><span class="line">root     17217     1  0 16:09 ?        00:00:00 /usr/bin/containerd</span><br><span class="line">root     17264 10585  0 16:13 pts/0    00:00:00 grep --color=auto containerd</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# ss -ntlup | grep containerd</span><br><span class="line">tcp    LISTEN     0      128    127.0.0.1:34412                 *:*                   users:((&quot;containerd&quot;,pid=17217,fd=13))</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看存储路径的内容</span></span><br><span class="line">[root@k8s-master-0 ~]# ls /data/containerd/</span><br><span class="line">io.containerd.content.v1.content  io.containerd.runtime.v2.task        io.containerd.snapshotter.v1.overlayfs</span><br><span class="line">io.containerd.metadata.v1.bolt    io.containerd.snapshotter.v1.btrfs   tmpmounts</span><br><span class="line">io.containerd.runtime.v1.linux    io.containerd.snapshotter.v1.native</span><br></pre></td></tr></table></figure><h3 id="4-3-安装-kubeadm-kubelet-kubectl"><a href="#4-3-安装-kubeadm-kubelet-kubectl" class="headerlink" title="4.3. 安装 kubeadm, kubelet, kubectl"></a>4.3. 安装 kubeadm, kubelet, kubectl</h3><blockquote><p><strong>01-配置软件源</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-安装软件包并设置开机自启</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">由于1.24刚发布，官方只有一个版本的包，有多个版本的时候，可以查询后指定版本安装</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">yum list kubelet --showduplicate</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">yum install kubelet-1.24.0-0</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ps: 由于官网未开放同步方式, 可能会有索引gpg检查失败的情况, 这时请用 yum install -y --nogpgcheck kubelet kubeadm kubectl 安装</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# yum install kubelet kubeadm kubectl --nogpgcheck -y</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package kubeadm.x86_64 0:1.24.0-0 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: kubernetes-cni &gt;= 0.8.6 <span class="keyword">for</span> package: kubeadm-1.24.0-0.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: cri-tools &gt;= 1.19.0 <span class="keyword">for</span> package: kubeadm-1.24.0-0.x86_64</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package kubectl.x86_64 0:1.24.0-0 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package kubelet.x86_64 0:1.24.0-0 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: socat <span class="keyword">for</span> package: kubelet-1.24.0-0.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: conntrack <span class="keyword">for</span> package: kubelet-1.24.0-0.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) <span class="keyword">for</span> package: conntrack-tools-1.4.4-7.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) <span class="keyword">for</span> package: conntrack-tools-1.4.4-7.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) <span class="keyword">for</span> package: conntrack-tools-1.4.4-7.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libnetfilter_queue.so.1()(64bit) <span class="keyword">for</span> package: conntrack-tools-1.4.4-7.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) <span class="keyword">for</span> package: conntrack-tools-1.4.4-7.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Processing Dependency: libnetfilter_cthelper.so.0()(64bit) <span class="keyword">for</span> package: conntrack-tools-1.4.4-7.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package cri-tools.x86_64 0:1.23.0-0 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package kubernetes-cni.x86_64 0:0.8.7-0 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package socat.x86_64 0:1.7.3.2-2.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Running transaction check</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">Finished Dependency Resolution</span></span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">==================================================================================================================</span><br><span class="line"> Package                             Arch                Version                    Repository               Size</span><br><span class="line">==================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> kubeadm                             x86_64              1.24.0-0                   kubernetes              9.5 M</span><br><span class="line"> kubectl                             x86_64              1.24.0-0                   kubernetes              9.9 M</span><br><span class="line"> kubelet                             x86_64              1.24.0-0                   kubernetes               20 M</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> conntrack-tools                     x86_64              1.4.4-7.el7                base                    187 k</span><br><span class="line"> cri-tools                           x86_64              1.23.0-0                   kubernetes              7.1 M</span><br><span class="line"> kubernetes-cni                      x86_64              0.8.7-0                    kubernetes               19 M</span><br><span class="line"> libnetfilter_cthelper               x86_64              1.0.0-11.el7               base                     18 k</span><br><span class="line"> libnetfilter_cttimeout              x86_64              1.0.0-7.el7                base                     18 k</span><br><span class="line"> libnetfilter_queue                  x86_64              1.0.2-2.el7_2              base                     23 k</span><br><span class="line"> socat                               x86_64              1.7.3.2-2.el7              base                    290 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==================================================================================================================</span><br><span class="line">Install  3 Packages (+7 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 66 M</span><br><span class="line">Installed size: 288 M</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/10): conntrack-tools-1.4.4-7.el7.x86_64.rpm                                             | 187 kB  00:00:00     </span><br><span class="line">(2/10): 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0- | 7.1 MB  00:00:06     </span><br><span class="line">(3/10): dda11ee75bc7fcb01e32512cefb8f686dc6a7383516b8b0828adb33761fe602e-kubeadm-1.24.0-0. | 9.5 MB  00:00:08     </span><br><span class="line">(4/10): 0c7a02e05273d05ea82ca13546853b65fbc257dd159565ce6eb658a0bdf31c9f-kubectl-1.24.0-0. | 9.9 MB  00:00:08     </span><br><span class="line">(5/10): libnetfilter_cthelper-1.0.0-11.el7.x86_64.rpm                                      |  18 kB  00:00:00     </span><br><span class="line">(6/10): socat-1.7.3.2-2.el7.x86_64.rpm                                                     | 290 kB  00:00:00     </span><br><span class="line">(7/10): libnetfilter_queue-1.0.2-2.el7_2.x86_64.rpm                                        |  23 kB  00:00:00     </span><br><span class="line">(8/10): libnetfilter_cttimeout-1.0.0-7.el7.x86_64.rpm                                      |  18 kB  00:00:00     </span><br><span class="line">(9/10): 363f3fbfa8b89bb978e2d089e52ba59847f143834f8ea1b559afa864d8c5c011-kubelet-1.24.0-0. |  20 MB  00:00:17     </span><br><span class="line">(10/10): db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0 |  19 MB  00:00:16     </span><br><span class="line">------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                             2.1 MB/s |  66 MB  00:00:31     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : libnetfilter_cthelper-1.0.0-11.el7.x86_64                                                     1/10 </span><br><span class="line">  Installing : socat-1.7.3.2-2.el7.x86_64                                                                    2/10 </span><br><span class="line">  Installing : libnetfilter_cttimeout-1.0.0-7.el7.x86_64                                                     3/10 </span><br><span class="line">  Installing : cri-tools-1.23.0-0.x86_64                                                                     4/10 </span><br><span class="line">  Installing : kubectl-1.24.0-0.x86_64                                                                       5/10 </span><br><span class="line">  Installing : libnetfilter_queue-1.0.2-2.el7_2.x86_64                                                       6/10 </span><br><span class="line">  Installing : conntrack-tools-1.4.4-7.el7.x86_64                                                            7/10 </span><br><span class="line">  Installing : kubernetes-cni-0.8.7-0.x86_64                                                                 8/10 </span><br><span class="line">  Installing : kubelet-1.24.0-0.x86_64                                                                       9/10 </span><br><span class="line">  Installing : kubeadm-1.24.0-0.x86_64                                                                      10/10 </span><br><span class="line">  Verifying  : conntrack-tools-1.4.4-7.el7.x86_64                                                            1/10 </span><br><span class="line">  Verifying  : kubernetes-cni-0.8.7-0.x86_64                                                                 2/10 </span><br><span class="line">  Verifying  : kubeadm-1.24.0-0.x86_64                                                                       3/10 </span><br><span class="line">  Verifying  : libnetfilter_queue-1.0.2-2.el7_2.x86_64                                                       4/10 </span><br><span class="line">  Verifying  : kubectl-1.24.0-0.x86_64                                                                       5/10 </span><br><span class="line">  Verifying  : cri-tools-1.23.0-0.x86_64                                                                     6/10 </span><br><span class="line">  Verifying  : libnetfilter_cttimeout-1.0.0-7.el7.x86_64                                                     7/10 </span><br><span class="line">  Verifying  : socat-1.7.3.2-2.el7.x86_64                                                                    8/10 </span><br><span class="line">  Verifying  : libnetfilter_cthelper-1.0.0-11.el7.x86_64                                                     9/10 </span><br><span class="line">  Verifying  : kubelet-1.24.0-0.x86_64                                                                      10/10 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  kubeadm.x86_64 0:1.24.0-0            kubectl.x86_64 0:1.24.0-0            kubelet.x86_64 0:1.24.0-0           </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  conntrack-tools.x86_64 0:1.4.4-7.el7                    cri-tools.x86_64 0:1.23.0-0                            </span><br><span class="line">  kubernetes-cni.x86_64 0:0.8.7-0                         libnetfilter_cthelper.x86_64 0:1.0.0-11.el7            </span><br><span class="line">  libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7             libnetfilter_queue.x86_64 0:1.0.2-2.el7_2              </span><br><span class="line">  socat.x86_64 0:1.7.3.2-2.el7                           </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-启动 kubelet 服务并设置开机自启</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# systemctl enable --now kubelet</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service.</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4-4-安装-Container-Runtime-Interface-CRI-CLI-crictl"><a href="#4-4-安装-Container-Runtime-Interface-CRI-CLI-crictl" class="headerlink" title="4.4 安装 Container Runtime Interface (CRI) CLI-crictl"></a>4.4 安装 Container Runtime Interface (CRI) CLI-crictl</h3><blockquote><p><strong>01-安装 crictl</strong></p></blockquote><p><strong>该配置为可选项，仅供参考，二进制安装受限于网络环境有可能安装不成功，建议使用上面安装 kubernetes 时安装的 cri-tools</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">VERSION=&quot;v1.23.0&quot;</span><br><span class="line">curl -L https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$&#123;VERSION&#125;-linux-amd64.tar.gz --output crictl-$&#123;VERSION&#125;-linux-amd64.tar.gz</span><br><span class="line">tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin</span><br><span class="line">rm -f crictl-$VERSION-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-配置 crictl</strong></p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置 runtime-endpoint</span></span><br><span class="line">[<span class="string">root@k8s-master-0</span> <span class="string">~</span>]<span class="comment"># crictl config --set runtime-endpoint=unix:///run/containerd/containerd.sock </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不配置使用默认值，会有下面的报错</span></span><br><span class="line">[<span class="string">root@k8s-master-0</span> <span class="string">~</span>]<span class="comment"># crictl images</span></span><br><span class="line"><span class="string">WARN[0000]</span> <span class="attr">image connect using default endpoints:</span> [<span class="string">unix:///var/run/dockershim.sock</span> <span class="string">unix:///run/containerd/containerd.sock</span> <span class="string">unix:///run/crio/crio.sock</span> <span class="string">unix:///var/run/cri-dockerd.sock</span>]<span class="string">.</span> <span class="string">As</span> <span class="string">the</span> <span class="string">default</span> <span class="string">settings</span> <span class="string">are</span> <span class="string">now</span> <span class="string">deprecated,</span> <span class="string">you</span> <span class="string">should</span> <span class="string">set</span> <span class="string">the</span> <span class="string">endpoint</span> <span class="string">instead.</span> </span><br><span class="line"><span class="string">ERRO[0002]</span> <span class="string">connect</span> <span class="string">endpoint</span> <span class="string">&#x27;unix:///var/run/dockershim.sock&#x27;</span><span class="string">,</span> <span class="attr">make sure you are running as root and the endpoint has been started:</span> <span class="string">context</span> <span class="string">deadline</span> <span class="string">exceeded</span> </span><br><span class="line"><span class="string">IMAGE</span>               <span class="string">TAG</span>                 <span class="string">IMAGE</span> <span class="string">ID</span>            <span class="string">SIZE</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>03-验证测试</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# crictl images</span><br><span class="line">IMAGE               TAG                 IMAGE ID            SIZE</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# crictl pods</span><br><span class="line">POD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIME</span><br></pre></td></tr></table></figure><h3 id="4-5-命令脚本汇总"><a href="#4-5-命令脚本汇总" class="headerlink" title="4.5. 命令脚本汇总"></a>4.5. 命令脚本汇总</h3><p><strong>初始化节点时，可以直接复制执行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-node-common.sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">init</span></span><br><span class="line">swapoff -a</span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">modprobe overlay</span><br><span class="line">modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">containerd</span></span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">yum install containerd.io -y</span><br><span class="line">cp /etc/containerd/config.toml /etc/containerd/config.toml.ori</span><br><span class="line">containerd  config default &gt; /etc/containerd/config.toml</span><br><span class="line">sed -i &#x27;s#k8s.gcr.io#registry.aliyuncs.com/google_containers#g&#x27; /etc/containerd/config.toml</span><br><span class="line">sed -i &#x27;s/SystemdCgroup = false/SystemdCgroup = true/g&#x27; /etc/containerd/config.toml</span><br><span class="line">sed -i &#x27;s#root = &quot;/var/lib/containerd&quot;#root = &quot;/data/containerd&quot;#g&#x27; /etc/containerd/config.toml</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable --now containerd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubernetes</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line">yum install kubelet kubeadm kubectl --nogpgcheck -y</span><br><span class="line">systemctl enable --now kubelet</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Verify</span></span><br><span class="line">crictl config --set runtime-endpoint=unix:///run/containerd/containerd.sock</span><br><span class="line">crictl images</span><br><span class="line">crictl pods</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure><hr><h2 id="5-k8s-单控集群部署"><a href="#5-k8s-单控集群部署" class="headerlink" title="5. k8s 单控集群部署"></a>5. k8s 单控集群部署</h2><h3 id="5-1-采用配置文件初始化集群"><a href="#5-1-采用配置文件初始化集群" class="headerlink" title="5.1. 采用配置文件初始化集群"></a>5.1. 采用配置文件初始化集群</h3><p><strong>可选参考，本文不执行，本文采用命令行直接配置参数执行的方式</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubeadm config print init-defaults &gt; kubeadmn-config.yaml</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 1.2.3.4</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: unix:///var/run/containerd/containerd.sock</span><br><span class="line">  imagePullPolicy: IfNotPresent</span><br><span class="line">  name: node</span><br><span class="line">  taints: null</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: &#123;&#125;</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: k8s.gcr.io</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: 1.24.0</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以使用上面的命令生成一个配置文件，编辑修改后，再执行下面的命令初始化集群</span></span><br><span class="line">kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.log</span><br></pre></td></tr></table></figure><h3 id="5-2-命令行直接配置初始化集群"><a href="#5-2-命令行直接配置初始化集群" class="headerlink" title="5.2. 命令行直接配置初始化集群"></a>5.2. 命令行直接配置初始化集群</h3><blockquote><p><strong>01-初始化集群</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--pod-network-cidr 192.168.0.0/16 使用Calico网络插件的时候需要这么配置，如果跟现有网络冲突，请自行修改。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--image-repository registry.aliyuncs.com/google_containers 受限于网络原因，指定image的仓库地址。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以提前将需要的image使用kubeadm config images pull，下载回来。</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version v1.24.0 --image-repository registry.aliyuncs.com/google_containers</span><br><span class="line">[init] Using Kubernetes version: v1.24.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master-0 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.9.61]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master-0 localhost] and IPs [192.168.9.61 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master-0 localhost] and IPs [192.168.9.61 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 12.504486 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-0 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-0 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: ueiemf.wfjtb2fmaju9dfmb</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.9.61:6443 --token hha3hi.v6g4ggfop3a27nv1 \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:99a69b81a2bc48332ea9e4a1df3645f101a7bbcd0f3a76b9f0a8cba2bb1486fb</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-查看安装后的底层变化</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# crictl images</span><br><span class="line">IMAGE                                                             TAG                 IMAGE ID            SIZE</span><br><span class="line">registry.aliyuncs.com/google_containers/coredns                   v1.8.6              a4ca41631cc7a       13.6MB</span><br><span class="line">registry.aliyuncs.com/google_containers/etcd                      3.5.3-0             aebe758cef4cd       102MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-apiserver            v1.24.0             529072250ccc6       33.8MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-controller-manager   v1.24.0             88784fb4ac2f6       31MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-proxy                v1.24.0             77b49675beae1       39.5MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-scheduler            v1.24.0             e3ed7dee73e93       15.5MB</span><br><span class="line">registry.aliyuncs.com/google_containers/pause                     3.6                 6270bb605e12e       302kB</span><br><span class="line">registry.aliyuncs.com/google_containers/pause                     3.7                 221177c6082a8       311kB</span><br><span class="line">[root@k8s-master-0 ~]# crictl pods</span><br><span class="line">POD ID              CREATED             STATE               NAME                                   NAMESPACE           ATTEMPT             RUNTIME</span><br><span class="line">77c4482fa7d43       28 seconds ago      Ready               kube-proxy-k59zz                       kube-system         0                   (default)</span><br><span class="line">4ece96938cec8       55 seconds ago      Ready               etcd-k8s-master-0                      kube-system         0                   (default)</span><br><span class="line">fc80ca83de6bf       55 seconds ago      Ready               kube-controller-manager-k8s-master-0   kube-system         0                   (default)</span><br><span class="line">a83747a21aa47       55 seconds ago      Ready               kube-scheduler-k8s-master-0            kube-system         0                   (default)</span><br><span class="line">0746ddf45df26       55 seconds ago      Ready               kube-apiserver-k8s-master-0            kube-system         0                   (default)</span><br></pre></td></tr></table></figure><h3 id="5-3-kubectl-管理环境配置"><a href="#5-3-kubectl-管理环境配置" class="headerlink" title="5.3. kubectl 管理环境配置"></a>5.3. kubectl 管理环境配置</h3><blockquote><p><strong>01-配置管理 config</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# mkdir -p $HOME/.kube</span><br><span class="line">[root@k8s-master-0 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">[root@k8s-master-0 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-配置 kubectl Bash 自动补齐</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# yum install bash-completion -y</span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;alias k=kubectl&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;complete -F __start_kubectl k&#x27; &gt;&gt;~/.bashrc</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-验证 kubectl</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# source ~/.bashrc </span><br><span class="line">[root@k8s-master-0 ~]# k get nodes</span><br><span class="line">NAME           STATUS     ROLES           AGE   VERSION</span><br><span class="line">k8s-master-0   NotReady   control-plane   15m   v1.24.0</span><br></pre></td></tr></table></figure><h3 id="5-4-添加-Pod-网络插件-Calico"><a href="#5-4-添加-Pod-网络插件-Calico" class="headerlink" title="5.4. 添加 Pod 网络插件-Calico"></a>5.4. 添加 Pod 网络插件-Calico</h3><blockquote><p><strong>01-安装 Tigera Calico Operator</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl create -f https://projectcalico.docs.tigera.io/manifests/tigera-operator.yaml</span><br><span class="line">namespace/tigera-operator created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/apiservers.operator.tigera.io created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/imagesets.operator.tigera.io created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/installations.operator.tigera.io created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/tigerastatuses.operator.tigera.io created</span><br><span class="line">Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class="line">podsecuritypolicy.policy/tigera-operator created</span><br><span class="line">serviceaccount/tigera-operator created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/tigera-operator created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/tigera-operator created</span><br><span class="line">deployment.apps/tigera-operator created</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-通过创建必要的自定义资源安装 Calico</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl create -f https://projectcalico.docs.tigera.io/manifests/custom-resources.yaml</span><br><span class="line">installation.operator.tigera.io/default created</span><br><span class="line">apiserver.operator.tigera.io/default created</span><br></pre></td></tr></table></figure><p><strong>官方默认 custom-resources.yaml 参考 , 注意 IP 地址范围，如果跟现有环境网络冲突，需要修改配置文件更换地址</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This section includes base Calico installation configuration.</span></span><br><span class="line"><span class="comment"># For more information, see: https://projectcalico.docs.tigera.io/v3.23/reference/installation/api#operator.tigera.io/v1.Installation</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">operator.tigera.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Installation</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># Configures Calico networking.</span></span><br><span class="line">  <span class="attr">calicoNetwork:</span></span><br><span class="line">    <span class="comment"># <span class="doctag">Note:</span> The ipPools section cannot be modified post-install.</span></span><br><span class="line">    <span class="attr">ipPools:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">blockSize:</span> <span class="number">26</span></span><br><span class="line">      <span class="attr">cidr:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line">      <span class="attr">encapsulation:</span> <span class="string">VXLANCrossSubnet</span></span><br><span class="line">      <span class="attr">natOutgoing:</span> <span class="string">Enabled</span></span><br><span class="line">      <span class="attr">nodeSelector:</span> <span class="string">all()</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="comment"># This section configures the Calico API server.</span></span><br><span class="line"><span class="comment"># For more information, see: https://projectcalico.docs.tigera.io/v3.23/reference/installation/api#operator.tigera.io/v1.APIServer</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">operator.tigera.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">APIServer</span> </span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">default</span> </span><br><span class="line"><span class="attr">spec:</span> &#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>03-观察 Pods 创建过程 (默认会失败)</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# watch kubectl get pods -n calico-system</span><br><span class="line"></span><br><span class="line">Every 2.0s: kubectl get pods -n calico-system                                                                      Wed May 18 09:40:53 2022</span><br><span class="line"></span><br><span class="line">NAME                                       READY   STATUS              RESTARTS   AGE</span><br><span class="line">calico-kube-controllers-68884f975d-9x48h   0/1     Pending             0          4s</span><br><span class="line">calico-node-fn4w9                          0/1     Init:0/2            0          4s</span><br><span class="line">calico-typha-86b5ddf878-mtd2v              0/1     ContainerCreating   0          4s</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>04-删除 master 节点的 Taint，保证 calico 相关 pod 能成功创建</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl taint nodes $(hostname) node-role.kubernetes.io/master:NoSchedule-</span><br><span class="line">[root@k8s-master-0 ~]# kubectl taint nodes $(hostname) node-role.kubernetes.io/control-plane:NoSchedule-</span><br></pre></td></tr></table></figure><blockquote><p><strong>05-再次观察 Pods 创建过程</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# watch kubectl get pods -n calico-system</span><br><span class="line"></span><br><span class="line">Every 2.0s: kubectl get pods -n calico-system                                                                      Wed May 18 10:03:30 2022</span><br><span class="line"></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-kube-controllers-68884f975d-9x48h   1/1     Running   0          22m</span><br><span class="line">calico-node-fn4w9                          1/1     Running   0          22m</span><br><span class="line">calico-typha-86b5ddf878-mtd2v              1/1     Running   0          22m</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>06-确认 node 状态</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl get nodes -o wide</span><br><span class="line">NAME           STATUS   ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">k8s-master-0   Ready    control-plane   27m   v1.24.0   192.168.9.61   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   containerd://1.6.4</span><br></pre></td></tr></table></figure><h3 id="5-5-添加-Worker-节点"><a href="#5-5-添加-Worker-节点" class="headerlink" title="5.5. 添加 Worker 节点"></a>5.5. 添加 Worker 节点</h3><blockquote><p><strong>01-参考 &lt;&lt;K8S 节点通用配置 &gt;&gt;，配置 Worker 节点</strong></p></blockquote><p><strong>配置过程略，请参考上文</strong></p><blockquote><p><strong>02-Join 到 k8s 集群</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Join 到集群</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行初始化集群时最后显示的 <span class="built_in">join</span> 命令，如果忘记了可以执行 kubeadm token create --print-join-command --ttl=0 打印出命令</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master-1 ~]# kubeadm join 192.168.9.61:6443 --token hha3hi.v6g4ggfop3a27nv1 \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:99a69b81a2bc48332ea9e4a1df3645f101a7bbcd0f3a76b9f0a8cba2bb1486fb</span><br><span class="line"></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 Join 到集群后，节点的状态</span></span><br><span class="line">[root@k8s-master-1 ~]# crictl images</span><br><span class="line">IMAGE                                                TAG                 IMAGE ID            SIZE</span><br><span class="line">docker.io/calico/cni                                 v3.23.1             90d97aa939bbf       111MB</span><br><span class="line">docker.io/calico/pod2daemon-flexvol                  v3.23.1             01dda8bd1b91e       8.67MB</span><br><span class="line">registry.aliyuncs.com/google_containers/kube-proxy   v1.24.0             77b49675beae1       39.5MB</span><br><span class="line">registry.aliyuncs.com/google_containers/pause        3.6                 6270bb605e12e       302kB</span><br><span class="line"></span><br><span class="line">[root@k8s-master-1 ~]# crictl pods</span><br><span class="line">POD ID              CREATED             STATE               NAME                NAMESPACE           ATTEMPT             RUNTIME</span><br><span class="line">54112207923a3       3 minutes ago       Ready               calico-node-mj5db   calico-system       0                   (default)</span><br><span class="line">58725b6e761da       3 minutes ago       Ready               kube-proxy-fvvjl    kube-system         0                   (default)</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-在 master 节点验证</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl get nodes -o wide</span><br><span class="line">NAME           STATUS   ROLES           AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">k8s-master-0   Ready    control-plane   71m     v1.24.0   192.168.9.61   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   containerd://1.6.4</span><br><span class="line">k8s-master-1   Ready    &lt;none&gt;          2m41s   v1.24.0   192.168.9.62   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   containerd://1.6.4</span><br></pre></td></tr></table></figure><h3 id="5-6-测试验证"><a href="#5-6-测试验证" class="headerlink" title="5.6. 测试验证"></a>5.6. 测试验证</h3><blockquote><p><strong>01-创建测试资源</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建deployment</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl create deployment nginx-test --image=nginx</span><br><span class="line">deployment.apps/nginx-test created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建NodePort类型的服务</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl expose deployment nginx-test --port 80 --target-port=80  --type=NodePort --name=nginx-test-external</span><br><span class="line">service/nginx-test-external exposed</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-验证创建结果</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl get deployment -o wide</span><br><span class="line">NAME         READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES   SELECTOR</span><br><span class="line">nginx-test   1/1     1            1           2m5s   nginx        nginx    app=nginx-test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubectl get pods -o wide</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE   IP              NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-test-847f5bc47c-n9dpw   1/1     Running   0          6s    192.168.196.2   k8s-master-1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# curl 192.168.196.2</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">html &#123; color-scheme: light dark; &#125;</span><br><span class="line">body &#123; width: 35em; margin: 0 auto;</span><br><span class="line">font-family: Tahoma, Verdana, Arial, sans-serif; &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class="line">working. Further configuration is required.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;For online documentation and support please refer to</span><br><span class="line">&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span><br><span class="line">Commercial support is available at</span><br><span class="line">&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubectl get svc -o wide</span><br><span class="line">NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span><br><span class="line">kubernetes            ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        91m   &lt;none&gt;</span><br><span class="line">nginx-test-external   NodePort    10.105.107.17   &lt;none&gt;        80:31632/TCP   64s   app=nginx-test</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试集群内部和集群外部服务访问，显示结果是一致的。</span></span><br><span class="line">[root@k8s-master-0 ~]# curl 10.105.107.17</span><br><span class="line">[root@k8s-master-0 ~]# curl 192.168.9.62:31632</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">html &#123; color-scheme: light dark; &#125;</span><br><span class="line">body &#123; width: 35em; margin: 0 auto;</span><br><span class="line">font-family: Tahoma, Verdana, Arial, sans-serif; &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class="line">working. Further configuration is required.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;For online documentation and support please refer to</span><br><span class="line">&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span><br><span class="line">Commercial support is available at</span><br><span class="line">&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="5-7-命令脚本汇总"><a href="#5-7-命令脚本汇总" class="headerlink" title="5.7. 命令脚本汇总"></a>5.7. 命令脚本汇总</h3><blockquote><p><strong>K8s-master.sh</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">K8s-master.sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubeadm-init.sh</span></span><br><span class="line">kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version v1.24.0 --image-repository registry.aliyuncs.com/google_containers</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kube config</span></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">yum install bash-completion -y</span><br><span class="line">echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">echo &#x27;alias k=kubectl&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">echo &#x27;complete -F __start_kubectl k&#x27; &gt;&gt;~/.bashrc</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Calico</span></span><br><span class="line">kubectl create -f https://projectcalico.docs.tigera.io/manifests/tigera-operator.yaml</span><br><span class="line">kubectl create -f https://projectcalico.docs.tigera.io/manifests/custom-resources.yaml</span><br><span class="line">kubectl taint nodes $(hostname) node-role.kubernetes.io/master:NoSchedule-</span><br><span class="line">kubectl taint nodes $(hostname) node-role.kubernetes.io/control-plane:NoSchedule-</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证</span></span><br><span class="line">kubectl get nodes -o wide</span><br></pre></td></tr></table></figure><blockquote><p><strong>K8s-worker.sh</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加入集群，下面的是示例，请用init时的实际语句替换</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubeadm <span class="built_in">join</span> 192.168.9.61:6443 --token hha3hi.v6g4ggfop3a27nv1 \</span></span><br><span class="line"><span class="language-bash">        --discovery-token-ca-cert-hash sha256:99a69b81a2bc48332ea9e4a1df3645f101a7bbcd0f3a76b9f0a8cba2bb1486fb</span></span><br></pre></td></tr></table></figure><hr><h2 id="6-K8S-高可用集群部署"><a href="#6-K8S-高可用集群部署" class="headerlink" title="6. K8S 高可用集群部署"></a>6. K8S 高可用集群部署</h2><h3 id="6-1-高可用方案选型"><a href="#6-1-高可用方案选型" class="headerlink" title="6.1. 高可用方案选型"></a>6.1. 高可用方案选型</h3><blockquote><p><strong>01-实验环境采用 Kubernetes 官方介绍的方案 <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/">Kubeadm HA topology - stacked etcd</a></strong></p></blockquote><p><img src="https://znotes-1258881081.cos.ap-beijing.myqcloud.com/k8s-on-kubesphere/kubeadm-ha-topology-stacked-etcd.svg" alt="kubeadm-ha-topology-stacked-etcd"></p><blockquote><p><strong>02-Load Balancer 选择 <a href="https://github.com/kubernetes/kubeadm/blob/main/docs/ha-considerations.md#options-for-software-load-balancing">官方方案</a> 中的 kube-vip</strong></p></blockquote><h3 id="6-2-初始化集群节点"><a href="#6-2-初始化集群节点" class="headerlink" title="6.2. 初始化集群节点"></a>6.2. 初始化集群节点</h3><p><strong>参考 &lt;&lt;k8s 服务器初始化 &gt;&gt; 和 &lt;&lt; K8S 节点通用配置 &gt;&gt;，配置所有节点。</strong></p><h3 id="6-3-kube-vip-安装配置-静态-pod"><a href="#6-3-kube-vip-安装配置-静态-pod" class="headerlink" title="6.3. kube-vip 安装配置 (静态 pod)"></a>6.3. kube-vip 安装配置 (静态 pod)</h3><p><strong>所有 master 节点 (control-plane) 配置</strong></p><blockquote><p><strong>01-生成 Manifest(ARP)</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">INTERFACE=ens160 网卡名称需要根据实际环境替换</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">KVVERSION=v0.4.4 kube-vip 版本</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">VIP=192.168.9.60 VIP 需要根据实际环境替换</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">alias</span> kube-vip=<span class="string">&quot;ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:<span class="variable">$KVVERSION</span> vip /kube-vip&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r <span class="string">&quot;.[0].name&quot;</span>)</span></span><br><span class="line">[root@k8s-master-0 ~]# export KVVERSION=v0.4.4</span><br><span class="line">[root@k8s-master-0 ~]# export VIP=192.168.9.60</span><br><span class="line">[root@k8s-master-0 ~]# export INTERFACE=ens160</span><br><span class="line">[root@k8s-master-0 ~]# ctr image pull docker.io/plndr/kube-vip:$KVVERSION</span><br><span class="line">docker.io/plndr/kube-vip:v0.4.4:                                                  resolved       |++++++++++++++++++++++++++++++++++++++| </span><br><span class="line">index-sha256:f59745f64f8e02158bc5aa70fb24e123e3f3891ca9bb86f8c259076e41a81924:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class="line">manifest-sha256:6c06a1a6c917afb9cfbd5c3e8714c941037bcd0b461e7ef2f21203c9cd22b713: exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class="line">layer-sha256:53dcb733c4018ed99b211857fdf656f8ab22a07ffbd6b5cc9974d95c200749a3:    done           |++++++++++++++++++++++++++++++++++++++| </span><br><span class="line">config-sha256:10a711aa9888db2d9173101453ad14aa0b9b4b256486620a6e3de90b1751365b:   exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class="line">layer-sha256:1ff217c64e92386b9d908ccc8978aa472db7eb1b1ffa4cb7abc33eecf799210b:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class="line">elapsed: 9.8 s                                                                    total:  11.7 M (1.2 MiB/s)                                       </span><br><span class="line">unpacking linux/amd64 sha256:f59745f64f8e02158bc5aa70fb24e123e3f3891ca9bb86f8c259076e41a81924...</span><br><span class="line">done: 1.012189313s</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# alias kube-vip=&quot;ctr run --rm --net-host docker.io/plndr/kube-vip:$KVVERSION vip /kube-vip&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在终端命令行执行</span></span><br><span class="line">kube-vip manifest pod \</span><br><span class="line">    --interface $INTERFACE \</span><br><span class="line">    --vip $VIP \</span><br><span class="line">    --controlplane \</span><br><span class="line">    --services \</span><br><span class="line">    --arp \</span><br><span class="line">    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  name: kube-vip</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - args:</span><br><span class="line">    - manager</span><br><span class="line">    env:</span><br><span class="line">    - name: vip_arp</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: port</span><br><span class="line">      value: &quot;6443&quot;</span><br><span class="line">    - name: vip_interface</span><br><span class="line">      value: ens160</span><br><span class="line">    - name: vip_cidr</span><br><span class="line">      value: &quot;32&quot;</span><br><span class="line">    - name: cp_enable</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: cp_namespace</span><br><span class="line">      value: kube-system</span><br><span class="line">    - name: vip_ddns</span><br><span class="line">      value: &quot;false&quot;</span><br><span class="line">    - name: svc_enable</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: vip_leaderelection</span><br><span class="line">      value: &quot;true&quot;</span><br><span class="line">    - name: vip_leaseduration</span><br><span class="line">      value: &quot;5&quot;</span><br><span class="line">    - name: vip_renewdeadline</span><br><span class="line">      value: &quot;3&quot;</span><br><span class="line">    - name: vip_retryperiod</span><br><span class="line">      value: &quot;1&quot;</span><br><span class="line">    - name: vip_address</span><br><span class="line">      value: 192.168.9.60</span><br><span class="line">    image: ghcr.io/kube-vip/kube-vip:v0.4.4</span><br><span class="line">    imagePullPolicy: Always</span><br><span class="line">    name: kube-vip</span><br><span class="line">    resources: &#123;&#125;</span><br><span class="line">    securityContext:</span><br><span class="line">      capabilities:</span><br><span class="line">        add:</span><br><span class="line">        - NET_ADMIN</span><br><span class="line">        - NET_RAW</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /etc/kubernetes/admin.conf</span><br><span class="line">      name: kubeconfig</span><br><span class="line">  hostAliases:</span><br><span class="line">  - hostnames:</span><br><span class="line">    - kubernetes</span><br><span class="line">    ip: 127.0.0.1</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  volumes:</span><br><span class="line">  - hostPath:</span><br><span class="line">      path: /etc/kubernetes/admin.conf</span><br><span class="line">    name: kubeconfig</span><br><span class="line">status: &#123;&#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-验证</strong></p></blockquote><p><strong>刚配置完静态 pod 并不会创建，等 k8s 集群 init 以后才会有类似下面的输出</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看ens160网卡配置</span></span><br><span class="line">[root@k8s-master-0 ~]# ip add show ens160</span><br><span class="line">2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link/ether 00:50:56:85:67:89 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.9.61/24 brd 192.168.9.255 scope global noprefixroute ens160</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 192.168.9.60/32 scope global ens160</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::250:56ff:fe85:6789/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看pod</span></span><br><span class="line">[root@k8s-master-0 ~]# crictl pods | grep kube-vip</span><br><span class="line">0158385d6d14a       3 minutes ago       Ready               kube-vip-k8s-master-0                  kube-system         0                   (default)</span><br></pre></td></tr></table></figure><h3 id="6-4-初始化-k8s-集群"><a href="#6-4-初始化-k8s-集群" class="headerlink" title="6.4. 初始化 k8s 集群"></a>6.4. 初始化 k8s 集群</h3><p><strong>第一个 master 节点 (control-plane) 配置</strong></p><blockquote><p><strong>01-初始化集群</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--pod-network-cidr 192.168.0.0/16 使用Calico网络插件的时候需要这么配置，如果跟现有网络冲突，请自行修改。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--image-repository 受限于网络原因，指定image的仓库地址。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以提前将需要的image使用kubeadm config images pull，下载回来。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--control-plane-endpoint <span class="string">&quot;192.168.9.60:6443&quot;</span> kube-vip配置的vip地址和6443端口</span></span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version v1.24.0 --image-repository registry.aliyuncs.com/google_containers --control-plane-endpoint &quot;192.168.9.60:6443&quot; --upload-certs</span><br><span class="line">[init] Using Kubernetes version: v1.24.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master-0 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.9.61 192.168.9.60]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master-0 localhost] and IPs [192.168.9.61 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master-0 localhost] and IPs [192.168.9.61 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 14.017737 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[upload-certs] Using certificate key:</span><br><span class="line">b32dc2ad50700e4b6b55da7d07725bc439f28abe107a35b5d5acd215bace4224</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-0 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-0 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: b2oizh.k4xs41xkvn4vze4o</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.9.60:6443 --token b2oizh.k4xs41xkvn4vze4o \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:66aa526cdfbfee2d3fe523d4bec97cf00fca644f55565e104ccc8b456cd2dba0 \</span><br><span class="line">        --control-plane --certificate-key b32dc2ad50700e4b6b55da7d07725bc439f28abe107a35b5d5acd215bace4224</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class="line">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.9.60:6443 --token b2oizh.k4xs41xkvn4vze4o \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:66aa526cdfbfee2d3fe523d4bec97cf00fca644f55565e104ccc8b456cd2dba0 </span><br><span class="line">[root@k8s-master-0 ~]# </span><br></pre></td></tr></table></figure><h3 id="6-5-kubectl-管理环境配置"><a href="#6-5-kubectl-管理环境配置" class="headerlink" title="6.5. kubectl 管理环境配置"></a>6.5. kubectl 管理环境配置</h3><p><strong>第一个 master 节点 (control-plane) 配置</strong></p><blockquote><p><strong>01-配置管理 config</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# mkdir -p $HOME/.kube</span><br><span class="line">[root@k8s-master-0 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">[root@k8s-master-0 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-配置 kubectl Bash 自动补齐</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# yum install bash-completion -y</span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;alias k=kubectl&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">[root@k8s-master-0 ~]# echo &#x27;complete -F __start_kubectl k&#x27; &gt;&gt;~/.bashrc</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-验证 kubectl</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# source ~/.bashrc </span><br><span class="line">[root@k8s-master-0 ~]# k get nodes</span><br><span class="line">NAME           STATUS     ROLES           AGE   VERSION</span><br><span class="line">k8s-master-0   NotReady   control-plane   15m   v1.24.0</span><br></pre></td></tr></table></figure><h3 id="6-6-添加-Pod-网络插件-Calico"><a href="#6-6-添加-Pod-网络插件-Calico" class="headerlink" title="6.6. 添加 Pod 网络插件-Calico"></a>6.6. 添加 Pod 网络插件-Calico</h3><p><strong>第一个 master 节点 (control-plane) 配置</strong></p><blockquote><p><strong>01-安装 Tigera Calico Operator</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl create -f https://projectcalico.docs.tigera.io/manifests/tigera-operator.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>02-通过创建必要的自定义资源安装 Calico</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl create -f https://projectcalico.docs.tigera.io/manifests/custom-resources.yaml</span><br><span class="line">installation.operator.tigera.io/default created</span><br><span class="line">apiserver.operator.tigera.io/default created</span><br></pre></td></tr></table></figure><p><strong>官方默认 custom-resources.yaml 参考 , 注意 IP 地址范围，如果跟现有环境网络冲突，需要修改配置文件更换地址</strong></p><blockquote><p><strong>03-删除 master 节点的 Taint，保证 calico 相关 pod 能成功创建。</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl taint nodes $(hostname) node-role.kubernetes.io/master:NoSchedule-</span><br><span class="line">[root@k8s-master-0 ~]# kubectl taint nodes $(hostname) node-role.kubernetes.io/control-plane:NoSchedule-</span><br></pre></td></tr></table></figure><blockquote><p><strong>04-确认 node 状态</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl get nodes -o wide</span><br><span class="line">NAME           STATUS   ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">k8s-master-0   Ready    control-plane   27m   v1.24.0   192.168.9.61   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1160.59.1.el7.x86_64   containerd://1.6.4</span><br></pre></td></tr></table></figure><h3 id="6-7-添加其他控制平面-master-节点"><a href="#6-7-添加其他控制平面-master-节点" class="headerlink" title="6.7. 添加其他控制平面 (master) 节点"></a>6.7. 添加其他控制平面 (master) 节点</h3><blockquote><p><strong>01-参考 6.3 配置 kube-vip</strong></p></blockquote><blockquote><p><strong>02-添加 control-plane node</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以 k8s-master-1 演示</span></span><br><span class="line">[root@k8s-master-1 ~]# kubeadm join 192.168.9.60:6443 --token b2oizh.k4xs41xkvn4vze4o \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:66aa526cdfbfee2d3fe523d4bec97cf00fca644f55565e104ccc8b456cd2dba0 \</span><br><span class="line">        --control-plane --certificate-key 048fde800500bc200995e57f447e71a6f5aebf525f6b21c3d1e1be5cd7bd280b</span><br><span class="line"></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &#x27;kubeadm config images pull&#x27;</span><br><span class="line">[download-certs] Downloading the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [k8s-master-2 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.9.62 192.168.9.60]</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [k8s-master-2 localhost] and IPs [192.168.9.62 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [k8s-master-2 localhost] and IPs [192.168.9.62 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[check-etcd] Checking that the etcd cluster is healthy</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[etcd] Announced new etcd member joining to the existing etcd cluster</span><br><span class="line">[etcd] Creating static Pod manifest for &quot;etcd&quot;</span><br><span class="line">[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s</span><br><span class="line">The &#x27;update-status&#x27; phase is deprecated and will be removed in a future release. Currently it performs no operation</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-2 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]</span><br><span class="line">[mark-control-plane] Marking the node k8s-master-2 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">        mkdir -p $HOME/.kube</span><br><span class="line">        sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">        sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; to see this node join the cluster.</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-certificates 过期的处理方法 (可选，非必需)</strong></p></blockquote><p><strong>如果不是在初始化集群后立刻添加的其他 master 节点，certificates key 会过期，采用下面的命令获取新 key</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubeadm init phase upload-certs --upload-certs</span><br><span class="line">[upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[upload-certs] Using certificate key:</span><br><span class="line">048fde800500bc200995e57f447e71a6f5aebf525f6b21c3d1e1be5cd7bd280b</span><br></pre></td></tr></table></figure><h3 id="6-8-添加-Worker-节点"><a href="#6-8-添加-Worker-节点" class="headerlink" title="6.8. 添加 Worker 节点"></a>6.8. 添加 Worker 节点</h3><blockquote><p><strong>01-添加 worker node</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以 k8s-worker-0 演示</span></span><br><span class="line">[root@k8s-worker-0 ~]# kubeadm join 192.168.9.60:6443 --token b2oizh.k4xs41xkvn4vze4o \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:66aa526cdfbfee2d3fe523d4bec97cf00fca644f55565e104ccc8b456cd2dba0 </span><br><span class="line"></span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure><h3 id="6-9-测试验证"><a href="#6-9-测试验证" class="headerlink" title="6.9. 测试验证"></a>6.9. 测试验证</h3><blockquote><p><strong>01-查看 nodes</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# k get nodes</span><br><span class="line">NAME           STATUS   ROLES           AGE     VERSION</span><br><span class="line">k8s-master-0   Ready    control-plane   15h     v1.24.0</span><br><span class="line">k8s-master-1   Ready    control-plane   14m     v1.24.0</span><br><span class="line">k8s-master-2   Ready    control-plane   10m     v1.24.0</span><br><span class="line">k8s-worker-0   Ready    &lt;none&gt;          3m22s   v1.24.0</span><br></pre></td></tr></table></figure><blockquote><p><strong>02-创建测试资源</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建deployment</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl create deployment nginx-test --image=nginx</span><br><span class="line">deployment.apps/nginx-test created</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建NodePort类型的服务</span></span><br><span class="line">[root@k8s-master-0 ~]# kubectl expose deployment nginx-test --port 80 --target-port=80  --type=NodePort --name=nginx-test-external</span><br><span class="line">service/nginx-test-external exposed</span><br></pre></td></tr></table></figure><blockquote><p><strong>03-验证创建结果</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# kubectl get deployment -o wide</span><br><span class="line">NAME         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR</span><br><span class="line">nginx-test   0/1     1            0           14s   nginx        nginx    app=nginx-test</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubectl get pods -o wide</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-test-847f5bc47c-9t77b   1/1     Running   0          34s   192.168.29.129   k8s-worker-0   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">[root@k8s-master-0 ~]# kubectl get svc -o wide</span><br><span class="line">NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span><br><span class="line">kubernetes            ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        15h   &lt;none&gt;</span><br><span class="line">nginx-test-external   NodePort    10.97.202.183   &lt;none&gt;        80:32617/TCP   52s   app=nginx-test</span><br></pre></td></tr></table></figure><blockquote><p><strong>04-查看 etcd 状态</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-0 ~]# crictl exec `crictl ps | grep etcd | awk &#x27;&#123;print $1&#125;&#x27;` etcdctl --cert /etc/kubernetes/pki/etcd/peer.crt --key /etc/kubernetes/pki/etcd/peer.key --cacert /etc/kubernetes/pki/etcd/ca.crt --endpoints https://192.168.9.61:2379 endpoint health --cluster</span><br><span class="line">https://192.168.9.61:2379 is healthy: successfully committed proposal: took = 27.310514ms</span><br><span class="line">https://192.168.9.63:2379 is healthy: successfully committed proposal: took = 34.384575ms</span><br><span class="line">https://192.168.9.62:2379 is healthy: successfully committed proposal: took = 35.74179ms</span><br></pre></td></tr></table></figure><h3 id="6-10-命令脚本汇总"><a href="#6-10-命令脚本汇总" class="headerlink" title="6.10. 命令脚本汇总"></a>6.10. 命令脚本汇总</h3><blockquote><p><strong>K8s-master-first.sh</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">K8s-master-first.sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kube-vip</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r <span class="string">&quot;.[0].name&quot;</span>)</span></span><br><span class="line">export KVVERSION=v0.4.4</span><br><span class="line">export VIP=192.168.9.60</span><br><span class="line">export INTERFACE=ens160</span><br><span class="line">ctr image pull docker.io/plndr/kube-vip:$KVVERSION</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">alias</span> kube-vip=<span class="string">&quot;ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:<span class="variable">$KVVERSION</span> vip /kube-vip&quot;</span></span></span><br><span class="line">alias kube-vip=&quot;ctr run --rm --net-host docker.io/plndr/kube-vip:$KVVERSION vip /kube-vip&quot;</span><br><span class="line">kube-vip manifest pod \</span><br><span class="line">    --interface $INTERFACE \</span><br><span class="line">    --vip $VIP \</span><br><span class="line">    --controlplane \</span><br><span class="line">    --services \</span><br><span class="line">    --arp \</span><br><span class="line">    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubeadm init</span></span><br><span class="line">kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version v1.24.0 --image-repository registry.aliyuncs.com/google_containers --control-plane-endpoint &quot;192.168.9.60:6443&quot; --upload-certs</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kube config</span></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">yum install bash-completion -y</span><br><span class="line">echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">echo &#x27;alias k=kubectl&#x27; &gt;&gt;~/.bashrc</span><br><span class="line">echo &#x27;complete -F __start_kubectl k&#x27; &gt;&gt;~/.bashrc</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Calico</span></span><br><span class="line">kubectl create -f https://projectcalico.docs.tigera.io/manifests/tigera-operator.yaml</span><br><span class="line">kubectl create -f https://projectcalico.docs.tigera.io/manifests/custom-resources.yaml</span><br><span class="line">kubectl taint nodes $(hostname) node-role.kubernetes.io/master:NoSchedule-</span><br><span class="line">kubectl taint nodes $(hostname) node-role.kubernetes.io/control-plane:NoSchedule-</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证</span></span><br><span class="line">kubectl get nodes -o wide</span><br></pre></td></tr></table></figure><blockquote><p><strong>K8s-master-other.sh</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">K8s-master-other.sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kube-vip</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">KVVERSION=$(curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r <span class="string">&quot;.[0].name&quot;</span>)</span></span><br><span class="line">export KVVERSION=v0.4.4</span><br><span class="line">export VIP=192.168.9.60</span><br><span class="line">export INTERFACE=ens160</span><br><span class="line">ctr image pull docker.io/plndr/kube-vip:$KVVERSION</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">alias</span> kube-vip=<span class="string">&quot;ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:<span class="variable">$KVVERSION</span> vip /kube-vip&quot;</span></span></span><br><span class="line">alias kube-vip=&quot;ctr run --rm --net-host docker.io/plndr/kube-vip:$KVVERSION vip /kube-vip&quot;</span><br><span class="line">kube-vip manifest pod \</span><br><span class="line">    --interface $INTERFACE \</span><br><span class="line">    --vip $VIP \</span><br><span class="line">    --controlplane \</span><br><span class="line">    --services \</span><br><span class="line">    --arp \</span><br><span class="line">    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加入集群，下面的是示例，请用init时的实际语句替换</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kubeadm <span class="built_in">join</span> 192.168.9.60:6443 --token fghmf1.zl29bwrlg8brcop8 \</span></span><br><span class="line"><span class="language-bash"><span class="comment">#        --discovery-token-ca-cert-hash sha256:045747aa25253136f686daa6fca94985a4482ca39f568abbe36ee0dec55c48a7 \</span></span></span><br><span class="line"><span class="language-bash"><span class="comment">#        --control-plane --certificate-key 35f6367feafc6755a7ab72b8a2f03321ac2545937d45ea84650de3a8835e341e</span></span></span><br></pre></td></tr></table></figure><blockquote><p><strong>K8s-worker.sh</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加入集群，下面的是示例，请用init时的实际语句替换</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kubeadm <span class="built_in">join</span> 192.168.9.60:6443 --token b2oizh.k4xs41xkvn4vze4o \</span></span><br><span class="line"><span class="language-bash"><span class="comment">#        --discovery-token-ca-cert-hash sha256:66aa526cdfbfee2d3fe523d4bec97cf00fca644f55565e104ccc8b456cd2dba0</span></span> </span><br></pre></td></tr></table></figure><hr><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>本文详细展示了 Kubernetes1.24 使用 Containerd 部署单 Master 和三 Master 集群的部署过程，仅供读者在学习测试环境使用。</p><hr><blockquote><p><strong>参考文档</strong></p></blockquote><ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">Getting started &#x2F; Production environment &#x2F; Container runtimes</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/">Getting started &#x2F; Production environment &#x2F; Installing Kubernetes with deployment tools</a></li><li><a href="https://github.com/kubernetes-sigs/cri-tools/blob/master/docs/crictl.md">https://github.com/kubernetes-sigs/cri-tools/blob/master/docs/crictl.md</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</a></li><li><a href="https://kube-vip.chipzoller.dev/docs/installation/static/">https://kube-vip.chipzoller.dev/docs/installation/static/</a></li></ul><blockquote><p><strong>Get 文档</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/z-notes">https://github.com/devops/z-notes</a></li><li>Gitee <a href="https://gitee.com/zdevops/z-notes">https://gitee.com/zdevops/z-notes</a></li></ul><blockquote><p><strong>Get 代码</strong></p></blockquote><ul><li>Github <a href="https://github.com/devops/ansible-zdevops">https://github.com/devops/ansible-zdevops</a></li><li>Gitee <a href="https://gitee.com/zdevops/ansible-zdevops">https://gitee.com/zdevops/ansible-zdevops</a></li></ul><blockquote><p><strong>B 站</strong></p></blockquote><ul><li><a href="https://space.bilibili.com/1039301316">老 Z 手记</a> <a href="https://space.bilibili.com/1039301316">https://space.bilibili.com/1039301316</a></li></ul><blockquote><p><strong>版权声明</strong> </p></blockquote><ul><li>所有内容均属于原创，整理不易，感谢收藏，转载请标明出处。</li></ul><blockquote><p><strong>About Me</strong></p></blockquote><ul><li>昵称：老 Z</li><li>坐标：山东济南</li><li>职业：运维架构师 &#x2F; 高级运维工程师 &#x3D;<strong>运维</strong></li><li>微信：zdevops</li><li>关注的领域：云计算 &#x2F; 云原生技术运维，自动化运维</li><li>技能标签：OpenStack、Ansible、K8S、Python、Go、CNCF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Kubernetes-v1-24-安装手记&quot;&gt;&lt;a href=&quot;#Kubernetes-v1-24-安装手记&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes v1.24 安装手记&quot;&gt;&lt;/a&gt;Kubernetes v1.24 安装手记&lt;/</summary>
      
    
    
    
    <category term="运维" scheme="https://lhhxs.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="k8s" scheme="https://lhhxs.github.io/tags/k8s/"/>
    
    <category term="kubesphere" scheme="https://lhhxs.github.io/tags/kubesphere/"/>
    
  </entry>
  
</feed>
